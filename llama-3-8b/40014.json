{
  "index": 40014,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.354,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.375,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            "ing",
            " to",
            " a",
            " body",
            " that",
            " reflects",
            " all",
            " incident",
            " radiation",
            ").",
            "Surface",
            " al",
            "bedo",
            " is",
            " defined",
            " as",
            " the",
            " ratio",
            " of",
            " radi",
            "osity",
            " Je",
            " to",
            " the",
            " irradi",
            "ance",
            " E",
            "e",
            " (",
            "flux",
            " per",
            " unit",
            " area",
            ")",
            " received",
            " by",
            " a",
            " surface",
            ".",
            " The",
            " proportion",
            " reflected",
            " is",
            " not",
            " only",
            " determined",
            " by",
            " properties",
            " of",
            " the",
            " surface",
            " itself",
            ",",
            " but",
            " also",
            " by",
            " the",
            " spectral",
            " and",
            " angular",
            " distribution",
            " of",
            " solar"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.496,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 39,
          "is_repeated_datapoint": false,
          "tokens": [
            " unstable",
            " in",
            " pitch",
            ",",
            " roll",
            ",",
            " and",
            " yaw",
            ".",
            " Pitch",
            " and",
            " yaw",
            " st",
            "abilities",
            " of",
            " conventional",
            " fixed",
            " wing",
            " designs",
            " require",
            " horizontal",
            " and",
            " vertical",
            " stabil",
            "isers",
            ",",
            " which",
            " act",
            " similarly",
            " to",
            " the",
            " feathers",
            " on",
            " an",
            " arrow",
            ".",
            " These",
            " stabil",
            "izing",
            " surfaces",
            " allow",
            " equilibrium",
            " of",
            " aer",
            "odynamic",
            " forces",
            " and",
            " to",
            " stabil",
            "ise",
            " the",
            " flight",
            " dynamics",
            " of",
            " pitch",
            " and",
            " yaw",
            ".",
            " They",
            " are",
            " usually",
            " mounted",
            " on"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.494,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            "atl",
            "antic",
            " crossing",
            " South",
            " Atlantic",
            " Peace",
            " and",
            " Cooperation",
            " Zone",
            " Atlantic",
            " Rev",
            "olutions",
            " Natural",
            " del",
            "imit",
            "ation",
            " between",
            " the",
            " Pacific",
            " and",
            " South",
            " Atlantic",
            " oceans",
            " by",
            " the",
            " Scotia",
            " Arc",
            "References",
            "Sources",
            " ",
            "  ",
            "  ",
            "  ",
            "   ",
            "  ",
            "  ",
            "  ",
            "  ",
            "  ",
            "  ",
            "  ",
            "  ",
            "  ",
            "  ",
            " ",
            " map",
            "Further",
            " reading",
            "External",
            " links",
            " ",
            " Atlantic",
            " Ocean",
            ".",
            " Cart",
            "age"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.494,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            " uptake",
            " to",
            " the",
            " liver",
            " depends",
            " on",
            " the",
            " individual",
            " and",
            " increases",
            " with",
            " age",
            ".",
            " In",
            " the",
            " bones",
            ",",
            " americ",
            "ium",
            " is",
            " first",
            " deposited",
            " over",
            " cortical",
            " and",
            " trab",
            "ec",
            "ular",
            " surfaces",
            " and",
            " slowly",
            " redistrib",
            "utes",
            " over",
            " the",
            " bone",
            " with",
            " time",
            ".",
            " The",
            " biological",
            " half",
            "-life",
            " of",
            " ",
            "241",
            "Am",
            " is",
            " ",
            "50",
            " years",
            " in",
            " the",
            " bones",
            " and",
            " ",
            "20",
            " years",
            " in",
            " the",
            " liver",
            ",",
            " whereas"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.492,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 29,
          "is_repeated_datapoint": false,
          "tokens": [
            " suggests",
            " most",
            " of",
            " the",
            " color",
            " change",
            " occurs",
            " rapidly",
            ",",
            " in",
            " the",
            " first",
            " hundred",
            " thousand",
            " years",
            ",",
            " limiting",
            " the",
            " usefulness",
            " of",
            " spectral",
            " measurement",
            " for",
            " determining",
            " the",
            " age",
            " of",
            " asteroids",
            ".",
            "Surface",
            " features",
            " ",
            "Except",
            " for",
            " the",
            " \"",
            "big",
            " four",
            "\"",
            " (",
            "C",
            "eres",
            ",",
            " P",
            "allas",
            ",",
            " V",
            "esta",
            ",",
            " and",
            " Hy",
            "gie",
            "a",
            "),",
            " asteroids",
            " are",
            " likely",
            " to",
            " be",
            " broadly",
            " similar",
            " in",
            " appearance"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.49,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 49,
          "is_repeated_datapoint": false,
          "tokens": [
            "-b",
            "urn",
            " def",
            "orestation",
            ",",
            " an",
            " element",
            " of",
            " shifting",
            " cultivation",
            " practiced",
            " by",
            " many",
            " natives",
            ".",
            "See",
            " also",
            " Development",
            " eas",
            "ement",
            " Land",
            " use",
            " statistics",
            " by",
            " country",
            " List",
            " of",
            " environment",
            " topics",
            " Soil",
            " fertility",
            "References",
            "External",
            " links",
            " Article",
            " from",
            " Techn",
            "or",
            "ati",
            " on",
            " Shr",
            "inking",
            " Ar",
            "able",
            " Far",
            "mland",
            " in",
            " the",
            " world",
            " Surface",
            " area",
            " of",
            " the",
            " Earth"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.49,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 49,
          "is_repeated_datapoint": false,
          "tokens": [
            "-b",
            "urn",
            " def",
            "orestation",
            ",",
            " an",
            " element",
            " of",
            " shifting",
            " cultivation",
            " practiced",
            " by",
            " many",
            " natives",
            ".",
            "See",
            " also",
            " Development",
            " eas",
            "ement",
            " Land",
            " use",
            " statistics",
            " by",
            " country",
            " List",
            " of",
            " environment",
            " topics",
            " Soil",
            " fertility",
            "References",
            "External",
            " links",
            " Article",
            " from",
            " Techn",
            "or",
            "ati",
            " on",
            " Shr",
            "inking",
            " Ar",
            "able",
            " Far",
            "mland",
            " in",
            " the",
            " world",
            " Surface",
            " area",
            " of",
            " the",
            " Earth"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.488,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " brothers",
            " gave",
            " up",
            ".",
            " There",
            " was",
            " no",
            " communication",
            ".\"",
            " He",
            " supported",
            " Herm",
            "ann",
            ",",
            " his",
            " brother",
            ",",
            " financially",
            " after",
            " the",
            " war",
            ".",
            " However",
            ",",
            " his",
            " other",
            " brother",
            " Ernst",
            " had",
            " died",
            " in",
            " the",
            " Battle",
            " of",
            " St",
            "aling",
            "rad",
            ",",
            " despite",
            " repeated",
            " requests",
            " from",
            " his",
            " parents",
            " for",
            " Spe",
            "er",
            " to",
            " rep",
            "atri",
            "ate",
            " him",
            ".",
            "Following",
            " his",
            " release",
            " from",
            " Sp",
            "and",
            "au",
            ",",
            " Spe"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.486,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " scientists",
            " at",
            " Berkeley",
            " and",
            " Dub",
            "na",
            ",",
            " included",
            " bombard",
            "ment",
            " of",
            " ",
            "243",
            "Am",
            " with",
            " ",
            "18",
            "O",
            ".",
            "S",
            "pect",
            "rometer",
            "Americ",
            "ium",
            "-",
            "241",
            " has",
            " been",
            " used",
            " as",
            " a",
            " portable",
            " source",
            " of",
            " both",
            " gamma",
            " rays",
            " and",
            " alpha",
            " particles",
            " for",
            " a",
            " number",
            " of",
            " medical",
            " and",
            " industrial",
            " uses",
            ".",
            " The",
            " ",
            "59",
            ".",
            "540",
            "9",
            "Âł",
            "ke",
            "V",
            " gamma",
            " ray",
            " emissions",
            " from"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.484,
            -0.0,
            -0.0
          ],
          "train_token_ind": 60,
          "is_repeated_datapoint": false,
          "tokens": [
            " gamma",
            " radiation",
            " did",
            " not",
            " impact",
            " the",
            " rodents",
            "'",
            " intellectual",
            " capabilities",
            ".",
            "A",
            " ",
            "202",
            "0",
            " study",
            " conducted",
            " on",
            " the",
            " brains",
            " of",
            " eight",
            " male",
            " Russian",
            " cos",
            "mon",
            "aut",
            "s",
            " after",
            " they",
            " returned",
            " from",
            " long",
            " stays",
            " aboard",
            " the",
            " International",
            " Space",
            " Station",
            " showed",
            " that",
            " long",
            "-duration",
            " space",
            "flight",
            " causes",
            " many",
            " physiological",
            " adapt",
            "ions",
            ",",
            " including",
            " macro",
            "-",
            " and",
            " micro",
            "structural",
            " changes",
            ".",
            " While",
            " scientists",
            " still",
            " know"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.482,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            "-",
            "emp",
            "ir",
            "ically",
            " describe",
            " the",
            " variation",
            " of",
            " al",
            "bedo",
            " with",
            " phase",
            " angle",
            ",",
            " including",
            " a",
            " characterization",
            " of",
            " the",
            " opposition",
            " effect",
            " of",
            " reg",
            "olith",
            " surfaces",
            ".",
            " One",
            " of",
            " these",
            " five",
            " parameters",
            " is",
            " yet",
            " another",
            " type",
            " of",
            " al",
            "bedo",
            " called",
            " the",
            " single",
            "-sc",
            "attering",
            " al",
            "bedo",
            ".",
            " It",
            " is",
            " used",
            " to",
            " define",
            " scattering",
            " of",
            " electromagnetic",
            " waves",
            " on",
            " small",
            " particles",
            ".",
            " It",
            " depends",
            " on",
            " properties"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.477,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 39,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " ",
            "197",
            "3",
            " in",
            " the",
            " United",
            " States",
            " as",
            " of",
            " ",
            "202",
            "3",
            ",",
            " and",
            " the",
            " I",
            "UC",
            "N",
            " lists",
            " the",
            " species",
            " as",
            " near",
            " threatened",
            ".",
            "During",
            " a",
            " ",
            "201",
            "3",
            " study",
            " of",
            " Amb",
            "ly",
            "opsis",
            " spel",
            "aea",
            ",",
            " scientists",
            " found",
            " that",
            " the",
            " species",
            " was",
            " divided",
            " into",
            " two",
            " distinct",
            " evolutionary",
            " line",
            "ages",
            ":",
            " one",
            " north",
            " of",
            " the",
            " Ohio",
            " River",
            ",",
            " in",
            " Indiana",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.441,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.477,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            " surface",
            ",",
            " along",
            " with",
            " its",
            " daytime",
            " thermal",
            " em",
            "ittance",
            ",",
            " has",
            " been",
            " proposed",
            " as",
            " a",
            " solar",
            " radiation",
            " management",
            " strategy",
            " to",
            " mitigate",
            " energy",
            " crises",
            " and",
            " global",
            " warming",
            " known",
            " as",
            " passive",
            " daytime",
            " radi",
            "ative",
            " cooling",
            " (",
            "PD",
            "RC",
            ").",
            " Eff",
            "orts",
            " toward",
            " widespread",
            " implementation",
            " of",
            " PD",
            "RC",
            "s",
            " may",
            " focus",
            " on",
            " maximizing",
            " the",
            " al",
            "bedo",
            " of",
            " surfaces",
            " from",
            " very",
            " low",
            " to",
            " high",
            " values",
            ",",
            " so"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.477,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            "pp",
            "b",
            " (",
            "i",
            ".e",
            ".,",
            " above",
            " the",
            " ",
            "10",
            "Âł",
            "pp",
            "b",
            " drinking",
            " water",
            " standard",
            ")",
            " compromises",
            " the",
            " initial",
            " immune",
            " response",
            " to",
            " H",
            "1",
            "N",
            "1",
            " or",
            " sw",
            "ine",
            " flu",
            " infection",
            " according",
            " to",
            " N",
            "IE",
            "HS",
            "-supported",
            " scientists",
            ".",
            " The",
            " study",
            ",",
            " conducted",
            " in",
            " laboratory",
            " mice",
            ",",
            " suggests",
            " that",
            " people",
            " exposed",
            " to",
            " arsen",
            "ic",
            " in",
            " their",
            " drinking",
            " water",
            " may",
            " be",
            " at",
            " increased"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.477,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            " prevent",
            " the",
            " build",
            "-up",
            " of",
            " dental",
            " plaque",
            ".",
            " The",
            " reason",
            " for",
            " chlor",
            "hex",
            "idine",
            "'s",
            " effectiveness",
            " is",
            " that",
            " it",
            " strongly",
            " adher",
            "es",
            " to",
            " surfaces",
            " in",
            " the",
            " mouth",
            " and",
            " thus",
            " remains",
            " present",
            " in",
            " effective",
            " concentrations",
            " for",
            " many",
            " hours",
            ".",
            "Since",
            " then",
            " commercial",
            " interest",
            " in",
            " mouth",
            "w",
            "ashes",
            " has",
            " been",
            " intense",
            " and",
            " several",
            " newer",
            " products",
            " claim",
            " effectiveness",
            " in",
            " reducing",
            " the",
            " build",
            "-up",
            " in",
            " dental",
            " plaque"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.475,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            "Â°",
            "S",
            " is",
            " ,",
            " or",
            " close",
            " to",
            " the",
            " average",
            " for",
            " the",
            " global",
            " ocean",
            ",",
            " with",
            " a",
            " modal",
            " depth",
            " between",
            " .",
            "In",
            " the",
            " South",
            " Atlantic",
            " the",
            " Wal",
            "vis",
            " Ridge",
            " and",
            " Rio",
            " Grande",
            " Rise",
            " form",
            " barriers",
            " to",
            " ocean",
            " currents",
            ".",
            "The",
            " Laurent",
            "ian",
            " Abyss",
            " is",
            " found",
            " off",
            " the",
            " eastern",
            " coast",
            " of",
            " Canada",
            ".",
            "Water",
            " characteristics",
            " ",
            "Surface",
            " water",
            " temperatures",
            ",",
            " which",
            " vary",
            " with",
            " latitude",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.475,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 32,
          "is_repeated_datapoint": false,
          "tokens": [
            " for",
            " example",
            ",",
            " pent",
            "ane",
            " (",
            "C",
            "5",
            "H",
            "12",
            ").",
            " In",
            " van",
            " '",
            "t",
            " Hoff",
            "'s",
            " way",
            " of",
            " modelling",
            " molecules",
            ",",
            " there",
            " are",
            " three",
            " possible",
            " configurations",
            " for",
            " pent",
            "ane",
            ",",
            " and",
            " scientists",
            " did",
            " go",
            " on",
            " to",
            " discover",
            " three",
            " and",
            " only",
            " three",
            " is",
            "omers",
            " of",
            " pent",
            "ane",
            ".",
            "Brown",
            "ian",
            " motion",
            "In",
            " ",
            "182",
            "7",
            ",",
            " the",
            " British",
            " bot",
            "an",
            "ist",
            " Robert"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.475,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            " manner",
            ".",
            "Mapping",
            " is",
            " possible",
            " for",
            " select",
            " species",
            " only",
            ":",
            " \"",
            "there",
            " are",
            " many",
            " valid",
            " examples",
            " of",
            " confined",
            " distribution",
            " patterns",
            ".\"",
            " For",
            " example",
            ",",
            " Cl",
            "ath",
            "rom",
            "orph",
            "um",
            " is",
            " an",
            " ar",
            "ctic",
            " genus",
            " and",
            " is",
            " not",
            " mapped",
            " far",
            " south",
            " of",
            " there",
            ".",
            " However",
            ",",
            " scientists",
            " regard",
            " the",
            " overall",
            " data",
            " as",
            " insufficient",
            " due",
            " to",
            " the",
            " \"",
            "diff",
            "icult",
            "ies",
            " of",
            " undertaking",
            " such",
            " studies"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.471,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            "E",
            "conomy",
            " ",
            "The",
            " Atlantic",
            " has",
            " contributed",
            " significantly",
            " to",
            " the",
            " development",
            " and",
            " economy",
            " of",
            " surrounding",
            " countries",
            ".",
            " Besides",
            " major",
            " trans",
            "atl",
            "antic",
            " transportation",
            " and",
            " communication",
            " routes",
            ",",
            " the",
            " Atlantic",
            " offers",
            " abundant",
            " petroleum",
            " deposits",
            " in",
            " the",
            " sediment",
            "ary",
            " rocks",
            " of",
            " the",
            " continental",
            " shelves",
            ".",
            "The",
            " Atlantic",
            " harb",
            "ors",
            " petroleum",
            " and",
            " gas",
            " fields",
            ",",
            " fish",
            ",",
            " marine",
            " mammals",
            " (",
            "se",
            "als",
            " and",
            " whales",
            "),"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.469,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            " called",
            " a",
            " lam",
            "ell",
            "ip",
            "odium",
            " which",
            " contain",
            " protr",
            "usions",
            " called",
            " fil",
            "op",
            "odia",
            ".",
            " The",
            " fil",
            "op",
            "odia",
            " are",
            " the",
            " mechanism",
            " by",
            " which",
            " the",
            " entire",
            " process",
            " adher",
            "es",
            " to",
            " surfaces",
            " and",
            " explores",
            " the",
            " surrounding",
            " environment",
            ".",
            " Act",
            "in",
            " plays",
            " a",
            " major",
            " role",
            " in",
            " the",
            " mobility",
            " of",
            " this",
            " system",
            ".",
            " En",
            "vironments",
            " with",
            " high",
            " levels",
            " of",
            " cell",
            " ad",
            "hesion",
            " molecules",
            " (",
            "CAM",
            "s"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.467,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 32,
          "is_repeated_datapoint": false,
          "tokens": [
            " or",
            " be",
            " l",
            "ichen",
            "ised",
            ".",
            " L",
            "ichen",
            " thus",
            " share",
            " some",
            " of",
            " the",
            " habitat",
            " and",
            " often",
            " similar",
            " appearance",
            " with",
            " specialized",
            " species",
            " of",
            " algae",
            " (",
            "a",
            "er",
            "ophy",
            "tes",
            ")",
            " growing",
            " on",
            " exposed",
            " surfaces",
            " such",
            " as",
            " tree",
            " tr",
            "unks",
            " and",
            " rocks",
            " and",
            " sometimes",
            " disc",
            "olor",
            "ing",
            " them",
            ".",
            "C",
            "oral",
            " reefs",
            " Coral",
            " reefs",
            " are",
            " accumulated",
            " from",
            " the",
            " calc",
            "are",
            "ous",
            " ex",
            "os",
            "keleton"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.297,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.465,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.467,
            -0.0
          ],
          "train_token_ind": 61,
          "is_repeated_datapoint": false,
          "tokens": [
            " given",
            " for",
            " the",
            " spectrum",
            " in",
            " which",
            " most",
            " solar",
            " energy",
            " reaches",
            " the",
            " surface",
            " (",
            "between",
            " ",
            "0",
            ".",
            "3",
            " and",
            " ",
            "3",
            " Î¼",
            "m",
            ").",
            " This",
            " spectrum",
            " includes",
            " visible",
            " light",
            " (",
            "0",
            ".",
            "4",
            "–",
            "0",
            ".",
            "7",
            " Î¼",
            "m",
            "),",
            " which",
            " explains",
            " why",
            " surfaces",
            " with",
            " a",
            " low",
            " al",
            "bedo",
            " appear",
            " dark",
            " (",
            "e",
            ".g",
            ".,",
            " trees",
            " absorb",
            " most",
            " radiation",
            "),",
            " whereas",
            " surfaces",
            " with"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.297,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.465,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.467,
            -0.0
          ],
          "train_token_ind": 61,
          "is_repeated_datapoint": false,
          "tokens": [
            " given",
            " for",
            " the",
            " spectrum",
            " in",
            " which",
            " most",
            " solar",
            " energy",
            " reaches",
            " the",
            " surface",
            " (",
            "between",
            " ",
            "0",
            ".",
            "3",
            " and",
            " ",
            "3",
            " Î¼",
            "m",
            ").",
            " This",
            " spectrum",
            " includes",
            " visible",
            " light",
            " (",
            "0",
            ".",
            "4",
            "–",
            "0",
            ".",
            "7",
            " Î¼",
            "m",
            "),",
            " which",
            " explains",
            " why",
            " surfaces",
            " with",
            " a",
            " low",
            " al",
            "bedo",
            " appear",
            " dark",
            " (",
            "e",
            ".g",
            ".,",
            " trees",
            " absorb",
            " most",
            " radiation",
            "),",
            " whereas",
            " surfaces",
            " with"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.465,
            -0.0
          ],
          "train_token_ind": 61,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " capture",
            " fertil",
            "izers",
            " in",
            " runoff",
            " from",
            " farms",
            ".",
            " When",
            " subsequently",
            " harvested",
            ",",
            " the",
            " enriched",
            " algae",
            " can",
            " be",
            " used",
            " as",
            " fertilizer",
            ".",
            " Aqu",
            "aria",
            " and",
            " ponds",
            " can",
            " be",
            " filtered",
            " using",
            " algae",
            ",",
            " which",
            " absorb",
            " nutrients",
            " from",
            " the",
            " water",
            " in",
            " a",
            " device",
            " called",
            " an",
            " algae",
            " scrub",
            "ber",
            ",",
            " also",
            " known",
            " as",
            " an",
            " algae",
            " turf",
            " scrub",
            "ber",
            ".",
            "A",
            "gricult",
            "ural",
            " Research",
            " Service",
            " scientists",
            " found"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.465,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 15,
          "is_repeated_datapoint": false,
          "tokens": [
            " asphalt",
            " concrete",
            "The",
            " largest",
            " use",
            " of",
            " bit",
            "umen",
            " is",
            " for",
            " making",
            " asphalt",
            " concrete",
            " for",
            " road",
            " surfaces",
            ";",
            " this",
            " accounts",
            " for",
            " approximately",
            " ",
            "85",
            "%",
            " of",
            " the",
            " bit",
            "umen",
            " consumed",
            " in",
            " the",
            " United",
            " States",
            ".",
            " There",
            " are",
            " about",
            " ",
            "4",
            ",",
            "000",
            " asphalt",
            " concrete",
            " mixing",
            " plants",
            " in",
            " the",
            " US",
            ",",
            " and",
            " a",
            " similar",
            " number",
            " in",
            " Europe",
            ".",
            "As",
            "phalt",
            " concrete",
            " pavement",
            " mixes",
            " are"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.465,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.248,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            " that",
            " deep",
            " sed",
            "iments",
            " can",
            " remove",
            " arsen",
            "ic",
            " and",
            " take",
            " it",
            " out",
            " of",
            " circulation",
            ".",
            " In",
            " this",
            " process",
            ",",
            " called",
            " ads",
            "orption",
            ",",
            " arsen",
            "ic",
            " sticks",
            " to",
            " the",
            " surfaces",
            " of",
            " deep",
            " sediment",
            " particles",
            " and",
            " is",
            " naturally",
            " removed",
            " from",
            " the",
            " ground",
            " water",
            ".",
            "M",
            "agnetic",
            " separ",
            "ations",
            " of",
            " arsen",
            "ic",
            " at",
            " very",
            " low",
            " magnetic",
            " field",
            " gradients",
            " with",
            " high",
            "-s",
            "urface",
            "-area",
            " and",
            " mon",
            "od"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.459,
            -0.0,
            -0.0,
            0.003,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 49,
          "is_repeated_datapoint": false,
          "tokens": [
            " (",
            "or",
            " agr",
            "isc",
            "ience",
            " for",
            " short",
            ")",
            " is",
            " a",
            " broad",
            " multid",
            "isc",
            "iplinary",
            " field",
            " of",
            " biology",
            " that",
            " encompasses",
            " the",
            " parts",
            " of",
            " exact",
            ",",
            " natural",
            ",",
            " economic",
            " and",
            " social",
            " sciences",
            " that",
            " are",
            " used",
            " in",
            " the",
            " practice",
            " and",
            " understanding",
            " of",
            " agriculture",
            ".",
            " Professionals",
            " of",
            " the",
            " agricultural",
            " science",
            " are",
            " called",
            " agricultural",
            " scientists",
            " or",
            " agricult",
            "ur",
            "ists",
            ".",
            "History",
            "In",
            " the",
            " ",
            "18",
            "th",
            " century"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.459,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " scientist",
            " O",
            "laus",
            " Rud",
            "beck",
            " (",
            "163",
            "0",
            "–",
            "170",
            "2",
            "),",
            " and",
            " in",
            " his",
            " turn",
            ",",
            " the",
            " boy",
            " was",
            " interested",
            " in",
            " engineering",
            ",",
            " particularly",
            " explosives",
            ",",
            " learning",
            " the",
            " basic",
            " principles",
            " from",
            " his",
            " father",
            " at",
            " a",
            " young",
            " age",
            ".",
            " Alfred",
            " Nobel",
            "'s",
            " interest",
            " in",
            " technology",
            " was",
            " inherited",
            " from",
            " his",
            " father",
            ",",
            " an",
            " al",
            "umn",
            "us",
            " of",
            " Royal",
            " Institute",
            " of",
            " Technology",
            " in",
            " Stockholm",
            ".F"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.459,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            " experience",
            ",",
            " as",
            " manifested",
            " in",
            " American",
            " Industrial",
            "ization",
            ",",
            " had",
            " completely",
            " altered",
            " the",
            " environment",
            ",",
            " often",
            " dis",
            "fig",
            "uring",
            " it",
            ",",
            " so",
            " as",
            " to",
            " suggest",
            " its",
            " ins",
            "uff",
            "iciency",
            " to",
            " human",
            " needs",
            ".",
            " Third",
            "ly",
            ",",
            " because",
            " scientists",
            " were",
            " constantly",
            " producing",
            " more",
            " data",
            "—to",
            " the",
            " point",
            " where",
            " no",
            " single",
            " human",
            " could",
            " grasp",
            " it",
            " all",
            " at",
            " once",
            "—it",
            " followed",
            " that",
            " human",
            " intelligence",
            " was",
            " incapable"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.459,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " journals",
            " –",
            " med",
            "itations",
            " on",
            " nature",
            ",",
            " Mid",
            "western",
            " village",
            " American",
            " life",
            ",",
            " and",
            " more",
            " –",
            " was",
            " published",
            " in",
            " ",
            "194",
            "1",
            " to",
            " praise",
            " from",
            " The",
            " New",
            " York",
            " Times",
            " Book",
            " Review",
            ":",
            " \"",
            "A",
            " book",
            " of",
            " instant",
            " sensitive",
            " responsiveness",
            "...",
            "re",
            "creates",
            " its",
            " scene",
            " with",
            " ac",
            "uten",
            "ess",
            " and",
            " beauty",
            ",",
            " and",
            " makes",
            " an",
            " unusual",
            " contribution",
            " to",
            " the",
            " Americ",
            "ana",
            " of",
            " the",
            " present"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.459,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.289,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " include",
            " Dallas",
            ",",
            " Low",
            "nd",
            "es",
            ",",
            " Mare",
            "ngo",
            " and",
            " Perry",
            ".\"",
            "In",
            " ",
            "197",
            "2",
            ",",
            " for",
            " the",
            " first",
            " time",
            " since",
            " ",
            "190",
            "1",
            ",",
            " the",
            " legislature",
            " completed",
            " the",
            " congressional",
            " red",
            "istrict",
            "ing",
            " based",
            " on",
            " the",
            " dec",
            "ennial",
            " census",
            ".",
            " This",
            " benefited",
            " the",
            " urban",
            " areas",
            " that",
            " had",
            " developed",
            ",",
            " as",
            " well",
            " as",
            " all",
            " in",
            " the",
            " population",
            " who",
            " had",
            " been",
            " under",
            "represented",
            " for"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.44,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 52,
          "is_repeated_datapoint": false,
          "tokens": [
            " or",
            " down",
            ".",
            " Control",
            " systems",
            " are",
            " also",
            " sometimes",
            " used",
            " to",
            " increase",
            " or",
            " decrease",
            " drag",
            ",",
            " for",
            " example",
            " to",
            " slow",
            " the",
            " aircraft",
            " to",
            " a",
            " safe",
            " speed",
            " for",
            " landing",
            ".",
            "The",
            " two",
            " main",
            " aer",
            "odynamic",
            " forces",
            " acting",
            " on",
            " any",
            " aircraft",
            " are",
            " lift",
            " supporting",
            " it",
            " in",
            " the",
            " air",
            " and",
            " drag",
            " opposing",
            " its",
            " motion",
            ".",
            " Control",
            " surfaces",
            " or",
            " other",
            " techniques",
            " may",
            " also",
            " be",
            " used",
            " to",
            " affect",
            " these"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.023,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.418,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " took",
            " up",
            " a",
            " position",
            " at",
            " the",
            " Institute",
            " for",
            " Advanced",
            " Study",
            ",",
            " noted",
            " for",
            " having",
            " become",
            " a",
            " refuge",
            " for",
            " scientists",
            " fleeing",
            " Nazi",
            " Germany",
            ".",
            " At",
            " the",
            " time",
            ",",
            " most",
            " American",
            " universities",
            ",",
            " including",
            " Harvard",
            ",",
            " Princeton",
            " and",
            " Yale",
            ",",
            " had",
            " minimal",
            " or",
            " no",
            " Jewish",
            " faculty",
            " or",
            " students",
            ",",
            " as",
            " a",
            " result",
            " of",
            " their",
            " Jewish",
            " quotas",
            ",",
            " which",
            " lasted",
            " until",
            " the",
            " late",
            " ",
            "194",
            "0"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.389,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.408,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            " everyday",
            " or",
            " util",
            "itarian",
            " writing",
            ",",
            " which",
            " was",
            " done",
            " on",
            " more",
            " perish",
            "able",
            " surfaces",
            ".",
            " Due",
            " to",
            " the",
            " \"",
            "per",
            "ish",
            "able",
            "\"",
            " nature",
            " of",
            " these",
            " surfaces",
            ",",
            " there",
            " are",
            " not",
            " as",
            " many",
            " examples",
            " of",
            " this",
            " style",
            " as",
            " there",
            " are",
            " of",
            " the",
            " monumental",
            ",",
            " but",
            " there",
            " are",
            " still",
            " many",
            " surviving",
            " examples",
            " of",
            " different",
            " types",
            " of",
            " c",
            "ursive",
            ",",
            " such",
            " as",
            " maj",
            "usc",
            "ule"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.408,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 8,
          "is_repeated_datapoint": false,
          "tokens": [
            " also",
            " had",
            " some",
            " one",
            "-shot",
            " collaborations",
            " with",
            " various",
            " scientists",
            ".",
            "E",
            "instein",
            "–",
            "de",
            " Ha",
            "as",
            " experiment",
            " ",
            "In",
            " ",
            "190",
            "8",
            ",",
            " Owen",
            " Will",
            "ans",
            " Richardson",
            " predicted",
            " that",
            " a",
            " change",
            " in",
            " the",
            " magnetic",
            " moment",
            " of",
            " a",
            " free",
            " body",
            " will",
            " cause",
            " this",
            " body",
            " to",
            " rotate",
            ".",
            " This",
            " effect",
            " is",
            " a",
            " consequence",
            " of",
            " the",
            " conservation",
            " of",
            " angular",
            " momentum",
            " and",
            " is",
            " strong",
            " enough",
            " to",
            " be"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.394,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 52,
          "is_repeated_datapoint": false,
          "tokens": [
            " views",
            ".",
            " Lind",
            "ber",
            "gh",
            " initially",
            " sought",
            " out",
            " Car",
            "rel",
            " to",
            " see",
            " if",
            " his",
            " sister",
            "-in",
            "-law",
            "'s",
            " heart",
            ",",
            " damaged",
            " by",
            " rhe",
            "umatic",
            " fever",
            ",",
            " could",
            " be",
            " repaired",
            ".",
            " When",
            " Lind",
            "ber",
            "gh",
            " saw",
            " the",
            " crud",
            "eness",
            " of",
            " Car",
            "rel",
            "'s",
            " machinery",
            ",",
            " he",
            " offered",
            " to",
            " build",
            " new",
            " equipment",
            " for",
            " the",
            " scientist",
            ".",
            " Eventually",
            " they",
            " built",
            " the",
            " first",
            " perf",
            "usion",
            " pump",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.393,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 16,
          "is_repeated_datapoint": false,
          "tokens": [
            "-born",
            " theoretical",
            " physicist",
            " who",
            " is",
            " widely",
            " held",
            " to",
            " be",
            " one",
            " of",
            " the",
            " greatest",
            " and",
            " most",
            " influential",
            " scientists",
            " of",
            " all",
            " time",
            ".",
            " Best",
            " known",
            " for",
            " developing",
            " the",
            " theory",
            " of",
            " rel",
            "ativity",
            ",",
            " Einstein",
            " also",
            " made",
            " important",
            " contributions",
            " to",
            " quantum",
            " mechanics",
            ",",
            " and",
            " was",
            " thus",
            " a",
            " central",
            " figure",
            " in",
            " the",
            " revolutionary",
            " resh",
            "aping",
            " of",
            " the",
            " scientific",
            " understanding",
            " of",
            " nature",
            " that",
            " modern",
            " physics",
            " accomplished",
            " in",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.359,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            " differently",
            " from",
            " typical",
            " terrestrial",
            " materials",
            ".",
            " The",
            " reflect",
            "ivity",
            " of",
            " a",
            " water",
            " surface",
            " is",
            " calculated",
            " using",
            " the",
            " Fres",
            "nel",
            " equations",
            ".",
            "At",
            " the",
            " scale",
            " of",
            " the",
            " wavelength",
            " of",
            " light",
            " even",
            " w",
            "avy",
            " water",
            " is",
            " always",
            " smooth",
            " so",
            " the",
            " light",
            " is",
            " reflected",
            " in",
            " a",
            " locally",
            " specular",
            " manner",
            " (",
            "not",
            " diff",
            "us",
            "ely",
            ").",
            " The",
            " gl",
            "int",
            " of",
            " light",
            " off",
            " water",
            " is",
            " a",
            " commonplace",
            " effect"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.356,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 44,
          "is_repeated_datapoint": false,
          "tokens": [
            " are",
            " dens",
            "er",
            ",",
            " presumably",
            " due",
            " to",
            " compression",
            ".",
            " There",
            " appears",
            " to",
            " be",
            " minimal",
            " macro",
            "-p",
            "or",
            "osity",
            " (",
            "inter",
            "stitial",
            " vacuum",
            ")",
            " in",
            " the",
            " score",
            " of",
            " asteroids",
            " with",
            " masses",
            " greater",
            " than",
            " .",
            "Composition",
            " is",
            " calculated",
            " from",
            " three",
            " primary",
            " sources",
            ":",
            " al",
            "bedo",
            ",",
            " surface",
            " spectrum",
            ",",
            " and",
            " density",
            ".",
            " The",
            " last",
            " can",
            " only",
            " be",
            " determined",
            " accurately",
            " by",
            " observing",
            " the",
            " orbits",
            " of",
            " moons"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.322,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 17,
          "is_repeated_datapoint": false,
          "tokens": [
            " People",
            " sometimes",
            " mistakenly",
            " fail",
            " to",
            " help",
            " when",
            " they",
            " intended",
            " to",
            ",",
            " or",
            " their",
            " helping",
            " may",
            " not",
            " be",
            " noticed",
            ",",
            " which",
            " may",
            " cause",
            " unintended",
            " conflicts",
            ".",
            " As",
            " such",
            ",",
            " it",
            " may",
            " be",
            " an",
            " optimal",
            " strategy",
            " to",
            " be",
            " slightly",
            " forgiving",
            " of",
            " and",
            " have",
            " a",
            " slightly",
            " generous",
            " interpretation",
            " of",
            " non",
            "-co",
            "operation",
            ".",
            "People",
            " are",
            " more",
            " likely",
            " to",
            " cooperate",
            " on",
            " a",
            " task",
            " if",
            " they",
            " can",
            " communicate"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.299,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 8,
          "is_repeated_datapoint": false,
          "tokens": [
            "un",
            "broken",
            " forest",
            "\"",
            " in",
            " Hurricane",
            " Township",
            ",",
            " Perry",
            " County",
            ",",
            " Indiana",
            ".",
            " In",
            " ",
            "186",
            "0",
            ",",
            " Lincoln",
            " noted",
            " that",
            " the",
            " family",
            "'s",
            " move",
            " to",
            " Indiana",
            " was",
            " \"",
            "part",
            "ly",
            " on",
            " account",
            " of",
            " slavery",
            "\",",
            " but",
            " mainly",
            " due",
            " to",
            " land",
            " title",
            " difficulties",
            ".",
            "In",
            " Kentucky",
            " and",
            " Indiana",
            ",",
            " Thomas",
            " worked",
            " as",
            " a",
            " farmer",
            ",",
            " cabinet",
            "maker",
            ",",
            " and",
            " carp",
            "enter",
            ".",
            " At"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.291,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            "le",
            "th",
            "'s",
            " finest",
            " work",
            ".",
            " This",
            " prose",
            " meditation",
            " is",
            " built",
            " out",
            " of",
            " the",
            " same",
            " fundamental",
            " material",
            " as",
            " the",
            " series",
            " of",
            " Sac",
            " Prairie",
            " journals",
            ",",
            " but",
            " is",
            " organized",
            " around",
            " three",
            " themes",
            ":",
            " \"",
            "the",
            " persistence",
            " of",
            " memory",
            "...",
            "the",
            " sounds",
            " and",
            " od",
            "ors",
            " of",
            " the",
            " country",
            "...",
            "and",
            " Th",
            "ore",
            "au",
            "'s",
            " observation",
            " that",
            " the",
            " '",
            "mass",
            " of",
            " men",
            " lead",
            " lives",
            " of",
            " quiet"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            " characters",
            "Female",
            " characters",
            " in",
            " literature",
            "F",
            "iction",
            "al",
            " amateur",
            " detectives",
            "Liter",
            "ary",
            " characters",
            " introduced",
            " in",
            " ",
            "192",
            "7",
            "F",
            "iction",
            "al",
            " English",
            " people",
            "Nov",
            "el",
            " series",
            "Nov",
            "els",
            " adapted",
            " into",
            " radio",
            " programs",
            "British",
            " novels",
            " adapted",
            " into",
            " television",
            " shows",
            "<|begin_of_text|>",
            "April",
            " is",
            " the",
            " fourth",
            " month",
            " of",
            " the",
            " year",
            " in",
            " the",
            " Greg",
            "orian",
            " and",
            " Julian",
            " calendars",
            ".",
            " It"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.27,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            " ped",
            "ic",
            "els",
            ".",
            " In",
            " others",
            ",",
            " poll",
            "ination",
            " occurs",
            " underwater",
            ",",
            " where",
            " pollen",
            " may",
            " form",
            " elong",
            "ated",
            " strands",
            ",",
            " increasing",
            " chance",
            " of",
            " success",
            ".",
            " Most",
            " aquatic",
            " species",
            " have",
            " a",
            " totally",
            " submerged",
            " juvenile",
            " phase",
            ",",
            " and",
            " flowers",
            " are",
            " either",
            " floating",
            " or",
            " emerge",
            " above",
            " the",
            " water",
            "'s",
            " surface",
            ".",
            " Veget",
            "ation",
            " may",
            " be",
            " totally",
            " sub",
            "mers",
            "ed",
            ",",
            " have",
            " floating",
            " leaves",
            ",",
            " or",
            " protr"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.01,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.209,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            " produced",
            " by",
            " these",
            " bacteria",
            ".",
            "L",
            "id",
            "oc",
            "aine",
            "/",
            "xy",
            "loc",
            "aine",
            "Or",
            "al",
            " lid",
            "oc",
            "aine",
            " is",
            " useful",
            " for",
            " the",
            " treatment",
            " of",
            " muc",
            "os",
            "itis",
            " symptoms",
            " (",
            "in",
            "flamm",
            "ation",
            " of",
            " muc",
            "ous",
            " membranes",
            ")",
            " induced",
            " by",
            " radiation",
            " or",
            " chemotherapy",
            ".",
            " There",
            " is",
            " evidence",
            " that",
            " lid",
            "oc",
            "aine",
            " an",
            "esthetic",
            " mouth",
            "wash",
            " has",
            " the",
            " potential",
            " to",
            " be",
            " system",
            "ically",
            " absorbed"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.18,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.186,
            -0.0,
            -0.0
          ],
          "train_token_ind": 60,
          "is_repeated_datapoint": false,
          "tokens": [
            " court",
            " within",
            " a",
            " country",
            ".",
            "The",
            " specific",
            " rules",
            " of",
            " the",
            " legal",
            " system",
            " will",
            " dictate",
            " exactly",
            " how",
            " the",
            " appeal",
            " is",
            " officially",
            " begun",
            ".",
            " For",
            " example",
            ",",
            " the",
            " appellant",
            " might",
            " have",
            " to",
            " file",
            " the",
            " notice",
            " of",
            " appeal",
            " with",
            " the",
            " appellate",
            " court",
            ",",
            " or",
            " with",
            " the",
            " court",
            " from",
            " which",
            " the",
            " appeal",
            " is",
            " taken",
            ",",
            " or",
            " both",
            ".",
            "Some",
            " courts",
            " have",
            " samples",
            " of",
            " a",
            " notice",
            " of",
            " appeal"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.179,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.148,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.185,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            " lawyer",
            " traditionally",
            " starts",
            " an",
            " oral",
            " argument",
            " to",
            " any",
            " appellate",
            " court",
            " with",
            " the",
            " words",
            " \"",
            "May",
            " it",
            " please",
            " the",
            " court",
            ".\"",
            "After",
            " an",
            " appeal",
            " is",
            " heard",
            ",",
            " the",
            " \"",
            "mand",
            "ate",
            "\"",
            " is",
            " a",
            " formal",
            " notice",
            " of",
            " a",
            " decision",
            " by",
            " a",
            " court",
            " of",
            " appeal",
            ";",
            " this",
            " notice",
            " is",
            " transmitted",
            " to",
            " the",
            " trial",
            " court",
            " and",
            ",",
            " when",
            " filed",
            " by",
            " the",
            " clerk",
            " of",
            " the",
            " trial",
            " court"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.165,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            " example",
            ".",
            "Common",
            " tools",
            " ",
            "Am",
            "ateur",
            " astronomers",
            " use",
            " a",
            " range",
            " of",
            " instruments",
            " to",
            " study",
            " the",
            " sky",
            ",",
            " depending",
            " on",
            " a",
            " combination",
            " of",
            " their",
            " interests",
            " and",
            " resources",
            ".",
            " ",
            " Methods",
            " include",
            " simply",
            " looking",
            " at",
            " the",
            " night",
            " sky",
            " with",
            " the",
            " naked",
            " eye",
            ",",
            " using",
            " bin",
            "ocular",
            "s",
            ",",
            " and",
            " using",
            " a",
            " variety",
            " of",
            " optical",
            " telesc",
            "opes",
            " of",
            " varying",
            " power",
            " and",
            " quality",
            ",",
            " as",
            " well"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.128,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            " not",
            "ar",
            "ization",
            " process",
            ".",
            " ",
            "The",
            " acceptance",
            " of",
            " an",
            " affidavit",
            " by",
            " one",
            " society",
            " does",
            " not",
            " confirm",
            " its",
            " acceptance",
            " as",
            " a",
            " legal",
            " document",
            " in",
            " other",
            " jurisdictions",
            ".",
            " Equ",
            "ally",
            ",",
            " the",
            " acceptance",
            " that",
            " a",
            " lawyer",
            " is",
            " an",
            " officer",
            " of",
            " the",
            " court",
            " (",
            "for",
            " swearing",
            " the",
            " affidavit",
            ")",
            " is",
            " not",
            " a",
            " given",
            ".",
            " This",
            " matter",
            " is",
            " addressed",
            " by",
            " the",
            " use",
            " of",
            " the",
            " apost",
            "ille"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.113,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            " hatch",
            " from",
            " the",
            " egg",
            " as",
            " larvae",
            " with",
            " external",
            " g",
            "ills",
            ".",
            " Met",
            "am",
            "orph",
            "osis",
            " in",
            " amphib",
            "ians",
            " is",
            " regulated",
            " by",
            " thy",
            "rox",
            "ine",
            " concentration",
            " in",
            " the",
            " blood",
            ",",
            " which",
            " stimulates",
            " metam",
            "orph",
            "osis",
            ",",
            " and",
            " prol",
            "act",
            "in",
            ",",
            " which",
            " counter",
            "acts",
            " thy",
            "rox",
            "ine",
            "'s",
            " effect",
            ".",
            " Specific",
            " events",
            " are",
            " dependent",
            " on",
            " threshold",
            " values",
            " for",
            " different",
            " tissues",
            ".",
            " Because",
            " most",
            " embry"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "d",
            ".",
            " ",
            "115",
            "6",
            ")",
            "143",
            "2",
            " –",
            " Anne",
            " of",
            " Austria",
            ",",
            " Land",
            "grav",
            "ine",
            " of",
            " Th",
            "uring",
            "ia",
            " (",
            "d",
            ".",
            " ",
            "146",
            "2",
            ")",
            "148",
            "4",
            " –",
            " Antonio",
            " da",
            " Sang",
            "allo",
            " the",
            " Young",
            "er",
            ",",
            " Italian",
            " architect",
            ",",
            " designed",
            " the",
            " Apost",
            "olic",
            " Palace",
            " and",
            " St",
            ".",
            " Peter",
            "'s",
            " Basil",
            "ica",
            " (",
            "d",
            ".",
            " ",
            "154",
            "6",
            ")",
            " ",
            " ",
            "148"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " urban",
            "ization",
            " in",
            " that",
            " it",
            " is",
            " centered",
            " on",
            " just",
            " a",
            " few",
            " cities",
            ".",
            "The",
            " only",
            " city",
            " with",
            " over",
            " a",
            " million",
            " residents",
            " is",
            " its",
            " capital",
            ",",
            " Kabul",
            ",",
            " located",
            " in",
            " the",
            " east",
            " of",
            " the",
            " country",
            ".",
            " The",
            " other",
            " large",
            " cities",
            " are",
            " located",
            " generally",
            " in",
            " the",
            " \"",
            "ring",
            "\"",
            " around",
            " the",
            " Central",
            " Highlands",
            ",",
            " namely",
            " K",
            "and",
            "ah",
            "ar",
            " in",
            " the",
            " south",
            ",",
            " Her",
            "at"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " Cro",
            "ag",
            "ha",
            "un",
            " mountain",
            " and",
            " in",
            " Cur",
            "ra",
            "un",
            ".",
            " At",
            " A",
            "ilt",
            ",",
            " K",
            "ild",
            "own",
            "et",
            ",",
            " the",
            " remains",
            " of",
            " a",
            " similar",
            " deserted",
            " village",
            " can",
            " be",
            " found",
            ".",
            " This",
            " village",
            " was",
            " deserted",
            " in",
            " ",
            "185",
            "5",
            " when",
            " the",
            " tenants",
            " were",
            " ev",
            "icted",
            " by",
            " the",
            " local",
            " landlord",
            " so",
            " the",
            " land",
            " could",
            " be",
            " used",
            " for",
            " cattle",
            " grazing",
            ";",
            " the",
            " tenants",
            " were",
            " forced"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " lower",
            " court",
            " applied",
            " and",
            " decides",
            " whether",
            " that",
            " decision",
            " was",
            " legally",
            " sound",
            " or",
            " not",
            ".",
            " ",
            " The",
            " appellate",
            " court",
            " will",
            " typically",
            " be",
            " defer",
            "ential",
            " to",
            " the",
            " lower",
            " court",
            "'s",
            " findings",
            " of",
            " fact",
            " (",
            "such",
            " as",
            " whether",
            " a",
            " defendant",
            " committed",
            " a",
            " particular",
            " act",
            "),",
            " unless",
            " clearly",
            " erroneous",
            ",",
            " and",
            " so",
            " will",
            " focus",
            " on",
            " the",
            " court",
            "'s",
            " application",
            " of",
            " the",
            " law",
            " to",
            " those",
            " facts",
            " ("
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " approval",
            " of",
            " Marvel",
            " publisher",
            " Martin",
            " Goodman",
            ",",
            " Lee",
            " had",
            " the",
            " comics",
            " published",
            " without",
            " the",
            " seal",
            ".",
            " The",
            " comics",
            " sold",
            " well",
            " and",
            " Marvel",
            " won",
            " praise",
            " for",
            " its",
            " socially",
            " conscious",
            " efforts",
            ".",
            " The",
            " C",
            "CA",
            " subsequently",
            " loos",
            "ened",
            " the",
            " Code",
            " to",
            " permit",
            " negative",
            " dep",
            "ictions",
            " of",
            " drugs",
            ",",
            " among",
            " other",
            " new",
            " freedoms",
            ".",
            "\"The",
            " Six",
            " Arms",
            " Saga",
            "\"",
            " of",
            " #",
            "100",
            "–",
            "102",
            " ("
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "fragistics",
    "ibu",
    "ayo",
    "aver",
    "Ã¡ch"
  ],
  "bottom_logits": [
    "1",
    "882",
    "isia",
    "spacer",
    "uchar"
  ],
  "act_min": -0.0,
  "act_max": 0.508
}
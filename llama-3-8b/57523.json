{
  "index": 57523,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            0.637,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.01,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " incentives",
            " for",
            " perceived",
            " original",
            "ity",
            " and",
            " publicity",
            " also",
            " encouraged",
            " artists",
            " to",
            " court",
            " controversy",
            ".",
            " Th",
            "Ã©",
            "odore",
            " G",
            "Ã©ric",
            "ault",
            "'s",
            " Ra",
            "ft",
            " of",
            " the",
            " Med",
            "usa",
            " (),",
            " was",
            " in",
            " part",
            " a",
            " political",
            " commentary",
            " on",
            " a",
            " recent",
            " event",
            ".",
            " Ãī",
            "dou",
            "ard",
            " Man",
            "et",
            "'s",
            " Le",
            " DÃ©",
            "je",
            "uner",
            " sur",
            " l",
            "'",
            "Her",
            "be",
            " (",
            "186",
            "3",
            "),",
            " was",
            " considered",
            " scandal",
            "ous",
            " not"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.613,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            " by",
            " ",
            "205",
            "0",
            ",",
            " the",
            " International",
            " Food",
            " Policy",
            " Research",
            " Institute",
            " found",
            " that",
            " the",
            " number",
            " of",
            " people",
            " at",
            " risk",
            " from",
            " hunger",
            " could",
            " be",
            " reduced",
            " by",
            " as",
            " much",
            " as",
            " ",
            "40",
            "%",
            " and",
            " food",
            " prices",
            " could",
            " be",
            " reduced",
            " by",
            " almost",
            " half",
            ".",
            "Payment",
            " for",
            " ecosystem",
            " services",
            " is",
            " a",
            " method",
            " of",
            " providing",
            " additional",
            " incentives",
            " to",
            " encourage",
            " farmers",
            " to",
            " conserve",
            " some",
            " aspects",
            " of",
            " the",
            " environment",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.613,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 27,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " climate",
            " information",
            " in",
            " local",
            " planning",
            " and",
            " strengthening",
            " weather",
            "-based",
            " ag",
            "ro",
            "-ad",
            "vis",
            "ory",
            " services",
            ",",
            " to",
            " stimulating",
            " divers",
            "ification",
            " of",
            " rural",
            " household",
            " incomes",
            " and",
            " providing",
            " incentives",
            " to",
            " farmers",
            " to",
            " adopt",
            " natural",
            " resource",
            " conservation",
            " measures",
            " to",
            " enhance",
            " forest",
            " cover",
            ",",
            " replen",
            "ish",
            " groundwater",
            " and",
            " use",
            " renewable",
            " energy",
            ".",
            "The",
            " ten",
            " countries",
            " of",
            " the",
            " Association",
            " of",
            " Southeast",
            " Asian",
            " Nations",
            " (",
            "ASE",
            "AN",
            ")"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.613,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 32,
          "is_repeated_datapoint": false,
          "tokens": [
            " reforms",
            " that",
            " would",
            " improve",
            " human",
            " health",
            " and",
            " the",
            " environment",
            ".",
            " For",
            " example",
            ",",
            " proposals",
            " in",
            " ",
            "201",
            "0",
            " for",
            " a",
            " voluntary",
            " code",
            " of",
            " conduct",
            " for",
            " the",
            " livestock",
            " industry",
            " that",
            " would",
            " have",
            " provided",
            " incentives",
            " for",
            " improving",
            " standards",
            " for",
            " health",
            ",",
            " and",
            " environmental",
            " regulations",
            ",",
            " such",
            " as",
            " the",
            " number",
            " of",
            " animals",
            " an",
            " area",
            " of",
            " land",
            " can",
            " support",
            " without",
            " long",
            "-term",
            " damage",
            ",",
            " were",
            " successfully",
            " defeated"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.609,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 42,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " fruits",
            " were",
            " grown",
            " in",
            " garden",
            " plots",
            ",",
            " close",
            " to",
            " habit",
            "ations",
            " and",
            " on",
            " higher",
            " ground",
            ",",
            " and",
            " had",
            " to",
            " be",
            " water",
            "ed",
            " by",
            " hand",
            ".",
            " Veget",
            "ables",
            " included",
            " le",
            "eks",
            ",",
            " garlic",
            ",",
            " mel",
            "ons",
            ",",
            " squ",
            "ashes",
            ",",
            " pulses",
            ",",
            " lettuce",
            ",",
            " and",
            " other",
            " crops",
            ",",
            " in",
            " addition",
            " to",
            " grapes",
            " that",
            " were",
            " made",
            " into",
            " wine",
            ".",
            "Anim",
            "als",
            "The",
            " Egyptians"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            " be",
            " grown",
            ",",
            " but",
            " the",
            " long",
            " sunny",
            " summer",
            " days",
            " make",
            " for",
            " productive",
            " growing",
            " seasons",
            ".",
            " The",
            " primary",
            " crops",
            " are",
            " potatoes",
            ",",
            " carrots",
            ",",
            " lettuce",
            ",",
            " and",
            " cabbage",
            ".",
            "The",
            " Tan",
            "ana",
            " Valley",
            " is",
            " another",
            " notable",
            " agricultural",
            " locus",
            ",",
            " especially",
            " the",
            " Delta",
            " Junction",
            " area",
            ",",
            " about",
            " ",
            " southeast",
            " of",
            " Fair",
            "banks",
            ",",
            " with",
            " a",
            " sizable",
            " concentration",
            " of",
            " farms",
            " growing",
            " agr",
            "onomic",
            " crops",
            ";",
            " these"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 16,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            "Salt",
            "fish",
            ",",
            " eggs",
            ",",
            " egg",
            "plant",
            " (",
            "also",
            " referred",
            " to",
            " as",
            " tro",
            "ba",
            "),",
            " lettuce",
            ",",
            " and",
            " other",
            " vegetables",
            " are",
            " typically",
            " served",
            " for",
            " breakfast",
            ".",
            " Lunch",
            "es",
            " typically",
            " consist",
            " of",
            " a",
            " starch",
            ",",
            " such",
            " as",
            " rice",
            ",",
            " mac",
            "aron",
            "i",
            ",",
            " or",
            " pasta",
            ",",
            " with",
            " vegetables",
            " or",
            " salad",
            ",",
            " an",
            " ent",
            "ree",
            " (",
            "such",
            " as",
            " fish",
            ",",
            " chicken",
            ",",
            " pork",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 16,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            "Salt",
            "fish",
            ",",
            " eggs",
            ",",
            " egg",
            "plant",
            " (",
            "also",
            " referred",
            " to",
            " as",
            " tro",
            "ba",
            "),",
            " lettuce",
            ",",
            " and",
            " other",
            " vegetables",
            " are",
            " typically",
            " served",
            " for",
            " breakfast",
            ".",
            " Lunch",
            "es",
            " typically",
            " consist",
            " of",
            " a",
            " starch",
            ",",
            " such",
            " as",
            " rice",
            ",",
            " mac",
            "aron",
            "i",
            ",",
            " or",
            " pasta",
            ",",
            " with",
            " vegetables",
            " or",
            " salad",
            ",",
            " an",
            " ent",
            "ree",
            " (",
            "such",
            " as",
            " fish",
            ",",
            " chicken",
            ",",
            " pork",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.602,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 55,
          "is_repeated_datapoint": false,
          "tokens": [
            " with",
            " one",
            " another",
            " first",
            ".",
            " This",
            " may",
            " be",
            " due",
            " to",
            " better",
            " cooper",
            "at",
            "iveness",
            " assessments",
            " or",
            " promises",
            " exchange",
            ".",
            " They",
            " are",
            " more",
            " cooperative",
            " if",
            " they",
            " can",
            " gradually",
            " build",
            " trust",
            " instead",
            " of",
            " being",
            " asked",
            " to",
            " give",
            " extensive",
            " help",
            " immediately",
            ".",
            " Direct",
            " recipro",
            "city",
            " and",
            " cooperation",
            " in",
            " a",
            " group",
            " can",
            " be",
            " increased",
            " by",
            " changing",
            " the",
            " focus",
            " and",
            " incentives",
            " from",
            " intra",
            "-group",
            " competition",
            " to",
            " larger",
            "-scale"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.602,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            "ati",
            "ens",
            ",",
            " mir",
            "abil",
            "is",
            ",",
            " wax",
            " beg",
            "onia",
            ",",
            " snap",
            "dragon",
            ",",
            " pel",
            "argon",
            "ium",
            ",",
            " cole",
            "us",
            " and",
            " pet",
            "un",
            "ia",
            ".",
            " Examples",
            " of",
            " true",
            " annual",
            "s",
            " include",
            " corn",
            ",",
            " wheat",
            ",",
            " rice",
            ",",
            " lettuce",
            ",",
            " peas",
            ",",
            " water",
            "melon",
            ",",
            " beans",
            ",",
            " z",
            "inn",
            "ia",
            " and",
            " mar",
            "ig",
            "old",
            ".",
            "Summer",
            "Summer",
            " annual",
            "s",
            " spr",
            "out",
            ",",
            " flower"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " leaf",
            " vegetables",
            " like",
            " lettuce",
            ",",
            " sun",
            "flower",
            " seeds",
            ",",
            " art",
            "ich",
            "okes",
            ",",
            " sweet",
            "ening",
            " agents",
            ",",
            " coffee",
            " substitutes",
            " and",
            " herbal",
            " teas",
            ".",
            " Several",
            " genera",
            " are",
            " of",
            " h",
            "ort",
            "icultural",
            " importance",
            ",",
            " including",
            " pot",
            " mar",
            "ig",
            "old",
            " (",
            "Cal",
            "end",
            "ula",
            " offic",
            "inal",
            "is",
            "),",
            " E",
            "chin",
            "acea",
            " (",
            "con",
            "ef",
            "low",
            "ers",
            "),",
            " various",
            " d",
            "ais",
            "ies",
            ",",
            " fle",
            "ab",
            "ane",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            " nearly",
            " so",
            ".",
            "Uses",
            "The",
            " Ast",
            "era",
            "les",
            ",",
            " by",
            " dint",
            " of",
            " being",
            " a",
            " super",
            "-set",
            " of",
            " the",
            " family",
            " Aster",
            "aceae",
            ",",
            " include",
            " some",
            " species",
            " grown",
            " for",
            " food",
            ",",
            " including",
            " the",
            " sun",
            "flower",
            " (",
            "Hel",
            "ian",
            "thus",
            " ann",
            "u",
            "us",
            "),",
            " lettuce",
            " (",
            "L",
            "act",
            "u",
            "ca",
            " sat",
            "iva",
            ")",
            " and",
            " chic",
            "ory",
            " (",
            "C",
            "ich",
            "or",
            "ium",
            ").",
            " Many",
            " are",
            " also"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " leaf",
            " vegetables",
            " like",
            " lettuce",
            ",",
            " sun",
            "flower",
            " seeds",
            ",",
            " art",
            "ich",
            "okes",
            ",",
            " sweet",
            "ening",
            " agents",
            ",",
            " coffee",
            " substitutes",
            " and",
            " herbal",
            " teas",
            ".",
            " Several",
            " genera",
            " are",
            " of",
            " h",
            "ort",
            "icultural",
            " importance",
            ",",
            " including",
            " pot",
            " mar",
            "ig",
            "old",
            " (",
            "Cal",
            "end",
            "ula",
            " offic",
            "inal",
            "is",
            "),",
            " E",
            "chin",
            "acea",
            " (",
            "con",
            "ef",
            "low",
            "ers",
            "),",
            " various",
            " d",
            "ais",
            "ies",
            ",",
            " fle",
            "ab",
            "ane",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            " European",
            " Union",
            "'s",
            " European",
            " Ne",
            "ighbour",
            "hood",
            " Policy",
            " (",
            "EN",
            "P",
            ")",
            " which",
            " aims",
            " at",
            " bringing",
            " the",
            " EU",
            " and",
            " its",
            " neighbours",
            " closer",
            ".",
            "Giving",
            " incentives",
            " and",
            " rewarding",
            " best",
            " performers",
            ",",
            " as",
            " well",
            " as",
            " offering",
            " funds",
            " in",
            " a",
            " faster",
            " and",
            " more",
            " flexible",
            " manner",
            ",",
            " are",
            " the",
            " two",
            " main",
            " principles",
            " underlying",
            " the",
            " European",
            " Ne",
            "ighbour",
            "hood",
            " Instrument",
            " (",
            "EN",
            "I",
            ")",
            " that",
            " came",
            " into",
            " force"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 29,
          "is_repeated_datapoint": false,
          "tokens": [
            " be",
            " made",
            " by",
            " political",
            " means",
            ",",
            " thus",
            " potential",
            " rulers",
            " were",
            " unins",
            "pired",
            " to",
            " seek",
            " power",
            ".",
            "When",
            " the",
            " war",
            " ended",
            " in",
            " ",
            "178",
            "3",
            ",",
            " certain",
            " special",
            " interests",
            " had",
            " incentives",
            " to",
            " create",
            " a",
            " new",
            " \"",
            "merchant",
            " state",
            ",\"",
            " much",
            " like",
            " the",
            " British",
            " state",
            " people",
            " had",
            " rebel",
            "led",
            " against",
            ".",
            " In",
            " particular",
            ",",
            " holders",
            " of",
            " war",
            " scri",
            "p",
            " and",
            " land",
            " spec",
            "ulators",
            " wanted",
            " a"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.586,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.167,
            0.095,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " whole",
            ")",
            " intrinsic",
            " and",
            " reput",
            "ational",
            " incentives",
            ",",
            " motivating",
            " the",
            " person",
            " to",
            " focus",
            " on",
            " obtaining",
            " the",
            " extr",
            "insic",
            " rewards",
            ",",
            " which",
            " may",
            " make",
            " the",
            " thus",
            "-in",
            "cent",
            "iv",
            "ized",
            " behaviors",
            " less",
            " desirable",
            ".",
            " People",
            " prefer",
            " altru",
            "ism",
            " in",
            " others",
            " when",
            " it",
            " appears",
            " to",
            " be",
            " due",
            " to",
            " a",
            " personality",
            " characteristic",
            " rather",
            " than",
            " overt",
            " reput",
            "ational",
            " concerns",
            ";",
            " simply",
            " pointing",
            " out",
            " that",
            " there",
            " are",
            " reput"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.586,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.167,
            0.095,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " whole",
            ")",
            " intrinsic",
            " and",
            " reput",
            "ational",
            " incentives",
            ",",
            " motivating",
            " the",
            " person",
            " to",
            " focus",
            " on",
            " obtaining",
            " the",
            " extr",
            "insic",
            " rewards",
            ",",
            " which",
            " may",
            " make",
            " the",
            " thus",
            "-in",
            "cent",
            "iv",
            "ized",
            " behaviors",
            " less",
            " desirable",
            ".",
            " People",
            " prefer",
            " altru",
            "ism",
            " in",
            " others",
            " when",
            " it",
            " appears",
            " to",
            " be",
            " due",
            " to",
            " a",
            " personality",
            " characteristic",
            " rather",
            " than",
            " overt",
            " reput",
            "ational",
            " concerns",
            ";",
            " simply",
            " pointing",
            " out",
            " that",
            " there",
            " are",
            " reput"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.586,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.167,
            0.095,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " whole",
            ")",
            " intrinsic",
            " and",
            " reput",
            "ational",
            " incentives",
            ",",
            " motivating",
            " the",
            " person",
            " to",
            " focus",
            " on",
            " obtaining",
            " the",
            " extr",
            "insic",
            " rewards",
            ",",
            " which",
            " may",
            " make",
            " the",
            " thus",
            "-in",
            "cent",
            "iv",
            "ized",
            " behaviors",
            " less",
            " desirable",
            ".",
            " People",
            " prefer",
            " altru",
            "ism",
            " in",
            " others",
            " when",
            " it",
            " appears",
            " to",
            " be",
            " due",
            " to",
            " a",
            " personality",
            " characteristic",
            " rather",
            " than",
            " overt",
            " reput",
            "ational",
            " concerns",
            ";",
            " simply",
            " pointing",
            " out",
            " that",
            " there",
            " are",
            " reput"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.582,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 21,
          "is_repeated_datapoint": false,
          "tokens": [
            " iPhone",
            " ",
            "7",
            " at",
            " its",
            " Bengal",
            "uru",
            " facility",
            ",",
            " keeping",
            " in",
            " mind",
            " demand",
            " from",
            " local",
            " customers",
            " even",
            " as",
            " they",
            " seek",
            " more",
            " incentives",
            " from",
            " the",
            " government",
            " of",
            " India",
            ".",
            " At",
            " the",
            " beginning",
            " of",
            " ",
            "202",
            "0",
            ",",
            " Tim",
            " Cook",
            " announced",
            " that",
            " Apple",
            " schedules",
            " the",
            " opening",
            " of",
            " its",
            " first",
            " physical",
            " outlet",
            " in",
            " India",
            " for",
            " ",
            "202",
            "1",
            ",",
            " while",
            " an",
            " online",
            " store",
            " is",
            " to",
            " be"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.582,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 21,
          "is_repeated_datapoint": false,
          "tokens": [
            " iPhone",
            " ",
            "7",
            " at",
            " its",
            " Bengal",
            "uru",
            " facility",
            ",",
            " keeping",
            " in",
            " mind",
            " demand",
            " from",
            " local",
            " customers",
            " even",
            " as",
            " they",
            " seek",
            " more",
            " incentives",
            " from",
            " the",
            " government",
            " of",
            " India",
            ".",
            " At",
            " the",
            " beginning",
            " of",
            " ",
            "202",
            "0",
            ",",
            " Tim",
            " Cook",
            " announced",
            " that",
            " Apple",
            " schedules",
            " the",
            " opening",
            " of",
            " its",
            " first",
            " physical",
            " outlet",
            " in",
            " India",
            " for",
            " ",
            "202",
            "1",
            ",",
            " while",
            " an",
            " online",
            " store",
            " is",
            " to",
            " be"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.578,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 32,
          "is_repeated_datapoint": false,
          "tokens": [
            " reflect",
            " information",
            ",",
            " the",
            " tot",
            "ality",
            " of",
            " which",
            " is",
            " not",
            " known",
            " to",
            " any",
            " single",
            " individual",
            ",",
            " which",
            " determines",
            " the",
            " allocation",
            " of",
            " resources",
            " in",
            " an",
            " economy",
            ".",
            " Because",
            " socialist",
            " systems",
            " lack",
            " the",
            " individual",
            " incentives",
            " and",
            " price",
            " discovery",
            " processes",
            " by",
            " which",
            " individuals",
            " act",
            " on",
            " their",
            " personal",
            " information",
            ",",
            " Hay",
            "ek",
            " argued",
            " that",
            " socialist",
            " economic",
            " planners",
            " lack",
            " all",
            " of",
            " the",
            " knowledge",
            " required",
            " to",
            " make",
            " optimal",
            " decisions"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.578,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 32,
          "is_repeated_datapoint": false,
          "tokens": [
            " reflect",
            " information",
            ",",
            " the",
            " tot",
            "ality",
            " of",
            " which",
            " is",
            " not",
            " known",
            " to",
            " any",
            " single",
            " individual",
            ",",
            " which",
            " determines",
            " the",
            " allocation",
            " of",
            " resources",
            " in",
            " an",
            " economy",
            ".",
            " Because",
            " socialist",
            " systems",
            " lack",
            " the",
            " individual",
            " incentives",
            " and",
            " price",
            " discovery",
            " processes",
            " by",
            " which",
            " individuals",
            " act",
            " on",
            " their",
            " personal",
            " information",
            ",",
            " Hay",
            "ek",
            " argued",
            " that",
            " socialist",
            " economic",
            " planners",
            " lack",
            " all",
            " of",
            " the",
            " knowledge",
            " required",
            " to",
            " make",
            " optimal",
            " decisions"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.003,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.57,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 55,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " present",
            ",",
            " some",
            " have",
            " shorter",
            " time",
            " hor",
            "izons",
            " than",
            " others",
            ",",
            " and",
            " these",
            " people",
            " tend",
            " to",
            " be",
            " less",
            " cooperative",
            ".",
            "Explicit",
            " extr",
            "insic",
            " rewards",
            " and",
            " punishments",
            " have",
            " sometimes",
            " been",
            " found",
            " to",
            " have",
            " a",
            " counter",
            "int",
            "uit",
            "ively",
            " inverse",
            " effect",
            " on",
            " behaviors",
            " when",
            " compared",
            " to",
            " intrinsic",
            " rewards",
            ".",
            " This",
            " may",
            " be",
            " because",
            " such",
            " extr",
            "insic",
            " incentives",
            " may",
            " replace",
            " (",
            "part",
            "ially",
            " or",
            " in"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.543,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 21,
          "is_repeated_datapoint": false,
          "tokens": [
            " North",
            " America",
            " from",
            " California",
            " to",
            " British",
            " Columbia",
            ",",
            " in",
            " Hawaii",
            " and",
            " by",
            " the",
            " M",
            "Äģ",
            "ori",
            " of",
            " New",
            " Zealand",
            ".",
            " Sea",
            " lettuce",
            " and",
            " b",
            "adder",
            "locks",
            " are",
            " salad",
            " ingredients",
            " in",
            " Scotland",
            ",",
            " Ireland",
            ",",
            " Greenland",
            ",",
            " and",
            " Iceland",
            ".",
            " Al",
            "gae",
            " is",
            " being",
            " considered",
            " a",
            " potential",
            " solution",
            " for",
            " world",
            " hunger",
            " problem",
            ".",
            "Two",
            " popular",
            " forms",
            " of",
            " algae",
            " are",
            " used",
            " in",
            " cuisine",
            ":",
            " Ch"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.48,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "ias",
            " tried",
            " to",
            " escape",
            ",",
            " he",
            " tri",
            "pped",
            " over",
            " a",
            " vine",
            " and",
            " was",
            " killed",
            " by",
            " his",
            " purs",
            "uers",
            ",",
            " including",
            " two",
            " of",
            " Alexander",
            "'s",
            " companions",
            ",",
            " Per",
            "dic",
            "cas",
            " and",
            " Leon",
            "n",
            "atus",
            ".",
            " Alexander",
            " was",
            " proclaimed",
            " king",
            " on",
            " the",
            " spot",
            " by",
            " the",
            " nob",
            "les",
            " and",
            " army",
            " at",
            " the",
            " age",
            " of",
            " ",
            "20",
            ".",
            "Cons",
            "olid",
            "ation",
            " of",
            " power",
            "Alexander",
            " began",
            " his"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.344,
            -0.0,
            -0.0,
            -0.0,
            0.455,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " involved",
            ".",
            "Rare",
            "ly",
            " parasites",
            " can",
            " cause",
            " abs",
            "cess",
            "es",
            " and",
            " this",
            " is",
            " more",
            " common",
            " in",
            " the",
            " developing",
            " world",
            ".",
            " Specific",
            " parasites",
            " known",
            " to",
            " do",
            " this",
            " include",
            " dr",
            "ac",
            "unc",
            "ul",
            "ias",
            "is",
            " and",
            " my",
            "ias",
            "is",
            ".",
            "Per",
            "ian",
            "al",
            " abs",
            "cess",
            "S",
            "urgery",
            " of",
            " the",
            " anal",
            " fist",
            "ula",
            " to",
            " drain",
            " an",
            " abs",
            "cess",
            " treats",
            " the",
            " fist",
            "ula",
            " and",
            " reduces",
            " likelihood"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.43
          ],
          "train_token_ind": 62,
          "is_repeated_datapoint": false,
          "tokens": [
            " Mag",
            "h",
            "reb",
            ",",
            " and",
            " the",
            " order",
            " of",
            " the",
            " letters",
            " was",
            " slightly",
            " different",
            " (",
            "at",
            " least",
            " when",
            " they",
            " were",
            " used",
            " as",
            " numer",
            "als",
            ").",
            "However",
            ",",
            " the",
            " old",
            " Mag",
            "h",
            "re",
            "bi",
            " variant",
            " has",
            " been",
            " abandoned",
            " except",
            " for",
            " call",
            "igraph",
            "ic",
            " purposes",
            " in",
            " the",
            " Mag",
            "h",
            "reb",
            " itself",
            ",",
            " and",
            " remains",
            " in",
            " use",
            " mainly",
            " in",
            " the",
            " Quran",
            "ic",
            " schools",
            " (",
            "za",
            "ou",
            "ias"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.428,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " le",
            "ish",
            "man",
            "ias",
            "is",
            " in",
            " domestic",
            " animals",
            ".",
            " Besides",
            " having",
            " low",
            " therapeutic",
            " indices",
            ",",
            " the",
            " drugs",
            " have",
            " minimal",
            " penetration",
            " of",
            " the",
            " bone",
            " marrow",
            ",",
            " where",
            " some",
            " of",
            " the",
            " Le",
            "ish",
            "mania",
            " am",
            "ast",
            "ig",
            "otes",
            " reside",
            ",",
            " and",
            " curing",
            " the",
            " disease",
            " –",
            " especially",
            " the",
            " visceral",
            " form",
            " –",
            " is",
            " very",
            " difficult",
            ".",
            " Elemental",
            " ant",
            "imony",
            " as",
            " an",
            " ant",
            "imony",
            " pill",
            " was",
            " once"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.426,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " poisoning",
            " by",
            " Olymp",
            "ias",
            ".",
            "News",
            " of",
            " Philip",
            "'s",
            " death",
            " r",
            "oused",
            " many",
            " states",
            " into",
            " revolt",
            ",",
            " including",
            " The",
            "bes",
            ",",
            " Athens",
            ",",
            " Th",
            "ess",
            "aly",
            ",",
            " and",
            " the",
            " Th",
            "rac",
            "ian",
            " tribes",
            " north",
            " of",
            " Maced",
            "on",
            ".",
            " When",
            " news",
            " of",
            " the",
            " rev",
            "ol",
            "ts",
            " reached",
            " Alexander",
            ",",
            " he",
            " responded",
            " quickly",
            ".",
            " Though",
            " advised",
            " to",
            " use",
            " diplomacy",
            ",",
            " Alexander",
            " must",
            "ered",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.422,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.157,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            " carried",
            " the",
            " I",
            "li",
            "ad",
            " with",
            " him",
            ",",
            " but",
            " his",
            " court",
            " bi",
            "ographers",
            " do",
            " not",
            " mention",
            " the",
            " spear",
            ";",
            " however",
            ",",
            " it",
            " was",
            " shown",
            " in",
            " the",
            " time",
            " of",
            " P",
            "aus",
            "an",
            "ias",
            " in",
            " the",
            " ",
            "2",
            "nd",
            " century",
            " CE",
            ".",
            "A",
            "ch",
            "illes",
            ",",
            " Ajax",
            " and",
            " a",
            " game",
            " of",
            " p",
            "ette",
            "ia",
            " ",
            "Numer",
            "ous",
            " paintings",
            " on",
            " pottery",
            " have",
            " suggested",
            " a",
            " tale",
            " not"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.422,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.35,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            " Deng",
            "ue",
            ",",
            " fil",
            "ari",
            "asis",
            ",",
            " le",
            "ish",
            "man",
            "ias",
            "is",
            " and",
            " on",
            "ch",
            "oc",
            "erc",
            "ias",
            "is",
            " (",
            "river",
            " blindness",
            ")",
            " are",
            " other",
            " diseases",
            " carried",
            " by",
            " insects",
            " that",
            " also",
            " occur",
            " in",
            " the",
            " region",
            ".",
            " Angola",
            " has",
            " one",
            " of",
            " the",
            " highest",
            " infant",
            " mortality",
            " rates",
            " in",
            " the",
            " world",
            " and",
            " one",
            " of",
            " the",
            " world",
            "'s",
            " lowest",
            " life",
            " expect",
            "ancies",
            ".",
            " A",
            " ",
            "200",
            "7"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.42,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " himself",
            ",",
            " in",
            " a",
            " dream",
            ",",
            " securing",
            " his",
            " wife",
            "'s",
            " womb",
            " with",
            " a",
            " seal",
            " engraved",
            " with",
            " a",
            " lion",
            "'s",
            " image",
            ".",
            " Pl",
            "ut",
            "arch",
            " offered",
            " a",
            " variety",
            " of",
            " interpretations",
            " for",
            " these",
            " dreams",
            ":",
            " that",
            " Olymp",
            "ias",
            " was",
            " pregnant",
            " before",
            " her",
            " marriage",
            ",",
            " indicated",
            " by",
            " the",
            " sealing",
            " of",
            " her",
            " womb",
            ";",
            " or",
            " that",
            " Alexander",
            "'s",
            " father",
            " was",
            " Zeus",
            ".",
            " Ancient",
            " commentators",
            " were",
            " divided",
            " about"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.42,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            " normal",
            ",",
            " or",
            " can",
            "'t",
            " get",
            " it",
            " out",
            " of",
            " your",
            " mind",
            ".\"",
            "The",
            " physiological",
            " symptoms",
            " of",
            " anxiety",
            " may",
            " include",
            ":",
            "Ne",
            "uro",
            "logical",
            ",",
            " as",
            " headache",
            ",",
            " p",
            "arest",
            "hes",
            "ias",
            ",",
            " fasc",
            "ic",
            "ulations",
            ",",
            " vert",
            "igo",
            ",",
            " or",
            " pres",
            "yn",
            "cope",
            ".",
            "Digest",
            "ive",
            ",",
            " as",
            " abdominal",
            " pain",
            ",",
            " nausea",
            ",",
            " diarrhea",
            ",",
            " ind",
            "igest",
            "ion",
            ",",
            " dry",
            " mouth",
            ",",
            " or"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.42,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 11,
          "is_repeated_datapoint": false,
          "tokens": [
            " ch",
            "rys",
            "anth",
            "em",
            "ums",
            ",",
            " dah",
            "lias",
            ",",
            " z",
            "inn",
            "ias",
            ",",
            " and",
            " h",
            "elenium",
            "s",
            ".",
            " Aster",
            "aceae",
            " are",
            " important",
            " in",
            " herbal",
            " medicine",
            ",",
            " including",
            " Gr",
            "ind",
            "elia",
            ",",
            " y",
            "arrow",
            ",",
            " and",
            " many",
            " others",
            ".",
            "Commercial",
            "ly",
            " important",
            " plants",
            " in",
            " Aster",
            "aceae",
            " include",
            " the",
            " food",
            " crops",
            " L",
            "act",
            "u",
            "ca",
            " sat",
            "iva",
            " (",
            "lett",
            "uce",
            "),",
            " C",
            "ich",
            "or",
            "ium"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.42,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " himself",
            ",",
            " in",
            " a",
            " dream",
            ",",
            " securing",
            " his",
            " wife",
            "'s",
            " womb",
            " with",
            " a",
            " seal",
            " engraved",
            " with",
            " a",
            " lion",
            "'s",
            " image",
            ".",
            " Pl",
            "ut",
            "arch",
            " offered",
            " a",
            " variety",
            " of",
            " interpretations",
            " for",
            " these",
            " dreams",
            ":",
            " that",
            " Olymp",
            "ias",
            " was",
            " pregnant",
            " before",
            " her",
            " marriage",
            ",",
            " indicated",
            " by",
            " the",
            " sealing",
            " of",
            " her",
            " womb",
            ";",
            " or",
            " that",
            " Alexander",
            "'s",
            " father",
            " was",
            " Zeus",
            ".",
            " Ancient",
            " commentators",
            " were",
            " divided",
            " about"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.418,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            " public",
            " meeting",
            " place",
            ".",
            " The",
            " building",
            " of",
            " Dok",
            "k",
            "1",
            " and",
            " the",
            " associated",
            " squares",
            " and",
            " streets",
            "cape",
            " is",
            " also",
            " collectively",
            " known",
            " as",
            " Urban",
            " Med",
            "ias",
            "pace",
            " A",
            "arhus",
            " and",
            " it",
            " is",
            " the",
            " largest",
            " construction",
            " project",
            " A",
            "arhus",
            " municipality",
            " has",
            " yet",
            " undertaken",
            ".",
            " Apart",
            " from",
            " this",
            " large",
            " main",
            " library",
            ",",
            " some",
            " neighbourhood",
            "s",
            " in",
            " A",
            "arhus",
            " have",
            " a",
            " local",
            " library",
            " engaged",
            " in",
            " similar",
            " cultural"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.418,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.418,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " Corn",
            "hill",
            " Publishing",
            " Co",
            ".",
            " ",
            "192",
            "2",
            ".",
            " Online",
            " version",
            " at",
            " the",
            " Per",
            "se",
            "us",
            " Digital",
            " Library",
            ".",
            " ",
            "10",
            ".",
            " ",
            "162",
            "–",
            "219",
            " (",
            "1",
            "–",
            "8",
            " CE",
            ")",
            " P",
            "aus",
            "an",
            "ias",
            ",",
            " P",
            "aus",
            "an",
            "ias",
            " Description",
            " of",
            " Greece",
            " with",
            " an",
            " English",
            " Translation",
            " by",
            " W",
            ".H",
            ".S",
            ".",
            " Jones",
            ",",
            " L",
            "itt",
            ".D",
            ".,",
            " and",
            " H",
            ".A",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.418,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.418,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " Corn",
            "hill",
            " Publishing",
            " Co",
            ".",
            " ",
            "192",
            "2",
            ".",
            " Online",
            " version",
            " at",
            " the",
            " Per",
            "se",
            "us",
            " Digital",
            " Library",
            ".",
            " ",
            "10",
            ".",
            " ",
            "162",
            "–",
            "219",
            " (",
            "1",
            "–",
            "8",
            " CE",
            ")",
            " P",
            "aus",
            "an",
            "ias",
            ",",
            " P",
            "aus",
            "an",
            "ias",
            " Description",
            " of",
            " Greece",
            " with",
            " an",
            " English",
            " Translation",
            " by",
            " W",
            ".H",
            ".S",
            ".",
            " Jones",
            ",",
            " L",
            "itt",
            ".D",
            ".,",
            " and",
            " H",
            ".A",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.418,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.418,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " Corn",
            "hill",
            " Publishing",
            " Co",
            ".",
            " ",
            "192",
            "2",
            ".",
            " Online",
            " version",
            " at",
            " the",
            " Per",
            "se",
            "us",
            " Digital",
            " Library",
            ".",
            " ",
            "10",
            ".",
            " ",
            "162",
            "–",
            "219",
            " (",
            "1",
            "–",
            "8",
            " CE",
            ")",
            " P",
            "aus",
            "an",
            "ias",
            ",",
            " P",
            "aus",
            "an",
            "ias",
            " Description",
            " of",
            " Greece",
            " with",
            " an",
            " English",
            " Translation",
            " by",
            " W",
            ".H",
            ".S",
            ".",
            " Jones",
            ",",
            " L",
            "itt",
            ".D",
            ".,",
            " and",
            " H",
            ".A",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.416,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 8,
          "is_repeated_datapoint": false,
          "tokens": [
            "sy",
            ",",
            " fe",
            "vers",
            ",",
            " strang",
            "ulated",
            " hern",
            "ias",
            ",",
            " nec",
            "rosis",
            ",",
            " abdominal",
            " tum",
            "ours",
            " and",
            " chronic",
            " const",
            "ipation",
            " and",
            " nicotine",
            " poisoning",
            ",",
            " while",
            " also",
            " attempting",
            " to",
            " deal",
            " with",
            " deliberate",
            " poison",
            "ings",
            ",",
            " fetish",
            "ism",
            " and",
            " fear",
            " of",
            " cann",
            "ibal",
            "ism",
            " among",
            " the",
            " Mb",
            "ah",
            "ou",
            "in",
            ".",
            "Sch",
            "we",
            "itzer",
            "'s",
            " wife",
            ",",
            " Hel",
            "ene",
            " Schwe",
            "itzer",
            ",",
            " served",
            " as",
            " an"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.408,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 55,
          "is_repeated_datapoint": false,
          "tokens": [
            " family",
            " friend",
            ",",
            " Dem",
            "ar",
            "atus",
            ",",
            " who",
            " mediated",
            " between",
            " the",
            " two",
            " parties",
            ".",
            "In",
            " the",
            " following",
            " year",
            ",",
            " the",
            " Persian",
            " sat",
            "rap",
            " (",
            "g",
            "overn",
            "or",
            ")",
            " of",
            " Car",
            "ia",
            ",",
            " Pix",
            "od",
            "arus",
            ",",
            " offered",
            " his",
            " eldest",
            " daughter",
            " to",
            " Alexander",
            "'s",
            " half",
            "-b",
            "ro",
            "ther",
            ",",
            " Philip",
            " Arr",
            "h",
            "ida",
            "eus",
            ".",
            " Olymp",
            "ias",
            " and",
            " several",
            " of",
            " Alexander",
            "'s",
            " friends",
            " suggested"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.369
          ],
          "train_token_ind": 62,
          "is_repeated_datapoint": false,
          "tokens": [
            "aged",
            " ",
            "15",
            "–",
            "49",
            ")",
            " are",
            " living",
            " with",
            " HIV",
            "/AIDS",
            " (",
            "as",
            " of",
            " ",
            "200",
            "9",
            ").",
            " The",
            " risk",
            " of",
            " contracting",
            " disease",
            " is",
            " very",
            " high",
            ".",
            " There",
            " are",
            " food",
            " and",
            " water",
            "borne",
            " diseases",
            ",",
            " bacterial",
            " and",
            " proto",
            "zo",
            "al",
            " diarrhea",
            ",",
            " hepatitis",
            " A",
            ",",
            " and",
            " ty",
            "ph",
            "oid",
            " fever",
            ";",
            " vector",
            "borne",
            " diseases",
            ",",
            " malaria",
            ",",
            " African",
            " try",
            "pan",
            "os",
            "om",
            "ias"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.369,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 16,
          "is_repeated_datapoint": false,
          "tokens": [
            " play",
            " called",
            " RÃ©",
            "vol",
            "te",
            " dans",
            " les",
            " Ast",
            "uries",
            " (",
            "Rev",
            "olt",
            " in",
            " the",
            " Ast",
            "ur",
            "ias",
            ")",
            " written",
            " with",
            " three",
            " friends",
            " in",
            " May",
            " ",
            "193",
            "6",
            ".",
            " The",
            " subject",
            " was",
            " the",
            " ",
            "193",
            "4",
            " revolt",
            " by",
            " Spanish",
            " miners",
            " that",
            " was",
            " brutally",
            " suppressed",
            " by",
            " the",
            " Spanish",
            " government",
            " resulting",
            " in",
            " ",
            "1",
            ",",
            "500",
            " to",
            " ",
            "2",
            ",",
            "000",
            " deaths",
            ".",
            " In",
            " May",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.322,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            " centers",
            " of",
            " Byz",
            "antine",
            " Anat",
            "olia",
            " included",
            " Ass",
            "os",
            ",",
            " Eph",
            "esus",
            ",",
            " M",
            "ilet",
            "us",
            ",",
            " N",
            "ica",
            "ea",
            ",",
            " P",
            "erg",
            "am",
            "um",
            ",",
            " Pri",
            "ene",
            ",",
            " S",
            "ard",
            "is",
            ",",
            " and",
            " Aph",
            "ro",
            "dis",
            "ias",
            ".",
            "From",
            " the",
            " mid",
            "-",
            "5",
            "th",
            " century",
            " onwards",
            ",",
            " urban",
            "ism",
            " was",
            " affected",
            " negatively",
            " and",
            " began",
            " to",
            " decline",
            ",",
            " while",
            " the",
            " rural",
            " areas",
            " reached"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.287,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            " M",
            "Ã¸",
            "ller",
            " have",
            " gained",
            " an",
            " international",
            " reputation",
            " for",
            " their",
            " contribution",
            " to",
            " functional",
            "ist",
            " architecture",
            ".",
            " The",
            " City",
            " Hall",
            " (",
            "A",
            "arhus",
            " R",
            "Ã¥",
            "d",
            "hus",
            ")",
            " from",
            " ",
            "194",
            "1",
            " with",
            " an",
            " iconic",
            " ",
            " tower",
            " clad",
            " in",
            " marble",
            ",",
            " was",
            " designed",
            " by",
            " Ar",
            "ne",
            " Jacobs",
            "en",
            " and",
            " Erik",
            " M",
            "Ã¸",
            "ller",
            " in",
            " a",
            " modern",
            " Function",
            "alist",
            " style",
            ".",
            "Culture",
            "A"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.27,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 15,
          "is_repeated_datapoint": false,
          "tokens": [
            " un",
            "placed",
            ".",
            " A",
            " ",
            "202",
            "1",
            " study",
            " suggested",
            " the",
            " relationships",
            " shown",
            " in",
            " the",
            " following",
            " clad",
            "ogram",
            ".",
            "The",
            " Plat",
            "ys",
            "ace",
            " cl",
            "ade",
            " and",
            " the",
            " genera",
            " K",
            "lot",
            "z",
            "sch",
            "ia",
            " and",
            " Herm",
            "as",
            " fell",
            " outside",
            " the",
            " four",
            " sub",
            "f",
            "amilies",
            ".",
            " It",
            " was",
            " suggested",
            " that",
            " they",
            " could",
            " be",
            " accommod",
            "ated",
            " in",
            " sub",
            "f",
            "amilies",
            " of",
            " their",
            " own",
            ".",
            " Ph",
            "ly",
            "ct"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.235,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            " Rebellion",
            ",",
            " some",
            " prominent",
            " political",
            " thinkers",
            " in",
            " the",
            " fled",
            "g",
            "ling",
            " union",
            " began",
            " asking",
            " for",
            " changes",
            " to",
            " the",
            " Articles",
            ".",
            " Their",
            " hope",
            " was",
            " to",
            " create",
            " a",
            " stronger",
            " government",
            ".",
            " Initially",
            ",",
            " in",
            " September",
            " ",
            "178",
            "6",
            ",",
            " some",
            " states",
            " met",
            " to",
            " address",
            " interstate",
            " protection",
            "ist",
            " trade",
            " barriers",
            " between",
            " them",
            ".",
            " Shortly",
            " thereafter",
            ",",
            " as",
            " more",
            " states",
            " became",
            " interested",
            " in",
            " meeting",
            " to",
            " revise",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.227,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " easy",
            " adoption",
            " of",
            " all",
            "-wheel",
            " drive",
            ",",
            " it",
            " goes",
            " against",
            " the",
            " ideal",
            " ",
            "50",
            ":",
            "50",
            " weight",
            " distribution",
            ".",
            "In",
            " all",
            " its",
            " post",
            " Volkswagen",
            "-era",
            " models",
            ",",
            " Audi",
            " has",
            " firmly",
            " refused",
            " to",
            " adopt",
            " the",
            " traditional",
            " rear",
            "-wheel",
            " drive",
            " layout",
            " favored",
            " by",
            " its",
            " two",
            " arch",
            "r",
            "ivals",
            " Mercedes",
            "-Benz",
            " and",
            " BMW",
            ",",
            " favor",
            "ing",
            " either",
            " front",
            "-wheel",
            " drive",
            " or",
            " all",
            "-wheel",
            " drive",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.178,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.176,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "berg",
            ");",
            " The",
            " Jean",
            " H",
            "ersh",
            "olt",
            " Human",
            "itarian",
            " Award",
            " (",
            "since",
            " ",
            "195",
            "7",
            ")",
            " (",
            "in",
            " the",
            " form",
            " of",
            " an",
            " Oscar",
            " stat",
            "u",
            "ette",
            ");",
            " ",
            " The",
            " Academy",
            " Scientific",
            " and",
            " Technical",
            " Awards",
            ":",
            " Academy",
            " Award",
            " of",
            " Mer",
            "it",
            " (",
            "non",
            "-",
            "competitive",
            ")",
            " (",
            "in",
            " the",
            " form",
            " of",
            " an",
            " Oscar",
            " stat",
            "u",
            "ette",
            ");",
            " Scientific",
            " and",
            " Engineering",
            " Award",
            " (",
            "in",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.155,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 17,
          "is_repeated_datapoint": false,
          "tokens": [
            "s",
            " through",
            " the",
            " National",
            " Hot",
            " Rod",
            " Association",
            " (",
            "NH",
            "RA",
            ").",
            " The",
            " NH",
            "RA",
            " was",
            " formed",
            " to",
            " discourage",
            " street",
            " racing",
            ".",
            "When",
            " launching",
            ",",
            " a",
            " top",
            " fuel",
            " drag",
            "ster",
            " will",
            " accelerate",
            " at",
            " ",
            "3",
            ".",
            "4",
            " g",
            " (",
            "33",
            "Âłm",
            "/s",
            "2",
            "),",
            " and",
            " when",
            " braking",
            " parach",
            "utes",
            " are",
            " deployed",
            " the",
            " dec",
            "eler",
            "ation",
            " is",
            " ",
            "4",
            "Âł",
            "g",
            " (",
            "39",
            "Âłm",
            "/s"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.023,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.015,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            " mixing",
            " an",
            "hy",
            "d",
            "rous",
            " aluminium",
            " chloride",
            " with",
            " potassium",
            " and",
            " produced",
            " a",
            " powder",
            " of",
            " aluminium",
            ".",
            " In",
            " ",
            "184",
            "5",
            ",",
            " he",
            " was",
            " able",
            " to",
            " produce",
            " small",
            " pieces",
            " of",
            " the",
            " metal",
            " and",
            " described",
            " some",
            " physical",
            " properties",
            " of",
            " this",
            " metal",
            ".",
            " For",
            " many",
            " years",
            " thereafter",
            ",",
            " W",
            "Ã¶h",
            "ler",
            " was",
            " credited",
            " as",
            " the",
            " discover",
            "er",
            " of",
            " aluminium",
            ".",
            "As",
            " W",
            "Ã¶h",
            "ler",
            "'s",
            " method"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " ad",
            "obe",
            " structures",
            " were",
            " widely",
            " damaged",
            " during",
            " earthquakes",
            " include",
            " the",
            " ",
            "197",
            "6",
            " Guatemala",
            " earthquake",
            ",",
            " the",
            " ",
            "200",
            "3",
            " Bam",
            " earthquake",
            ",",
            " and",
            " the",
            " ",
            "201",
            "0",
            " Chile",
            " earthquake",
            ".",
            "Distribution",
            "Build",
            "ings",
            " made",
            " of",
            " sun",
            "-d",
            "ried",
            " earth",
            " are",
            " common",
            " throughout",
            " the",
            " world",
            " (",
            "Middle",
            " East",
            ",",
            " Western",
            " Asia",
            ",",
            " North",
            " Africa",
            ",",
            " West",
            " Africa",
            ",",
            " South",
            " America",
            ",",
            " South"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " honorary",
            " degrees",
            " from",
            " Queen",
            "'s",
            " University",
            " at",
            " Kingston",
            " in",
            " ",
            "197",
            "9",
            ",",
            " University",
            " of",
            " Rome",
            " Tor",
            " Verg",
            "ata",
            " in",
            " ",
            "199",
            "7",
            ",",
            " University",
            " of",
            " Oslo",
            " in",
            " ",
            "199",
            "9",
            ",",
            " University",
            " of",
            " Southern",
            " Denmark",
            " in",
            " ",
            "200",
            "9",
            ",",
            " Univers",
            "itÃ©",
            " Libre",
            " de",
            " Br",
            "ux",
            "elles",
            " in",
            " ",
            "201",
            "0",
            " and",
            " Shanghai",
            " F",
            "ud",
            "an",
            " University",
            " in",
            " ",
            "201",
            "7",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " regions",
            " such",
            " as",
            " Europe",
            " and",
            " the",
            " U",
            ".S",
            ".,",
            " ant",
            "imony",
            " is",
            " considered",
            " to",
            " be",
            " a",
            " critical",
            " mineral",
            " for",
            " industrial",
            " manufacturing",
            " that",
            " is",
            " at",
            " risk",
            " of",
            " supply",
            " chain",
            " disruption",
            ".",
            " With",
            " ",
            " global",
            " ",
            " production",
            " coming",
            " mainly",
            " from",
            " China",
            " (",
            "74",
            "%),",
            " Taj",
            "ik",
            "istan",
            " (",
            "8",
            "%),",
            " and",
            " Russia",
            " (",
            "4",
            "%),",
            " these",
            " sources",
            " are",
            " critical",
            " to",
            " supply",
            ".",
            "European",
            " Union",
            ":"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            "After",
            " implementing",
            " the",
            " Em",
            "anc",
            "ipation",
            " Pro",
            "clamation",
            ",",
            " Lincoln",
            " increased",
            " pressure",
            " on",
            " Congress",
            " to",
            " outlaw",
            " slavery",
            " throughout",
            " the",
            " nation",
            " with",
            " a",
            " constitutional",
            " amendment",
            ".",
            " He",
            " declared",
            " that",
            " such",
            " an",
            " amendment",
            " would",
            " \"",
            "cl",
            "inch",
            " the",
            " whole",
            " matter",
            "\"",
            " and",
            " by",
            " December",
            " ",
            "186",
            "3",
            " an",
            " amendment",
            " was",
            " brought",
            " to",
            " Congress",
            ".",
            " The",
            " Senate",
            " passed",
            " it",
            " on",
            " April",
            " ",
            "8",
            ",",
            " "
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "onn",
    "inu",
    "ogl",
    "Ð¾Ð»Ñİ",
    " \""
  ],
  "bottom_logits": [
    "eview",
    "innacle",
    "á»¯u",
    "ÑģÑıÑĩ",
    "ocator"
  ],
  "act_min": -0.0,
  "act_max": 0.637
}
{
  "index": 14469,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.828,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            " space",
            "-based",
            " resources",
            " to",
            " build",
            " solar",
            "-power",
            " satellites",
            " and",
            " space",
            " habitats",
            ",",
            " becomes",
            " more",
            " attractive",
            ".",
            " Hyp",
            "oth",
            "etically",
            ",",
            " water",
            " processed",
            " from",
            " ice",
            " could",
            " ref",
            "uel",
            " orbit",
            "ing",
            " prop",
            "ellant",
            " dep",
            "ots",
            ".",
            "From",
            " the",
            " astro",
            "bi",
            "ological",
            " perspective",
            ",",
            " asteroid",
            " prospect",
            "ing",
            " could",
            " provide",
            " scientific",
            " data",
            " for",
            " the",
            " search",
            " for",
            " extr",
            "ater",
            "restrial",
            " intelligence",
            " (",
            "SET",
            "I",
            ").",
            " Some",
            " ast",
            "roph"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.699,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 29,
          "is_repeated_datapoint": false,
          "tokens": [
            "%.",
            " However",
            ",",
            " on",
            " ",
            "23",
            " March",
            " ",
            "201",
            "6",
            ",",
            " official",
            " data",
            " revealed",
            " by",
            " Angola",
            "'s",
            " National",
            " Stat",
            "istic",
            " Institute",
            " –",
            " Instituto",
            " Nacional",
            " de",
            " Est",
            "at",
            "ÃŃstica",
            " (",
            "INE",
            "),",
            " states",
            " that",
            " Angola",
            " has",
            " a",
            " population",
            " of",
            " ",
            "25",
            ",",
            "789",
            ",",
            "024",
            " inhabitants",
            ".",
            "It",
            " is",
            " estimated",
            " that",
            " Angola",
            " was",
            " host",
            " to",
            " ",
            "12",
            ",",
            "100",
            " refugees",
            " and",
            " ",
            "2",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.695,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.186,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.186,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 16,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " these",
            " are",
            " the",
            " same",
            " as",
            " the",
            " ASCII",
            " set",
            ".",
            "The",
            " Internet",
            " Assigned",
            " Numbers",
            " Authority",
            " (",
            "IAN",
            "A",
            ")",
            " prefers",
            " the",
            " name",
            " US",
            "-",
            "ASCII",
            " for",
            " this",
            " character",
            " encoding",
            ".",
            " ",
            "ASCII",
            " is",
            " one",
            " of",
            " the",
            " IEEE",
            " milestones",
            ".",
            "Overview",
            "ASCII",
            " was",
            " developed",
            " from",
            " tele",
            "graph",
            " code",
            ".",
            " Its",
            " first",
            " commercial",
            " use",
            " was",
            " in",
            " the",
            " Te",
            "let",
            "ype",
            " Model",
            " ",
            "33",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.125,
            0.007,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.008,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.691,
            -0.0,
            -0.0,
            0.234,
            0.061,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.002,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.695,
            -0.0,
            -0.0,
            0.241,
            0.065,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            "2",
            ")",
            " ANSI",
            " INC",
            "ITS",
            " ",
            "4",
            "-",
            "198",
            "6",
            " (",
            "R",
            "200",
            "7",
            ")",
            " (",
            "ANS",
            "I",
            ")",
            " INC",
            "ITS",
            " ",
            "4",
            "-",
            "198",
            "6",
            "[R",
            "201",
            "2",
            "]",
            " (",
            "ANS",
            "I",
            ")",
            " INC",
            "ITS",
            " ",
            "4",
            "-",
            "198",
            "6",
            "[R",
            "201",
            "7",
            "]",
            "In",
            " the",
            " X",
            "3",
            ".",
            "15",
            " standard",
            ",",
            " the",
            " X",
            "3",
            " committee",
            " also",
            " addressed",
            " how",
            " ASCII",
            " should",
            " be"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.695,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            "ed",
            " and",
            " has",
            " eventually",
            " been",
            " changed",
            ".",
            " ",
            "In",
            " modern",
            " usage",
            ",",
            " an",
            " ESC",
            " sent",
            " to",
            " the",
            " terminal",
            " usually",
            " indicates",
            " the",
            " start",
            " of",
            " a",
            " command",
            " sequence",
            " usually",
            " in",
            " the",
            " form",
            " of",
            " a",
            " so",
            "-called",
            " \"",
            "ANS",
            "I",
            " escape",
            " code",
            "\"",
            " (",
            "or",
            ",",
            " more",
            " properly",
            ",",
            " a",
            " \"",
            "Control",
            " Sequence",
            " Int",
            "rodu",
            "cer",
            "\")",
            " from",
            " EC",
            "MA",
            "-",
            "48",
            " (",
            "197",
            "2",
            ")"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.695,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 32,
          "is_repeated_datapoint": false,
          "tokens": [
            " so",
            " it",
            " did",
            " not",
            " have",
            " a",
            " key",
            " on",
            " its",
            " keyboard",
            " to",
            " send",
            " a",
            " BS",
            " (",
            "back",
            "space",
            ").",
            " Instead",
            ",",
            " there",
            " was",
            " a",
            " key",
            " marked",
            " ",
            " that",
            " sent",
            " code",
            " ",
            "127",
            " (",
            "DEL",
            ").",
            " The",
            " purpose",
            " of",
            " this",
            " key",
            " was",
            " to",
            " erase",
            " mistakes",
            " in",
            " a",
            " manually",
            "-input",
            " paper",
            " tape",
            ":",
            " the",
            " operator",
            " had",
            " to",
            " push",
            " a",
            " button",
            " on",
            " the",
            " tape",
            " punch",
            " to",
            " back"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.695,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            " are",
            " Italy",
            ",",
            " Greece",
            ",",
            " China",
            ",",
            " Spain",
            ",",
            " Kosovo",
            " and",
            " the",
            " United",
            " States",
            ".",
            " The",
            " le",
            "k",
            " (",
            "ALL",
            ")",
            " is",
            " the",
            " country",
            "'s",
            " currency",
            " and",
            " is",
            " peg",
            "ged",
            " at",
            " approximately",
            " ",
            "132",
            ".",
            "51",
            " le",
            "k",
            " per",
            " euro",
            ".",
            "The",
            " cities",
            " of",
            " Tir",
            "ana",
            " and",
            " D",
            "urr",
            "Ã«",
            "s",
            " constitute",
            " the",
            " economic",
            " and",
            " financial",
            " heart",
            " of",
            " Albania",
            " due",
            " to",
            " their",
            " high"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.125,
            0.007,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.008,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.691,
            -0.0,
            -0.0,
            0.234,
            0.061,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.002,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.695,
            -0.0,
            -0.0,
            0.241,
            0.065,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            "2",
            ")",
            " ANSI",
            " INC",
            "ITS",
            " ",
            "4",
            "-",
            "198",
            "6",
            " (",
            "R",
            "200",
            "7",
            ")",
            " (",
            "ANS",
            "I",
            ")",
            " INC",
            "ITS",
            " ",
            "4",
            "-",
            "198",
            "6",
            "[R",
            "201",
            "2",
            "]",
            " (",
            "ANS",
            "I",
            ")",
            " INC",
            "ITS",
            " ",
            "4",
            "-",
            "198",
            "6",
            "[R",
            "201",
            "7",
            "]",
            "In",
            " the",
            " X",
            "3",
            ".",
            "15",
            " standard",
            ",",
            " the",
            " X",
            "3",
            " committee",
            " also",
            " addressed",
            " how",
            " ASCII",
            " should",
            " be"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.125,
            0.007,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.008,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.691,
            -0.0,
            -0.0,
            0.234,
            0.061,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.002,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.695,
            -0.0,
            -0.0,
            0.241,
            0.065,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            "2",
            ")",
            " ANSI",
            " INC",
            "ITS",
            " ",
            "4",
            "-",
            "198",
            "6",
            " (",
            "R",
            "200",
            "7",
            ")",
            " (",
            "ANS",
            "I",
            ")",
            " INC",
            "ITS",
            " ",
            "4",
            "-",
            "198",
            "6",
            "[R",
            "201",
            "2",
            "]",
            " (",
            "ANS",
            "I",
            ")",
            " INC",
            "ITS",
            " ",
            "4",
            "-",
            "198",
            "6",
            "[R",
            "201",
            "7",
            "]",
            "In",
            " the",
            " X",
            "3",
            ".",
            "15",
            " standard",
            ",",
            " the",
            " X",
            "3",
            " committee",
            " also",
            " addressed",
            " how",
            " ASCII",
            " should",
            " be"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.004,
            -0.0,
            -0.0,
            -0.0,
            0.691,
            -0.0
          ],
          "train_token_ind": 61,
          "is_repeated_datapoint": false,
          "tokens": [
            "ewear",
            ".",
            " This",
            " standard",
            " is",
            " commonly",
            " used",
            " for",
            " shop",
            " glasses",
            ",",
            " shooting",
            " glasses",
            ",",
            " and",
            " many",
            " other",
            " examples",
            " of",
            " protective",
            " ey",
            "ewear",
            ".",
            " While",
            " compliance",
            " to",
            " this",
            " standard",
            " is",
            " required",
            " by",
            " United",
            " States",
            " federal",
            " law",
            ",",
            " it",
            " is",
            " not",
            " made",
            " freely",
            " available",
            " by",
            " ANSI",
            ",",
            " who",
            " charges",
            " $",
            "65",
            " to",
            " read",
            " a",
            " PDF",
            " of",
            " it",
            ".",
            " The",
            " ANSI",
            " paper",
            " sizes",
            " (",
            "ANS",
            "I"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            "ets",
            " (",
            "see",
            " also",
            " Extended",
            " Binary",
            " C",
            "oded",
            " Decimal",
            " Inter",
            "change",
            " Code",
            " or",
            " E",
            "BC",
            "DIC",
            ").",
            " In",
            " Microsoft",
            " Windows",
            ",",
            " the",
            " phrase",
            " \"",
            "ANS",
            "I",
            "\"",
            " refers",
            " to",
            " the",
            " Windows",
            " ANSI",
            " code",
            " pages",
            " (",
            "even",
            " though",
            " they",
            " are",
            " not",
            " ANSI",
            " standards",
            ").",
            " Most",
            " of",
            " these",
            " are",
            " fixed",
            " width",
            ",",
            " though",
            " some",
            " characters",
            " for",
            " ide",
            "ographic",
            " languages",
            " are",
            " variable",
            " width",
            ".",
            " Since",
            " these"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 52,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " space",
            " bar",
            " of",
            " a",
            " keyboard",
            ".",
            " Since",
            " the",
            " space",
            " character",
            " is",
            " considered",
            " an",
            " invisible",
            " graphic",
            " (",
            "rather",
            " than",
            " a",
            " control",
            " character",
            ")",
            " it",
            " is",
            " listed",
            " in",
            " the",
            " table",
            " below",
            " instead",
            " of",
            " in",
            " the",
            " previous",
            " section",
            ".",
            "Code",
            " ",
            "7",
            "F",
            "hex",
            " corresponds",
            " to",
            " the",
            " non",
            "-print",
            "able",
            " \"",
            "delete",
            "\"",
            " (",
            "DEL",
            ")",
            " control",
            " character",
            " and",
            " is",
            " therefore",
            " omitted",
            " from",
            " this",
            " chart"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            "ets",
            " (",
            "see",
            " also",
            " Extended",
            " Binary",
            " C",
            "oded",
            " Decimal",
            " Inter",
            "change",
            " Code",
            " or",
            " E",
            "BC",
            "DIC",
            ").",
            " In",
            " Microsoft",
            " Windows",
            ",",
            " the",
            " phrase",
            " \"",
            "ANS",
            "I",
            "\"",
            " refers",
            " to",
            " the",
            " Windows",
            " ANSI",
            " code",
            " pages",
            " (",
            "even",
            " though",
            " they",
            " are",
            " not",
            " ANSI",
            " standards",
            ").",
            " Most",
            " of",
            " these",
            " are",
            " fixed",
            " width",
            ",",
            " though",
            " some",
            " characters",
            " for",
            " ide",
            "ographic",
            " languages",
            " are",
            " variable",
            " width",
            ".",
            " Since",
            " these"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 52,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " space",
            " bar",
            " of",
            " a",
            " keyboard",
            ".",
            " Since",
            " the",
            " space",
            " character",
            " is",
            " considered",
            " an",
            " invisible",
            " graphic",
            " (",
            "rather",
            " than",
            " a",
            " control",
            " character",
            ")",
            " it",
            " is",
            " listed",
            " in",
            " the",
            " table",
            " below",
            " instead",
            " of",
            " in",
            " the",
            " previous",
            " section",
            ".",
            "Code",
            " ",
            "7",
            "F",
            "hex",
            " corresponds",
            " to",
            " the",
            " non",
            "-print",
            "able",
            " \"",
            "delete",
            "\"",
            " (",
            "DEL",
            ")",
            " control",
            " character",
            " and",
            " is",
            " therefore",
            " omitted",
            " from",
            " this",
            " chart"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.224,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.684,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 32,
          "is_repeated_datapoint": false,
          "tokens": [
            "Âł",
            "mg",
            "/m",
            "3",
            " (",
            "0",
            ".",
            "01",
            "Âł",
            "pp",
            "b",
            "),",
            " and",
            " the",
            " National",
            " Institute",
            " for",
            " Occupational",
            " Safety",
            " and",
            " Health",
            " (",
            "NI",
            "OSH",
            ")",
            " has",
            " set",
            " the",
            " recommended",
            " exposure",
            " limit",
            " (",
            "REL",
            ")",
            " to",
            " a",
            " ",
            "15",
            "-minute",
            " constant",
            " exposure",
            " of",
            " ",
            "0",
            ".",
            "002",
            "Âł",
            "mg",
            "/m",
            "3",
            " (",
            "0",
            ".",
            "002",
            "Âł",
            "pp",
            "b",
            ").",
            " The",
            " P",
            "EL",
            " for",
            " organic"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.004,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " same",
            " subjects",
            " are",
            " used",
            " for",
            " each",
            " factor",
            " (",
            "e",
            ".g",
            ".,",
            " in",
            " a",
            " longitudinal",
            " study",
            ").",
            "Mult",
            "ivariate",
            " analysis",
            " of",
            " variance",
            " (",
            "MAN",
            "O",
            "VA",
            ")",
            " is",
            " used",
            " when",
            " there",
            " is",
            " more",
            " than",
            " one",
            " response",
            " variable",
            ".",
            "C",
            "aut",
            "ions",
            "Bal",
            "anced",
            " experiments",
            " (",
            "those",
            " with",
            " an",
            " equal",
            " sample",
            " size",
            " for",
            " each",
            " treatment",
            ")",
            " are",
            " relatively",
            " easy",
            " to",
            " interpret",
            ";",
            " un"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " Spanish",
            ").",
            "External",
            " links",
            " ",
            " Umb",
            "ell",
            "if",
            "era",
            "e",
            " at",
            " The",
            " Families",
            " of",
            " Flower",
            "ing",
            " Plants",
            " (",
            "DEL",
            "TA",
            ")",
            " Api",
            "aceae",
            " at",
            " Discover",
            " Life",
            " Umb",
            "ell",
            "ifer",
            " Resource",
            " Centre",
            " at",
            " the",
            " Royal",
            " Bot",
            "anic",
            " Garden",
            " Edinburgh",
            " Umb",
            "ell",
            "ifer",
            " Information",
            " Server",
            " at",
            " Moscow",
            " State",
            " University",
            " ",
            "A",
            "ster",
            "id",
            " families",
            "<|begin_of_text|>",
            "An",
            " ax",
            "on",
            " (",
            "from",
            " Greek",
            " á¼"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 44,
          "is_repeated_datapoint": false,
          "tokens": [
            " represents",
            " one",
            " of",
            " the",
            " fastest",
            " growing",
            " and",
            " dynamic",
            " sectors",
            " in",
            " Albania",
            ".",
            " V",
            "odafone",
            " Albania",
            ",",
            " Tele",
            "kom",
            " Albania",
            " and",
            " Alb",
            "tele",
            "com",
            " are",
            " the",
            " three",
            " large",
            " providers",
            " of",
            " mobile",
            " and",
            " internet",
            " in",
            " Albania",
            ".",
            " As",
            " of",
            " the",
            " Electronic",
            " and",
            " Postal",
            " Communications",
            " Authority",
            " (",
            "AKE",
            "P",
            ")",
            " in",
            " ",
            "201",
            "8",
            ",",
            " the",
            " country",
            " had",
            " approximately",
            " ",
            "2",
            ".",
            "7",
            " million",
            " active",
            " mobile"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.672,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 16,
          "is_repeated_datapoint": false,
          "tokens": [
            " depleted",
            ".",
            " Major",
            " oil",
            " and",
            " gas",
            " reserves",
            " were",
            " found",
            " in",
            " the",
            " Alaska",
            " North",
            " Slo",
            "pe",
            " (",
            "ANS",
            ")",
            " and",
            " Cook",
            " In",
            "let",
            " bas",
            "ins",
            ",",
            " but",
            " according",
            " to",
            " the",
            " Energy",
            " Information",
            " Administration",
            ",",
            " by",
            " February",
            " ",
            "201",
            "4",
            " Alaska",
            " had",
            " fallen",
            " to",
            " fourth",
            " place",
            " in",
            " the",
            " nation",
            " in",
            " crude",
            " oil",
            " production",
            " after",
            " Texas",
            ",",
            " North",
            " Dakota",
            ",",
            " and",
            " California",
            ".",
            " Pr",
            "ud",
            "hoe"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.562,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.465,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.562,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.672,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 52,
          "is_repeated_datapoint": false,
          "tokens": [
            "im",
            "ult",
            "aneous",
            " component",
            " analysis",
            "Analysis",
            " of",
            " covariance",
            " (",
            "AN",
            "CO",
            "VA",
            ")",
            "Analysis",
            " of",
            " molecular",
            " variance",
            " (",
            "AM",
            "O",
            "VA",
            ")",
            "Analysis",
            " of",
            " rhyth",
            "mic",
            " variance",
            " (",
            "AN",
            "OR",
            "VA",
            ")",
            "Expected",
            " mean",
            " squares",
            "Expl",
            "ained",
            " variation",
            "Linear",
            " trend",
            " estimation",
            "Mixed",
            "-design",
            " analysis",
            " of",
            " variance",
            "Mult",
            "ivariate",
            " analysis",
            " of",
            " covariance",
            " (",
            "MAN",
            "CO",
            "VA",
            ")",
            "Per",
            "mut"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.562,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.465,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.562,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.672,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 52,
          "is_repeated_datapoint": false,
          "tokens": [
            "im",
            "ult",
            "aneous",
            " component",
            " analysis",
            "Analysis",
            " of",
            " covariance",
            " (",
            "AN",
            "CO",
            "VA",
            ")",
            "Analysis",
            " of",
            " molecular",
            " variance",
            " (",
            "AM",
            "O",
            "VA",
            ")",
            "Analysis",
            " of",
            " rhyth",
            "mic",
            " variance",
            " (",
            "AN",
            "OR",
            "VA",
            ")",
            "Expected",
            " mean",
            " squares",
            "Expl",
            "ained",
            " variation",
            "Linear",
            " trend",
            " estimation",
            "Mixed",
            "-design",
            " analysis",
            " of",
            " variance",
            "Mult",
            "ivariate",
            " analysis",
            " of",
            " covariance",
            " (",
            "MAN",
            "CO",
            "VA",
            ")",
            "Per",
            "mut"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.672,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 16,
          "is_repeated_datapoint": false,
          "tokens": [
            " depleted",
            ".",
            " Major",
            " oil",
            " and",
            " gas",
            " reserves",
            " were",
            " found",
            " in",
            " the",
            " Alaska",
            " North",
            " Slo",
            "pe",
            " (",
            "ANS",
            ")",
            " and",
            " Cook",
            " In",
            "let",
            " bas",
            "ins",
            ",",
            " but",
            " according",
            " to",
            " the",
            " Energy",
            " Information",
            " Administration",
            ",",
            " by",
            " February",
            " ",
            "201",
            "4",
            " Alaska",
            " had",
            " fallen",
            " to",
            " fourth",
            " place",
            " in",
            " the",
            " nation",
            " in",
            " crude",
            " oil",
            " production",
            " after",
            " Texas",
            ",",
            " North",
            " Dakota",
            ",",
            " and",
            " California",
            ".",
            " Pr",
            "ud",
            "hoe"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.005,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.346,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.668,
            -0.0,
            -0.0,
            0.03,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.228,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.065,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            " standards",
            " panels",
            ":",
            " ANSI",
            " Homeland",
            " Defense",
            " and",
            " Security",
            " Standard",
            "ization",
            " Collabor",
            "ative",
            " (",
            "HD",
            "SS",
            "C",
            ")",
            " ANSI",
            " Nan",
            "otechnology",
            " Standards",
            " Panel",
            " (",
            "ANS",
            "I",
            "-",
            "NS",
            "P",
            ")",
            " ID",
            " Theft",
            " Prevention",
            " and",
            " ID",
            " Management",
            " Standards",
            " Panel",
            " (",
            "ID",
            "SP",
            ")",
            " ANSI",
            " Energy",
            " Efficiency",
            " Standard",
            "ization",
            " Coord",
            "ination",
            " Collabor",
            "ative",
            " (",
            "E",
            "ES",
            "CC",
            ")",
            " Nuclear",
            " Energy",
            " Standards",
            " Coord",
            "ination",
            " Collabor",
            "ative",
            " ("
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.656,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.644,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            " V",
            ".",
            " Dy",
            "bo",
            ",",
            " and",
            " O",
            "leg",
            " A",
            ".",
            " Mud",
            "rak",
            " (",
            "does",
            " not",
            " include",
            " introductory",
            " chapters",
            ")",
            "LING",
            "UI",
            "ST",
            " List",
            " ",
            "5",
            ".",
            "911",
            " defense",
            " of",
            " Alta",
            "ic",
            " by",
            " Alexis",
            " Man",
            "aster",
            " Ram",
            "er",
            " (",
            "199",
            "4",
            ")",
            "LING",
            "UI",
            "ST",
            " List",
            " ",
            "5",
            ".",
            "926",
            " ",
            "1",
            ".",
            " Remarks",
            " by",
            " Alexander",
            " V",
            "ov",
            "in",
            ".",
            " ",
            "2",
            ".",
            " Clar"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.656,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.644,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            " V",
            ".",
            " Dy",
            "bo",
            ",",
            " and",
            " O",
            "leg",
            " A",
            ".",
            " Mud",
            "rak",
            " (",
            "does",
            " not",
            " include",
            " introductory",
            " chapters",
            ")",
            "LING",
            "UI",
            "ST",
            " List",
            " ",
            "5",
            ".",
            "911",
            " defense",
            " of",
            " Alta",
            "ic",
            " by",
            " Alexis",
            " Man",
            "aster",
            " Ram",
            "er",
            " (",
            "199",
            "4",
            ")",
            "LING",
            "UI",
            "ST",
            " List",
            " ",
            "5",
            ".",
            "926",
            " ",
            "1",
            ".",
            " Remarks",
            " by",
            " Alexander",
            " V",
            "ov",
            "in",
            ".",
            " ",
            "2",
            ".",
            " Clar"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.652,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.467,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.102,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.183,
            -0.0,
            -0.0,
            0.067,
            -0.0,
            -0.0,
            0.052,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            " such",
            " systems",
            " includes",
            ":",
            " Lincoln",
            " Near",
            "-E",
            "arth",
            " Aster",
            "oid",
            " Research",
            " (",
            "LINE",
            "AR",
            ")",
            " Near",
            "-E",
            "arth",
            " Aster",
            "oid",
            " Tracking",
            " (",
            "NE",
            "AT",
            ")",
            " Space",
            "watch",
            " Lowell",
            " Observatory",
            " Near",
            "-E",
            "arth",
            "-",
            "Object",
            " Search",
            " (",
            "L",
            "ONE",
            "OS",
            ")",
            " Catal",
            "ina",
            " Sky",
            " Survey",
            " (",
            "CSS",
            ")",
            " Pan",
            "-ST",
            "ARR",
            "S",
            " NE",
            "OW",
            "ISE",
            " Aster",
            "oid",
            " Ter",
            "restrial",
            "-",
            "impact"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.652,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " American",
            " National",
            " Standards",
            " Institute",
            " (",
            "ANS",
            "I",
            " ",
            " )",
            " is",
            " a",
            " private",
            " nonprofit",
            " organization",
            " that",
            " oversees",
            " the",
            " development",
            " of",
            " voluntary",
            " consensus",
            " standards",
            " for",
            " products",
            ",",
            " services",
            ",",
            " processes",
            ",",
            " systems",
            ",",
            " and",
            " personnel",
            " in",
            " the",
            " United",
            " States",
            ".",
            " The",
            " organization",
            " also",
            " coordinates",
            " U",
            ".S",
            ".",
            " standards",
            " with",
            " international",
            " standards",
            " so",
            " that",
            " American",
            " products",
            " can",
            " be",
            " used",
            " worldwide",
            ".",
            "ANS",
            "I",
            " acc",
            "redits",
            " standards"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.336,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.652,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            " ASA",
            " later",
            " became",
            " the",
            " United",
            " States",
            " of",
            " America",
            " Standards",
            " Institute",
            " (",
            "US",
            "ASI",
            ")",
            " and",
            " ultimately",
            " became",
            " the",
            " American",
            " National",
            " Standards",
            " Institute",
            " (",
            "ANS",
            "I",
            ").",
            "With",
            " the",
            " other",
            " special",
            " characters",
            " and",
            " control",
            " codes",
            " filled",
            " in",
            ",",
            " ASCII",
            " was",
            " published",
            " as",
            " ASA",
            " X",
            "3",
            ".",
            "4",
            "-",
            "196",
            "3",
            ",",
            " leaving",
            " ",
            "28",
            " code",
            " positions",
            " without",
            " any",
            " assigned",
            " meaning",
            ",",
            " reserved",
            " for",
            " future"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.648,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.148,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            " US",
            "–",
            "T",
            "al",
            "iban",
            " deal",
            " was",
            " made",
            " in",
            " Qatar",
            ".",
            " The",
            " deal",
            " was",
            " one",
            " of",
            " the",
            " critical",
            " events",
            " that",
            " caused",
            " the",
            " collapse",
            " of",
            " the",
            " Afghan",
            " National",
            " Security",
            " Forces",
            " (",
            "ANS",
            "F",
            ");",
            " following",
            " the",
            " signing",
            " of",
            " the",
            " deal",
            ",",
            " the",
            " US",
            " dramatically",
            " reduced",
            " the",
            " number",
            " of",
            " air",
            " attacks",
            " and",
            " deprived",
            " the",
            " AN",
            "SF",
            " of",
            " a",
            " critical",
            " edge",
            " in",
            " fighting",
            " the",
            " Taliban",
            " insurgency"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.352,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.031,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.046,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.06,
            -0.0,
            -0.0,
            -0.0,
            0.648,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.356,
            -0.0,
            -0.0,
            0.512,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.531,
            -0.0
          ],
          "train_token_ind": 36,
          "is_repeated_datapoint": false,
          "tokens": [
            "etic",
            " acid",
            " (",
            "CH",
            "3",
            "CO",
            "OH",
            ")",
            " Cit",
            "ric",
            " acid",
            " (",
            "C",
            "6",
            "H",
            "8",
            "O",
            "7",
            ")",
            " Form",
            "ic",
            " acid",
            " (",
            "H",
            "CO",
            "OH",
            ")",
            " Gl",
            "u",
            "con",
            "ic",
            " acid",
            " HO",
            "CH",
            "2",
            "-(",
            "CHO",
            "H",
            ")",
            "4",
            "-C",
            "OO",
            "H",
            " L",
            "actic",
            " acid",
            " (",
            "CH",
            "3",
            "-",
            "CHO",
            "H",
            "-C",
            "OO",
            "H",
            ")",
            " Ox",
            "alic",
            " acid",
            " (",
            "HO",
            "OC"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.644,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.179,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " acknowledge",
            " (",
            "ACK",
            ").",
            " These",
            " were",
            " positioned",
            " to",
            " maximize",
            " the",
            " Ham",
            "ming",
            " distance",
            " between",
            " their",
            " bit",
            " patterns",
            ".",
            "Character",
            " order",
            "ASCII",
            "-code",
            " order",
            " is",
            " also",
            " called",
            " ASCII",
            "bet",
            "ical",
            " order",
            ".",
            " Coll",
            "ation",
            " of",
            " data",
            " is",
            " sometimes",
            " done",
            " in",
            " this",
            " order",
            " rather",
            " than",
            " \"",
            "standard",
            "\"",
            " alphabetical",
            " order",
            " (",
            "coll",
            "ating",
            " sequence",
            ").",
            " The",
            " main",
            " deviations",
            " in",
            " ASCII",
            " order",
            " are",
            ":"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.644,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.16,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " due",
            " process",
            ".",
            "ANS",
            "I",
            " also",
            " design",
            "ates",
            " specific",
            " standards",
            " as",
            " American",
            " National",
            " Standards",
            ",",
            " or",
            " AN",
            "S",
            ",",
            " when",
            " the",
            " Institute",
            " determines",
            " that",
            " the",
            " standards",
            " were",
            " developed",
            " in",
            " an",
            " environment",
            " that",
            " is",
            " equitable",
            ",",
            " accessible",
            " and",
            " responsive",
            " to",
            " the",
            " requirements",
            " of",
            " various",
            " stakeholders",
            ".",
            "Vol",
            "untary",
            " consensus",
            " standards",
            " quick",
            "en",
            " the",
            " market",
            " acceptance",
            " of",
            " products",
            " while",
            " making",
            " clear",
            " how",
            " to",
            " improve",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.641,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.172,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.176,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " variance",
            " (",
            "ANO",
            "VA",
            ")",
            " is",
            " a",
            " collection",
            " of",
            " statistical",
            " models",
            " and",
            " their",
            " associated",
            " estimation",
            " procedures",
            " (",
            "such",
            " as",
            " the",
            " \"",
            "variation",
            "\"",
            " among",
            " and",
            " between",
            " groups",
            ")",
            " used",
            " to",
            " analyze",
            " the",
            " differences",
            " among",
            " means",
            ".",
            " AN",
            "O",
            "VA",
            " was",
            " developed",
            " by",
            " the",
            " statistic",
            "ian",
            " Ronald",
            " Fisher",
            ".",
            " AN",
            "O",
            "VA",
            " is",
            " based",
            " on",
            " the",
            " law",
            " of",
            " total",
            " variance",
            ",",
            " where",
            " the",
            " observed"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.539,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.024,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.641,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 52,
          "is_repeated_datapoint": false,
          "tokens": [
            " American",
            " Society",
            " of",
            " Civil",
            " Engineers",
            " (",
            "AS",
            "CE",
            ")",
            " American",
            " Institute",
            " of",
            " Mining",
            " Engineers",
            " (",
            "A",
            "IME",
            ",",
            " now",
            " American",
            " Institute",
            " of",
            " Mining",
            ",",
            " Met",
            "all",
            "urgical",
            ",",
            " and",
            " Petroleum",
            " Engineers",
            ")",
            " American",
            " Society",
            " for",
            " Testing",
            " and",
            " Materials",
            " (",
            "now",
            " ASTM",
            " International",
            ")",
            "had",
            " been",
            " members",
            " of",
            " the",
            " United",
            " Engineering",
            " Society",
            " (",
            "UES",
            ").",
            " At",
            " the",
            " be",
            "hest",
            " of",
            " the",
            " A",
            "IE",
            "E"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.002,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.641,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            "ambique",
            " and",
            " Angola",
            " into",
            " a",
            " separate",
            " autonomous",
            " province",
            " of",
            " the",
            " Anglic",
            "an",
            " Comm",
            "union",
            ",",
            " to",
            " be",
            " named",
            " the",
            " Anglic",
            "an",
            " Church",
            " of",
            " Moz",
            "ambique",
            " and",
            " Angola",
            " ",
            " (",
            "I",
            "AMA",
            ").",
            " The",
            " plans",
            " were",
            " also",
            " outlined",
            " to",
            " the",
            " Moz",
            "ambique",
            " and",
            " Angola",
            " Anglic",
            "an",
            " Association",
            " (",
            "MAN",
            "NA",
            ")",
            " at",
            " its",
            " September",
            " ",
            "202",
            "0",
            " annual",
            " general",
            " meeting",
            ".",
            " The",
            " new",
            " province"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.586,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.212,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            "RE",
            "OB",
            "\"",
            " or",
            " \"",
            "RE",
            "OB",
            "s",
            "\"",
            "the",
            " residue",
            " of",
            " recycled",
            " automotive",
            " engine",
            " oil",
            " collected",
            " from",
            " the",
            " bottoms",
            " of",
            " re",
            "-ref",
            "ining",
            " vacuum",
            " dist",
            "illation",
            " towers",
            ",",
            " in",
            " the",
            " manufacture",
            " of",
            " asphalt",
            ".",
            " RE",
            "OB",
            " contains",
            " various",
            " elements",
            " and",
            " compounds",
            " found",
            " in",
            " recycled",
            " engine",
            " oil",
            ":",
            " additives",
            " to",
            " the",
            " original",
            " oil",
            " and",
            " materials",
            " accumulating",
            " from",
            " its",
            " circulation",
            " in",
            " the",
            " engine",
            " ("
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.357,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.586,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.19,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " from",
            " RF",
            "Z",
            " to",
            " Florian",
            "opol",
            "is",
            " Fr",
            "act",
            "ure",
            " Zone",
            " (",
            "FF",
            "Z",
            ",",
            " north",
            " of",
            " Wal",
            "vis",
            " Ridge",
            " and",
            " Rio",
            " Grande",
            " Rise",
            ");",
            " Southern",
            " segment",
            ",",
            " from",
            " FF",
            "Z",
            " to",
            " the",
            " Ag",
            "ul",
            "has",
            "-F",
            "alk",
            "land",
            " Fr",
            "act",
            "ure",
            " Zone",
            " (",
            "AFF",
            "Z",
            ");",
            " and",
            " Falk",
            "land",
            " segment",
            ",",
            " south",
            " of",
            " AFF",
            "Z",
            ".",
            "In",
            " the",
            " southern",
            " segment",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.045,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.578,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.038,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 42,
          "is_repeated_datapoint": false,
          "tokens": [
            " neur",
            "one",
            " diseases",
            " (",
            "M",
            "ND",
            "s",
            ")",
            " are",
            " a",
            " group",
            " of",
            " rare",
            " neuro",
            "de",
            "gener",
            "ative",
            " disorders",
            " that",
            " selectively",
            " affect",
            " motor",
            " neurons",
            ",",
            " the",
            " cells",
            " which",
            " control",
            " voluntary",
            " muscles",
            " of",
            " the",
            " body",
            ".",
            " They",
            " include",
            " amy",
            "ot",
            "rophic",
            " lateral",
            " sclerosis",
            " (",
            "ALS",
            "),",
            " progressive",
            " bul",
            "bar",
            " p",
            "alsy",
            " (",
            "P",
            "BP",
            "),",
            " pseud",
            "ob",
            "ul",
            "bar",
            " p",
            "alsy",
            ",",
            " progressive",
            " muscular",
            " at"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.539,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.535,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            " European",
            " Union",
            "'s",
            " European",
            " Ne",
            "ighbour",
            "hood",
            " Policy",
            " (",
            "EN",
            "P",
            ")",
            " which",
            " aims",
            " at",
            " bringing",
            " the",
            " EU",
            " and",
            " its",
            " neighbours",
            " closer",
            ".",
            "Giving",
            " incentives",
            " and",
            " rewarding",
            " best",
            " performers",
            ",",
            " as",
            " well",
            " as",
            " offering",
            " funds",
            " in",
            " a",
            " faster",
            " and",
            " more",
            " flexible",
            " manner",
            ",",
            " are",
            " the",
            " two",
            " main",
            " principles",
            " underlying",
            " the",
            " European",
            " Ne",
            "ighbour",
            "hood",
            " Instrument",
            " (",
            "EN",
            "I",
            ")",
            " that",
            " came",
            " into",
            " force"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.088,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.021,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            " video",
            "\"",
            " (",
            "O",
            "AV",
            ");",
            " and",
            " are",
            " typically",
            " not",
            " released",
            " theat",
            "ric",
            "ally",
            " or",
            " televised",
            " prior",
            " to",
            " home",
            " media",
            " release",
            ".",
            " The",
            " emergence",
            " of",
            " the",
            " Internet",
            " has",
            " led",
            " some",
            " anim",
            "ators",
            " to",
            " distribute",
            " works",
            " online",
            " in",
            " a",
            " format",
            " called",
            " \"",
            "original",
            " net",
            " animation",
            "\"",
            " (",
            "ONA",
            ").",
            "The",
            " home",
            " distribution",
            " of",
            " anime",
            " releases",
            " was",
            " popular",
            "ized",
            " in",
            " the",
            " ",
            "198",
            "0",
            "s"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.482,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.48,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.475,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 8,
          "is_repeated_datapoint": false,
          "tokens": [
            "7",
            "–",
            "21",
            " April",
            " ",
            "200",
            "7",
            " (",
            "ISS",
            "),",
            " ",
            "26",
            " March",
            " –",
            " ",
            "8",
            " April",
            " ",
            "200",
            "9",
            " (",
            "ISS",
            ")",
            " Richard",
            " Gar",
            "riott",
            " (",
            "British",
            " /",
            " American",
            "):",
            " ",
            "12",
            "–",
            "24",
            " October",
            " ",
            "200",
            "8",
            " (",
            "ISS",
            ")",
            " Guy",
            " Lal",
            "ib",
            "ert",
            "Ã©",
            " (",
            "Canadian",
            "):",
            " ",
            "30",
            " September",
            " ",
            "200",
            "9",
            " –",
            " ",
            "11",
            " October",
            " ",
            "200",
            "9"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.422,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            " They",
            " would",
            " continue",
            " to",
            " do",
            " so",
            " until",
            " they",
            " performed",
            " their",
            " last",
            " mid",
            "-course",
            " correction",
            ",",
            " switching",
            " to",
            " a",
            " reference",
            " frame",
            " based",
            " on",
            " ideal",
            " orientation",
            " for",
            " the",
            " second",
            " engine",
            " burn",
            " they",
            " would",
            " make",
            " in",
            " lunar",
            " orbit",
            ".",
            "The",
            " last",
            " major",
            " event",
            " before",
            " Lunar",
            " Orbit",
            " Insert",
            "ion",
            " (",
            "LO",
            "I",
            ")",
            " was",
            " a",
            " second",
            " mid",
            "-course",
            " correction",
            ".",
            " It",
            " was",
            " in",
            " retro",
            "grade",
            " (",
            "against"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.42,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            " Consortium",
            ",",
            " operated",
            " a",
            " booth",
            " which",
            " demonstrated",
            " a",
            " phone",
            " compartment",
            " using",
            " the",
            " Qi",
            " open",
            " interface",
            " standard",
            " at",
            " the",
            " Consumer",
            " Electronics",
            " Show",
            " (",
            "CES",
            ").",
            " In",
            " May",
            ",",
            " most",
            " of",
            " the",
            " Audi",
            " dealers",
            " in",
            " the",
            " UK",
            " falsely",
            " claimed",
            " that",
            " the",
            " Audi",
            " A",
            "7",
            ",",
            " A",
            "8",
            ",",
            " and",
            " R",
            "8",
            " were",
            " Euro",
            " NC",
            "AP",
            " safety",
            " tested",
            ",",
            " all",
            " achieving",
            " five",
            " out",
            " of",
            " five",
            " stars"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.4,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.414,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.312,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.285,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            " substances",
            " can",
            " be",
            " oxid",
            "ized",
            " in",
            " this",
            " process",
            ".",
            " Ch",
            "emo",
            "aut",
            "ot",
            "rophic",
            " arsen",
            "ite",
            " oxid",
            "izers",
            " (",
            "CA",
            "O",
            ")",
            " and",
            " heter",
            "ot",
            "rophic",
            " arsen",
            "ite",
            " oxid",
            "izers",
            " (",
            "HA",
            "O",
            ")",
            " convert",
            " As",
            "(",
            "III",
            ")",
            " into",
            " As",
            "(V",
            ").",
            " CA",
            "O",
            " combine",
            " the",
            " oxidation",
            " of",
            " As",
            "(",
            "III",
            ")",
            " with",
            " the",
            " reduction",
            " of",
            " oxygen",
            " or",
            " nit",
            "rate",
            ".",
            " They"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.367,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.237,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            " symbolic",
            " form",
            " by",
            " a",
            " finite",
            " number",
            " of",
            " boxes",
            " [",
            "i",
            ".e",
            ".,",
            " INPUT",
            "]",
            " being",
            " marked",
            " with",
            " a",
            " stroke",
            ".",
            " Likewise",
            ",",
            " the",
            " answer",
            " [",
            "i",
            ".e",
            ".,",
            " OUTPUT",
            "]",
            " is",
            " to",
            " be",
            " given",
            " in",
            " symbolic",
            " form",
            " by",
            " such",
            " a",
            " configuration",
            " of",
            " marked",
            " boxes",
            "...",
            "\"A",
            " set",
            " of",
            " directions",
            " applicable",
            " to",
            " a",
            " general",
            " problem",
            " sets",
            " up",
            " a",
            " deterministic",
            " process",
            " when",
            " applied",
            " to",
            " each"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.326,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.332,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            "usion",
            "ist",
            " (",
            "British",
            "-F",
            "rench",
            ",",
            " ",
            "201",
            "0",
            ").",
            " Trad",
            "itionally",
            " animated",
            " films",
            " produced",
            " with",
            " the",
            " aid",
            " of",
            " computer",
            " technology",
            " include",
            " The",
            " Lion",
            " King",
            " (",
            "US",
            ",",
            " ",
            "199",
            "4",
            "),",
            " The",
            " Prince",
            " of",
            " Egypt",
            " (",
            "US",
            ",",
            " ",
            "199",
            "8",
            "),",
            " Ak",
            "ira",
            " (",
            "Japan",
            ",",
            " ",
            "198",
            "8",
            "),",
            " Spir",
            "ited",
            " Away",
            " (",
            "Japan",
            ",",
            " ",
            "200",
            "1",
            "),"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.285,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.279,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.27,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " UNIT",
            "A",
            " and",
            " the",
            " MPL",
            "A",
            " consent",
            "ed",
            " to",
            " the",
            " Lu",
            "ena",
            " Memor",
            "andum",
            " of",
            " Understanding",
            " in",
            " April",
            ";",
            " UNIT",
            "A",
            " agreed",
            " to",
            " give",
            " up",
            " its",
            " armed",
            " wing",
            ".",
            " With",
            " the",
            " elections",
            " in",
            " ",
            "200",
            "8",
            " and",
            " ",
            "201",
            "2",
            ",",
            " an",
            " MPL",
            "A",
            "-",
            "ru",
            "led",
            " dominant",
            "-party",
            " system",
            " emerged",
            ",",
            " with",
            " UNIT",
            "A",
            " and",
            " the",
            " FN",
            "LA",
            " as",
            " opposition",
            " parties",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.283,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            " mass",
            " measurements",
            " (",
            "0",
            ".",
            "003",
            "2",
            " and",
            " ",
            " respectively",
            ")",
            " is",
            " large",
            " enough",
            " to",
            " make",
            " this",
            " discrepancy",
            " statistically",
            " insignificant",
            ".",
            " HD",
            " ",
            "215",
            "152",
            " c",
            " also",
            " orbits",
            " further",
            " from",
            " the",
            " star",
            " than",
            " HD",
            " ",
            "215",
            "152",
            " b",
            ",",
            " ",
            "0",
            ".",
            "085",
            "2",
            "Âł",
            "AU",
            " compared",
            " to",
            " ",
            "0",
            ".",
            "065",
            "2",
            ".",
            "On",
            " ",
            "23",
            " February",
            " ",
            "201",
            "7",
            ",",
            " NASA"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.281,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.277,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            " lun",
            "cheon",
            " for",
            " award",
            " hon",
            "ore",
            "es",
            " takes",
            " place",
            " the",
            " following",
            " January",
            ".",
            "AF",
            "I",
            " Maya",
            " Der",
            "en",
            " Award",
            "AF",
            "I",
            " ",
            "100",
            " Years",
            "...",
            " series",
            "The",
            " A",
            "FI",
            " ",
            "100",
            " Years",
            "...",
            " series",
            ",",
            " which",
            " ran",
            " from",
            " ",
            "199",
            "8",
            " to",
            " ",
            "200",
            "8",
            " and",
            " created",
            " jury",
            "-selected",
            " lists",
            " of",
            " America",
            "'s",
            " best",
            " movies",
            " in",
            " categories",
            " such",
            " as",
            " Mus",
            "icals"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.247,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " a",
            " narrow",
            " size",
            " shoe",
            ",",
            " or",
            " a",
            " small",
            " cup",
            " size",
            " in",
            " a",
            " brass",
            "iere",
            ".",
            "Related",
            " characters",
            "Desc",
            "endants",
            " and",
            " related",
            " characters",
            " in",
            " the",
            " Latin",
            " alphabet",
            " ",
            "ÃĨ",
            " Ã¦",
            " :",
            " Latin",
            " AE",
            " lig",
            "ature",
            "A",
            " with",
            " di",
            "ac",
            "rit",
            "ics",
            ":",
            " Ãħ",
            " Ã¥",
            " ",
            "Ç",
            "º",
            " ",
            "Ç",
            "»",
            " á",
            "¸",
            "Ģ",
            " á",
            "¸",
            "ģ",
            " áº",
            "ļ",
            " Ä",
            "Ĥ",
            " "
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.172,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            " $",
            "400",
            "million",
            " data",
            " center",
            " in",
            " Birmingham",
            ".",
            " Many",
            " smaller",
            " banks",
            " are",
            " also",
            " headquartered",
            " in",
            " the",
            " Birmingham",
            " area",
            ",",
            " including",
            " Serv",
            "is",
            "First",
            " and",
            " New",
            " South",
            " Federal",
            " Savings",
            " Bank",
            ".",
            " Birmingham",
            " also",
            " serves",
            " as",
            " the",
            " headquarters",
            " for",
            " several",
            " large",
            " investment",
            " management",
            " companies",
            ",",
            " including",
            " Har",
            "bert",
            " Management",
            " Corporation",
            ".",
            "Elect",
            "ronics",
            " and",
            " communications",
            " ",
            "Tele",
            "communications",
            " provider",
            " AT",
            "&T",
            ",",
            " formerly",
            " Bell",
            "South"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.042,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.025,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            " ranking",
            " was",
            " ",
            "67",
            ".",
            " She",
            " reached",
            " the",
            " semi",
            "-finals",
            " at",
            " the",
            " IT",
            "F",
            " tournament",
            " in",
            " Sea",
            " Island",
            ",",
            " before",
            " withdrawing",
            " from",
            " a",
            " match",
            " versus",
            " Maria",
            " Shar",
            "ap",
            "ova",
            " due",
            " to",
            " the",
            " add",
            "uctor",
            " injury",
            ".",
            " She",
            " lost",
            " in",
            " the",
            " first",
            " round",
            " of",
            " the",
            " IT",
            "F",
            " tournament",
            " in",
            " Charlottesville",
            ".",
            " She",
            " did",
            " not",
            " compete",
            " for",
            " the",
            " rest",
            " of",
            " the",
            " season",
            " due",
            " to",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " rap",
            " in",
            " German",
            " (",
            "although",
            " their",
            " name",
            " is",
            " in",
            " English",
            ").",
            " Furthermore",
            ",",
            " their",
            " songs",
            " tackled",
            " controversial",
            " social",
            " and",
            " political",
            " issues",
            ",",
            " distinguishing",
            " them",
            " from",
            " early",
            " German",
            " hip",
            " hop",
            " group",
            " \"",
            "Die",
            " Fant",
            "ast",
            "ischen",
            " V",
            "ier",
            "\"",
            " (",
            "The",
            " Fantastic",
            " Four",
            "),",
            " ",
            " which",
            " had",
            " a",
            " more",
            " light",
            "-hearted",
            ",",
            " playful",
            ",",
            " party",
            " image",
            ".",
            "Career",
            "Advanced",
            " Chemistry",
            " frequently",
            " r",
            "apped"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "-old",
            " Scott",
            " Sa",
            "fr",
            "an",
            " of",
            " Cherry",
            " Hill",
            ",",
            " New",
            " Jersey",
            ",",
            " set",
            " a",
            " new",
            " record",
            " at",
            " ",
            "41",
            ",",
            "336",
            ",",
            "440",
            " points",
            ".",
            " ",
            " In",
            " ",
            "199",
            "8",
            ",",
            " to",
            " congratulate",
            " Sa",
            "fr",
            "an",
            " on",
            " his",
            " accomplishment",
            ",",
            " the",
            " Twin",
            " Gal",
            "axies",
            " Int",
            "erg",
            "al",
            "actic",
            " Score",
            "board",
            " searched",
            " for",
            " him",
            " for",
            " four",
            " years",
            " until",
            " ",
            "200",
            "2",
            ",",
            " when",
            " it"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " Arabs",
            " who",
            " had",
            " become",
            " Muslims",
            ".",
            " It",
            " is",
            " also",
            " often",
            ",",
            " albeit",
            " not",
            " exclusively",
            ",",
            " used",
            " in",
            " this",
            " way",
            " by",
            " B",
            "Ã¡b",
            "ists",
            ",",
            " Bah",
            "Ã¡",
            "Ê",
            "¼",
            "ÃŃs",
            ",",
            " Mand",
            "ae",
            "ans",
            ",",
            " Indonesian",
            " and",
            " Mal",
            "tes",
            "e",
            " Christians",
            ",",
            " and",
            " Sep",
            "hard",
            "i",
            " Jews",
            ",",
            " as",
            " well",
            " as",
            " by",
            " the",
            " G",
            "ag",
            "au",
            "z",
            " people",
            ".",
            " Similar",
            " usage",
            " by",
            " Christians",
            " and"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "achuset",
    "OrNil",
    "terminal",
    " Ð¾ÑģÑĤÐ°Ð½Ð½Ñĸ",
    "ãĥ¼ãĥ³"
  ],
  "bottom_logits": [
    " shed",
    "ctxt",
    " Romero",
    " Hem",
    " Gover"
  ],
  "act_min": -0.0,
  "act_max": 0.828
}
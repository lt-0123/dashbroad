{
  "index": 17003,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.719,
            -0.0,
            0.277,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            " for",
            " some",
            " individuals",
            " to",
            " serve",
            " others",
            " is",
            " supported",
            " by",
            " the",
            " enforcement",
            " of",
            " coerc",
            "ive",
            " private",
            " property",
            " relations",
            ".",
            " Some",
            " philosoph",
            "ies",
            " view",
            " any",
            " ownership",
            " claims",
            " on",
            " land",
            " and",
            " natural",
            " resources",
            " as",
            " immoral",
            " and",
            " illeg",
            "itimate",
            ".",
            " Object",
            "ivist",
            " philosopher",
            " Harry",
            " B",
            "ins",
            "w",
            "anger",
            " critic",
            "izes",
            " an",
            "ar",
            "cho",
            "-capital",
            "ism",
            " by",
            " arguing",
            " that",
            " \"",
            "capital",
            "ism",
            " requires",
            " government",
            "\",",
            " questioning",
            " who",
            " or"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.719,
            -0.0,
            0.277,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            " for",
            " some",
            " individuals",
            " to",
            " serve",
            " others",
            " is",
            " supported",
            " by",
            " the",
            " enforcement",
            " of",
            " coerc",
            "ive",
            " private",
            " property",
            " relations",
            ".",
            " Some",
            " philosoph",
            "ies",
            " view",
            " any",
            " ownership",
            " claims",
            " on",
            " land",
            " and",
            " natural",
            " resources",
            " as",
            " immoral",
            " and",
            " illeg",
            "itimate",
            ".",
            " Object",
            "ivist",
            " philosopher",
            " Harry",
            " B",
            "ins",
            "w",
            "anger",
            " critic",
            "izes",
            " an",
            "ar",
            "cho",
            "-capital",
            "ism",
            " by",
            " arguing",
            " that",
            " \"",
            "capital",
            "ism",
            " requires",
            " government",
            "\",",
            " questioning",
            " who",
            " or"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.715,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " Dallas",
            ",",
            " Texas",
            ".",
            "Music",
            " ",
            "War",
            "hol",
            " strongly",
            " influenced",
            " the",
            " new",
            " wave",
            "/p",
            "unk",
            " rock",
            " band",
            " De",
            "vo",
            ",",
            " as",
            " well",
            " as",
            " David",
            " Bowie",
            ".",
            " Bowie",
            " recorded",
            " a",
            " song",
            " called",
            " \"",
            "Andy",
            " War",
            "hol",
            "\"",
            " for",
            " his",
            " ",
            "197",
            "1",
            " album",
            " H",
            "unky",
            " D",
            "ory",
            ".",
            " Lou",
            " Reed",
            " wrote",
            " the",
            " song",
            " \"",
            "Andy",
            "'s",
            " Chest",
            "\",",
            " about",
            " Valerie",
            " Sol",
            "anas",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.715,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " include",
            " Dallas",
            ",",
            " Low",
            "nd",
            "es",
            ",",
            " Mare",
            "ngo",
            " and",
            " Perry",
            ".\"",
            "In",
            " ",
            "197",
            "2",
            ",",
            " for",
            " the",
            " first",
            " time",
            " since",
            " ",
            "190",
            "1",
            ",",
            " the",
            " legislature",
            " completed",
            " the",
            " congressional",
            " red",
            "istrict",
            "ing",
            " based",
            " on",
            " the",
            " dec",
            "ennial",
            " census",
            ".",
            " This",
            " benefited",
            " the",
            " urban",
            " areas",
            " that",
            " had",
            " developed",
            ",",
            " as",
            " well",
            " as",
            " all",
            " in",
            " the",
            " population",
            " who",
            " had",
            " been",
            " under",
            "represented",
            " for"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.715,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " Dallas",
            ",",
            " Texas",
            ",",
            " was",
            " renamed",
            " Cedar",
            " Crest",
            " Elementary",
            ".",
            " Johnston",
            " Middle",
            " School",
            " in",
            " Houston",
            ",",
            " Texas",
            ",",
            " was",
            " also",
            " renamed",
            " Meyer",
            "land",
            " Middle",
            " School",
            ".",
            " Three",
            " other",
            " elementary",
            " schools",
            " named",
            " for",
            " Confederate",
            " veterans",
            " were",
            " renamed",
            " simultaneously",
            ".",
            "See",
            " also",
            " Albert",
            " Sidney",
            " Johnston",
            " High",
            " School",
            ",",
            " a",
            " def",
            "unct",
            " public",
            " high",
            " school",
            " in",
            " Austin",
            ",",
            " Texas",
            " Statue",
            " of",
            " Albert",
            " Sidney"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.703,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " condemned",
            " the",
            " initiation",
            " of",
            " force",
            " as",
            " immoral",
            " and",
            " supported",
            " laisse",
            "z",
            "-f",
            "aire",
            " capitalism",
            ",",
            " which",
            " she",
            " defined",
            " as",
            " the",
            " system",
            " based",
            " on",
            " recognizing",
            " individual",
            " rights",
            ",",
            " including",
            " private",
            " property",
            " rights",
            ".",
            " Although",
            " Rand",
            " opposed",
            " libertarian",
            "ism",
            ",",
            " which",
            " she",
            " viewed",
            " as",
            " anarch",
            "ism",
            ",",
            " she",
            " is",
            " often",
            " associated",
            " with",
            " the",
            " modern",
            " libertarian",
            " movement",
            " in",
            " the",
            " United",
            " States",
            ".",
            " In",
            " art",
            ",",
            " Rand"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.703,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " condemned",
            " the",
            " initiation",
            " of",
            " force",
            " as",
            " immoral",
            " and",
            " supported",
            " laisse",
            "z",
            "-f",
            "aire",
            " capitalism",
            ",",
            " which",
            " she",
            " defined",
            " as",
            " the",
            " system",
            " based",
            " on",
            " recognizing",
            " individual",
            " rights",
            ",",
            " including",
            " private",
            " property",
            " rights",
            ".",
            " Although",
            " Rand",
            " opposed",
            " libertarian",
            "ism",
            ",",
            " which",
            " she",
            " viewed",
            " as",
            " anarch",
            "ism",
            ",",
            " she",
            " is",
            " often",
            " associated",
            " with",
            " the",
            " modern",
            " libertarian",
            " movement",
            " in",
            " the",
            " United",
            " States",
            ".",
            " In",
            " art",
            ",",
            " Rand"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.695,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            " private",
            " ...",
            " Much",
            " of",
            " that",
            " property",
            " is",
            " stolen",
            ".",
            " Much",
            " is",
            " of",
            " dubious",
            " title",
            ".",
            " All",
            " of",
            " it",
            " is",
            " deeply",
            " intertwined",
            " with",
            " an",
            " immoral",
            ",",
            " coerc",
            "ive",
            " state",
            " system",
            "\".",
            "By",
            " accepting",
            " an",
            " ax",
            "i",
            "omatic",
            " definition",
            " of",
            " private",
            " property",
            " and",
            " property",
            " rights",
            ",",
            " an",
            "ar",
            "cho",
            "-capital",
            "ists",
            " deny",
            " the",
            " legitimacy",
            " of",
            " a",
            " state",
            " on",
            " principle",
            ".",
            " Hans",
            "-H",
            "ermann",
            " Hop",
            "pe"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.695,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " ac",
            "rimon",
            "ious",
            " separation",
            ",",
            " Lady",
            " Byron",
            " continued",
            " throughout",
            " her",
            " life",
            " to",
            " make",
            " allegations",
            " about",
            " her",
            " husband",
            "'s",
            " immoral",
            " behaviour",
            ".",
            " This",
            " set",
            " of",
            " events",
            " made",
            " Lov",
            "el",
            "ace",
            " infamous",
            " in",
            " Victorian",
            " society",
            ".",
            " Ada",
            " did",
            " not",
            " have",
            " a",
            " relationship",
            " with",
            " her",
            " father",
            ".",
            " He",
            " died",
            " in",
            " ",
            "182",
            "4",
            " when",
            " she",
            " was",
            " eight",
            " years",
            " old",
            ".",
            " Her",
            " mother",
            " was",
            " the",
            " only",
            " significant"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.695,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " ac",
            "rimon",
            "ious",
            " separation",
            ",",
            " Lady",
            " Byron",
            " continued",
            " throughout",
            " her",
            " life",
            " to",
            " make",
            " allegations",
            " about",
            " her",
            " husband",
            "'s",
            " immoral",
            " behaviour",
            ".",
            " This",
            " set",
            " of",
            " events",
            " made",
            " Lov",
            "el",
            "ace",
            " infamous",
            " in",
            " Victorian",
            " society",
            ".",
            " Ada",
            " did",
            " not",
            " have",
            " a",
            " relationship",
            " with",
            " her",
            " father",
            ".",
            " He",
            " died",
            " in",
            " ",
            "182",
            "4",
            " when",
            " she",
            " was",
            " eight",
            " years",
            " old",
            ".",
            " Her",
            " mother",
            " was",
            " the",
            " only",
            " significant"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            "0",
            " T",
            "DI",
            ",",
            " Audi",
            " A",
            "3",
            " Sport",
            "back",
            " ",
            "2",
            ".",
            "0",
            " T",
            "DI",
            " with",
            " S",
            " tr",
            "onic",
            " transmission",
            ")",
            " travelling",
            " across",
            " the",
            " American",
            " continent",
            " from",
            " New",
            " York",
            " to",
            " Los",
            " Angeles",
            ",",
            " passing",
            " major",
            " cities",
            " like",
            " Chicago",
            ",",
            " Dallas",
            " and",
            " Las",
            " Vegas",
            " during",
            " the",
            " ",
            "13",
            " daily",
            " stages",
            ",",
            " as",
            " well",
            " as",
            " natural",
            " wonders",
            " including",
            " the",
            " Rocky",
            " Mountains",
            ",",
            " Death",
            " Valley"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.672,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " moved",
            " to",
            " Cah",
            "aba",
            " in",
            " Dallas",
            " County",
            ".",
            "C",
            "ah",
            "aba",
            ",",
            " now",
            " a",
            " ghost",
            " town",
            ",",
            " was",
            " the",
            " first",
            " permanent",
            " state",
            " capital",
            " from",
            " ",
            "182",
            "0",
            " to",
            " ",
            "182",
            "5",
            ".",
            " The",
            " Alabama",
            " Fever",
            " land",
            " rush",
            " was",
            " underway",
            " when",
            " the",
            " state",
            " was",
            " admitted",
            " to",
            " the",
            " Union",
            ",",
            " with",
            " settlers",
            " and",
            " land",
            " spec",
            "ulators",
            " pouring",
            " into",
            " the",
            " state",
            " to",
            " take",
            " advantage",
            " of",
            " fertile"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.672,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " moved",
            " to",
            " Cah",
            "aba",
            " in",
            " Dallas",
            " County",
            ".",
            "C",
            "ah",
            "aba",
            ",",
            " now",
            " a",
            " ghost",
            " town",
            ",",
            " was",
            " the",
            " first",
            " permanent",
            " state",
            " capital",
            " from",
            " ",
            "182",
            "0",
            " to",
            " ",
            "182",
            "5",
            ".",
            " The",
            " Alabama",
            " Fever",
            " land",
            " rush",
            " was",
            " underway",
            " when",
            " the",
            " state",
            " was",
            " admitted",
            " to",
            " the",
            " Union",
            ",",
            " with",
            " settlers",
            " and",
            " land",
            " spec",
            "ulators",
            " pouring",
            " into",
            " the",
            " state",
            " to",
            " take",
            " advantage",
            " of",
            " fertile"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.664,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " Bran",
            "iff",
            "'s",
            " chairman",
            " and",
            " president",
            " Harding",
            " Lawrence",
            ",",
            " was",
            " representing",
            " the",
            " Dallas",
            "-based",
            " carrier",
            " at",
            " that",
            " time",
            ".",
            " Lois",
            " succeeded",
            " Wells",
            " Rich",
            " Greene",
            " Agency",
            " on",
            " December",
            " ",
            "1",
            ",",
            " ",
            "196",
            "8",
            ".",
            " The",
            " rights",
            " to",
            " War",
            "hol",
            "'s",
            " films",
            " for",
            " Bran",
            "iff",
            " and",
            " his",
            " signed",
            " contracts",
            " are",
            " owned",
            " by",
            " a",
            " private",
            " trust",
            " and",
            " are",
            " administered",
            " by",
            " Bran",
            "iff",
            " Airways",
            " Foundation"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.656,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " World",
            " Cup",
            " last",
            " July",
            " at",
            " BC",
            " Place",
            " in",
            " Vancouver",
            ",",
            " British",
            " Columbia",
            ",",
            " Canada",
            " before",
            " an",
            " undis",
            "puted",
            " AT",
            "&T",
            " Stadium",
            " audience",
            " of",
            " ",
            "101",
            ",",
            "763",
            " to",
            " open",
            " Wrestle",
            "Man",
            "ia",
            " ",
            "32",
            " in",
            " Dallas",
            ",",
            " Texas",
            ".",
            "In",
            " ",
            "201",
            "7",
            ",",
            " Jackie",
            " Evan",
            "cho",
            " released",
            " Together",
            " We",
            " Stand",
            ",",
            " a",
            " disc",
            " containing",
            " three",
            " patriotic",
            " songs",
            " including",
            " \"",
            "America",
            " the",
            " Beautiful"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.609,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " Engineering",
            ")",
            " Greg",
            " Jos",
            "iw",
            "ak",
            " (",
            "sen",
            "ior",
            " vice",
            " president",
            " –",
            " Worldwide",
            " Marketing",
            ")",
            " John",
            "y",
            " S",
            "rou",
            "ji",
            " (",
            "sen",
            "ior",
            " vice",
            " president",
            " –",
            " Hardware",
            " Technologies",
            ")",
            " Sab",
            "ih",
            " Khan",
            " (",
            "sen",
            "ior",
            " vice",
            " president",
            " –",
            " Operations",
            ")",
            "Board",
            " of",
            " directors",
            " ",
            "As",
            " of",
            " January",
            " ",
            "20",
            ",",
            " ",
            "202",
            "3",
            ",",
            " the",
            " board",
            " of",
            " directors",
            " of",
            " Apple",
            " Inc",
            ".",
            " includes"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.609,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " Engineering",
            ")",
            " Greg",
            " Jos",
            "iw",
            "ak",
            " (",
            "sen",
            "ior",
            " vice",
            " president",
            " –",
            " Worldwide",
            " Marketing",
            ")",
            " John",
            "y",
            " S",
            "rou",
            "ji",
            " (",
            "sen",
            "ior",
            " vice",
            " president",
            " –",
            " Hardware",
            " Technologies",
            ")",
            " Sab",
            "ih",
            " Khan",
            " (",
            "sen",
            "ior",
            " vice",
            " president",
            " –",
            " Operations",
            ")",
            "Board",
            " of",
            " directors",
            " ",
            "As",
            " of",
            " January",
            " ",
            "20",
            ",",
            " ",
            "202",
            "3",
            ",",
            " the",
            " board",
            " of",
            " directors",
            " of",
            " Apple",
            " Inc",
            ".",
            " includes"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.57,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            " Bart",
            "old",
            "Keith",
            " H",
            ".",
            " B",
            "asso",
            "D",
            "aisy",
            " Bates",
            "Greg",
            "ory",
            " Bates",
            "on",
            "Mary",
            " Catherine",
            " Bates",
            "on",
            "R",
            "uth",
            " Beh",
            "ar",
            "R",
            "uth",
            " Benedict",
            "D",
            "or",
            "othy",
            " A",
            ".",
            " Bennett",
            "Carl",
            " H",
            ".",
            " Ber",
            "end",
            "t",
            "Lee",
            " Berger",
            "B",
            "rent",
            " Berlin",
            "C",
            "atherine",
            " Helen",
            " Webb",
            " Ber",
            "nd",
            "t",
            "C",
            "atherine"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.566,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            " George",
            " Washington",
            " Car",
            "ver",
            " Carl",
            " Henry",
            " Clerk",
            " George",
            " C",
            ".",
            " Clerk",
            " Ren",
            "Ã©",
            " Dum",
            "ont",
            " Sir",
            " Albert",
            " Howard",
            " K",
            "ail",
            "as",
            " Nath",
            " K",
            "aul",
            "Thomas",
            " Le",
            "cky",
            " Just",
            "us",
            " von",
            " Lie",
            "big",
            " Jay",
            " Laure",
            "nce",
            " L",
            "ush",
            " Greg",
            "or",
            " Mend",
            "el",
            " Louis",
            " Paste",
            "ur",
            " M",
            ".",
            " S",
            ".",
            " Sw",
            "amin",
            "athan"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.551
          ],
          "train_token_ind": 49,
          "is_repeated_datapoint": false,
          "tokens": [
            "k",
            "heim",
            "E",
            "Mary",
            " Lindsay",
            " Elm",
            "end",
            "olf",
            "Ver",
            "rier",
            " El",
            "win",
            "Matthew",
            " Engel",
            "ke",
            "F",
            "ried",
            "rich",
            " Eng",
            "els",
            "Art",
            "uro",
            " Esc",
            "obar",
            "E",
            ".",
            " E",
            ".",
            " Evans",
            "-P",
            "ritch",
            "ard",
            "F",
            "James",
            " Ferguson",
            "Ray",
            "mond",
            " F",
            "irth",
            "Ray",
            "mond",
            " D",
            ".",
            " Fog",
            "elson",
            "M",
            "eyer",
            " Fort",
            "es",
            "Greg"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.547,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " performance",
            " of",
            " plays",
            " or",
            " musical",
            " theater",
            ",",
            " often",
            " to",
            " high",
            " standards",
            ",",
            " but",
            " lacking",
            " the",
            " budgets",
            " of",
            " professional",
            " West",
            " End",
            " or",
            " Broadway",
            " performances",
            ".",
            " Astronomy",
            ",",
            " chemistry",
            ",",
            " history",
            ",",
            " lingu",
            "istics",
            ",",
            " and",
            " the",
            " natural",
            " sciences",
            " are",
            " among",
            " the",
            " fields",
            " that",
            " have",
            " benefited",
            " from",
            " the",
            " activities",
            " of",
            " amateurs",
            ".",
            " Greg",
            "or",
            " Mend",
            "el",
            " was",
            " an",
            " amateur",
            " scientist",
            " who",
            " never",
            " held",
            " a",
            " position"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.547,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " German",
            " singer",
            "-song",
            "writer",
            " and",
            " actor",
            "195",
            "7",
            " –",
            " Greg",
            " Child",
            ",",
            " Australian",
            " mount",
            "aine",
            "er",
            " and",
            " author",
            " ",
            " ",
            "195",
            "7",
            "  ",
            " –",
            " Vince",
            " Gill",
            ",",
            " American",
            " singer",
            "-song",
            "writer",
            " and",
            " guitarist",
            " ",
            " ",
            " ",
            "195",
            "7",
            "  ",
            " –",
            " T",
            "ama",
            " Jan",
            "owitz",
            ",",
            " American",
            " novelist",
            " and",
            " short",
            " story",
            " writer",
            "195",
            "8",
            " –",
            " Will",
            " Sergeant",
            ",",
            " English",
            " guitarist"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.012,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.547,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            " A",
            " regular",
            " repair",
            " was",
            " not",
            " possible",
            " in",
            " the",
            " available",
            " time",
            " but",
            " the",
            " station",
            " director",
            ",",
            " Charles",
            " Force",
            ",",
            " had",
            " his",
            " ten",
            "-year",
            "-old",
            " son",
            " Greg",
            " use",
            " his",
            " small",
            " hands",
            " to",
            " reach",
            " into",
            " the",
            " housing",
            " and",
            " pack",
            " it",
            " with",
            " grease",
            ".",
            " Greg",
            " was",
            " later",
            " thanked",
            " by",
            " Armstrong",
            ".",
            "Splash",
            "down",
            " and",
            " quarantine",
            " ",
            "The",
            " aircraft",
            " carrier",
            " ,",
            " under",
            " the",
            " command",
            " of",
            " Captain",
            " Carl"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.543,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            "\".",
            " The",
            " song",
            " chart",
            "ed",
            " at",
            " No",
            ".",
            " ",
            "4",
            " on",
            " Billboard",
            "'s",
            " Classical",
            " Digital",
            " Song",
            " sales",
            " chart",
            ".",
            "An",
            " abbreviated",
            " cover",
            " with",
            " the",
            " ",
            "191",
            "1",
            " lyrics",
            " was",
            " performed",
            " by",
            " Greg",
            " Jong",
            " for",
            " the",
            " soundtrack",
            " of",
            " the",
            " ",
            "202",
            "0",
            " video",
            " game",
            " W",
            "ast",
            "eland",
            " ",
            "3",
            ",",
            " and",
            " is",
            " played",
            " during",
            " the",
            " final",
            " hostile",
            " encounters",
            " in",
            " the",
            " Denver",
            " section",
            ".",
            "In"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.539,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " start",
            " of",
            " ",
            "197",
            "2",
            ",",
            " plus",
            " ",
            "27",
            " leap",
            " seconds",
            " in",
            " UTC",
            " since",
            " ",
            "197",
            "2",
            ".",
            "TA",
            "I",
            " may",
            " be",
            " reported",
            " using",
            " traditional",
            " means",
            " of",
            " specifying",
            " days",
            ",",
            " carried",
            " over",
            " from",
            " non",
            "-un",
            "iform",
            " time",
            " standards",
            " based",
            " on",
            " the",
            " rotation",
            " of",
            " the",
            " Earth",
            ".",
            " Specifically",
            ",",
            " both",
            " Julian",
            " days",
            " and",
            " the",
            " Greg",
            "orian",
            " calendar",
            " are",
            " used",
            ".",
            " T",
            "AI",
            " in"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.535,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            "b",
            ".",
            " ",
            "191",
            "2",
            ")",
            "197",
            "3",
            " –",
            " Ful",
            "g",
            "enc",
            "io",
            " Bat",
            "ista",
            ",",
            " Cuban",
            " colon",
            "el",
            " and",
            " politician",
            ",",
            " ",
            "9",
            "th",
            " President",
            " of",
            " Cuba",
            " (",
            "b",
            ".",
            " ",
            "190",
            "1",
            ")",
            "197",
            "6",
            " –",
            " Greg",
            "or",
            " P",
            "iat",
            "ig",
            "ors",
            "ky",
            ",",
            " Russian",
            "-American",
            " cell",
            "ist",
            " and",
            " educator",
            " (",
            "b",
            ".",
            " ",
            "190",
            "3",
            ")",
            "197",
            "8",
            " –",
            " Pope"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.535,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 43,
          "is_repeated_datapoint": false,
          "tokens": [
            "parents",
            " Day",
            " (",
            "Tai",
            "wan",
            ")",
            "Last",
            " Monday",
            " ",
            " Father",
            "'s",
            " Day",
            " (",
            "South",
            " Sudan",
            ")",
            " National",
            " Heroes",
            "'",
            " Day",
            " (",
            "Phil",
            "ippines",
            ")",
            " Liberation",
            " Day",
            " (",
            "Hong",
            " Kong",
            ")",
            " Late",
            " Summer",
            " Bank",
            " Holiday",
            " (",
            "England",
            ",",
            " Northern",
            " Ireland",
            " and",
            " Wales",
            ")",
            "Fixed",
            " Greg",
            "orian",
            " ",
            " Season",
            " of",
            " Em",
            "anc",
            "ipation",
            " (",
            "Bar",
            "b",
            "ados",
            ")",
            " (",
            "April",
            " ",
            "14",
            " to",
            " August",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.535,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            "b",
            ".",
            " ",
            "189",
            "0",
            ")",
            "192",
            "5",
            " –",
            " Sure",
            "nd",
            "ran",
            "ath",
            " Ban",
            "er",
            "jee",
            ",",
            " Indian",
            " academic",
            " and",
            " politician",
            " (",
            "b",
            ".",
            " ",
            "184",
            "8",
            ")",
            " ",
            " ",
            "192",
            "5",
            "  ",
            " –",
            " Greg",
            "orio",
            " Ric",
            "ci",
            "-C",
            "urb",
            "astro",
            ",",
            " Italian",
            " mathematic",
            "ian",
            " (",
            "b",
            ".",
            " ",
            "185",
            "3",
            ")",
            "193",
            "1",
            " –",
            " B",
            "ix",
            " Be",
            "ider",
            "beck",
            "e",
            ",",
            " American"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.531,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 49,
          "is_repeated_datapoint": false,
          "tokens": [
            " characters",
            "Female",
            " characters",
            " in",
            " literature",
            "F",
            "iction",
            "al",
            " amateur",
            " detectives",
            "Liter",
            "ary",
            " characters",
            " introduced",
            " in",
            " ",
            "192",
            "7",
            "F",
            "iction",
            "al",
            " English",
            " people",
            "Nov",
            "el",
            " series",
            "Nov",
            "els",
            " adapted",
            " into",
            " radio",
            " programs",
            "British",
            " novels",
            " adapted",
            " into",
            " television",
            " shows",
            "<|begin_of_text|>",
            "April",
            " is",
            " the",
            " fourth",
            " month",
            " of",
            " the",
            " year",
            " in",
            " the",
            " Greg",
            "orian",
            " and",
            " Julian",
            " calendars",
            ".",
            " It"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.531,
            -0.0,
            -0.0
          ],
          "train_token_ind": 60,
          "is_repeated_datapoint": false,
          "tokens": [
            " Ste",
            "vie",
            " Ray",
            " Vaughan",
            ",",
            " American",
            " singer",
            "-song",
            "writer",
            ",",
            " guitarist",
            ",",
            " and",
            " producer",
            " (",
            "b",
            ".",
            " ",
            "195",
            "4",
            ")",
            "199",
            "2",
            " –",
            " Beng",
            "t",
            " Hol",
            "bek",
            ",",
            " Danish",
            " folk",
            "lor",
            "ist",
            " (",
            "b",
            ".",
            " ",
            "193",
            "3",
            ")",
            "199",
            "4",
            " –",
            " Frank",
            " Jes",
            "ke",
            ",",
            " German",
            " football",
            "er",
            " (",
            "b",
            ".",
            " ",
            "196",
            "0",
            ")",
            "199",
            "6",
            " –",
            " Greg",
            " Morris",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.527,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 42,
          "is_repeated_datapoint": false,
          "tokens": [
            "April",
            " ",
            "25",
            ").",
            " Flor",
            "alia",
            " was",
            " held",
            " April",
            " ",
            "27",
            " during",
            " the",
            " Republican",
            " era",
            ",",
            " or",
            " April",
            " ",
            "28",
            " on",
            " the",
            " Julian",
            " calendar",
            ",",
            " and",
            " lasted",
            " until",
            " May",
            " ",
            "3",
            ".",
            " However",
            ",",
            " these",
            " dates",
            " do",
            " not",
            " correspond",
            " to",
            " the",
            " modern",
            " Greg",
            "orian",
            " calendar",
            ".",
            "The",
            " Ly",
            "rid",
            "s",
            " meteor",
            " shower",
            " appears",
            " on",
            " April",
            " ",
            "16",
            " –",
            " April",
            " ",
            "26",
            " each",
            " year"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.527,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            "External",
            " links",
            " ",
            " National",
            " Arbor",
            " Day",
            " Foundation",
            " ",
            "04",
            "<|begin_of_text|>",
            "August",
            " is",
            " the",
            " eighth",
            " month",
            " of",
            " the",
            " year",
            " in",
            " the",
            " Julian",
            " and",
            " Greg",
            "orian",
            " calendars",
            ",",
            " and",
            " the",
            " fifth",
            " of",
            " seven",
            " months",
            " to",
            " have",
            " a",
            " length",
            " of",
            " ",
            "31",
            " days",
            ".",
            "In",
            " the",
            " Southern",
            " Hemisphere",
            ",",
            " August",
            " is",
            " the",
            " seasonal",
            " equivalent",
            " of",
            " February",
            " in",
            " the",
            " Northern",
            " Hemisphere",
            ".",
            " In",
            " the",
            " Northern"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.527,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "4",
            ".",
            " (",
            "Those",
            " churches",
            " that",
            " follow",
            " the",
            " traditional",
            " Julian",
            " calendar",
            " celebrate",
            " this",
            " day",
            " on",
            " September",
            " ",
            "17",
            " of",
            " the",
            " modern",
            " Greg",
            "orian",
            " calendar",
            ").",
            " Aaron",
            " is",
            " also",
            " commemor",
            "ated",
            " with",
            " other",
            " Old",
            " Testament",
            " saints",
            " on",
            " the",
            " Sunday",
            " of",
            " the",
            " Holy",
            " Fathers",
            ",",
            " the",
            " Sunday",
            " before",
            " Christmas",
            ".",
            "In",
            " Eastern",
            " Orthodox",
            " Church",
            " he",
            " is",
            " commemor",
            "ated",
            " on",
            " ",
            "20",
            " July",
            ",",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.527,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.017,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 42,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " a",
            " plant",
            " to",
            " develop",
            " crops",
            " with",
            " more",
            " beneficial",
            " characteristics",
            " for",
            " humans",
            ",",
            " for",
            " example",
            ",",
            " larger",
            " fruits",
            " or",
            " seeds",
            ",",
            " drought",
            "-t",
            "olerance",
            ",",
            " or",
            " resistance",
            " to",
            " pests",
            ".",
            " Significant",
            " advances",
            " in",
            " plant",
            " breeding",
            " ensued",
            " after",
            " the",
            " work",
            " of",
            " genetic",
            "ist",
            " Greg",
            "or",
            " Mend",
            "el",
            ".",
            " His",
            " work",
            " on",
            " dominant",
            " and",
            " recess",
            "ive",
            " alleles",
            ",",
            " although",
            " initially",
            " largely",
            " ignored",
            " for",
            " almost",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.527,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "4",
            ".",
            " (",
            "Those",
            " churches",
            " that",
            " follow",
            " the",
            " traditional",
            " Julian",
            " calendar",
            " celebrate",
            " this",
            " day",
            " on",
            " September",
            " ",
            "17",
            " of",
            " the",
            " modern",
            " Greg",
            "orian",
            " calendar",
            ").",
            " Aaron",
            " is",
            " also",
            " commemor",
            "ated",
            " with",
            " other",
            " Old",
            " Testament",
            " saints",
            " on",
            " the",
            " Sunday",
            " of",
            " the",
            " Holy",
            " Fathers",
            ",",
            " the",
            " Sunday",
            " before",
            " Christmas",
            ".",
            "In",
            " Eastern",
            " Orthodox",
            " Church",
            " he",
            " is",
            " commemor",
            "ated",
            " on",
            " ",
            "20",
            " July",
            ",",
            " "
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.003,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.523,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 58,
          "is_repeated_datapoint": false,
          "tokens": [
            " by",
            " avant",
            "-g",
            "arde",
            " cine",
            "ast",
            " Jonas",
            " Mek",
            "as",
            " have",
            " caught",
            " the",
            " moments",
            " of",
            " War",
            "hol",
            "'s",
            " life",
            ".",
            " Sean",
            " Gregory",
            " Sullivan",
            " depicted",
            " War",
            "hol",
            " in",
            " the",
            " film",
            " ",
            "54",
            " (",
            "199",
            "8",
            ").",
            " Guy",
            " Pearce",
            " portrayed",
            " War",
            "hol",
            " in",
            " the",
            " film",
            " Factory",
            " Girl",
            " (",
            "200",
            "7",
            ")",
            " about",
            " Ed",
            "ie",
            " Sed",
            "g",
            "wick",
            "'s",
            " life",
            ".",
            " Actor",
            " Greg",
            " Travis",
            " portrays",
            " War",
            "hol"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.477,
            -0.0
          ],
          "train_token_ind": 61,
          "is_repeated_datapoint": false,
          "tokens": [
            " especially",
            " difficult",
            ".",
            " Chem",
            "other",
            "apeutic",
            " agents",
            ",",
            " including",
            " mouth",
            "w",
            "ashes",
            ",",
            " could",
            " have",
            " a",
            " key",
            " role",
            " as",
            " adjunct",
            "s",
            " to",
            " daily",
            " home",
            " care",
            ",",
            " preventing",
            " and",
            " controlling",
            " sup",
            "rag",
            "ing",
            "ival",
            " plaque",
            ",",
            " ging",
            "iv",
            "itis",
            " and",
            " oral",
            " mal",
            "odor",
            ".",
            "Minor",
            " and",
            " transient",
            " side",
            " effects",
            " of",
            " mouth",
            "w",
            "ashes",
            " are",
            " very",
            " common",
            ",",
            " such",
            " as",
            " taste",
            " disturbance",
            ",",
            " tooth",
            " staining"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.475,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 21,
          "is_repeated_datapoint": false,
          "tokens": [
            " public",
            " quar",
            "rels",
            " when",
            " he",
            " ran",
            " into",
            " them",
            " in",
            " public",
            ".",
            " Sch",
            "openh",
            "auer",
            "'s",
            " main",
            " occupation",
            " during",
            " his",
            " stay",
            " in",
            " Dresden",
            " was",
            " his",
            " seminal",
            " philosophical",
            " work",
            ",",
            " The",
            " World",
            " as",
            " Will",
            " and",
            " Representation",
            ",",
            " which",
            " he",
            " started",
            " writing",
            " in",
            " ",
            "181",
            "4",
            " and",
            " finished",
            " in",
            " ",
            "181",
            "8",
            ".",
            " He",
            " was",
            " recommended",
            " to",
            " the",
            " publisher",
            " Friedrich",
            " Arnold",
            " Brock",
            "haus",
            " by",
            " Baron",
            " Ferdinand"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.473,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 39,
          "is_repeated_datapoint": false,
          "tokens": [
            "ace",
            " of",
            " my",
            " life",
            ",",
            " it",
            " will",
            " be",
            " the",
            " sol",
            "ace",
            " of",
            " my",
            " death",
            ".",
            "As",
            " the",
            " relationship",
            " with",
            " his",
            " mother",
            " fell",
            " to",
            " a",
            " new",
            " low",
            ",",
            " in",
            " May",
            " ",
            "181",
            "4",
            " he",
            " left",
            " We",
            "imar",
            " and",
            " moved",
            " to",
            " Dresden",
            ".",
            " He",
            " continued",
            " his",
            " philosophical",
            " studies",
            ",",
            " enjoyed",
            " the",
            " cultural",
            " life",
            ",",
            " social",
            "ized",
            " with",
            " intellectuals",
            " and",
            " engaged",
            " in",
            " sexual",
            " affairs",
            ".",
            " His"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.443,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "Far",
            "lane",
            " [#",
            "306",
            "–",
            "314",
            ";",
            " The",
            " Spect",
            "acular",
            " Spider",
            "-Man",
            " Annual",
            " #",
            "10",
            "]",
            " ()",
            "Leg",
            "ends",
            ",",
            " Vol",
            ".",
            " ",
            "3",
            ":",
            " Todd",
            " Mc",
            "Far",
            "lane",
            " [#",
            "315",
            "–",
            "323",
            ",",
            " ",
            "325",
            ",",
            " ",
            "328",
            "]",
            " ()",
            "Spider",
            "-Man",
            ":",
            " Venom",
            " Returns",
            " [#",
            "330",
            "–",
            "333",
            ",",
            " ",
            "344",
            "–",
            "347",
            ";",
            "Annual",
            " #",
            "25",
            "]",
            " ()",
            "Spider",
            "-Man"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.314,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.406,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 59,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " Academy",
            " for",
            " US",
            "$",
            "1",
            ".",
            " If",
            " a",
            " winner",
            " refuses",
            " to",
            " agree",
            " to",
            " this",
            " stip",
            "ulation",
            ",",
            " then",
            " the",
            " Academy",
            " keeps",
            " the",
            " stat",
            "u",
            "ette",
            ".",
            " Academy",
            " Awards",
            " pred",
            "ating",
            " this",
            " agreement",
            " have",
            " been",
            " sold",
            " in",
            " public",
            " auctions",
            " and",
            " private",
            " deals",
            " for",
            " six",
            "-figure",
            " sums",
            ".",
            "In",
            " ",
            "198",
            "9",
            ",",
            " Michael",
            " Todd",
            "'s",
            " grandson",
            " tried",
            " to",
            " sell",
            " Todd",
            "'s",
            " Best",
            " Picture"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.404,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            "3",
            ")",
            " \"",
            "co",
            "-",
            "creative",
            " digital",
            " altru",
            "ism",
            "\"",
            " involving",
            " creativity",
            ",",
            " moral",
            " engagement",
            ",",
            " and",
            " meta",
            " cooperative",
            " efforts",
            ".",
            "See",
            " also",
            "Notes",
            "References",
            "External",
            " links",
            " ",
            " ",
            " ",
            "August",
            "e",
            " Com",
            "te",
            "Def",
            "ence",
            " mechanisms",
            "Mor",
            "ality",
            "M",
            "oral",
            " psychology",
            "Phil",
            "anth",
            "ropy",
            "Social",
            " philosophy",
            "Inter",
            "personal",
            " relationships",
            "V",
            "irt"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.352,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            " political",
            " lines",
            ",",
            " forming",
            " rival",
            " Southern",
            " and",
            " Northern",
            " churches",
            ".",
            " For",
            " example",
            ",",
            " in",
            " ",
            "184",
            "5",
            " the",
            " Bapt",
            "ists",
            " split",
            " into",
            " the",
            " Northern",
            " Bapt",
            "ists",
            " and",
            " Southern",
            " Bapt",
            "ists",
            " over",
            " the",
            " issue",
            " of",
            " slavery",
            ".",
            "Ab",
            "ol",
            "ition",
            "ist",
            " sentiment",
            " was",
            " not",
            " strictly",
            " religious",
            " or",
            " moral",
            " in",
            " origin",
            ".",
            " The",
            " Wh",
            "ig",
            " Party",
            " became",
            " increasingly",
            " opposed",
            " to",
            " slavery",
            " because",
            " it",
            " saw",
            " it"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.324,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 44,
          "is_repeated_datapoint": false,
          "tokens": [
            " known",
            " for",
            " the",
            " concept",
            " of",
            " micro",
            " credit",
            " which",
            " allows",
            " poor",
            " and",
            " dest",
            "it",
            "ute",
            " people",
            " with",
            " little",
            " or",
            " no",
            " collateral",
            " to",
            " borrow",
            " money",
            ".",
            " The",
            " borrowers",
            " typically",
            " pay",
            " back",
            " money",
            " within",
            " the",
            " specified",
            " period",
            " and",
            " the",
            " incidence",
            " of",
            " default",
            " is",
            " very",
            " low",
            ".",
            "The",
            " Dal",
            "ai",
            " Lama",
            " has",
            " received",
            " approximately",
            " eighty",
            "-four",
            " awards",
            " over",
            " his",
            " spiritual",
            " and",
            " political",
            " career",
            ".",
            " On",
            " ",
            "22"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.301,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 42,
          "is_repeated_datapoint": false,
          "tokens": [
            " language",
            " and",
            " of",
            " the",
            " Catholic",
            " Church",
            ",",
            " inter",
            "ming",
            "led",
            " with",
            " a",
            " variety",
            " of",
            " indigenous",
            " customs",
            " and",
            " traditions",
            ".",
            "Et",
            "ymology",
            "The",
            " name",
            " Angola",
            " comes",
            " from",
            " the",
            " Portuguese",
            " colonial",
            " name",
            " ",
            " ('",
            "King",
            "dom",
            " of",
            " Angola",
            "'),",
            " which",
            " appeared",
            " as",
            " early",
            " as",
            " Paulo",
            " Dias",
            " de",
            " Nov",
            "ais",
            "'s",
            " ",
            "157",
            "1",
            " charter",
            ".",
            " The",
            " to",
            "pon",
            "ym",
            " was",
            " derived",
            " by",
            " the",
            " Portuguese"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.279,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            " than",
            " the",
            " childbirth",
            " mortality",
            " rate",
            " at",
            " the",
            " time",
            ".",
            " In",
            " ",
            "193",
            "6",
            ",",
            " the",
            " prominent",
            " professor",
            " of",
            " obst",
            "etrics",
            " and",
            " g",
            "ynec",
            "ology",
            " Frederick",
            " J",
            ".",
            " Ta",
            "uss",
            "ig",
            " wrote",
            " that",
            " a",
            " cause",
            " of",
            " increasing",
            " mortality",
            " during",
            " the",
            " years",
            " of",
            " illeg",
            "ality",
            " in",
            " the",
            " U",
            ".S",
            ".",
            " was",
            " that",
            "M",
            "ental",
            " health",
            "Current",
            " evidence",
            " finds",
            " no",
            " relationship",
            " between",
            " most",
            " induced"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.258,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.052,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " but",
            " instead",
            " produce",
            " corros",
            "ive",
            " wastes",
            ".",
            " ",
            " The",
            " fungus",
            " Ge",
            "ot",
            "rich",
            "um",
            " candid",
            "um",
            " can",
            " consume",
            " the",
            " aluminium",
            " in",
            " compact",
            " discs",
            ".",
            " The",
            " bacter",
            "ium",
            " P",
            "seud",
            "omon",
            "as",
            " aer",
            "ugin",
            "osa",
            " and",
            " the",
            " fungus",
            " Cl",
            "ados",
            "por",
            "ium",
            " res",
            "inae",
            " are",
            " commonly",
            " detected",
            " in",
            " aircraft",
            " fuel",
            " tanks",
            " that",
            " use",
            " k",
            "eros",
            "ene",
            "-based",
            " fuels",
            " (",
            "not",
            " avg",
            "as",
            "),",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.239,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            "nak",
            " and",
            " Ãĩ",
            "orum",
            ".",
            " All",
            " have",
            " populations",
            " of",
            " more",
            " than",
            " ",
            "500",
            ",",
            "000",
            ".",
            "See",
            " also",
            " Ae",
            "olis",
            " Anat",
            "olian",
            " hypothesis",
            " Anat",
            "olian",
            "ism",
            " Anat",
            "olian",
            " leopard",
            " Anat",
            "olian",
            " Plate",
            " Anat",
            "olian",
            " Shepherd",
            " Ancient",
            " kingdoms",
            " of",
            " Anat",
            "olia",
            " Ant",
            "igon",
            "id",
            " dynasty",
            " Dor",
            "is",
            " (",
            "Asia",
            " Minor",
            ")",
            " Empire",
            " of",
            " N",
            "ica"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.195,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.157,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            " defence",
            " of",
            " Muslim",
            " lands",
            " simultaneously",
            " constit",
            "uting",
            " the",
            " reason",
            " for",
            " tit",
            "ling",
            " the",
            " league",
            " Committee",
            " of",
            " the",
            " Real",
            " Muslims",
            ".",
            "Approx",
            "imately",
            " ",
            "300",
            " Muslims",
            " participated",
            " in",
            " the",
            " assembly",
            " composed",
            " by",
            " delegates",
            " from",
            " Bosnia",
            ",",
            " the",
            " administrator",
            " of",
            " the",
            " San",
            "jak",
            " of",
            " Pr",
            "iz",
            "ren",
            " as",
            " representatives",
            " of",
            " the",
            " central",
            " authorities",
            " and",
            " no",
            " delegates",
            " from",
            " Vil",
            "ayet",
            " of",
            " Sc",
            "ut",
            "ari",
            ".",
            " Signed"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.186,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.002,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            " reflective",
            " of",
            " the",
            " increasing",
            " power",
            " and",
            " wealth",
            " of",
            " the",
            " elite",
            ",",
            " as",
            " well",
            " as",
            " societal",
            " personal",
            "-use",
            " items",
            ",",
            " which",
            " included",
            " com",
            "bs",
            ",",
            " small",
            " stat",
            "uary",
            ",",
            " painted",
            " pottery",
            ",",
            " high",
            " quality",
            " decorative",
            " stone",
            " v",
            "ases",
            ",",
            " cosmetic",
            " pa",
            "lettes",
            ",",
            " and",
            " jewelry",
            " made",
            " of",
            " gold",
            ",",
            " l",
            "apis",
            ",",
            " and",
            " ivory",
            ".",
            " They",
            " also",
            " developed",
            " a",
            " ceramic",
            " gl",
            "aze",
            " known",
            " as"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "ai",
            ";",
            " for",
            " that",
            " heart",
            " which",
            " had",
            " le",
            "aped",
            " with",
            " joy",
            " over",
            " his",
            " younger",
            " brother",
            "'s",
            " rise",
            " to",
            " glory",
            " greater",
            " than",
            " his",
            " was",
            " decorated",
            " with",
            " the",
            " U",
            "rim",
            " and",
            " Th",
            "umm",
            "im",
            ",",
            " which",
            " were",
            " to",
            " \"",
            "be",
            " upon",
            " Aaron",
            "'s",
            " heart",
            " when",
            " he",
            " go",
            "eth",
            " in",
            " before",
            " the",
            " Lord",
            "\".",
            " Moses",
            " and",
            " Aaron",
            " met",
            " in",
            " glad",
            "ness",
            " of",
            " heart",
            ",",
            " kissing",
            " each"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "ine",
            " is",
            "otope",
            " has",
            " been",
            " observed",
            ",",
            " nor",
            " is",
            " one",
            " expected",
            " to",
            " exist",
            ".",
            "A",
            "stat",
            "ine",
            "'s",
            " alpha",
            " decay",
            " energies",
            " follow",
            " the",
            " same",
            " trend",
            " as",
            " for",
            " other",
            " heavy",
            " elements",
            ".",
            " Light",
            "er",
            " a",
            "stat",
            "ine",
            " isot",
            "opes",
            " have",
            " quite",
            " high",
            " energies",
            " of",
            " alpha",
            " decay",
            ",",
            " which",
            " become",
            " lower",
            " as",
            " the",
            " nuclei",
            " become",
            " heavier",
            ".",
            " A",
            "stat",
            "ine",
            "-",
            "211",
            " has",
            " a",
            " significantly"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " spectral",
            " lines",
            ".",
            "The",
            " amount",
            " of",
            " energy",
            " needed",
            " to",
            " remove",
            " or",
            " add",
            " an",
            " electron",
            "—the",
            " electron",
            " binding",
            " energy",
            "—is",
            " far",
            " less",
            " than",
            " the",
            " binding",
            " energy",
            " of",
            " nucle",
            "ons",
            ".",
            " For",
            " example",
            ",",
            " it",
            " requires",
            " only",
            " ",
            "13",
            ".",
            "6",
            "Âł",
            "e",
            "V",
            " to",
            " strip",
            " a",
            " ground",
            "-state",
            " electron",
            " from",
            " a",
            " hydrogen",
            " atom",
            ",",
            " compared",
            " to",
            " ",
            "2",
            ".",
            "23",
            "Âł",
            "million",
            " e",
            "V"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " truck",
            " the",
            " grain",
            " to",
            " central",
            " points",
            ".",
            "Albert",
            "a",
            " is",
            " the",
            " leading",
            " bee",
            "keeping",
            " province",
            " of",
            " Canada",
            ",",
            " with",
            " some",
            " bee",
            "keepers",
            " winter",
            "ing",
            " h",
            "ives",
            " indoors",
            " in",
            " specially",
            " designed",
            " barn",
            "s",
            " in",
            " southern",
            " Alberta",
            ",",
            " then",
            " migrating",
            " north",
            " during",
            " the",
            " summer",
            " into",
            " the",
            " Peace",
            " River",
            " valley",
            " where",
            " the",
            " season",
            " is",
            " short",
            " but",
            " the",
            " working",
            " days",
            " are",
            " long",
            " for",
            " honey",
            "be",
            "es",
            " to"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "Ã§a",
            ".",
            " \"",
            "Cit",
            "izens",
            "hip",
            ",",
            " National",
            " Identity",
            ",",
            " and",
            " Nation",
            "-B",
            "uild",
            "ing",
            " in",
            " Azerbaijan",
            ":",
            " Between",
            " the",
            " Legacy",
            " of",
            " the",
            " Past",
            " and",
            " the",
            " Spirit",
            " of",
            " Independence",
            ".\"",
            " National",
            "ities",
            " Papers",
            " (",
            "202",
            "1",
            "):",
            " ",
            "1",
            "–",
            "18",
            ".",
            " online",
            " G",
            "olt",
            "z",
            ",",
            " Thomas",
            ".",
            " Azerbaijan",
            " Diary",
            " :",
            " A",
            " Rogue",
            " Reporter",
            "'s",
            " Adventures",
            " in",
            " an",
            " Oil",
            "-R",
            "ich"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "ãĤ²",
    ".gdx",
    "adro",
    "iegel",
    "onda"
  ],
  "bottom_logits": [
    ".eng",
    "orage",
    " timezone",
    "assel",
    " Evel"
  ],
  "act_min": -0.0,
  "act_max": 0.719
}
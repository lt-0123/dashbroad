{
  "index": 56944,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.034,
            0.781,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " Battle",
            " of",
            " Jam",
            "rud",
            ".",
            " Ak",
            "bar",
            " Khan",
            " and",
            " the",
            " Afghan",
            " army",
            " failed",
            " to",
            " capture",
            " the",
            " Jam",
            "rud",
            " Fort",
            " from",
            " the",
            " Sikh",
            " Kh",
            "alsa",
            " Army",
            ",",
            " but",
            " killed",
            " Sikh",
            " Commander",
            " Hari",
            " Singh",
            " N",
            "al",
            "wa",
            ",",
            " thus",
            " ending",
            " the",
            " Afghan",
            "-S",
            "ikh",
            " Wars",
            ".",
            " By",
            " this",
            " time",
            " the",
            " British",
            " were",
            " advancing",
            " from",
            " the",
            " east",
            ",",
            " capital",
            "izing",
            " off",
            " of",
            " the",
            " decline",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.034,
            0.781,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " Battle",
            " of",
            " Jam",
            "rud",
            ".",
            " Ak",
            "bar",
            " Khan",
            " and",
            " the",
            " Afghan",
            " army",
            " failed",
            " to",
            " capture",
            " the",
            " Jam",
            "rud",
            " Fort",
            " from",
            " the",
            " Sikh",
            " Kh",
            "alsa",
            " Army",
            ",",
            " but",
            " killed",
            " Sikh",
            " Commander",
            " Hari",
            " Singh",
            " N",
            "al",
            "wa",
            ",",
            " thus",
            " ending",
            " the",
            " Afghan",
            "-S",
            "ikh",
            " Wars",
            ".",
            " By",
            " this",
            " time",
            " the",
            " British",
            " were",
            " advancing",
            " from",
            " the",
            " east",
            ",",
            " capital",
            "izing",
            " off",
            " of",
            " the",
            " decline",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.014,
            0.777,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 39,
          "is_repeated_datapoint": false,
          "tokens": [
            "al",
            "ized",
            "\"",
            " di",
            "ac",
            "ritic",
            " ()",
            " as",
            ":",
            " .",
            " This",
            " simultaneous",
            " artic",
            "ulation",
            " is",
            " described",
            " as",
            " \"",
            "Ret",
            "r",
            "acted",
            " Tong",
            "ue",
            " Root",
            "\"",
            " by",
            " phon",
            "ologists",
            ".",
            " In",
            " some",
            " transcription",
            " systems",
            ",",
            " emphasis",
            " is",
            " shown",
            " by",
            " capital",
            "izing",
            " the",
            " letter",
            ",",
            " for",
            " example",
            ",",
            " ",
            " is",
            " written",
            " ;",
            " in",
            " others",
            " the",
            " letter",
            " is",
            " under",
            "lined",
            " or",
            " has",
            " a",
            " dot",
            " below",
            " it"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.02,
            0.699,
            -0.0,
            0.003,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " capital",
            " of",
            " Per",
            "se",
            "pol",
            "is",
            " via",
            " the",
            " Persian",
            " Royal",
            " Road",
            ".",
            " Alexander",
            " himself",
            " took",
            " selected",
            " troops",
            " on",
            " the",
            " direct",
            " route",
            " to",
            " the",
            " city",
            ".",
            " He",
            " then",
            " stormed",
            " the",
            " pass",
            " of",
            " the",
            " Persian",
            " Gates",
            " (",
            "in",
            " the",
            " modern",
            " Zag",
            "ros",
            " Mountains",
            ")",
            " which",
            " had",
            " been",
            " blocked",
            " by",
            " a",
            " Persian",
            " army",
            " under",
            " Ari",
            "obar",
            "z",
            "anes",
            " and",
            " then",
            " hurried",
            " to",
            " Per",
            "se",
            "pol",
            "is"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.033,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.029,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " transl",
            "iteration",
            ",",
            " but",
            " some",
            " have",
            " named",
            " it",
            " Arabic",
            " Chat",
            " Alphabet",
            ".",
            " Other",
            " systems",
            " of",
            " transl",
            "iteration",
            " exist",
            ",",
            " such",
            " as",
            " using",
            " dots",
            " or",
            " capital",
            "ization",
            " to",
            " represent",
            " the",
            " \"",
            "em",
            "ph",
            "atic",
            "\"",
            " counterparts",
            " of",
            " certain",
            " conson",
            "ants",
            ".",
            " For",
            " instance",
            ",",
            " using",
            " capital",
            "ization",
            ",",
            " the",
            " letter",
            " ,",
            " may",
            " be",
            " represented",
            " by",
            " d",
            ".",
            " Its",
            " emph",
            "atic",
            " counterpart",
            ",",
            " ,"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.033,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.029,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " transl",
            "iteration",
            ",",
            " but",
            " some",
            " have",
            " named",
            " it",
            " Arabic",
            " Chat",
            " Alphabet",
            ".",
            " Other",
            " systems",
            " of",
            " transl",
            "iteration",
            " exist",
            ",",
            " such",
            " as",
            " using",
            " dots",
            " or",
            " capital",
            "ization",
            " to",
            " represent",
            " the",
            " \"",
            "em",
            "ph",
            "atic",
            "\"",
            " counterparts",
            " of",
            " certain",
            " conson",
            "ants",
            ".",
            " For",
            " instance",
            ",",
            " using",
            " capital",
            "ization",
            ",",
            " the",
            " letter",
            " ,",
            " may",
            " be",
            " represented",
            " by",
            " d",
            ".",
            " Its",
            " emph",
            "atic",
            " counterpart",
            ",",
            " ,"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.032,
            0.672,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 52,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " ",
            "201",
            "7",
            ",",
            " The",
            " Wall",
            " Street",
            " Journal",
            " reported",
            " that",
            " Apple",
            " had",
            " cash",
            " reserves",
            " of",
            " $",
            "250",
            "Âłb",
            "illion",
            ",",
            " officially",
            " confirmed",
            " by",
            " Apple",
            " as",
            " specifically",
            " $",
            "256",
            ".",
            "8",
            "Âłb",
            "illion",
            " a",
            " few",
            " days",
            " later",
            ".",
            ",",
            " Apple",
            " was",
            " the",
            " largest",
            " publicly",
            " traded",
            " corporation",
            " in",
            " the",
            " world",
            " by",
            " market",
            " capital",
            "ization",
            ".",
            " On",
            " August",
            " ",
            "2",
            ",",
            " ",
            "201",
            "8",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.028,
            0.664,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.032,
            0.668,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            " Mini",
            " computers",
            ".",
            "On",
            " August",
            " ",
            "20",
            ",",
            " ",
            "201",
            "2",
            ",",
            " Apple",
            "'s",
            " rising",
            " stock",
            " price",
            " increased",
            " the",
            " company",
            "'s",
            " market",
            " capital",
            "ization",
            " to",
            " a",
            " then",
            "-record",
            " $",
            "624",
            "Âłb",
            "illion",
            ".",
            " This",
            " beat",
            " the",
            " non",
            "-in",
            "flation",
            "-adjust",
            "ed",
            " record",
            " for",
            " market",
            " capital",
            "ization",
            " previously",
            " set",
            " by",
            " Microsoft",
            " in",
            " ",
            "199",
            "9",
            ".",
            " On",
            " August",
            " ",
            "24",
            ",",
            " ",
            "201",
            "2"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.028,
            0.668,
            0.173,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 17,
          "is_repeated_datapoint": false,
          "tokens": [
            " briefly",
            " topped",
            " $",
            "467",
            ".",
            "77",
            ",",
            " making",
            " Apple",
            " the",
            " first",
            " US",
            " company",
            " with",
            " a",
            " market",
            " capital",
            "ization",
            " of",
            " $",
            "2",
            " trillion",
            ".",
            "During",
            " its",
            " annual",
            " WW",
            "DC",
            " keynote",
            " speech",
            " on",
            " June",
            " ",
            "22",
            ",",
            " ",
            "202",
            "0",
            ",",
            " Apple",
            " announced",
            " it",
            " would",
            " move",
            " away",
            " from",
            " Intel",
            " processors",
            ",",
            " and",
            " the",
            " Mac",
            " would",
            " transition",
            " to",
            " processors",
            " developed",
            " in",
            "-house",
            ".",
            " The",
            " announcement",
            " was"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.028,
            0.664,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.032,
            0.668,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            " Mini",
            " computers",
            ".",
            "On",
            " August",
            " ",
            "20",
            ",",
            " ",
            "201",
            "2",
            ",",
            " Apple",
            "'s",
            " rising",
            " stock",
            " price",
            " increased",
            " the",
            " company",
            "'s",
            " market",
            " capital",
            "ization",
            " to",
            " a",
            " then",
            "-record",
            " $",
            "624",
            "Âłb",
            "illion",
            ".",
            " This",
            " beat",
            " the",
            " non",
            "-in",
            "flation",
            "-adjust",
            "ed",
            " record",
            " for",
            " market",
            " capital",
            "ization",
            " previously",
            " set",
            " by",
            " Microsoft",
            " in",
            " ",
            "199",
            "9",
            ".",
            " On",
            " August",
            " ",
            "24",
            ",",
            " ",
            "201",
            "2"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.037,
            0.664,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " Nashville",
            ",",
            " the",
            " capital",
            " of",
            " Tennessee",
            " and",
            " an",
            " increasingly",
            " important",
            " Confederate",
            " industrial",
            " center",
            ",",
            " beginning",
            " on",
            " February",
            " ",
            "11",
            ",",
            " ",
            "186",
            "2",
            ".",
            "John",
            "ston",
            " also",
            " reinforced",
            " Fort",
            " Don",
            "elson",
            " with",
            " ",
            "12",
            ",",
            "000",
            " more",
            " men",
            ",",
            " including",
            " those",
            " under",
            " Floyd",
            " and",
            " Pillow",
            ",",
            " a",
            " curious",
            " decision",
            " given",
            " his",
            " thought",
            " that",
            " the",
            " U",
            ".S",
            ".",
            " gun",
            "boats",
            " alone",
            " could",
            " take",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.022,
            0.664,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            "Regions",
            " of",
            " Turkey",
            "<|begin_of_text|>",
            "Apple",
            " Inc",
            ".",
            " is",
            " an",
            " American",
            " multinational",
            " technology",
            " company",
            " headquartered",
            " in",
            " Cupertino",
            ",",
            " California",
            ".",
            " ,",
            " Apple",
            " is",
            " the",
            " world",
            "'s",
            " biggest",
            " company",
            " by",
            " market",
            " capital",
            "ization",
            ",",
            " and",
            " with",
            " ",
            " the",
            " largest",
            " technology",
            " company",
            " by",
            " ",
            "202",
            "2",
            " revenue",
            ".",
            " ,",
            " Apple",
            " is",
            " the",
            " fourth",
            "-largest",
            " personal",
            " computer",
            " vendor",
            " by",
            " unit",
            " sales",
            ";",
            " the",
            " largest",
            " manufacturing",
            " company"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.04,
            0.648,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 33,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " Ankara",
            " Province",
            ",",
            " making",
            " it",
            " Turkey",
            "'s",
            " second",
            "-largest",
            " city",
            " after",
            " Istanbul",
            ",",
            " but",
            " first",
            " by",
            " the",
            " urban",
            " area",
            " (",
            "2",
            ",",
            "767",
            "Âł",
            "km",
            "2",
            ").",
            "S",
            "erving",
            " as",
            " the",
            " capital",
            " of",
            " the",
            " ancient",
            " Celtic",
            " state",
            " of",
            " Gal",
            "at",
            "ia",
            " (",
            "280",
            "–",
            "64",
            "Âł",
            "BC",
            "),",
            " and",
            " later",
            " of",
            " the",
            " Roman",
            " province",
            " with",
            " the",
            " same",
            " name",
            " (",
            "25",
            "Âł",
            "BC"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.039,
            0.648,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            "ists",
            " (",
            "Alabama",
            " Cre",
            "oles",
            ")",
            " in",
            " ",
            "170",
            "2",
            " as",
            " the",
            " capital",
            " of",
            " French",
            " Louisiana",
            ".",
            " Greater",
            " Birmingham",
            " is",
            " Alabama",
            "'s",
            " largest",
            " metropolitan",
            " area",
            " and",
            " its",
            " economic",
            " center",
            ".",
            "Originally",
            " home",
            " to",
            " many",
            " native",
            " tribes",
            ",",
            " present",
            "-day",
            " Alabama",
            " was",
            " a",
            " Spanish",
            " territory",
            " beginning",
            " in",
            " the",
            " six",
            "teenth",
            " century",
            " until",
            " the",
            " French",
            " acquired",
            " it",
            " in",
            " the",
            " early",
            " eight",
            "eenth",
            " century",
            ".",
            " The"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.039,
            0.648,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            "ists",
            " (",
            "Alabama",
            " Cre",
            "oles",
            ")",
            " in",
            " ",
            "170",
            "2",
            " as",
            " the",
            " capital",
            " of",
            " French",
            " Louisiana",
            ".",
            " Greater",
            " Birmingham",
            " is",
            " Alabama",
            "'s",
            " largest",
            " metropolitan",
            " area",
            " and",
            " its",
            " economic",
            " center",
            ".",
            "Originally",
            " home",
            " to",
            " many",
            " native",
            " tribes",
            ",",
            " present",
            "-day",
            " Alabama",
            " was",
            " a",
            " Spanish",
            " territory",
            " beginning",
            " in",
            " the",
            " six",
            "teenth",
            " century",
            " until",
            " the",
            " French",
            " acquired",
            " it",
            " in",
            " the",
            " early",
            " eight",
            "eenth",
            " century",
            ".",
            " The"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.045,
            0.644,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 27,
          "is_repeated_datapoint": false,
          "tokens": [
            " flag",
            " of",
            " American",
            " Samoa",
            " on",
            " Apollo",
            " ",
            "11",
            " is",
            " on",
            " display",
            " at",
            " the",
            " Jean",
            " P",
            ".",
            " Hay",
            "don",
            " Museum",
            " in",
            " P",
            "ago",
            " P",
            "ago",
            ",",
            " the",
            " capital",
            " of",
            " American",
            " Samoa",
            ".",
            "This",
            " celebration",
            " began",
            " a",
            " ",
            "38",
            "-day",
            " world",
            " tour",
            " that",
            " brought",
            " the",
            " astronauts",
            " to",
            " ",
            "22",
            " foreign",
            " countries",
            " and",
            " included",
            " visits",
            " with",
            " the",
            " leaders",
            " of",
            " many",
            " countries",
            ".",
            " The",
            " crew",
            " toured",
            " from"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.039,
            0.644,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            "an",
            " conv",
            "oked",
            " an",
            " assembly",
            " of",
            " the",
            " states",
            ",",
            " and",
            " in",
            " ",
            "106",
            "6",
            ",",
            " he",
            " declared",
            " his",
            " son",
            " Malik",
            " Shah",
            " I",
            " his",
            " heir",
            " and",
            " successor",
            ".",
            " With",
            " the",
            " hope",
            " of",
            " capturing",
            " Ca",
            "es",
            "area",
            " Maz",
            "aca",
            ",",
            " the",
            " capital",
            " of",
            " C",
            "app",
            "ad",
            "oc",
            "ia",
            ",",
            " he",
            " placed",
            " himself",
            " at",
            " the",
            " head",
            " of",
            " the",
            " Turk",
            "oman",
            " cavalry",
            ",",
            " crossed",
            " the",
            " E",
            "up"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.046,
            0.644,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            " D",
            "urr",
            "ani",
            " S",
            "ard",
            "ars",
            " and",
            " influential",
            " tribal",
            " leaders",
            " in",
            " Kabul",
            " and",
            " K",
            "and",
            "ah",
            "ar",
            ".",
            " One",
            " of",
            " Tim",
            "ur",
            " Shah",
            "'s",
            " reforms",
            " was",
            " to",
            " move",
            " the",
            " capital",
            " of",
            " the",
            " D",
            "urr",
            "ani",
            " Empire",
            " from",
            " K",
            "and",
            "ah",
            "ar",
            " to",
            " Kabul",
            ".",
            " Tim",
            "ur",
            " Shah",
            " fought",
            " multiple",
            " series",
            " of",
            " rebell",
            "ions",
            " to",
            " consolidate",
            " the",
            " empire",
            ",",
            " and",
            " he",
            " also",
            " led",
            " campaigns"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.046,
            0.641,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.06,
            -0.0,
            -0.0
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            " five",
            " presidents",
            " to",
            " do",
            " so",
            ".",
            "He",
            " has",
            " been",
            " memorial",
            "ized",
            " in",
            " many",
            " town",
            ",",
            " city",
            ",",
            " and",
            " county",
            " names",
            ",",
            " including",
            " the",
            " capital",
            " of",
            " Nebraska",
            ".",
            " The",
            " United",
            " States",
            " Navy",
            "  ",
            " is",
            " named",
            " after",
            " Lincoln",
            ",",
            " the",
            " second",
            " Navy",
            " ship",
            " to",
            " bear",
            " his",
            " name",
            ".",
            " The",
            " Lincoln",
            " Memorial",
            " is",
            " one",
            " of",
            " the",
            " most",
            " visited",
            " monuments",
            " in",
            " the",
            " nation",
            "'s",
            " capital",
            " and",
            " is"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.042,
            0.641,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " two",
            " days",
            " before",
            " Johnston",
            " arrived",
            " in",
            " the",
            " Confeder",
            "acy",
            "'s",
            " capital",
            " of",
            " Richmond",
            ",",
            " Virginia",
            ",",
            " after",
            " his",
            " cross",
            "-country",
            " journey",
            ",",
            " drove",
            " Kentucky",
            " from",
            " its",
            " stated",
            " neutrality",
            ".",
            " The",
            " majority",
            " of",
            " Kent",
            "uck",
            "ians",
            " allied",
            " with",
            " the",
            " U",
            ".S",
            ".",
            " camp",
            ".",
            " Pol",
            "k",
            " and",
            " Pillow",
            "'s",
            " action",
            " gave",
            " U",
            ".S",
            ".",
            " Brig",
            ".",
            " Gen",
            ".",
            " U",
            "ly",
            "ss",
            "es",
            " S"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.05,
            0.641,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 59,
          "is_repeated_datapoint": false,
          "tokens": [
            "ik",
            " I",
            " was",
            " able",
            " to",
            " ou",
            "st",
            " the",
            " Assy",
            "rians",
            " with",
            " the",
            " help",
            " of",
            " Greek",
            " mercenaries",
            ",",
            " who",
            " were",
            " recruited",
            " to",
            " form",
            " Egypt",
            "'s",
            " first",
            " navy",
            ".",
            " Greek",
            " influence",
            " expanded",
            " greatly",
            " as",
            " the",
            " city",
            "-state",
            " of",
            " Na",
            "uc",
            "r",
            "atis",
            " became",
            " the",
            " home",
            " of",
            " Greeks",
            " in",
            " the",
            " Nile",
            " Delta",
            ".",
            " The",
            " Sa",
            "ite",
            " kings",
            " based",
            " in",
            " the",
            " new",
            " capital",
            " of",
            " S",
            "ais",
            " witnessed"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.05,
            0.637,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 48,
          "is_repeated_datapoint": false,
          "tokens": [
            " government",
            " is",
            " headed",
            " by",
            " the",
            " premier",
            ".",
            " The",
            " premier",
            " is",
            " normally",
            " a",
            " member",
            " of",
            " the",
            " Legislative",
            " Assembly",
            ",",
            " and",
            " draws",
            " all",
            " the",
            " members",
            " of",
            " the",
            " Cabinet",
            " from",
            " among",
            " the",
            " members",
            " of",
            " the",
            " Legislative",
            " Assembly",
            ".",
            " The",
            " City",
            " of",
            " Edmonton",
            " is",
            " the",
            " seat",
            " of",
            " the",
            " provincial",
            " government",
            "—the",
            " capital",
            " of",
            " Alberta",
            ".",
            " The",
            " current",
            " premier",
            " is",
            " Danielle",
            " Smith",
            ",",
            " who",
            " was",
            " sworn",
            " in",
            " on"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.042,
            0.637,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            " at",
            " ",
            "20",
            ",",
            "000",
            " to",
            " ",
            "60",
            ",",
            "000",
            ".",
            " It",
            " was",
            " sacked",
            " by",
            " Egyptians",
            " under",
            " Ibrahim",
            " P",
            "asha",
            " in",
            " ",
            "183",
            "2",
            ".",
            "From",
            " ",
            "186",
            "7",
            " to",
            " ",
            "192",
            "2",
            ",",
            " the",
            " city",
            " served",
            " as",
            " the",
            " capital",
            " of",
            " the",
            " Ang",
            "ora",
            " Vil",
            "ayet",
            ",",
            " which",
            " included",
            " most",
            " of",
            " ancient",
            " Gal",
            "at",
            "ia",
            ".",
            "Prior",
            " to",
            " World",
            " War",
            " I",
            ",",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.045,
            0.637,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            "Tem",
            "ple",
            " of",
            " August",
            "us",
            " and",
            " Rome",
            "The",
            " August",
            "eum",
            ",",
            " now",
            " known",
            " as",
            " the",
            " Temple",
            " of",
            " August",
            "us",
            " and",
            " Rome",
            ",",
            " was",
            " built",
            " ",
            "25",
            "Âł",
            "Âł",
            "20",
            "Âł",
            "BC",
            " following",
            " the",
            " conquest",
            " of",
            " Central",
            " Anat",
            "olia",
            " by",
            " the",
            " Roman",
            " Empire",
            ".",
            " A",
            "ncy",
            "ra",
            " then",
            " formed",
            " the",
            " capital",
            " of",
            " the",
            " new",
            " province",
            " of",
            " Gal",
            "at",
            "ia",
            ".",
            " After",
            " the",
            " death"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.037,
            0.637,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            " that",
            " the",
            " union",
            " would",
            " produce",
            " a",
            " legitimate",
            " heir",
            ".",
            "In",
            " ",
            "337",
            " BC",
            ",",
            " Alexander",
            " fled",
            " Maced",
            "on",
            " with",
            " his",
            " mother",
            ",",
            " dropping",
            " her",
            " off",
            " with",
            " her",
            " brother",
            ",",
            " King",
            " Alexander",
            " I",
            " of",
            " E",
            "pir",
            "us",
            " in",
            " Dod",
            "ona",
            ",",
            " capital",
            " of",
            " the",
            " Mol",
            "oss",
            "ians",
            ".",
            " He",
            " continued",
            " to",
            " Il",
            "ly",
            "ria",
            ",",
            " where",
            " he",
            " sought",
            " refuge",
            " with",
            " one",
            " or",
            " more",
            " Il"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.025,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.041,
            0.637,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 43,
          "is_repeated_datapoint": false,
          "tokens": [
            "ncy",
            "ra",
            " became",
            " capital",
            " of",
            " the",
            " Ops",
            "ician",
            " Theme",
            ",",
            " which",
            " was",
            " the",
            " largest",
            " and",
            " most",
            " important",
            " theme",
            " until",
            " it",
            " was",
            " split",
            " up",
            " under",
            " Emperor",
            " Constant",
            "ine",
            " V",
            " (",
            "r",
            ".",
            " ",
            "741",
            "–",
            "775",
            ");",
            " A",
            "ncy",
            "ra",
            " then",
            " became",
            " the",
            " capital",
            " of",
            " the",
            " new",
            " B",
            "uc",
            "ell",
            "arian",
            " Theme",
            ".",
            " The",
            " city",
            " was",
            " captured",
            " at",
            " least",
            " temporarily",
            " by",
            " the",
            " U",
            "may"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.045,
            0.637,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            "Alexander",
            " III",
            " was",
            " born",
            " in",
            " P",
            "ella",
            ",",
            " the",
            " capital",
            " of",
            " the",
            " Kingdom",
            " of",
            " Maced",
            "on",
            ",",
            " on",
            " the",
            " sixth",
            " day",
            " of",
            " the",
            " ancient",
            " Greek",
            " month",
            " of",
            " H",
            "ek",
            "at",
            "omba",
            "ion",
            ",",
            " which",
            " probably",
            " corresponds",
            " to",
            " ",
            "20",
            " July",
            " ",
            "356",
            " BC",
            " (",
            "although",
            " the",
            " exact",
            " date",
            " is",
            " uncertain",
            ").",
            " He",
            " was",
            " the",
            " son",
            " of",
            " the",
            " erst",
            "while",
            " king",
            " of",
            " Maced"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.034,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.042,
            0.633,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            "6",
            ",",
            "659",
            ",",
            "300",
            " inhabitants",
            ".",
            "Of",
            " these",
            " various",
            " metropolitan",
            " area",
            " configurations",
            ",",
            " only",
            " the",
            " St",
            "ads",
            "reg",
            "io",
            " Amsterdam",
            " (",
            "City",
            " Region",
            " of",
            " Amsterdam",
            ")",
            " has",
            " a",
            " formal",
            " governmental",
            " status",
            ".",
            " Its",
            " responsibilities",
            " include",
            " regional",
            " spatial",
            " planning",
            " and",
            " the",
            " metropolitan",
            " public",
            " transport",
            " concessions",
            ".",
            "National",
            " capital",
            "Under",
            " the",
            " Dutch",
            " Constitution",
            ",",
            " Amsterdam",
            " is",
            " the",
            " capital",
            " of",
            " the",
            " Netherlands",
            ".",
            " Since"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.042,
            0.633,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 53,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            " in",
            " July",
            ",",
            " with",
            " an",
            " annual",
            " mean",
            " of",
            " .",
            "Dem",
            "ographics",
            " ",
            "An",
            "kara",
            " had",
            " a",
            " population",
            " of",
            " ",
            "75",
            ",",
            "000",
            " in",
            " ",
            "192",
            "7",
            ".",
            " As",
            " of",
            " ",
            "201",
            "9",
            ",",
            " the",
            " population",
            " of",
            " the",
            " Ankara",
            " Province",
            " was",
            " ",
            "5",
            ",",
            "639",
            ",",
            "076",
            ".",
            " When",
            " Ankara",
            " became",
            " the",
            " capital",
            " of",
            " the",
            " Republic",
            " of",
            " Turkey",
            " in",
            " ",
            "192",
            "3",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.036,
            0.633,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.038,
            -0.0
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            " carried",
            " out",
            " an",
            " expanded",
            " colonization",
            " program",
            " during",
            " the",
            " early",
            "-to",
            "-m",
            "id",
            "-",
            "19",
            "th",
            " century",
            ".",
            " Sit",
            "ka",
            ",",
            " renamed",
            " New",
            " Arch",
            "angel",
            " from",
            " ",
            "180",
            "4",
            " to",
            " ",
            "186",
            "7",
            ",",
            " on",
            " Bar",
            "an",
            "of",
            " Island",
            " in",
            " the",
            " Alexander",
            " Arch",
            "ipel",
            "ago",
            " in",
            " what",
            " is",
            " now",
            " Southeast",
            " Alaska",
            ",",
            " became",
            " the",
            " capital",
            " of",
            " Russian",
            " America",
            ".",
            " It",
            " remained",
            " the",
            " capital",
            " after"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.044,
            0.633,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "13",
            " October",
            " ",
            "192",
            "3",
            ",",
            " and",
            " Republican",
            " officials",
            " declared",
            " that",
            " the",
            " city",
            "'s",
            " name",
            " is",
            " Ankara",
            ".",
            "After",
            " Ankara",
            " became",
            " the",
            " capital",
            " of",
            " the",
            " newly",
            " founded",
            " Republic",
            " of",
            " Turkey",
            ",",
            " new",
            " development",
            " divided",
            " the",
            " city",
            " into",
            " an",
            " old",
            " section",
            ",",
            " called",
            " Ulus",
            ",",
            " and",
            " a",
            " new",
            " section",
            ",",
            " called",
            " Yeni",
            "ÅŁehir",
            ".",
            " Ancient",
            " buildings",
            " reflecting",
            " Roman",
            ",",
            " Byz",
            "antine",
            ",",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.037,
            0.633,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            " ()",
            " means",
            " \"",
            "stone",
            ",\"",
            " and",
            " some",
            " to",
            "pon",
            "yms",
            " may",
            " be",
            " derived",
            " from",
            " this",
            " word",
            ":",
            " ",
            " (",
            "P",
            "ella",
            ",",
            " the",
            " capital",
            " of",
            " ancient",
            " Macedonia",
            ")",
            " and",
            " ",
            " (",
            "P",
            "ell",
            "Äĵ",
            "n",
            "Äĵ",
            "/P",
            "ell",
            "ene",
            ").",
            "The",
            " H",
            "itt",
            "ite",
            " form",
            " Ap",
            "ali",
            "unas",
            " (",
            "d",
            ")",
            " is",
            " att",
            "ested",
            " in",
            " the",
            " Man",
            "apa",
            "-T",
            "ar",
            "h",
            "unta"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.044,
            0.633,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "13",
            " October",
            " ",
            "192",
            "3",
            ",",
            " and",
            " Republican",
            " officials",
            " declared",
            " that",
            " the",
            " city",
            "'s",
            " name",
            " is",
            " Ankara",
            ".",
            "After",
            " Ankara",
            " became",
            " the",
            " capital",
            " of",
            " the",
            " newly",
            " founded",
            " Republic",
            " of",
            " Turkey",
            ",",
            " new",
            " development",
            " divided",
            " the",
            " city",
            " into",
            " an",
            " old",
            " section",
            ",",
            " called",
            " Ulus",
            ",",
            " and",
            " a",
            " new",
            " section",
            ",",
            " called",
            " Yeni",
            "ÅŁehir",
            ".",
            " Ancient",
            " buildings",
            " reflecting",
            " Roman",
            ",",
            " Byz",
            "antine",
            ",",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.029,
            0.629,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 44,
          "is_repeated_datapoint": false,
          "tokens": [
            " Some",
            " men",
            " enlisted",
            " in",
            " the",
            " Union",
            " Army",
            " and",
            " others",
            " in",
            " the",
            " Confederate",
            " Army",
            ".",
            " West",
            " Virginia",
            " separated",
            " from",
            " Virginia",
            " and",
            " was",
            " admitted",
            " to",
            " the",
            " Union",
            " on",
            " June",
            " ",
            "20",
            ",",
            " ",
            "186",
            "3",
            ".",
            "Mary",
            "land",
            "'s",
            " territory",
            " surrounded",
            " the",
            " United",
            " States",
            "'",
            " capital",
            " of",
            " Washington",
            ",",
            " D",
            ".C",
            ".,",
            " and",
            " could",
            " cut",
            " it",
            " off",
            " from",
            " the",
            " North",
            ".",
            " It",
            " had",
            " numerous",
            " anti"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.029,
            0.625,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            " T",
            "arga",
            " Flor",
            "io",
            " was",
            " an",
            " open",
            " road",
            " endurance",
            " automobile",
            " race",
            " held",
            " in",
            " the",
            " mountains",
            " of",
            " Sic",
            "ily",
            ",",
            " Italy",
            " near",
            " the",
            " island",
            "'s",
            " capital",
            " of",
            " Pal",
            "ermo",
            ".",
            " Founded",
            " in",
            " ",
            "190",
            "6",
            ",",
            " it",
            " was",
            " the",
            " oldest",
            " sports",
            " car",
            " racing",
            " event",
            ",",
            " part",
            " of",
            " the",
            " World",
            " Sport",
            "scar",
            " Championship",
            " between",
            " ",
            "195",
            "5",
            " and",
            " ",
            "197",
            "3",
            ".",
            "The",
            " oldest",
            " surviving"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.049,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            " end",
            " of",
            " the",
            " year",
            ".",
            " Popular",
            " support",
            " w",
            "aver",
            "ed",
            ",",
            " and",
            " morale",
            " declined",
            ".",
            " On",
            " December",
            " ",
            "20",
            ",",
            " ",
            "177",
            "6",
            ",",
            " the",
            " Continental",
            " Congress",
            " abandoned",
            " the",
            " revolutionary",
            " capital",
            " of",
            " Philadelphia",
            " and",
            " moved",
            " to",
            " Baltimore",
            ",",
            " where",
            " it",
            " remained",
            " for",
            " over",
            " two",
            " months",
            ",",
            " until",
            " February",
            " ",
            "27",
            ",",
            " ",
            "177",
            "7",
            ".",
            " L",
            "oyal",
            "ist",
            " activity",
            " surged",
            " in",
            " the",
            " wake"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.035,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 7,
          "is_repeated_datapoint": false,
          "tokens": [
            " Institute",
            " standards",
            "<|begin_of_text|>",
            "Austin",
            " is",
            " the",
            " capital",
            " of",
            " Texas",
            " in",
            " the",
            " United",
            " States",
            ".",
            "Austin",
            " may",
            " also",
            " refer",
            " to",
            ":",
            "Ge",
            "ographical",
            " locations",
            "Australia",
            " Austin",
            ",",
            " Western",
            " Australia",
            "Canada",
            " Austin",
            ",",
            " Manitoba",
            " Austin",
            ",",
            " Ontario",
            " Austin",
            ",",
            " Quebec",
            " Austin",
            " Island",
            ",",
            " Nun",
            "av",
            "ut",
            "France",
            " Saint",
            "-A",
            "ustin",
            ",",
            " ham",
            "let",
            " at",
            " la",
            " Neu"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.02,
            0.586
          ],
          "train_token_ind": 62,
          "is_repeated_datapoint": false,
          "tokens": [
            " Golden",
            " Age",
            ",",
            " and",
            " the",
            " establishment",
            " of",
            " the",
            " Van",
            " G",
            "ogh",
            " Museum",
            ",",
            " displaying",
            " the",
            " work",
            " of",
            " the",
            " famous",
            " Dutch",
            " modern",
            " artist",
            ",",
            " have",
            " attracted",
            " millions",
            " of",
            " visitors",
            " to",
            " Amsterdam",
            " annually",
            ".",
            "The",
            " Amsterdam",
            " Stock",
            " Exchange",
            ",",
            " founded",
            " in",
            " ",
            "160",
            "2",
            ",",
            " is",
            " considered",
            " the",
            " oldest",
            " \"",
            "modern",
            "\"",
            " securities",
            " market",
            " stock",
            " exchange",
            " in",
            " the",
            " world",
            ".",
            " As",
            " the",
            " commercial",
            " capital",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.023,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.12,
            0.535,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            " debate",
            " within",
            " anarch",
            "ism",
            ",",
            " as",
            " many",
            " of",
            " these",
            " types",
            " like",
            " to",
            " pretend",
            ",",
            " but",
            " a",
            " debate",
            " between",
            " anarch",
            "ism",
            " and",
            " its",
            " old",
            " enemy",
            " capitalism",
            ".",
            " ...",
            " Equ",
            "ally",
            ",",
            " given",
            " that",
            " anarchists",
            " and",
            " '",
            "an",
            "ar",
            "cho",
            "'-",
            "capital",
            "ists",
            " have",
            " fundamentally",
            " different",
            " analyses",
            " and",
            " goals",
            " it",
            " is",
            " hardly",
            " '",
            "sect",
            "arian",
            "'",
            " to",
            " point",
            " this",
            " out",
            "\".",
            "Davis",
            " writes",
            " that",
            " \""
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.005,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.006,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.512,
            -0.0,
            -0.0
          ],
          "train_token_ind": 60,
          "is_repeated_datapoint": false,
          "tokens": [
            " simplistic",
            ",",
            " and",
            " unrealistic",
            ",",
            " respectively",
            ".",
            " Classical",
            " anarch",
            "ism",
            " has",
            " been",
            " criticised",
            " for",
            " relying",
            " too",
            " heavily",
            " on",
            " the",
            " belief",
            " that",
            " the",
            " abolition",
            " of",
            " the",
            " state",
            " will",
            " lead",
            " to",
            " human",
            " cooperation",
            " prosper",
            "ing",
            ".",
            "F",
            "ried",
            "rich",
            " Eng",
            "els",
            ",",
            " considered",
            " to",
            " be",
            " one",
            " of",
            " the",
            " principal",
            " founders",
            " of",
            " Marxism",
            ",",
            " criticised",
            " anarch",
            "ism",
            "'s",
            " anti",
            "-author",
            "itarian",
            "ism",
            " as",
            " inherently",
            " counter",
            "-re"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.381,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 49,
          "is_repeated_datapoint": false,
          "tokens": [
            " her",
            " figure",
            " prominently",
            " in",
            " novels",
            " by",
            " American",
            " authors",
            ",",
            " including",
            " Kay",
            " N",
            "ol",
            "te",
            " Smith",
            ",",
            " Mary",
            " Ga",
            "its",
            "kill",
            ",",
            " Matt",
            " R",
            "uff",
            ",",
            " and",
            " Tobias",
            " Wolff",
            ".",
            " Nick",
            " Gilles",
            "pie",
            ",",
            " former",
            " editor",
            "-in",
            "-chief",
            " of",
            " Reason",
            ",",
            " remarked",
            ":",
            " \"",
            "Rand",
            "'s",
            " is",
            " a",
            " tortured",
            " imm",
            "ortality",
            ",",
            " one",
            " in",
            " which",
            " she",
            "'s",
            " as",
            " likely",
            " to",
            " be",
            " a",
            " punch",
            " line"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.037,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.359,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " court",
            " of",
            " Mahm",
            "ud",
            " of",
            " Gh",
            "az",
            "ni",
            ",",
            " reported",
            " that",
            " they",
            "The",
            " goals",
            " of",
            " al",
            "chemy",
            " in",
            " India",
            " included",
            " the",
            " creation",
            " of",
            " a",
            " divine",
            " body",
            " (",
            "S",
            "ansk",
            "rit",
            " div",
            "ya",
            "-de",
            "ham",
            ")",
            " and",
            " imm",
            "ortality",
            " while",
            " still",
            " embodied",
            " (",
            "S",
            "ansk",
            "rit",
            " j",
            "Ä«",
            "van",
            "-m",
            "uk",
            "ti",
            ").",
            " Sans",
            "krit",
            " al",
            "chemical",
            " texts",
            " include",
            " much",
            " material",
            " on"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.247,
            0.305,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.249,
            0.338,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.047,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.256,
            0.254,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.256,
            0.268,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            " anarchist",
            " until",
            " the",
            " mid",
            "-",
            "20",
            "th",
            " century",
            ",",
            " when",
            " an",
            "ar",
            "cho",
            "-capital",
            "ist",
            " theory",
            " developed",
            ".",
            "An",
            "ar",
            "cho",
            "-capital",
            "ists",
            " are",
            " distinguished",
            " from",
            " the",
            " dominant",
            " anarchist",
            " tradition",
            " by",
            " their",
            " relation",
            " to",
            " property",
            " and",
            " capital",
            ".",
            " While",
            " both",
            " anarch",
            "ism",
            " and",
            " an",
            "ar",
            "cho",
            "-capital",
            "ism",
            " share",
            " general",
            " ant",
            "ip",
            "athy",
            " towards",
            " government",
            " authority",
            ",",
            " an",
            "ar",
            "cho",
            "-capital",
            "ism",
            " favors"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.082,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.245,
            0.332,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.062,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 49,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " extension",
            " of",
            " \"",
            "entre",
            "preneur",
            "ial",
            " freedom",
            "\"",
            " and",
            " \"",
            "competitive",
            " market",
            " rational",
            "ity",
            "\"",
            " to",
            " the",
            " point",
            " where",
            " the",
            " scope",
            " for",
            " private",
            " enterprise",
            " is",
            " all",
            "-en",
            "compass",
            "ing",
            " and",
            " \"",
            "le",
            "aves",
            " no",
            " space",
            " for",
            " state",
            " action",
            " whatsoever",
            "\".",
            "On",
            " the",
            " state",
            " ",
            "An",
            "ar",
            "cho",
            "-capital",
            "ists",
            " oppose",
            " the",
            " state",
            " and",
            " seek",
            " to",
            " privat",
            "ize",
            " any",
            " useful",
            " service",
            " the",
            " government"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.25,
            0.33,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            " which",
            " he",
            " includes",
            " direct",
            " violence",
            ",",
            " assault",
            " and",
            " murder",
            ")",
            " or",
            " property",
            " (",
            "in",
            " which",
            " he",
            " includes",
            " fraud",
            ",",
            " burglary",
            ",",
            " theft",
            " and",
            " taxation",
            ").",
            " The",
            " initiation",
            " of",
            " force",
            " is",
            " usually",
            " referred",
            " to",
            " as",
            " aggression",
            " or",
            " coercion",
            ".",
            " The",
            " difference",
            " between",
            " an",
            "ar",
            "cho",
            "-capital",
            "ists",
            " and",
            " other",
            " libert",
            "arians",
            " is",
            " largely",
            " one",
            " of",
            " the",
            " degree",
            " to",
            " which",
            " they",
            " take",
            " this",
            " axiom",
            "."
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.241,
            0.254,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.247,
            0.324,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            " a",
            " monopol",
            "istic",
            " private",
            " defense",
            " and",
            " judicial",
            " agency",
            " that",
            " no",
            " longer",
            " faces",
            " competition",
            ".",
            " He",
            " argues",
            " that",
            " an",
            "ar",
            "cho",
            "-capital",
            "ism",
            " results",
            " in",
            " an",
            " unstable",
            " system",
            " that",
            " would",
            " not",
            " endure",
            " in",
            " the",
            " real",
            " world",
            ".",
            " While",
            " an",
            "ar",
            "cho",
            "-capital",
            "ists",
            " such",
            " as",
            " Roy",
            " Child",
            "s",
            " and",
            " Murray",
            " Roth",
            "bard",
            " have",
            " rejected",
            " No",
            "z",
            "ick",
            "'s",
            " arguments",
            ",",
            " with",
            " Roth",
            "bard",
            " arguing"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.258,
            0.295,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 42,
          "is_repeated_datapoint": false,
          "tokens": [
            " financial",
            " system",
            " from",
            " an",
            " anthrop",
            "ological",
            " perspective",
            ".",
            "Political",
            " economy",
            "Political",
            " economy",
            " in",
            " anthropology",
            " is",
            " the",
            " application",
            " of",
            " the",
            " theories",
            " and",
            " methods",
            " of",
            " historical",
            " material",
            "ism",
            " to",
            " the",
            " traditional",
            " concerns",
            " of",
            " anthropology",
            ",",
            " including",
            ",",
            " but",
            " not",
            " limited",
            " to",
            ",",
            " non",
            "-capital",
            "ist",
            " societies",
            ".",
            " Political",
            " economy",
            " introduced",
            " questions",
            " of",
            " history",
            " and",
            " colonial",
            "ism",
            " to",
            " ah",
            "istorical",
            " anthrop",
            "ological",
            " theories",
            " of",
            " social"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.275,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " continuing",
            " ,",
            " Apple",
            " publicly",
            " disagreed",
            " with",
            " the",
            " BBC",
            " and",
            " stated",
            ":",
            " \"",
            "We",
            " are",
            " aware",
            " of",
            " no",
            " other",
            " company",
            " doing",
            " as",
            " much",
            " as",
            " Apple",
            " to",
            " ensure",
            " fair",
            " and",
            " safe",
            " working",
            " conditions",
            "\".",
            "In",
            " December",
            " ",
            "201",
            "4",
            ",",
            " the",
            " Institute",
            " for",
            " Global",
            " Labour",
            " and",
            " Human",
            " Rights",
            " published",
            " a",
            " report",
            " which",
            " documented",
            " in",
            "hum",
            "ane",
            " conditions",
            " for",
            " the",
            " ",
            "15",
            ",",
            "000",
            " workers",
            " at"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.264,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 42,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            "Dr",
            ".",
            " Cast",
            "el",
            ":",
            " Dr",
            ".",
            " Cast",
            "el",
            " is",
            " one",
            " of",
            " R",
            "ieux",
            "'s",
            " medical",
            " colleagues",
            " and",
            " is",
            " much",
            " older",
            " than",
            " R",
            "ieux",
            ".",
            " He",
            " realizes",
            " after",
            " the",
            " first",
            " few",
            " cases",
            " that",
            " the",
            " disease",
            " is",
            " bub",
            "onic",
            " plague",
            " and",
            " is",
            " aware",
            " of",
            " the",
            " seriousness",
            " of",
            " the",
            " situation",
            ".",
            " He",
            " works",
            " hard",
            " to",
            " make",
            " an",
            " anti",
            "pl",
            "ague",
            " serum",
            ",",
            " but",
            " as"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.158,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 44,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " Commun",
            "ism",
            ",",
            " not",
            " to",
            " be",
            " confused",
            " with",
            " the",
            " philosophy",
            " of",
            " Animal",
            "ism",
            ".",
            " Soon",
            " after",
            ",",
            " Napoleon",
            " and",
            " S",
            "que",
            "aler",
            " part",
            "ake",
            " in",
            " activities",
            " associated",
            " with",
            " the",
            " humans",
            " (",
            "dr",
            "inking",
            " alcohol",
            ",",
            " sleeping",
            " in",
            " beds",
            ",",
            " trading",
            "),",
            " which",
            " were",
            " explicitly",
            " prohibited",
            " by",
            " the",
            " Seven",
            " Command",
            "ments",
            ".",
            " S",
            "que",
            "aler",
            " is",
            " employed",
            " to",
            " alter",
            " the",
            " Seven",
            " Command",
            "ments"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " beer",
            " selection",
            ",",
            " F",
            "atter",
            " Esk",
            "ild",
            " with",
            " a",
            " broad",
            " selection",
            " of",
            " Danish",
            " bands",
            " playing",
            " mostly",
            " blues",
            " and",
            " rock",
            ",",
            " the",
            " wine",
            " and",
            " book",
            " cafÃ©",
            " L",
            "Ã¸",
            "ve",
            "'s",
            " in",
            " N",
            "Ã¸r",
            "reg",
            "ade",
            ",",
            " Sherlock",
            " Holmes",
            ",",
            " a",
            " British",
            "-style",
            " pub",
            " with",
            " live",
            " music",
            ",",
            " and",
            " the",
            " brew",
            " pub",
            " of",
            " S",
            "ct",
            ".",
            " Clem",
            "ens",
            ",",
            " with",
            " A",
            " Here",
            "ford",
            " Beef",
            "st"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " Or",
            "phe",
            "us",
            ",",
            " E",
            "ri",
            "opis",
            ",",
            " famous",
            " for",
            " her",
            " beautiful",
            " hair",
            ",",
            " Mel",
            "ite",
            " the",
            " heroine",
            ",",
            " Pam",
            "ph",
            "ile",
            " the",
            " silk",
            " we",
            "aver",
            ",",
            " Par",
            "then",
            "os",
            ",",
            " and",
            " by",
            " some",
            " accounts",
            ",",
            " Ph",
            "oe",
            "be",
            ",",
            " H",
            "ily",
            "ra",
            " and",
            " Sc",
            "yll",
            "a",
            ".",
            " Apollo",
            " turned",
            " Par",
            "then",
            "os",
            " into",
            " a",
            " constellation",
            " after",
            " her",
            " early",
            " death",
            ".",
            "Additionally"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " form",
            " similar",
            " to",
            " what",
            " is",
            " now",
            " known",
            " as",
            " K",
            "arna",
            "ugh",
            " maps",
            ".",
            " J",
            "ev",
            "ons",
            " (",
            "188",
            "0",
            ")",
            " describes",
            " first",
            " a",
            " simple",
            " \"",
            "ab",
            "acus",
            "\"",
            " of",
            " \"",
            "sl",
            "ips",
            " of",
            " wood",
            " furnished",
            " with",
            " pins",
            ",",
            " contr",
            "ived",
            " so",
            " that",
            " any",
            " part",
            " or",
            " class",
            " of",
            " the",
            " [",
            "logical",
            "]",
            " combinations",
            " can",
            " be",
            " picked",
            " out",
            " mechanically",
            " ...",
            " More",
            " recently",
            ",",
            " however",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "Latin",
            "-spe",
            "akers",
            " adopted",
            " the",
            " Greek",
            " term",
            " as",
            " ,",
            " which",
            " in",
            " French",
            " ultimately",
            " became",
            " ,",
            " whence",
            " the",
            " English",
            " word",
            " \"",
            "ars",
            "enic",
            "\".",
            "Ars",
            "enic",
            " sulf",
            "ides",
            " (",
            "orp",
            "iment",
            ",",
            " real",
            "gar",
            ")",
            " and",
            " ox",
            "ides",
            " have",
            " been",
            " known",
            " and",
            " used",
            " since",
            " ancient",
            " times",
            ".",
            " Z",
            "os",
            "imos",
            " ()",
            " describes",
            " ro",
            "asting",
            " sand",
            "ar",
            "ach",
            " (",
            "real",
            "gar",
            ")",
            " to",
            " obtain",
            " cloud"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " chosen",
            " by",
            " the",
            " ",
            "38",
            " provinces",
            ".",
            " The",
            " body",
            " has",
            " a",
            " permanent",
            " secret",
            "ariat",
            ",",
            " the",
            " Anglic",
            "an",
            " Comm",
            "union",
            " Office",
            ",",
            " of",
            " which",
            " the",
            " arch",
            "bishop",
            " of",
            " Canterbury",
            " is",
            " president",
            ".",
            " The",
            " Prim",
            "ates",
            "'",
            " Meeting",
            " (",
            "first",
            " met",
            " in",
            " ",
            "197",
            "9",
            ")",
            " is",
            " the",
            " most",
            " recent",
            " manifestation",
            " of",
            " international",
            " consultation",
            " and",
            " deliber",
            "ation",
            ",",
            " having",
            " been",
            " first",
            " convened",
            " by",
            " Archbishop"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    " WaitForSeconds",
    "celik",
    "kola",
    "acula",
    "cura"
  ],
  "bottom_logits": [
    "psz",
    "aget",
    "FINE",
    ".Mask",
    "textInput"
  ],
  "act_min": -0.0,
  "act_max": 0.781
}
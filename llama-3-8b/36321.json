{
  "index": 36321,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.629,
            0.064,
            -0.0,
            -0.0,
            -0.0,
            0.633,
            0.065,
            -0.0,
            0.621,
            0.06,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.039,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            "186",
            "0",
            " United",
            " States",
            " presidential",
            " election",
            "Candidates",
            " in",
            " the",
            " ",
            "186",
            "4",
            " United",
            " States",
            " presidential",
            " election",
            "Hall",
            " of",
            " Fame",
            " for",
            " Great",
            " Americans",
            " in",
            "duct",
            "ees",
            "Ill",
            "inois",
            " Central",
            " Railroad",
            " people",
            "Ill",
            "inois",
            " Republicans",
            "Ill",
            "inois",
            " lawyers",
            "Ab",
            "raham",
            "Male",
            " murder",
            " victims",
            "Members",
            " of",
            " the",
            " Illinois",
            " House",
            " of",
            " Representatives",
            "People",
            " associated",
            " with",
            " the",
            " assassination",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.629,
            0.064,
            -0.0,
            -0.0,
            -0.0,
            0.633,
            0.065,
            -0.0,
            0.621,
            0.06,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.039,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            "186",
            "0",
            " United",
            " States",
            " presidential",
            " election",
            "Candidates",
            " in",
            " the",
            " ",
            "186",
            "4",
            " United",
            " States",
            " presidential",
            " election",
            "Hall",
            " of",
            " Fame",
            " for",
            " Great",
            " Americans",
            " in",
            "duct",
            "ees",
            "Ill",
            "inois",
            " Central",
            " Railroad",
            " people",
            "Ill",
            "inois",
            " Republicans",
            "Ill",
            "inois",
            " lawyers",
            "Ab",
            "raham",
            "Male",
            " murder",
            " victims",
            "Members",
            " of",
            " the",
            " Illinois",
            " House",
            " of",
            " Representatives",
            "People",
            " associated",
            " with",
            " the",
            " assassination",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.629,
            0.064,
            -0.0,
            -0.0,
            -0.0,
            0.633,
            0.065,
            -0.0,
            0.621,
            0.06,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.039,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            "186",
            "0",
            " United",
            " States",
            " presidential",
            " election",
            "Candidates",
            " in",
            " the",
            " ",
            "186",
            "4",
            " United",
            " States",
            " presidential",
            " election",
            "Hall",
            " of",
            " Fame",
            " for",
            " Great",
            " Americans",
            " in",
            "duct",
            "ees",
            "Ill",
            "inois",
            " Central",
            " Railroad",
            " people",
            "Ill",
            "inois",
            " Republicans",
            "Ill",
            "inois",
            " lawyers",
            "Ab",
            "raham",
            "Male",
            " murder",
            " victims",
            "Members",
            " of",
            " the",
            " Illinois",
            " House",
            " of",
            " Representatives",
            "People",
            " associated",
            " with",
            " the",
            " assassination",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.625,
            0.069,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            " movement",
            "American",
            " lawyers",
            " admitted",
            " to",
            " the",
            " practice",
            " of",
            " law",
            " by",
            " reading",
            " law",
            "American",
            " military",
            " personnel",
            " of",
            " the",
            " Indian",
            " Wars",
            "American",
            " militia",
            " officers",
            "American",
            " nationalists",
            "American",
            " political",
            " party",
            " founders",
            "Ill",
            "inois",
            " post",
            "masters",
            "American",
            " survey",
            "ors",
            "Ass",
            "ass",
            "inated",
            " presidents",
            " of",
            " the",
            " United",
            " States",
            "Bur",
            "ials",
            " at",
            " Oak",
            " Ridge",
            " Cemetery",
            "Candidates",
            " in",
            " the",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.617,
            0.065,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            " Lincoln",
            " borrowed",
            " legal",
            " texts",
            " from",
            " attorneys",
            " John",
            " Todd",
            " Stuart",
            " and",
            " Thomas",
            " Drum",
            "mond",
            ",",
            " purchased",
            " books",
            " including",
            " Black",
            "stone",
            "'s",
            " Comment",
            "aries",
            " and",
            " Ch",
            "itty",
            "'s",
            " P",
            "lead",
            "ings",
            ",",
            " and",
            " read",
            " law",
            " on",
            " his",
            " own",
            ".",
            " He",
            " later",
            " said",
            " of",
            " his",
            " legal",
            " education",
            " that",
            " \"",
            "I",
            " studied",
            " with",
            " nobody",
            ".\"",
            "Ill",
            "inois",
            " state",
            " legislature",
            " (",
            "183",
            "4",
            "–",
            "184",
            "2",
            ")",
            " "
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.613,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.1,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            "'d",
            " circ",
            "led",
            " with",
            " the",
            " intention",
            " to",
            " print",
            ".\"",
            "Ill",
            "ness",
            " and",
            " death",
            "In",
            " ",
            "196",
            "0",
            ",",
            " he",
            " was",
            " treated",
            " for",
            " a",
            " tropical",
            " disease",
            ",",
            " and",
            " it",
            " is",
            " speculated",
            " that",
            " he",
            " contracted",
            " hepatitis",
            " from",
            " an",
            " un",
            "ster",
            "il",
            "ized",
            " needle",
            " administered",
            " by",
            " a",
            " doctor",
            ",",
            " which",
            " played",
            " a",
            " role",
            " in",
            " his",
            " death",
            " ",
            "37",
            " years",
            " later",
            ".",
            "G",
            "ins",
            "berg",
            " was"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.613,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.1,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            "'d",
            " circ",
            "led",
            " with",
            " the",
            " intention",
            " to",
            " print",
            ".\"",
            "Ill",
            "ness",
            " and",
            " death",
            "In",
            " ",
            "196",
            "0",
            ",",
            " he",
            " was",
            " treated",
            " for",
            " a",
            " tropical",
            " disease",
            ",",
            " and",
            " it",
            " is",
            " speculated",
            " that",
            " he",
            " contracted",
            " hepatitis",
            " from",
            " an",
            " un",
            "ster",
            "il",
            "ized",
            " needle",
            " administered",
            " by",
            " a",
            " doctor",
            ",",
            " which",
            " played",
            " a",
            " role",
            " in",
            " his",
            " death",
            " ",
            "37",
            " years",
            " later",
            ".",
            "G",
            "ins",
            "berg",
            " was"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.562,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.015,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " ",
            "20",
            "th",
            " century",
            " and",
            " eventually",
            " outr",
            "anked",
            " Iz",
            "mir",
            " as",
            " Turkey",
            "'s",
            " second",
            "-largest",
            " city",
            ",",
            " after",
            " Istanbul",
            ".",
            " Ankara",
            "'s",
            " urban",
            " population",
            " reached",
            " ",
            "4",
            ",",
            "587",
            ",",
            "558",
            " in",
            " ",
            "201",
            "4",
            ",",
            " while",
            " the",
            " population",
            " of",
            " Ankara",
            " Province",
            " reached",
            " ",
            "5",
            ",",
            "150",
            ",",
            "072",
            " in",
            " ",
            "201",
            "5",
            ".",
            "The",
            " Presidential",
            " Palace",
            " of",
            " Turkey",
            " is",
            " situated"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.547
          ],
          "train_token_ind": 62,
          "is_repeated_datapoint": false,
          "tokens": [
            " on",
            " the",
            " words",
            " \"",
            "traditional",
            "\"",
            " and",
            " \"",
            "digital",
            "\")",
            " to",
            " describe",
            " cel",
            " animation",
            " that",
            " uses",
            " significant",
            " computer",
            " technology",
            ".",
            "Examples",
            " of",
            " traditionally",
            " animated",
            " feature",
            " films",
            " include",
            " Pin",
            "oc",
            "chio",
            " (",
            "United",
            " States",
            ",",
            " ",
            "194",
            "0",
            "),",
            " Animal",
            " Farm",
            " (",
            "United",
            " Kingdom",
            ",",
            " ",
            "195",
            "4",
            "),",
            " Lucky",
            " and",
            " Z",
            "or",
            "ba",
            " (",
            "Italy",
            ",",
            " ",
            "199",
            "8",
            "),",
            " and",
            " The",
            " Ill"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.547,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            " H",
            "ux",
            "ley",
            " and",
            " Alternative",
            " Spirit",
            "uality",
            ",",
            " Brill",
            ",",
            " ",
            "201",
            "9",
            ".",
            " .",
            " R",
            "olo",
            ",",
            " Charles",
            " J",
            ".",
            " (",
            "ed",
            ".).",
            " The",
            " World",
            " of",
            " Ald",
            "ous",
            " H",
            "ux",
            "ley",
            ",",
            " Gros",
            "set",
            " Universal",
            " Library",
            ",",
            " ",
            "194",
            "7",
            ".",
            " Shaw",
            ",",
            " Jeffrey",
            " M",
            ".",
            " Ill",
            "usions",
            " of",
            " Freedom",
            ":",
            " Thomas",
            " M",
            "erton",
            " and",
            " Jacques",
            " Ell",
            "ul",
            " on",
            " Technology",
            " and",
            " the"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.543,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 36,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " city",
            ".",
            "The",
            " Mo",
            "es",
            "g",
            "Ã¥",
            "rd",
            " Museum",
            " special",
            "ises",
            " in",
            " archae",
            "ology",
            " and",
            " ethn",
            "ography",
            " in",
            " collaboration",
            " with",
            " A",
            "arhus",
            " University",
            " with",
            " exhibits",
            " on",
            " Denmark",
            "'s",
            " pre",
            "history",
            ",",
            " including",
            " weapon",
            " sacrifices",
            " from",
            " Ill",
            "er",
            "up",
            " Ãħ",
            "dal",
            " and",
            " the",
            " Gra",
            "ub",
            "alle",
            " Man",
            ".",
            " Kv",
            "ind",
            "em",
            "use",
            "et",
            ",",
            " the",
            " Women",
            "'s",
            " Museum",
            ",",
            " from",
            " ",
            "198",
            "4"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.539,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            "0",
            " –",
            " Ish",
            "ida",
            " Mits",
            "un",
            "ari",
            "’s",
            " Western",
            " Army",
            " comm",
            "ences",
            " the",
            " Siege",
            " of",
            " F",
            "ush",
            "imi",
            " Castle",
            ",",
            " which",
            " is",
            " lightly",
            " defended",
            " by",
            " a",
            " much",
            " smaller",
            " Tok",
            "ug",
            "awa",
            " g",
            "arrison",
            " led",
            " by",
            " Tor",
            "ii",
            " Mot",
            "ot",
            "ada",
            ".",
            "160",
            "1",
            "–",
            "190",
            "0",
            "168",
            "9",
            " –",
            " The",
            " Treaty",
            " of",
            " Ner",
            "ch",
            "insk",
            " is",
            " signed",
            " by",
            " Russia",
            " and",
            " the",
            " Qing"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.539,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " ill",
            "-t",
            "reatment",
            " persisted",
            ".\"",
            "The",
            " Guardian",
            " reported",
            " in",
            " April",
            " ",
            "201",
            "7",
            " that",
            " \"",
            "A",
            "zerbai",
            "jan",
            "'s",
            " ruling",
            " elite",
            " operated",
            " a",
            " secret",
            " $",
            "2",
            ".",
            "9",
            "bn",
            " (Â£",
            "2",
            ".",
            "2",
            "bn",
            ")",
            " scheme",
            " to",
            " pay",
            " prominent",
            " Europeans",
            ",",
            " buy",
            " luxury",
            " goods",
            " and",
            " launder",
            " money",
            " through",
            " a",
            " network",
            " of",
            " opaque",
            " British",
            " companies",
            " ....",
            " Le",
            "aked",
            " data",
            " shows",
            " that",
            " the",
            " Azerbai",
            "j"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.539,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " ill",
            "-t",
            "reatment",
            " persisted",
            ".\"",
            "The",
            " Guardian",
            " reported",
            " in",
            " April",
            " ",
            "201",
            "7",
            " that",
            " \"",
            "A",
            "zerbai",
            "jan",
            "'s",
            " ruling",
            " elite",
            " operated",
            " a",
            " secret",
            " $",
            "2",
            ".",
            "9",
            "bn",
            " (Â£",
            "2",
            ".",
            "2",
            "bn",
            ")",
            " scheme",
            " to",
            " pay",
            " prominent",
            " Europeans",
            ",",
            " buy",
            " luxury",
            " goods",
            " and",
            " launder",
            " money",
            " through",
            " a",
            " network",
            " of",
            " opaque",
            " British",
            " companies",
            " ....",
            " Le",
            "aked",
            " data",
            " shows",
            " that",
            " the",
            " Azerbai",
            "j"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.523,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            " I",
            ".B",
            ".",
            " T",
            "aur",
            "is",
            ",",
            " ",
            "201",
            "0",
            ".",
            " ",
            " Aug",
            "ros",
            ",",
            " Robert",
            " M",
            ".,",
            " St",
            "anc",
            "iu",
            ",",
            " George",
            " N",
            ".",
            " The",
            " New",
            " Story",
            " of",
            " Science",
            ":",
            " mind",
            " and",
            " the",
            " universe",
            ",",
            " Lake",
            " Bl",
            "uff",
            ",",
            " Ill",
            ".:",
            " Reg",
            "n",
            "ery",
            " Gateway",
            ",",
            " ",
            "198",
            "4",
            ".",
            " ",
            " (",
            "this",
            " book",
            " has",
            " significant",
            " material",
            " on",
            " art",
            " and",
            " science",
            ")"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.523,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            " I",
            ".B",
            ".",
            " T",
            "aur",
            "is",
            ",",
            " ",
            "201",
            "0",
            ".",
            " ",
            " Aug",
            "ros",
            ",",
            " Robert",
            " M",
            ".,",
            " St",
            "anc",
            "iu",
            ",",
            " George",
            " N",
            ".",
            " The",
            " New",
            " Story",
            " of",
            " Science",
            ":",
            " mind",
            " and",
            " the",
            " universe",
            ",",
            " Lake",
            " Bl",
            "uff",
            ",",
            " Ill",
            ".:",
            " Reg",
            "n",
            "ery",
            " Gateway",
            ",",
            " ",
            "198",
            "4",
            ".",
            " ",
            " (",
            "this",
            " book",
            " has",
            " significant",
            " material",
            " on",
            " art",
            " and",
            " science",
            ")"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.52,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            "le",
            " Ill",
            "iec",
            ",",
            " where",
            " the",
            " Lind",
            "ber",
            "gh",
            "s",
            " often",
            " res",
            "ided",
            " in",
            " the",
            " late",
            " ",
            "193",
            "0",
            "s",
            ".",
            "Contrib",
            "utions",
            " to",
            " science",
            "V",
            "ascular",
            " s",
            "uture",
            " ",
            "Car",
            "rel",
            " was",
            " a",
            " young",
            " surgeon",
            " who",
            " was",
            " deeply",
            " affected",
            " by",
            " the",
            " ",
            "189",
            "4",
            " assassination",
            " of",
            " the",
            " French",
            " president",
            ",",
            " S",
            "adi",
            " Carn",
            "ot",
            ",",
            " who",
            " died",
            " from",
            " a",
            " severed",
            " portal"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.52,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            "minated",
            " and",
            " ill",
            "-defined",
            ",",
            " and",
            " finally",
            ",",
            " lesions",
            " are",
            " strictly",
            " per",
            "iven",
            "ous",
            ",",
            " while",
            " in",
            " MS",
            " they",
            " are",
            " disposed",
            " around",
            " veins",
            ",",
            " but",
            " not",
            " so",
            " sharply",
            ".",
            "Nevertheless",
            ",",
            " the",
            " co",
            "-",
            "occ",
            "urrence",
            " of",
            " per",
            "iven",
            "ous",
            " and",
            " confl",
            "uent",
            " dem",
            "y",
            "el",
            "ination",
            " in",
            " some",
            " individuals",
            " suggests",
            " path",
            "ogenic",
            " overlap",
            " between",
            " acute",
            " disse",
            "minated",
            " en",
            "ceph",
            "al",
            "omy",
            "el"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.52,
            -0.0
          ],
          "train_token_ind": 61,
          "is_repeated_datapoint": false,
          "tokens": [
            "ery",
            " and",
            " Advoc",
            "acy",
            " in",
            " Angola",
            ",",
            " Dis",
            "asters",
            " ",
            "29",
            "(",
            "1",
            "):",
            " ",
            "1",
            "–",
            "25",
            ".",
            " Le",
            " Bill",
            "on",
            ",",
            " Philippe",
            " (",
            "200",
            "1",
            ").",
            " \"",
            "Ang",
            "ola",
            "'s",
            " Political",
            " Economy",
            " of",
            " War",
            ":",
            " The",
            " Role",
            " of",
            " Oil",
            " and",
            " Diamonds",
            "\".",
            " African",
            " Affairs",
            " (",
            "100",
            "):",
            " ",
            "55",
            "–",
            "80",
            ".",
            " ",
            " Mac",
            "Queen",
            ",",
            " Nor",
            "rie",
            " An",
            " Ill",
            " Wind"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.52,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            "minated",
            " and",
            " ill",
            "-defined",
            ",",
            " and",
            " finally",
            ",",
            " lesions",
            " are",
            " strictly",
            " per",
            "iven",
            "ous",
            ",",
            " while",
            " in",
            " MS",
            " they",
            " are",
            " disposed",
            " around",
            " veins",
            ",",
            " but",
            " not",
            " so",
            " sharply",
            ".",
            "Nevertheless",
            ",",
            " the",
            " co",
            "-",
            "occ",
            "urrence",
            " of",
            " per",
            "iven",
            "ous",
            " and",
            " confl",
            "uent",
            " dem",
            "y",
            "el",
            "ination",
            " in",
            " some",
            " individuals",
            " suggests",
            " path",
            "ogenic",
            " overlap",
            " between",
            " acute",
            " disse",
            "minated",
            " en",
            "ceph",
            "al",
            "omy",
            "el"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " benefit",
            " of",
            " preventing",
            " ill",
            "-b",
            "eg",
            "otten",
            " children",
            ".",
            " Concern",
            "ing",
            " this",
            ",",
            " he",
            " stated",
            " that",
            " \"",
            "the",
            " vice",
            " we",
            " are",
            " considering",
            " appears",
            " to",
            " work",
            " directly",
            " against",
            " the",
            " aims",
            " and",
            " ends",
            " of",
            " nature",
            ",",
            " and",
            " that",
            " in",
            " a",
            " matter",
            " that",
            " is",
            " all",
            " important",
            " and",
            " of",
            " the",
            " greatest",
            " concern",
            " to",
            " her",
            " it",
            " must",
            " in",
            " fact",
            " serve",
            " these",
            " very",
            " aims",
            ",",
            " although",
            " only",
            " indirectly",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.512,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " any",
            " ill",
            " or",
            " damage",
            " intended",
            " him",
            " without",
            " defending",
            " him",
            " there",
            "from",
            ".\"",
            " This",
            " was",
            " thought",
            " to",
            " favour",
            " the",
            " doctrine",
            " of",
            " absolute",
            " non",
            "-res",
            "istance",
            ",",
            " and",
            ",",
            " accordingly",
            ",",
            " the",
            " Convention",
            " Parliament",
            " enacted",
            " the",
            " form",
            " that",
            " has",
            " been",
            " in",
            " use",
            " since",
            " that",
            " time",
            " –",
            " \"",
            "I",
            " do",
            " sincerely",
            " promise",
            " and",
            " swear",
            " that",
            " I",
            " will",
            " be",
            " faithful",
            " and",
            " bear",
            " true",
            " allegiance",
            " to",
            " His",
            " Majesty"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 29,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " severe",
            " consequences",
            ",",
            " such",
            " as",
            " internal",
            " exile",
            ",",
            " extended",
            " imprisonment",
            " and",
            " execution",
            ".",
            " The",
            " regime",
            " confronted",
            " a",
            " multitude",
            " of",
            " challenges",
            " in",
            " Albania",
            " that",
            " encompass",
            "ed",
            " widespread",
            " poverty",
            ",",
            " ill",
            "iter",
            "acy",
            ",",
            " health",
            " crises",
            " and",
            " gender",
            " inequality",
            ".",
            " As",
            " a",
            " response",
            ",",
            " H",
            "ox",
            "ha",
            " initiated",
            " a",
            " modern",
            "isation",
            " initiative",
            " aimed",
            " at",
            " att",
            "aining",
            " economic",
            " and",
            " social",
            " liberation",
            " and",
            " transforming",
            " the",
            " country"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " ill",
            "iter",
            "acy",
            ",",
            " the",
            " Alger",
            "ian",
            " government",
            " introduced",
            " a",
            " decree",
            " by",
            " which",
            " school",
            " attendance",
            " became",
            " compulsory",
            " for",
            " all",
            " children",
            " aged",
            " between",
            " ",
            "6",
            " and",
            " ",
            "15",
            " years",
            " who",
            " have",
            " the",
            " ability",
            " to",
            " track",
            " their",
            " learning",
            " through",
            " the",
            " ",
            "20",
            " facilities",
            " built",
            " since",
            " independence",
            ",",
            " now",
            " the",
            " literacy",
            " rate",
            " is",
            " around",
            " ",
            "92",
            ".",
            "6",
            "%.",
            " Since",
            " ",
            "197",
            "2",
            ",",
            " Arabic"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 29,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " severe",
            " consequences",
            ",",
            " such",
            " as",
            " internal",
            " exile",
            ",",
            " extended",
            " imprisonment",
            " and",
            " execution",
            ".",
            " The",
            " regime",
            " confronted",
            " a",
            " multitude",
            " of",
            " challenges",
            " in",
            " Albania",
            " that",
            " encompass",
            "ed",
            " widespread",
            " poverty",
            ",",
            " ill",
            "iter",
            "acy",
            ",",
            " health",
            " crises",
            " and",
            " gender",
            " inequality",
            ".",
            " As",
            " a",
            " response",
            ",",
            " H",
            "ox",
            "ha",
            " initiated",
            " a",
            " modern",
            "isation",
            " initiative",
            " aimed",
            " at",
            " att",
            "aining",
            " economic",
            " and",
            " social",
            " liberation",
            " and",
            " transforming",
            " the",
            " country"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 29,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " severe",
            " consequences",
            ",",
            " such",
            " as",
            " internal",
            " exile",
            ",",
            " extended",
            " imprisonment",
            " and",
            " execution",
            ".",
            " The",
            " regime",
            " confronted",
            " a",
            " multitude",
            " of",
            " challenges",
            " in",
            " Albania",
            " that",
            " encompass",
            "ed",
            " widespread",
            " poverty",
            ",",
            " ill",
            "iter",
            "acy",
            ",",
            " health",
            " crises",
            " and",
            " gender",
            " inequality",
            ".",
            " As",
            " a",
            " response",
            ",",
            " H",
            "ox",
            "ha",
            " initiated",
            " a",
            " modern",
            "isation",
            " initiative",
            " aimed",
            " at",
            " att",
            "aining",
            " economic",
            " and",
            " social",
            " liberation",
            " and",
            " transforming",
            " the",
            " country"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.504
          ],
          "train_token_ind": 62,
          "is_repeated_datapoint": false,
          "tokens": [
            " or",
            " technical",
            ".",
            " At",
            " the",
            " end",
            " of",
            " the",
            " third",
            " year",
            " of",
            " secondary",
            " school",
            ",",
            " students",
            " pass",
            " the",
            " exam",
            " of",
            " the",
            " b",
            "acc",
            "ala",
            "ure",
            "ate",
            ",",
            " which",
            " allows",
            " once",
            " it",
            " is",
            " successful",
            " to",
            " pursue",
            " graduate",
            " studies",
            " in",
            " universities",
            " and",
            " institutes",
            ".",
            "Education",
            " is",
            " officially",
            " compulsory",
            " for",
            " children",
            " between",
            " the",
            " ages",
            " of",
            " six",
            " and",
            " ",
            "15",
            ".",
            " In",
            " ",
            "200",
            "8",
            ",",
            " the",
            " ill"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            "iter",
            "acy",
            " rate",
            " for",
            " people",
            " over",
            " ",
            "10",
            " was",
            " ",
            "22",
            ".",
            "3",
            "%,",
            " ",
            "15",
            ".",
            "6",
            "%",
            " for",
            " men",
            " and",
            " ",
            "29",
            ".",
            "0",
            "%",
            " for",
            " women",
            ".",
            " The",
            " province",
            " with",
            " the",
            " lowest",
            " rate",
            " of",
            " ill",
            "iter",
            "acy",
            " was",
            " Alg",
            "iers",
            " Province",
            " at",
            " ",
            "11",
            ".",
            "6",
            "%,",
            " while",
            " the",
            " province",
            " with",
            " the",
            " highest",
            " rate",
            " was",
            " Dj",
            "elf",
            "a",
            " Province",
            " at"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.498,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " time",
            ",",
            " Peter",
            " dealt",
            " with",
            " public",
            " hostility",
            " towards",
            " Spider",
            "-Man",
            " and",
            " the",
            " antagon",
            "ism",
            " of",
            " his",
            " classmates",
            " Flash",
            " Thompson",
            " and",
            " Liz",
            " Allan",
            " at",
            " Mid",
            "town",
            " High",
            " School",
            ",",
            " while",
            " emb",
            "arking",
            " on",
            " a",
            " tentative",
            ",",
            " ill",
            "-f",
            "ated",
            " romance",
            " with",
            " James",
            "on",
            "'s",
            " secretary",
            ",",
            " Betty",
            " Br",
            "ant",
            ".",
            "By",
            " focusing",
            " on",
            " Parker",
            "'s",
            " everyday",
            " problems",
            ",",
            " Lee",
            " and",
            " Dit",
            "ko",
            " created",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.498,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " healing",
            " are",
            " associated",
            " with",
            " Apollo",
            ",",
            " whether",
            " through",
            " the",
            " god",
            " himself",
            " or",
            " mediated",
            " through",
            " his",
            " son",
            " As",
            "cle",
            "pi",
            "us",
            ".",
            " Apollo",
            " delivered",
            " people",
            " from",
            " epid",
            "emics",
            ",",
            " yet",
            " he",
            " is",
            " also",
            " a",
            " god",
            " who",
            " could",
            " bring",
            " ill",
            " health",
            " and",
            " deadly",
            " plague",
            " with",
            " his",
            " arrows",
            ".",
            " The",
            " invention",
            " of",
            " arch",
            "ery",
            " itself",
            " is",
            " credited",
            " to",
            " Apollo",
            " and",
            " his",
            " sister",
            " Artem",
            "is",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.498,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " healing",
            " are",
            " associated",
            " with",
            " Apollo",
            ",",
            " whether",
            " through",
            " the",
            " god",
            " himself",
            " or",
            " mediated",
            " through",
            " his",
            " son",
            " As",
            "cle",
            "pi",
            "us",
            ".",
            " Apollo",
            " delivered",
            " people",
            " from",
            " epid",
            "emics",
            ",",
            " yet",
            " he",
            " is",
            " also",
            " a",
            " god",
            " who",
            " could",
            " bring",
            " ill",
            " health",
            " and",
            " deadly",
            " plague",
            " with",
            " his",
            " arrows",
            ".",
            " The",
            " invention",
            " of",
            " arch",
            "ery",
            " itself",
            " is",
            " credited",
            " to",
            " Apollo",
            " and",
            " his",
            " sister",
            " Artem",
            "is",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.029,
            -0.0,
            -0.0,
            -0.0,
            0.496,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 29,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " Administrative",
            " regions",
            " of",
            " Greece",
            " border",
            " the",
            " sea",
            ",",
            " along",
            " with",
            " the",
            " Turkish",
            " provinces",
            " of",
            " Ed",
            "ir",
            "ne",
            ",",
            " Ãĩ",
            "an",
            "akk",
            "ale",
            ",",
            " Bal",
            "Ä±",
            "kes",
            "ir",
            ",",
            " Iz",
            "mir",
            ",",
            " AydÄ±n",
            " and",
            " Mu",
            "ÄŁ",
            "la",
            " to",
            " the",
            " east",
            " of",
            " the",
            " sea",
            ".",
            " Various",
            " Turkish",
            " islands",
            " in",
            " the",
            " sea",
            " are",
            " Im",
            "b",
            "ros",
            ",",
            " T",
            "ened",
            "os",
            ",",
            " C",
            "unda",
            " Island",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.494,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            " The",
            " orientation",
            " of",
            " the",
            " thor",
            "acic",
            " append",
            "ages",
            " appears",
            " ill",
            "-su",
            "ited",
            " for",
            " b",
            "enth",
            "ic",
            " living",
            ".",
            " Recent",
            " work",
            " suggests",
            " that",
            " some",
            " ag",
            "nost",
            "ids",
            " were",
            " b",
            "enth",
            "ic",
            " predators",
            ",",
            " engaging",
            " in",
            " cann",
            "ibal",
            "ism",
            " and",
            " possibly",
            " pack",
            "-h",
            "unting",
            " behavior",
            ".",
            "They",
            " are",
            " sometimes",
            " preserved",
            " within",
            " the",
            " void",
            "s",
            " of",
            " other",
            " organisms",
            ",",
            " for",
            " instance",
            " within",
            " empty",
            " hy",
            "olith"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.494,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.03,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            " January",
            " ",
            "19",
            ",",
            " ",
            "186",
            "2",
            ",",
            " the",
            " ill",
            "-pre",
            "pared",
            " Confeder",
            "ates",
            ",",
            " after",
            " a",
            " night",
            " march",
            " in",
            " the",
            " rain",
            ",",
            " attacked",
            " the",
            " U",
            ".S",
            ".",
            " soldiers",
            " with",
            " some",
            " initial",
            " success",
            ".",
            " As",
            " the",
            " battle",
            " progressed",
            ",",
            " Z",
            "ol",
            "lic",
            "offer",
            " was",
            " killed",
            " and",
            " the",
            " Confeder",
            "ates",
            " were",
            " turned",
            " back",
            " and",
            " routed",
            " by",
            " a",
            " U",
            ".S",
            ".",
            " bay",
            "onet",
            " charge",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.492,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 44,
          "is_repeated_datapoint": false,
          "tokens": [
            "201",
            "7",
            ",",
            " it",
            " was",
            " announced",
            " by",
            " E",
            "ber",
            "hard",
            " van",
            " der",
            " La",
            "an",
            " in",
            " an",
            " open",
            " letter",
            " to",
            " Amsterdam",
            " citizens",
            " that",
            " K",
            "aj",
            "sa",
            " O",
            "ll",
            "ong",
            "ren",
            " would",
            " take",
            " up",
            " his",
            " office",
            " as",
            " acting",
            " Mayor",
            " of",
            " Amsterdam",
            " with",
            " immediate",
            " effect",
            " due",
            " to",
            " ill",
            " health",
            ".",
            " O",
            "ll",
            "ong",
            "ren",
            " was",
            " succeeded",
            " as",
            " acting",
            " Mayor",
            " by",
            " Eric",
            " van",
            " der",
            " Burg",
            " on",
            " "
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.492,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " into",
            " an",
            " industrial",
            " society",
            ".",
            " The",
            " regime",
            " placed",
            " a",
            " high",
            " priority",
            " on",
            " the",
            " divers",
            "ification",
            " of",
            " the",
            " economy",
            " through",
            " a",
            " programme",
            " of",
            " Soviet",
            "-style",
            " industrial",
            "isation",
            ",",
            " comprehensive",
            " infrastructure",
            " development",
            " such",
            " as",
            " the",
            " introduction",
            " of",
            " a",
            " transformative",
            " railway",
            " system",
            ",",
            " expansion",
            " of",
            " education",
            " and",
            " healthcare",
            " services",
            ",",
            " elimination",
            " of",
            " adult",
            " ill",
            "iter",
            "acy",
            " and",
            " targeted",
            " advancements",
            " in",
            " areas",
            " such",
            " as",
            " women",
            "'s",
            " rights"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.486,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            " Party",
            ".",
            " It",
            " insisted",
            " that",
            " the",
            " Constitution",
            " did",
            " not",
            " bind",
            " legislators",
            " to",
            " a",
            " policy",
            " of",
            " balance",
            "—that",
            " slavery",
            " could",
            " be",
            " excluded",
            " in",
            " a",
            " territory",
            ",",
            " as",
            " it",
            " was",
            " in",
            " the",
            " Northwest",
            " Ord",
            "inance",
            " of",
            " ",
            "178",
            "7",
            ",",
            " at",
            " the",
            " discretion",
            " of",
            " Congress",
            ".",
            " Thus",
            " Congress",
            " could",
            " restrict",
            " human",
            " bondage",
            ",",
            " but",
            " never",
            " establish",
            " it",
            ".",
            " The",
            " ill",
            "-f",
            "ated",
            " W",
            "ilm",
            "ot"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.441,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " comm",
            "uted",
            ".",
            " The",
            " technique",
            " is",
            " a",
            " form",
            " of",
            " av",
            "ersion",
            " therapy",
            " in",
            " which",
            " Alex",
            " is",
            " injected",
            " with",
            " nausea",
            "-ind",
            "ucing",
            " drugs",
            " while",
            " watching",
            " graph",
            "ically",
            " violent",
            " films",
            ",",
            " eventually",
            " conditioning",
            " him",
            " to",
            " become",
            " severely",
            " ill",
            " at",
            " the",
            " mere",
            " thought",
            " of",
            " violence",
            ".",
            " As",
            " an",
            " unintended",
            " consequence",
            ",",
            " the",
            " soundtrack",
            " to",
            " one",
            " of",
            " the",
            " films",
            ",",
            " Be",
            "ethoven",
            "'s",
            " Ninth",
            " Symphony",
            ",",
            " renders"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.385,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 58,
          "is_repeated_datapoint": false,
          "tokens": [
            "95",
            "}",
            "Am",
            " ->",
            "[\\",
            "ce",
            "{(",
            "n",
            ",\\",
            "gamma",
            ")}",
            "]",
            " ^{",
            "244",
            "}_{",
            "95",
            "}",
            "Am",
            " ->",
            "[\\",
            "beta",
            "^-",
            "][",
            "10",
            ".",
            "1",
            " \\",
            " \\",
            "ce",
            "{",
            "h",
            "}]",
            " ^{",
            "244",
            "}_{",
            "96",
            "}",
            "C",
            "m",
            "I",
            "rr",
            "adi",
            "ation",
            " of",
            " ",
            "241",
            "Am",
            " by",
            " ",
            "12",
            "C",
            " or",
            " ",
            "22",
            "Ne",
            " ions",
            " yields",
            " the",
            " isot",
            "opes",
            " ",
            "247"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.379,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.356,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.361,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            "onium",
            ",",
            " or",
            " rad",
            "on",
            ".",
            " Most",
            " of",
            " its",
            " isot",
            "opes",
            " are",
            " very",
            " unstable",
            ",",
            " with",
            " half",
            "-l",
            "ives",
            " of",
            " seconds",
            " or",
            " less",
            ".",
            " Of",
            " the",
            " first",
            " ",
            "101",
            " elements",
            " in",
            " the",
            " periodic",
            " table",
            ",",
            " only",
            " franc",
            "ium",
            " is",
            " less",
            " stable",
            ",",
            " and",
            " all",
            " the",
            " a",
            "stat",
            "ine",
            " isot",
            "opes",
            " more",
            " stable",
            " than",
            " the",
            " longest",
            "-lived",
            " franc",
            "ium",
            " isot",
            "opes",
            " are",
            " in",
            " any"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.207,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.369,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            " FM",
            " (",
            "Frequency",
            " Mod",
            "ulation",
            ")",
            " transmission",
            ",",
            " IR",
            " (",
            "Inf",
            "ra",
            " Red",
            ")",
            " transmission",
            ",",
            " IL",
            " (",
            "Ind",
            "uction",
            " Loop",
            ")",
            " transmission",
            ",",
            " or",
            " other",
            " transmission",
            " methods",
            ".",
            " The",
            " person",
            " who",
            " is",
            " listening",
            " may",
            " use",
            " an",
            " FM",
            "/",
            "IR",
            "/",
            "IL",
            " Receiver",
            " to",
            " tune",
            " into",
            " the",
            " signal",
            " and",
            " listen",
            " at",
            " his",
            "/her",
            " preferred",
            " volume",
            ".",
            "Am",
            "pl",
            "ified",
            " telephone",
            " equipment",
            " ",
            "This"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.344,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            " that",
            " would",
            " purported",
            "ly",
            " solve",
            " social",
            " and",
            " economic",
            " ",
            "ills",
            ".",
            " Swift",
            " was",
            " especially",
            " attacking",
            " projects",
            " that",
            " tried",
            " to",
            " fix",
            " population",
            " and",
            " labour",
            " issues",
            " with",
            " a",
            " simple",
            " cure",
            "-all",
            " solution",
            ".",
            " A",
            " memorable",
            " example",
            " of",
            " these",
            " sorts",
            " of",
            " schemes",
            " \"",
            "inv",
            "olved",
            " the",
            " idea",
            " of",
            " running",
            " the",
            " poor",
            " through",
            " a",
            " joint",
            "-stock",
            " company",
            "\".",
            " In",
            " response",
            ",",
            " Swift",
            "'s",
            " Mod",
            "est",
            " Proposal",
            " was"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.328,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " make",
            " Western",
            " audiences",
            " more",
            " sympathetic",
            " to",
            " the",
            " reception",
            " of",
            " later",
            " generations",
            " of",
            " Japanese",
            " film",
            "-makers",
            " ranging",
            " from",
            " Kon",
            " Ich",
            "ik",
            "awa",
            ",",
            " Mas",
            "aki",
            " Kob",
            "ay",
            "ashi",
            ",",
            " Nag",
            "isa",
            " O",
            "shima",
            " and",
            " Sho",
            "hei",
            " Im",
            "amura",
            " to",
            " J",
            "uz",
            "o",
            " It",
            "ami",
            ",",
            " Takes",
            "hi",
            " Kit",
            "ano",
            " and",
            " Tak",
            "ashi",
            " Mi",
            "ike",
            ".",
            "His",
            " career",
            " boosted",
            " by",
            " his",
            " sudden",
            " international",
            " fame",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.287,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " Furthermore",
            ",",
            " the",
            " royal",
            " Il",
            "ly",
            "rian",
            " tom",
            "bs",
            ",",
            " the",
            " remains",
            " of",
            " Ap",
            "oll",
            "onia",
            ",",
            " the",
            " ancient",
            " Amph",
            "ithe",
            "atre",
            " of",
            " D",
            "urr",
            "Ã«",
            "s",
            " and",
            " the",
            " Fortress",
            " of",
            " Bas",
            "ht",
            "ov",
            "Ã«",
            " has",
            " been",
            " included",
            " on",
            " the",
            " tentative",
            " list",
            " of",
            " Albania",
            ".",
            "C",
            "uisine",
            " ",
            "Throughout",
            " the",
            " centuries",
            ",",
            " Alban",
            "ian",
            " cuisine",
            " has",
            " been",
            " widely",
            " influenced",
            " by",
            " Alban",
            "ian",
            " culture"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.283,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 7,
          "is_repeated_datapoint": false,
          "tokens": [
            " In",
            " April",
            " ",
            "201",
            "8",
            ",",
            " President",
            " Il",
            "ham",
            " Ali",
            "y",
            "ev",
            " secured",
            " his",
            " fourth",
            " consecutive",
            " term",
            " in",
            " the",
            " election",
            " that",
            " was",
            " boyc",
            "otted",
            " by",
            " the",
            " main",
            " opposition",
            " parties",
            " as",
            " fraudulent",
            ".",
            " On",
            " ",
            "27",
            " September",
            " ",
            "202",
            "0",
            ",",
            " new",
            " clashes",
            " in",
            " the",
            " unresolved",
            " Nag",
            "orno",
            "-K",
            "ar",
            "ab",
            "akh",
            " conflict",
            " resumed",
            " along",
            " the",
            " Nag",
            "orno",
            "-K",
            "ar",
            "ab",
            "akh",
            " Line",
            " of"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 20,
          "is_repeated_datapoint": false,
          "tokens": [
            " film",
            " The",
            " Chelsea",
            " Girls",
            " (",
            "196",
            "6",
            "),",
            " an",
            " unfinished",
            " film",
            " depicting",
            " the",
            " setting",
            " sun",
            " commissioned",
            " by",
            " the",
            " de",
            " Men",
            "il",
            " family",
            " and",
            " funded",
            " by",
            " the",
            " Roman",
            " Catholic",
            " Church",
            ",",
            " and",
            " drawings",
            " created",
            " by",
            " War",
            "hol",
            "'s",
            " mother",
            ",",
            " Julia",
            " War",
            "h",
            "ola",
            ",",
            " when",
            " she",
            " lived",
            " with",
            " her",
            " son",
            " in",
            " New",
            " York",
            " City",
            ".",
            "In",
            " pop",
            " culture",
            "War",
            "hol",
            " founded",
            " Interview"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.224,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.027,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 32,
          "is_repeated_datapoint": false,
          "tokens": [
            " seas",
            "Se",
            "as",
            " of",
            " Asia",
            "Ge",
            "ography",
            " of",
            " Europe",
            "Ge",
            "ography",
            " of",
            " West",
            " Asia",
            "Land",
            "forms",
            " of",
            " Ãĩ",
            "an",
            "akk",
            "ale",
            " Province",
            "Land",
            "forms",
            " of",
            " Mu",
            "ÄŁ",
            "la",
            " Province",
            "Land",
            "forms",
            " of",
            " Ä°zmir",
            " Province",
            "Land",
            "forms",
            " of",
            " Bal",
            "Ä±",
            "kes",
            "ir",
            " Province",
            "Land",
            "forms",
            " of",
            " Ed",
            "ir",
            "ne",
            " Province",
            "Land",
            "forms",
            " of",
            " AydÄ±n",
            " Province"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.19,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            " =",
            " ",
            "1",
            ".",
            "When",
            " the",
            " alk",
            "ali",
            " metals",
            " react",
            " with",
            " the",
            " heavier",
            " elements",
            " in",
            " the",
            " carbon",
            " group",
            " (",
            "sil",
            "icon",
            ",",
            " german",
            "ium",
            ",",
            " tin",
            ",",
            " and",
            " lead",
            "),",
            " ",
            "ionic",
            " substances",
            " with",
            " cage",
            "-like",
            " structures",
            " are",
            " formed",
            ",",
            " such",
            " as",
            " the",
            " sil",
            "icides",
            " M",
            "4",
            "Si",
            "4",
            " (",
            "M",
            " =",
            " K",
            ",",
            " R",
            "b",
            ",",
            " or",
            " Cs",
            "),",
            " which",
            " contains",
            " M"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.177,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            " for",
            " the",
            " non",
            "being",
            " and",
            " resulting",
            " anxiety",
            ":",
            " ont",
            "ic",
            " (",
            "f",
            "ate",
            " and",
            " death",
            "),",
            " moral",
            " (",
            "gu",
            "ilt",
            " and",
            " condemnation",
            "),",
            " and",
            " spiritual",
            " (",
            "empt",
            "iness",
            " and",
            " meaning",
            "lessness",
            ").",
            " According",
            " to",
            " Til",
            "lich",
            ",",
            " the",
            " last",
            " of",
            " these",
            " three",
            " types",
            " of",
            " existential",
            " anxiety",
            ",",
            " i",
            ".e",
            ".",
            " spiritual",
            " anxiety",
            ",",
            " is",
            " predominant",
            " in",
            " modern",
            " times",
            " while",
            " the",
            " others",
            " were",
            " predominant"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.057,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.142,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.136,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            " humorous",
            " significance",
            " to",
            " Holmes",
            "ian",
            " scholars",
            ".",
            " ",
            " For",
            " approximately",
            " a",
            " decade",
            ",",
            " an",
            " active",
            " supporting",
            " group",
            " was",
            " the",
            " Pra",
            "ed",
            " Street",
            " Ir",
            "regular",
            "s",
            ",",
            " pattern",
            "ed",
            " after",
            " the",
            " Baker",
            " Street",
            " Ir",
            "regular",
            "s",
            ".",
            "In",
            " ",
            "194",
            "6",
            ",",
            " Conan",
            " Doyle",
            "'s",
            " two",
            " sons",
            " made",
            " some",
            " attempts",
            " to",
            " force",
            " Der",
            "le",
            "th",
            " to",
            " cease",
            " publishing",
            " the",
            " Solar",
            " P",
            "ons",
            " series",
            ","
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " conduct",
            "ive",
            ",",
            " has",
            " adequate",
            " mechanical",
            " strength",
            " and",
            " low",
            " density",
            ",",
            " and",
            " res",
            "ists",
            " corrosion",
            ";",
            " A",
            " wide",
            " range",
            " of",
            " household",
            " items",
            ",",
            " from",
            " cooking",
            " utens",
            "ils",
            " to",
            " furniture",
            ".",
            " Low",
            " density",
            ",",
            " good",
            " appearance",
            ",",
            " ease",
            " of",
            " fabrication",
            ",",
            " and",
            " durability",
            " are",
            " the",
            " key",
            " factors",
            " of",
            " aluminium",
            " usage",
            ";",
            " Machinery",
            " and",
            " equipment",
            " (",
            "processing",
            " equipment",
            ",",
            " pipes",
            ",",
            " tools",
            ").",
            " Aluminium",
            " is"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " modern",
            " era",
            " –",
            " a",
            " factor",
            " where",
            " progress",
            " is",
            " also",
            " slowed",
            " by",
            " contemporary",
            " conflict",
            " and",
            " political",
            " instability",
            ".",
            " The",
            " country",
            " imports",
            " over",
            " $",
            "7",
            "Âłb",
            "illion",
            " worth",
            " of",
            " goods",
            " but",
            " exports",
            " only",
            " $",
            "784",
            "Âł",
            "million",
            ",",
            " mainly",
            " fruits",
            " and",
            " nuts",
            ".",
            " It",
            " has",
            " $",
            "2",
            ".",
            "8",
            "Âłb",
            "illion",
            " in",
            " external",
            " debt",
            ".",
            " The",
            " service",
            " sector",
            " contributed",
            " the",
            " most",
            " to",
            " the",
            " GDP"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "istic",
            " inspiration",
            " is",
            " one",
            " of",
            " the",
            " main",
            " drivers",
            " of",
            " art",
            ",",
            " and",
            " may",
            " be",
            " considered",
            " to",
            " stem",
            " from",
            " instinct",
            ",",
            " impressions",
            ",",
            " and",
            " feelings",
            ".",
            "Creation",
            "In",
            " the",
            " second",
            " step",
            ",",
            " the",
            " artist",
            " executes",
            " the",
            " creation",
            " of",
            " their",
            " work",
            ".",
            " The",
            " creation",
            " of",
            " a",
            " piece",
            " can",
            " be",
            " affected",
            " by",
            " factors",
            " such",
            " as",
            " the",
            " artist",
            "'s",
            " mood",
            ",",
            " surroundings",
            ",",
            " and",
            " mental",
            " state"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " P",
            "apyrus",
            " gra",
            "ec",
            "us",
            " hol",
            "mi",
            "ensis",
            " (",
            "P",
            ".",
            " hol",
            "m",
            ".",
            ");",
            " Re",
            "cept",
            "e",
            " fÃ¼r",
            " Sil",
            "ber",
            ",",
            " Ste",
            "ine",
            " und",
            " Pur",
            "pur",
            ",",
            " bear",
            "b",
            ".",
            " von",
            " Otto",
            " Lager",
            "cr",
            "antz",
            ".",
            " H",
            "r",
            "sg",
            ".",
            " mit",
            " Unter",
            "stÃ¼t",
            "zung",
            " des",
            " Vil",
            "h",
            ".",
            " Ek",
            "man",
            "'s",
            "chen",
            " Univers",
            "itÃ¤",
            "ts",
            "f",
            "onds",
            ".",
            " Mich",
            "Ã¨le",
            " M",
            "ert"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " venues",
            " did",
            " not",
            " sell",
            " out",
            ".",
            " Due",
            " to",
            " a",
            " lack",
            " of",
            " demand",
            ",",
            " they",
            " were",
            " even",
            " forced",
            " to",
            " cancel",
            " a",
            " few",
            " shows",
            ",",
            " including",
            " a",
            " sole",
            " concert",
            " scheduled",
            " in",
            " Switzerland",
            ".",
            " The",
            " second",
            " leg",
            " of",
            " the",
            " tour",
            ",",
            " which",
            " took",
            " them",
            " through",
            " Scandin",
            "avia",
            " in",
            " January",
            " ",
            "197",
            "5",
            ",",
            " was",
            " very",
            " different",
            ".",
            " They",
            " played",
            " to",
            " full",
            " houses",
            " everywhere",
            " and",
            " finally",
            " got"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "ibu",
    "elfare",
    "ÐºÐ¾ÑĤ",
    "éĳĳ",
    "_Collections"
  ],
  "bottom_logits": [
    " Andrews",
    " impression",
    " Gaines",
    "dek",
    "blk"
  ],
  "act_min": -0.0,
  "act_max": 0.633
}
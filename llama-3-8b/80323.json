{
  "index": 80323,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.637,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " (",
            " E",
            "ire",
            "ne",
            ";",
            " Latin",
            ":",
            " ),",
            " first",
            " version",
            ",",
            " ",
            "421",
            " BC",
            " The",
            " Birds",
            " (",
            " Orn",
            "ith",
            "es",
            ";",
            " Latin",
            ":",
            " ),",
            " ",
            "414",
            " BC",
            " L",
            "ys",
            "istr",
            "ata",
            " (",
            " L",
            "ys",
            "istrate",
            "),",
            " ",
            "411",
            " BC",
            " Th",
            "es",
            "m",
            "oph",
            "oria",
            "z",
            "us",
            "ae",
            " or",
            " The",
            " Women",
            " Celebr",
            "ating",
            " the",
            " Th",
            "es",
            "m",
            "oph",
            "oria",
            " (",
            " Th"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.637,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 11,
          "is_repeated_datapoint": false,
          "tokens": [
            "ovsky",
            " began",
            " production",
            " of",
            " the",
            " film",
            " The",
            " First",
            " Day",
            " (",
            "Russian",
            ":",
            " ÐŁÐµÑĢÐ²",
            "ÑĭÐ¹",
            " ÐĶ",
            "ÐµÐ½ÑĮ",
            " P",
            "erv",
            "y",
            "j",
            " Dy",
            "en",
            "),",
            " based",
            " on",
            " a",
            " script",
            " by",
            " his",
            " friend",
            " and",
            " long",
            "-term",
            " collabor",
            "ator",
            " Andre",
            "i",
            " Kon",
            "chal",
            "ovsky",
            ".",
            " The",
            " film",
            " was",
            " set",
            " in",
            " ",
            "18",
            "th",
            "-century",
            " Russia",
            " during",
            " the",
            " reign",
            " of",
            " Peter",
            " the",
            " Great",
            " and",
            " starred",
            " Natal",
            "ya",
            " Bond"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.637,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " (",
            " E",
            "ire",
            "ne",
            ";",
            " Latin",
            ":",
            " ),",
            " first",
            " version",
            ",",
            " ",
            "421",
            " BC",
            " The",
            " Birds",
            " (",
            " Orn",
            "ith",
            "es",
            ";",
            " Latin",
            ":",
            " ),",
            " ",
            "414",
            " BC",
            " L",
            "ys",
            "istr",
            "ata",
            " (",
            " L",
            "ys",
            "istrate",
            "),",
            " ",
            "411",
            " BC",
            " Th",
            "es",
            "m",
            "oph",
            "oria",
            "z",
            "us",
            "ae",
            " or",
            " The",
            " Women",
            " Celebr",
            "ating",
            " the",
            " Th",
            "es",
            "m",
            "oph",
            "oria",
            " (",
            " Th"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.633,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            " body",
            " functions",
            " such",
            " as",
            " neurotrans",
            "mission",
            ",",
            " muscle",
            " contraction",
            ",",
            " and",
            " heart",
            " function",
            ".",
            " Dis",
            "ruption",
            " of",
            " this",
            " balance",
            " may",
            " thus",
            " be",
            " fatal",
            ":",
            " for",
            " example",
            ",",
            " ingestion",
            " of",
            " large",
            " amounts",
            " of",
            " potassium",
            " compounds",
            " can",
            " lead",
            " to",
            " hyper",
            "k",
            "alem",
            "ia",
            " strongly",
            " influencing",
            " the",
            " cardiovascular",
            " system",
            ".",
            " Pot",
            "assium",
            " chloride",
            " is",
            " used",
            " in",
            " the",
            " United",
            " States",
            " for",
            " lethal",
            " injection",
            " executions",
            ".",
            "Due",
            " to"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.005,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.629,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.582,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.566,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 11,
          "is_repeated_datapoint": false,
          "tokens": [
            " The",
            " Knights",
            " (",
            " Hip",
            "pe",
            "is",
            ";",
            " Att",
            "ic",
            " ;",
            " Latin",
            ":",
            " ),",
            " ",
            "424",
            " BC",
            " The",
            " Cloud",
            "s",
            " (",
            " N",
            "eph",
            "el",
            "ai",
            ";",
            " Latin",
            ":",
            " ),",
            " original",
            " ",
            "423",
            " BC",
            ",",
            " un",
            "completed",
            " revised",
            " version",
            " from",
            " ",
            "419",
            " to",
            " ",
            "416",
            " BC",
            " survives",
            " The",
            " Was",
            "ps",
            " (",
            " Sp",
            "he",
            "kes",
            ";",
            " Latin",
            ":",
            " ),",
            " ",
            "422",
            " BC",
            " Peace"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.629,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " Walter",
            " (",
            "French",
            ":",
            " Les",
            " Cah",
            "iers",
            " d",
            "'",
            "And",
            "rÃ©",
            " Walter",
            "),",
            " in",
            " ",
            "189",
            "1",
            ",",
            " at",
            " the",
            " age",
            " of",
            " twenty",
            "-one",
            ".",
            "In",
            " ",
            "189",
            "3",
            " and",
            " ",
            "189",
            "4",
            ",",
            " G",
            "ide",
            " traveled",
            " in",
            " Northern",
            " Africa",
            ".",
            " There",
            " he",
            " came",
            " to",
            " accept",
            " his",
            " attraction",
            " to",
            " boys",
            " and",
            " youths",
            ".",
            "G",
            "ide",
            " bef",
            "ri",
            "ended",
            " Irish",
            " playwright",
            " Oscar",
            " Wilde",
            " in"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.625,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            " electric",
            " chair",
            ".",
            " Then",
            " you",
            "'re",
            " as",
            " happy",
            " as",
            " can",
            " be",
            " when",
            " you",
            " wake",
            " up",
            " because",
            " you",
            "'re",
            " relieved",
            ".\"",
            " During",
            " filming",
            " of",
            " North",
            " by",
            " Northwest",
            ",",
            " Hitch",
            "cock",
            " explained",
            " his",
            " reasons",
            " for",
            " recre",
            "ating",
            " the",
            " set",
            " of",
            " Mount",
            " Rush",
            "more",
            ":",
            " \"",
            "The",
            " audience",
            " responds",
            " in",
            " proportion",
            " to",
            " how",
            " realistic",
            " you",
            " make",
            " it",
            ".",
            " One",
            " of",
            " the",
            " dramatic",
            " reasons",
            " for",
            " this",
            " type"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.625,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            "yl",
            "ase",
            " (",
            "G",
            "AD",
            ":",
            " enzyme",
            " changing",
            " glut",
            "amate",
            " into",
            " G",
            "ABA",
            ")",
            " cause",
            " cere",
            "bell",
            "ar",
            " deficits",
            ".",
            " The",
            " antibodies",
            " impair",
            " motor",
            " learning",
            " and",
            " cause",
            " behavioral",
            " deficits",
            ".",
            "G",
            "AD",
            " antibodies",
            " related",
            " at",
            "ax",
            "ia",
            " is",
            " part",
            " of",
            " the",
            " group",
            " called",
            " immune",
            "-mediated",
            " cere",
            "bell",
            "ar",
            " at",
            "ax",
            "ias",
            ".",
            " The",
            " antibodies",
            " induce",
            " a",
            " syn",
            "aptop",
            "athy",
            ".",
            " The",
            " cere",
            "bell"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " United",
            " States",
            ")",
            " Apple",
            "seed",
            " Ex",
            " Mach",
            "ina",
            " (",
            "200",
            "7",
            ",",
            " Japan",
            "),",
            " The",
            " Legend",
            " of",
            " Zelda",
            ":",
            " The",
            " Wind",
            " W",
            "aker",
            " (",
            "200",
            "2",
            ",",
            " Japan",
            "),",
            " The",
            " Legend",
            " of",
            " Zelda",
            ":",
            " Breath",
            " of",
            " the",
            " Wild",
            " (",
            "201",
            "7",
            ",",
            " Japan",
            ")",
            " Mach",
            "in",
            "ima",
            " –",
            " Films",
            " created",
            " by",
            " screen",
            " capturing",
            " in",
            " video",
            " games",
            " and",
            " virtual",
            " worlds",
            ".",
            " The",
            " term"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.363,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            "ough",
            "ed",
            "\")",
            " is",
            " any",
            " land",
            " capable",
            " of",
            " being",
            " pl",
            "ough",
            "ed",
            " and",
            " used",
            " to",
            " grow",
            " crops",
            ".",
            " Alternatively",
            ",",
            " for",
            " the",
            " purposes",
            " of",
            " agricultural",
            " statistics",
            ",",
            " the",
            " term",
            " often",
            " has",
            " a",
            " more",
            " precise",
            " definition",
            ":",
            " ",
            "A",
            " more",
            " concise",
            " definition",
            " appearing",
            " in",
            " the",
            " Euro",
            "stat",
            " gloss",
            "ary",
            " similarly",
            " refers",
            " to",
            " actual",
            " rather",
            " than",
            " potential",
            " uses",
            ":",
            " \"",
            "land",
            " worked",
            " (",
            "pl",
            "ough"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 20,
          "is_repeated_datapoint": false,
          "tokens": [
            " disc",
            "ography",
            " would",
            " be",
            " released",
            " on",
            " coloured",
            " vinyl",
            " for",
            " the",
            " first",
            " time",
            ",",
            " in",
            " a",
            " box",
            " set",
            " titled",
            " AB",
            "BA",
            ":",
            " The",
            " Studio",
            " Albums",
            ".",
            " In",
            " July",
            " ",
            "202",
            "0",
            ",",
            " Ul",
            "vae",
            "us",
            " revealed",
            " that",
            " the",
            " release",
            " of",
            " the",
            " new",
            " AB",
            "BA",
            " recordings",
            " had",
            " been",
            " delayed",
            " until",
            " ",
            "202",
            "1",
            ".",
            "On",
            " ",
            "22",
            " September",
            " ",
            "202",
            "0",
            ",",
            " all",
            " four",
            " AB"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.005,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.006,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 21,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " two",
            " Australian",
            " cult",
            " films",
            " caught",
            " the",
            " attention",
            " of",
            " the",
            " world",
            "'s",
            " media",
            ",",
            " both",
            " focusing",
            " on",
            " admiration",
            " for",
            " AB",
            "BA",
            ":",
            " The",
            " Adventures",
            " of",
            " Pr",
            "isc",
            "illa",
            ",",
            " Queen",
            " of",
            " the",
            " Desert",
            " and",
            " M",
            "uri",
            "el",
            "'s",
            " Wedding",
            ".",
            " The",
            " same",
            " year",
            ",",
            " Thank",
            " You",
            " for",
            " the",
            " Music",
            ",",
            " a",
            " four",
            "-disc",
            " box",
            " set",
            " comprising",
            " all",
            " the",
            " group",
            "'s",
            " hits",
            " and",
            " stand"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 32,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " because",
            " he",
            " thought",
            " that",
            " a",
            " so",
            " great",
            " animal",
            " deserved",
            " a",
            " great",
            " name",
            ".",
            " The",
            " elephant",
            " had",
            " gold",
            " rings",
            " around",
            " its",
            " tus",
            "ks",
            " and",
            " an",
            " inscription",
            " was",
            " on",
            " them",
            " written",
            " in",
            " Greek",
            ":",
            " \"",
            "Alexander",
            " the",
            " son",
            " of",
            " Zeus",
            " ded",
            "icates",
            " Ajax",
            " to",
            " the",
            " Hel",
            "ios",
            "\"",
            " (",
            "ÎĳÎĽ",
            "Îķ",
            "Îŀ",
            "ÎĳÎĿ",
            "ÎĶ",
            "Î¡",
            "ÎŁÎ£",
            " ÎŁ",
            " ÎĶ",
            "ÎĻ",
            "ÎŁÎ£",
            " Î¤",
            "ÎŁÎĿ",
            " Îĳ",
            "ÎĻÎĳ"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            ")",
            " Square",
            " (",
            "Tur",
            "kish",
            ":",
            " Za",
            "fer",
            " Mey",
            "dan",
            "Ä±",
            "),",
            " the",
            " marble",
            " and",
            " bronze",
            " statue",
            " was",
            " crafted",
            " by",
            " the",
            " renowned",
            " Italian",
            " sculpt",
            "or",
            " Piet",
            "ro",
            " Canon",
            "ica",
            " in",
            " ",
            "192",
            "7",
            " and",
            " depicts",
            " a",
            " standing",
            " AtatÃ¼rk",
            " who",
            " wears",
            " a",
            " Republic",
            " era",
            " modern",
            " military",
            " uniform",
            ",",
            " with",
            " the",
            " rank",
            " Field",
            " Marshal",
            ".",
            "Mon",
            "ument",
            " to",
            " a",
            " Secure",
            ",",
            " Conf",
            "ident",
            " Future"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " United",
            " States",
            ")",
            " Apple",
            "seed",
            " Ex",
            " Mach",
            "ina",
            " (",
            "200",
            "7",
            ",",
            " Japan",
            "),",
            " The",
            " Legend",
            " of",
            " Zelda",
            ":",
            " The",
            " Wind",
            " W",
            "aker",
            " (",
            "200",
            "2",
            ",",
            " Japan",
            "),",
            " The",
            " Legend",
            " of",
            " Zelda",
            ":",
            " Breath",
            " of",
            " the",
            " Wild",
            " (",
            "201",
            "7",
            ",",
            " Japan",
            ")",
            " Mach",
            "in",
            "ima",
            " –",
            " Films",
            " created",
            " by",
            " screen",
            " capturing",
            " in",
            " video",
            " games",
            " and",
            " virtual",
            " worlds",
            ".",
            " The",
            " term"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " United",
            " States",
            ")",
            " Apple",
            "seed",
            " Ex",
            " Mach",
            "ina",
            " (",
            "200",
            "7",
            ",",
            " Japan",
            "),",
            " The",
            " Legend",
            " of",
            " Zelda",
            ":",
            " The",
            " Wind",
            " W",
            "aker",
            " (",
            "200",
            "2",
            ",",
            " Japan",
            "),",
            " The",
            " Legend",
            " of",
            " Zelda",
            ":",
            " Breath",
            " of",
            " the",
            " Wild",
            " (",
            "201",
            "7",
            ",",
            " Japan",
            ")",
            " Mach",
            "in",
            "ima",
            " –",
            " Films",
            " created",
            " by",
            " screen",
            " capturing",
            " in",
            " video",
            " games",
            " and",
            " virtual",
            " worlds",
            ".",
            " The",
            " term"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.465,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.445,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 11,
          "is_repeated_datapoint": false,
          "tokens": [
            "ie",
            ",",
            " The",
            " Valley",
            " of",
            " And",
            "orra",
            ".",
            " Bristol",
            ",",
            " UK",
            ":",
            " J",
            ".",
            " W",
            ".",
            " Ar",
            "rows",
            "mith",
            ",",
            " ",
            "188",
            "6",
            ".",
            " Butler",
            ",",
            " Michael",
            ",",
            " Fr",
            "isch",
            ":",
            " And",
            "orra",
            ".",
            " Carr",
            "ick",
            ",",
            " Noel",
            ",",
            " Let",
            "'s",
            " Visit",
            " And",
            "orra",
            ".",
            " London",
            ":",
            " Mac",
            "mill",
            "an",
            ",",
            " ",
            "198",
            "8",
            ".",
            " ",
            " De",
            "ane",
            ",",
            " Shirley",
            ",",
            " The",
            " Road"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 8,
          "is_repeated_datapoint": false,
          "tokens": [
            " second",
            " argument",
            " to",
            " its",
            " square",
            ",",
            " see",
            " Talk",
            ":",
            "Ell",
            "ipt",
            "ic",
            " integral",
            "#",
            "List",
            " of",
            " not",
            "ations",
            ";",
            " dealing",
            " with",
            " complex",
            " values",
            ",",
            " this",
            " may",
            " cause",
            " problems",
            ".",
            " Ex",
            "ponential",
            " integral",
            " Herm",
            "ite",
            " polynomial",
            "Expressions",
            " ",
            "Amb",
            "iguous",
            " expressions",
            " often",
            " appear",
            " in",
            " physical",
            " and",
            " mathematical",
            " texts",
            ".",
            "It",
            " is",
            " common",
            " practice",
            " to",
            " omit",
            " multiplication",
            " signs",
            " in",
            " mathematical",
            " expressions",
            ".",
            " Also"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.609,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " tour",
            " and",
            " its",
            " subsequent",
            " AB",
            "BA",
            ":",
            " The",
            " Movie",
            " produced",
            " some",
            " AB",
            "BA",
            " lore",
            ",",
            " as",
            " well",
            ".",
            " F",
            "Ã¤l",
            "ts",
            "k",
            "og",
            "'s",
            " blonde",
            " good",
            " looks",
            " had",
            " long",
            " made",
            " her",
            " the",
            " band",
            "'s",
            " \"",
            "pin",
            "-up",
            " girl",
            "\",",
            " a",
            " role",
            " she",
            " dis",
            "d",
            "ained",
            ".",
            " During",
            " the",
            " Australian",
            " tour",
            ",",
            " she",
            " performed",
            " in",
            " a",
            " skin",
            "-t",
            "ight",
            " white",
            " jumps",
            "uit",
            ",",
            " causing"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 33,
          "is_repeated_datapoint": false,
          "tokens": [
            "In",
            " this",
            " work",
            ",",
            " he",
            " criticized",
            " the",
            " behavior",
            " of",
            " French",
            " business",
            " interests",
            " in",
            " the",
            " Congo",
            " and",
            " inspired",
            " reform",
            ".",
            " In",
            " particular",
            ",",
            " he",
            " strongly",
            " criticized",
            " the",
            " Large",
            " Con",
            "cess",
            "ions",
            " regime",
            " (",
            "French",
            ":",
            " R",
            "Ã©g",
            "ime",
            " des",
            " Grand",
            "es",
            " Con",
            "cess",
            "ions",
            ").",
            " The",
            " government",
            " had",
            " essentially",
            " conceded",
            " part",
            " of",
            " the",
            " colony",
            " to",
            " French",
            " companies",
            ",",
            " allowing",
            " them",
            " to",
            " exploit",
            " the",
            " area"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            "\",",
            " to",
            " feature",
            " in",
            " a",
            " TV",
            " special",
            " set",
            " to",
            " air",
            " later",
            " that",
            " year",
            ".",
            " In",
            " September",
            " ",
            "201",
            "8",
            ",",
            " Ul",
            "vae",
            "us",
            " stated",
            " that",
            " the",
            " two",
            " new",
            " songs",
            ",",
            " as",
            " well",
            " as",
            " the",
            " TV",
            " special",
            ",",
            " now",
            " called",
            " AB",
            "BA",
            ":",
            " Thank",
            " You",
            " for",
            " the",
            " Music",
            ",",
            " An",
            " All",
            "-Star",
            " Tribute",
            ",",
            " would",
            " not",
            " be",
            " released",
            " until",
            " ",
            "201",
            "9",
            ".",
            " The"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 21,
          "is_repeated_datapoint": false,
          "tokens": [
            "es",
            "m",
            "oph",
            "oria",
            "z",
            "ous",
            "ai",
            "),",
            " first",
            " version",
            " ",
            " The",
            " Fro",
            "gs",
            " (",
            " Bat",
            "rak",
            "ho",
            "i",
            ";",
            " Latin",
            ":",
            " ),",
            " ",
            "405",
            " BC",
            " Ecc",
            "les",
            "iaz",
            "us",
            "ae",
            " or",
            " The",
            " Assembly",
            "women",
            ";",
            " (",
            " E",
            "kk",
            "les",
            "iaz",
            "ous",
            "ai",
            "),",
            " ",
            " Wealth",
            " (",
            " Pl",
            "out",
            "os",
            ";",
            " Latin",
            " Pl",
            "ut",
            "us",
            ")",
            " second",
            " version",
            ",",
            " ",
            "388",
            " BC"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.594,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            "armac",
            " Seal",
            "coat",
            " St",
            "amped",
            " asphalt",
            "Notes",
            "References",
            "Sources",
            " Barth",
            ",",
            " Edwin",
            " J",
            ".",
            " (",
            "196",
            "2",
            "),",
            " Asphalt",
            ":",
            " Science",
            " and",
            " Technology",
            ",",
            " Gordon",
            " and",
            " Bre",
            "ach",
            ".",
            " .",
            "External",
            " links",
            "  ",
            " ",
            " Pav",
            "ement",
            " Interactive",
            " –",
            " Asphalt",
            " CS",
            "U",
            " Sacramento",
            ",",
            " The",
            " World",
            " Famous",
            " Asphalt",
            " Museum",
            "!",
            " ",
            " National",
            " Institute",
            " for",
            " Occupational",
            " Safety"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.594,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.467,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            " departure",
            ")",
            " of",
            " portions",
            " of",
            " the",
            " animal",
            " tissue",
            " from",
            " each",
            " other",
            " to",
            " make",
            " room",
            " for",
            " the",
            " sup",
            "pur",
            "ated",
            " matter",
            " lodged",
            " between",
            " them",
            ".",
            "The",
            " word",
            " carb",
            "unc",
            "le",
            " is",
            " believed",
            " to",
            " have",
            " originated",
            " from",
            " the",
            " Latin",
            ":",
            " carb",
            "unc",
            "ulus",
            ",",
            " originally",
            " a",
            " small",
            " coal",
            ";",
            " dimin",
            "utive",
            " of",
            " carbon",
            "-,",
            " car",
            "bo",
            ":",
            " charcoal",
            " or",
            " ember",
            ",",
            " but",
            " also",
            " a",
            " carb"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.594,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.41,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 8,
          "is_repeated_datapoint": false,
          "tokens": [
            " Jack",
            " Ker",
            "ou",
            "ac",
            " School",
            ",",
            " New",
            " York",
            ":",
            " Harper",
            "Coll",
            "ins",
            " Per",
            "ennial",
            ",",
            " ",
            "200",
            "5",
            ".",
            " ",
            " Pod",
            "h",
            "oret",
            "z",
            ",",
            " Norman",
            ".",
            " \"",
            "At",
            " War",
            " with",
            " Allen",
            " Gins",
            "berg",
            "\",",
            " in",
            " Ex",
            "-F",
            "riends",
            " (",
            "Free",
            " Press",
            ",",
            " ",
            "199",
            "9",
            "),",
            " ",
            "22",
            "–",
            "56",
            ".",
            " .",
            " McB",
            "ride",
            ",",
            " Dick",
            ":",
            " Com",
            "eth",
            " With",
            " Cloud",
            "s"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.594,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "28",
            "th",
            " book",
            " of",
            " al",
            "-Z",
            "ahr",
            "Äģ",
            "w",
            "Ä«",
            "'s",
            " (",
            "Latin",
            ":",
            " Ab",
            "ul",
            "c",
            "asis",
            ",",
            " ",
            "936",
            "–",
            "101",
            "3",
            ")",
            " Kit",
            "Äģ",
            "b",
            " al",
            "-Ta",
            "á¹",
            "£",
            "r",
            "Ä«",
            "f",
            " (",
            "later",
            " translated",
            " into",
            " Latin",
            " as",
            " Liber",
            " serv",
            "ator",
            "is",
            ").",
            " In",
            " the",
            " tw",
            "elfth",
            " century",
            ",",
            " recipes",
            " for",
            " the",
            " production",
            " of",
            " aqu",
            "a",
            " ar",
            "dens",
            " (\""
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.594,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            "Ã¼n",
            ")",
            " instead",
            " of",
            " \"",
            "Be",
            " proud",
            "\"(",
            "Tur",
            "kish",
            ":",
            " Ã¶",
            "v",
            "Ã¼n",
            "))",
            "The",
            " monument",
            " was",
            " depicted",
            " on",
            " the",
            " reverse",
            " of",
            " the",
            " Turkish",
            " ",
            "5",
            " l",
            "ira",
            " bank",
            "note",
            " of",
            " ",
            "193",
            "7",
            "–",
            "195",
            "2",
            " and",
            " of",
            " the",
            " ",
            "100",
            "0",
            " l",
            "ira",
            " bank",
            "notes",
            " of",
            " ",
            "193",
            "9",
            "–",
            "194",
            "6",
            ".",
            "H",
            "atti",
            " Monument",
            "E",
            "rect",
            "ed"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 49,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " unprecedented",
            " media",
            " attention",
            " (\"",
            "Sw",
            "edish",
            " AB",
            "BA",
            " st",
            "irs",
            " box",
            "-office",
            " in",
            " Down",
            " Under",
            " tour",
            "...",
            "and",
            " the",
            " media",
            " coverage",
            " of",
            " the",
            " quart",
            "et",
            " rivals",
            " that",
            " set",
            " to",
            " cover",
            " the",
            " upcoming",
            " Royal",
            " tour",
            " of",
            " Australia",
            "\",",
            " wrote",
            " Variety",
            "),",
            " and",
            " is",
            " captured",
            " on",
            " film",
            " in",
            " AB",
            "BA",
            ":",
            " The",
            " Movie",
            ",",
            " directed",
            " by",
            " L",
            "asse",
            " Hall",
            "str",
            "Ã¶m",
            ".",
            "The",
            " Australian"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " Apple",
            " II",
            ":",
            " compatibility",
            " with",
            " the",
            " office",
            ",",
            " but",
            " Apple",
            " II",
            " market",
            " share",
            " remained",
            " behind",
            " home",
            " computers",
            " made",
            " by",
            " competitors",
            " such",
            " as",
            " Atari",
            ",",
            " Commod",
            "ore",
            ",",
            " and",
            " T",
            "andy",
            ".",
            "On",
            " December",
            " ",
            "12",
            ",",
            " ",
            "198",
            "0",
            ",",
            " Apple",
            " (",
            "ticker",
            " symbol",
            " \"",
            "AAP",
            "L",
            "\")",
            " went",
            " public",
            " selling",
            " ",
            "4",
            ".",
            "6",
            "Âł",
            "million",
            " shares",
            " at",
            " $",
            "22",
            " per",
            " share"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.361,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.482,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.486,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " the",
            " Shadow",
            " of",
            " the",
            " Third",
            " Reich",
            ".",
            " Hav",
            "ert",
            "own",
            ",",
            " PA",
            ":",
            " Cas",
            "em",
            "ate",
            ".",
            " ",
            " Hudson",
            ",",
            " Simon",
            ".",
            " (",
            "200",
            "0",
            ").",
            " Snow",
            " Business",
            ":",
            " A",
            " Study",
            " of",
            " the",
            " International",
            " Ski",
            " Industry",
            ".",
            " New",
            " York",
            ":",
            " C",
            "engage",
            " ",
            " K",
            "Ã¶r",
            "ner",
            ",",
            " Christian",
            ".",
            " (",
            "200",
            "3",
            ").",
            " Alpine",
            " Plant",
            " Life",
            ".",
            " New",
            " York",
            ":",
            " Springer",
            " Ver"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.48,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 11,
          "is_repeated_datapoint": false,
          "tokens": [
            " other",
            " as",
            " true",
            " brothers",
            ",",
            " and",
            " of",
            " them",
            " it",
            " is",
            " written",
            ":",
            " \"",
            "Beh",
            "old",
            " how",
            " good",
            " and",
            " how",
            " pleasant",
            " [",
            "it",
            " is",
            "]",
            " for",
            " brethren",
            " to",
            " dwell",
            " together",
            " in",
            " unity",
            "!\"",
            " Of",
            " them",
            " it",
            " is",
            " said",
            ":",
            " \"",
            "Merc",
            "y",
            " and",
            " truth",
            " are",
            " met",
            " together",
            ";",
            " righteousness",
            " and",
            " peace",
            " have",
            " kissed",
            " [",
            "each",
            " other",
            "]",
            "\";",
            " for",
            " Moses",
            " stood",
            " for",
            " righteousness",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.586,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.428,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " New",
            " York",
            ",",
            " NY",
            ":",
            " Harper",
            "Coll",
            "ins",
            ".",
            " .",
            "  ",
            " .",
            " Thompson",
            ",",
            " Laura",
            " (",
            "200",
            "8",
            "),",
            " Ag",
            "atha",
            " Christie",
            ":",
            " An",
            " English",
            " Mystery",
            ",",
            " London",
            ":",
            " Head",
            "line",
            " Review",
            ",",
            " .",
            "External",
            " links",
            " ",
            " ",
            " A",
            " Christie",
            " reading",
            " list",
            " (",
            "on",
            " official",
            " website",
            ")",
            "  ",
            "  ",
            " ",
            " Ag",
            "atha",
            " Christie",
            "/S",
            "ir",
            " Max",
            " M",
            "allow",
            "an",
            "'s",
            " blue",
            " plaque",
            " at"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.543,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " Curtain",
            ":",
            " P",
            "oi",
            "rot",
            "'s",
            " Last",
            " Case",
            " when",
            " the",
            " seemingly",
            "-",
            "cri",
            "pp",
            "led",
            " P",
            "oi",
            "rot",
            " asks",
            " Hastings",
            " to",
            " assist",
            " him",
            " in",
            " his",
            " final",
            " case",
            ".",
            " When",
            " the",
            " killer",
            " they",
            " are",
            " tracking",
            " nearly",
            " manip",
            "ulates",
            " Hastings",
            " into",
            " committing",
            " murder",
            ",",
            " P",
            "oi",
            "rot",
            " describes",
            " this",
            " in",
            " his",
            " final",
            " farewell",
            " letter",
            " to",
            " Hastings",
            " as",
            " the",
            " catalyst",
            " that",
            " prompted",
            " him",
            " to",
            " eliminate"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.539,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            " all",
            " due",
            " to",
            " charge",
            " rep",
            "ulsion",
            ".",
            " In",
            " co",
            "ag",
            "ulation",
            ",",
            " a",
            " positively",
            " charged",
            " co",
            "ag",
            "ulent",
            " such",
            " as",
            " Fe",
            " and",
            " Al",
            "um",
            " (",
            "common",
            " used",
            " salts",
            ":",
            " Fe",
            "Cl",
            "3",
            ",",
            " Fe",
            "2",
            "(S",
            "O",
            "4",
            ")",
            "3",
            ",",
            " Al",
            "2",
            "(S",
            "O",
            "4",
            ")",
            "3",
            ")",
            " neutral",
            "ise",
            " the",
            " negatively",
            " charged",
            " arsen",
            "ate",
            ",",
            " enable",
            " it",
            " to",
            " settle",
            ".",
            " Flo"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.512,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " dispar",
            "age",
            " Hay",
            "ek",
            ".",
            " Ye",
            "ager",
            " stated",
            ":",
            " \"",
            "To",
            " try",
            " to",
            " drive",
            " a",
            " wedge",
            " between",
            " M",
            "ises",
            " and",
            " Hay",
            "ek",
            " on",
            " [",
            "the",
            " role",
            " of",
            " knowledge",
            " in",
            " economic",
            " calculation",
            "],",
            " especially",
            " to",
            " the",
            " dispar",
            "agement",
            " of",
            " Hay",
            "ek",
            ",",
            " is",
            " unfair",
            " to",
            " these",
            " two",
            " great",
            " men",
            ",",
            " un",
            "faith",
            "ful",
            " to",
            " the",
            " history",
            " of",
            " economic",
            " thought",
            "\".",
            " He",
            " went",
            " on"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            0.5,
            0.057,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            ":",
            "Although",
            " I",
            " have",
            " been",
            " prevented",
            " by",
            " outward",
            " circumstances",
            " from",
            " observing",
            " a",
            " strictly",
            " vegetarian",
            " diet",
            ",",
            " I",
            " have",
            " long",
            " been",
            " an",
            " adher",
            "ent",
            " to",
            " the",
            " cause",
            " in",
            " principle",
            ".",
            " Besides",
            " agreeing",
            " with",
            " the",
            " aims",
            " of",
            " vegetarian",
            "ism",
            " for",
            " aesthetic",
            " and",
            " moral",
            " reasons",
            ",",
            " it",
            " is",
            " my",
            " view",
            " that",
            " a",
            " vegetarian",
            " manner",
            " of",
            " living",
            " by",
            " its",
            " purely",
            " physical",
            " effect",
            " on",
            " the",
            " human",
            " temperament",
            " would"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            ":",
            " UTC",
            ",",
            " GPS",
            ",",
            " L",
            "OR",
            "AN",
            " and",
            " T",
            "AI",
            "Time",
            " scales",
            "<|begin_of_text|>",
            "Al",
            "tru",
            "ism",
            " is",
            " the",
            " principle",
            " and",
            " practice",
            " of",
            " concern",
            " for",
            " the",
            " well",
            "-being",
            " and",
            "/or",
            " happiness",
            " of",
            " other",
            " humans",
            " or",
            " animals",
            ".",
            " While",
            " objects",
            " of",
            " altru",
            "istic",
            " concern",
            " vary",
            ",",
            " it",
            " is",
            " an",
            " important",
            " moral",
            " value",
            " in",
            " many",
            " cultures",
            " and",
            " religions",
            ".",
            " It",
            " may",
            " be",
            " considered",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.074,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.49
          ],
          "train_token_ind": 62,
          "is_repeated_datapoint": false,
          "tokens": [
            "oi",
            "rot",
            " as",
            " her",
            " inspiration",
            " while",
            " she",
            " attempts",
            " to",
            " solve",
            " the",
            " mystery",
            " of",
            " the",
            " cheating",
            " spouse",
            ".",
            " Throughout",
            " the",
            " episode",
            ",",
            " she",
            " is",
            " mocked",
            " as",
            " Herc",
            "ule",
            " P",
            "oi",
            "rot",
            " and",
            " Ag",
            "atha",
            " Christie",
            " by",
            " the",
            " suspects",
            ".",
            " TV",
            "F",
            "Play",
            " also",
            " tele",
            "cast",
            "ed",
            " a",
            " spoof",
            " of",
            " Indian",
            " TV",
            " suspense",
            " drama",
            " CID",
            " as",
            " \"",
            "Q",
            "issa",
            " Missing",
            " D",
            "ima",
            "ag",
            " Ka",
            ":"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.486,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            "acus",
            " appeared",
            " during",
            " the",
            " Han",
            " dynasty",
            ",",
            " and",
            " the",
            " beads",
            " are",
            " oval",
            ".",
            " The",
            " Song",
            " dynasty",
            " and",
            " earlier",
            " used",
            " the",
            " ",
            "1",
            ":",
            "4",
            " type",
            " or",
            " four",
            "-be",
            "ads",
            " ab",
            "acus",
            " similar",
            " to",
            " the",
            " modern",
            " ab",
            "acus",
            " including",
            " the",
            " shape",
            " of",
            " the",
            " beads",
            " commonly",
            " known",
            " as",
            " Japanese",
            "-style",
            " ab",
            "acus",
            ".",
            "In",
            " the",
            " early",
            " Ming",
            " dynasty",
            ",",
            " the",
            " ab",
            "acus",
            " began",
            " to",
            " appear"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.4,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.482,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.449,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 33,
          "is_repeated_datapoint": false,
          "tokens": [
            " [#",
            "629",
            "–",
            "633",
            ";",
            " Web",
            " of",
            " Spider",
            "-Man",
            " (",
            "vol",
            ".",
            " ",
            "2",
            ")",
            " #",
            "6",
            "]",
            " ()",
            "Spider",
            "-Man",
            ":",
            " Grim",
            " Hunt",
            " [#",
            "634",
            "–",
            "637",
            ";",
            " The",
            " Amazing",
            " Spider",
            "-Man",
            ":",
            " Extra",
            "!",
            " #",
            "3",
            ";",
            " Spider",
            "-Man",
            ":",
            " Grim",
            " Hunt",
            " –",
            " The",
            " Kr",
            "aven",
            " Saga",
            ";",
            " Web",
            " of",
            " Spider",
            "-Man",
            " (",
            "vol",
            ".",
            " ",
            "2",
            ")",
            " #",
            "7",
            "]"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.465,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 36,
          "is_repeated_datapoint": false,
          "tokens": [
            "ini",
            " and",
            " Or",
            "son",
            " Wel",
            "les",
            ",",
            " and",
            " picked",
            " Seven",
            " Samurai",
            ",",
            " Throne",
            " of",
            " Blood",
            " and",
            " The",
            " Hidden",
            " Fortress",
            " for",
            " praise",
            ".",
            " Bern",
            "ardo",
            " Bert",
            "ol",
            "ucci",
            " considered",
            " K",
            "uros",
            "awa",
            "'s",
            " influence",
            " to",
            " be",
            " seminal",
            ":",
            " \"",
            "K",
            "uros",
            "awa",
            "'s",
            " movies",
            " and",
            " La",
            " Dol",
            "ce",
            " Vita",
            " of",
            " Fell",
            "ini",
            " are",
            " the",
            " things",
            " that",
            " pushed",
            " me",
            ",",
            " sucked",
            " me",
            " into",
            " being",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.461,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.42,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.342,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.217,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.35,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            "437",
            " m",
            ":",
            " ",
            "12",
            " ",
            "914",
            " to",
            " ",
            "1",
            ",",
            "523",
            " m",
            ":",
            " ",
            "4",
            " under",
            " ",
            "914",
            " m",
            ":",
            " ",
            "1",
            " (",
            "200",
            "8",
            ")",
            "Air",
            "ports",
            " –",
            " with",
            " unp",
            "aved",
            " run",
            "ways",
            " ",
            " total",
            ":",
            " ",
            " ",
            "181",
            " (",
            "200",
            "8",
            ")",
            " over",
            " ",
            "3",
            ",",
            "047",
            " m",
            ":",
            " ",
            "2",
            " ",
            "2",
            ",",
            "438",
            " to"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.438,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.279,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            " Arist",
            "oph",
            "anes",
            "'",
            " plays",
            " requires",
            " an",
            " understanding",
            " of",
            " the",
            " poetic",
            " forms",
            " he",
            " employed",
            " with",
            " virt",
            "u",
            "oso",
            " skill",
            ",",
            " and",
            " of",
            " their",
            " different",
            " rhythms",
            " and",
            " associations",
            ".",
            " There",
            " were",
            " three",
            " broad",
            " poetic",
            " forms",
            ":",
            " i",
            "amb",
            "ic",
            " dialogue",
            ",",
            " tet",
            "ram",
            "eter",
            " verses",
            " and",
            " lyrics",
            ":",
            " I",
            "amb",
            "ic",
            " dialogue",
            ":",
            " Arist",
            "oph",
            "anes",
            " achieves",
            " an",
            " effect",
            " resembling",
            " natural",
            " speech",
            " through",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.238,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.334,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.336,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.166,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.42,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.369,
            -0.0,
            -0.0
          ],
          "train_token_ind": 44,
          "is_repeated_datapoint": false,
          "tokens": [
            " Rights",
            " Week",
            " (",
            "United",
            " States",
            "):",
            " April",
            " ",
            "19",
            "–",
            "25",
            " National",
            " Volunteer",
            " Week",
            ":",
            " April",
            " ",
            "19",
            "–",
            "25",
            " European",
            " Immun",
            "ization",
            " Week",
            ":",
            " April",
            " ",
            "20",
            "–",
            "26",
            " Day",
            " of",
            " Silence",
            " (",
            "United",
            " States",
            "):",
            " April",
            " ",
            "24",
            " Pay",
            " It",
            " Forward",
            " Day",
            ":",
            " April",
            " ",
            "28",
            " (",
            "International",
            " observ",
            "ance",
            ")",
            " Den",
            "im",
            " Day",
            ":",
            " April",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.398,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.35,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.318,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.318,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 11,
          "is_repeated_datapoint": false,
          "tokens": [
            "502",
            "/",
            "498",
            "-",
            "502",
            "]",
            " ()",
            "Vol",
            ".",
            " ",
            "7",
            ":",
            " The",
            " Book",
            " of",
            " Ezek",
            "iel",
            " [#",
            "503",
            "–",
            "508",
            "]",
            " ()",
            "Vol",
            ".",
            " ",
            "8",
            ":",
            " S",
            "ins",
            " Past",
            " [#",
            "509",
            "–",
            "514",
            "]",
            " ()",
            "Vol",
            ".",
            " ",
            "9",
            ":",
            " Skin",
            " Deep",
            " [#",
            "515",
            "–",
            "518",
            "]",
            " ()",
            "Vol",
            ".",
            " ",
            "10",
            ":",
            " New",
            " Avengers",
            " [#",
            "519",
            "–",
            "524",
            "]",
            " ()"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.387,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.371,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " United",
            " Nations",
            ",",
            " and",
            " the",
            " Arab",
            " Mag",
            "h",
            "reb",
            " Union",
            ",",
            " of",
            " which",
            " it",
            " is",
            " a",
            " founding",
            " member",
            ".",
            "Name",
            " ",
            "Other",
            " forms",
            " of",
            " the",
            " name",
            " are",
            ":",
            " ,",
            " ;",
            " Ber",
            "ber",
            " languages",
            ":",
            " ,",
            " ,",
            " ;",
            " .",
            " It",
            " is",
            " officially",
            " the",
            " People",
            "'s",
            " Democratic",
            " Republic",
            " of",
            " Algeria",
            " (;",
            " ,",
            " abbreviated",
            " as",
            " RAD",
            "P",
            ").",
            "Et",
            "ymology",
            "Al",
            "ger",
            "ia",
            "'s"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.371,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.316,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.381,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 53,
          "is_repeated_datapoint": false,
          "tokens": [
            " appeal",
            " can",
            " be",
            ":",
            "Aff",
            "irmed",
            ":",
            " Where",
            " the",
            " reviewing",
            " court",
            " basically",
            " agrees",
            " with",
            " the",
            " result",
            " of",
            " the",
            " lower",
            " courts",
            "'",
            " ruling",
            "(s",
            ").",
            " ",
            "Re",
            "versed",
            ":",
            " Where",
            " the",
            " reviewing",
            " court",
            " basically",
            " disagrees",
            " with",
            " the",
            " result",
            " of",
            " the",
            " lower",
            " courts",
            "'",
            " ruling",
            "(s",
            "),",
            " and",
            " overturn",
            "s",
            " their",
            " decision",
            ".",
            "Vac",
            "ated",
            ":",
            " Where",
            " the",
            " reviewing",
            " court",
            " overturn",
            "s",
            " the",
            " lower",
            " courts"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.369,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 39,
          "is_repeated_datapoint": false,
          "tokens": [
            "External",
            " links",
            " ",
            "  ",
            " ",
            " Albert",
            " Einstein",
            " on",
            " Religion",
            " Sh",
            "ap",
            "ell",
            " Manus",
            "cript",
            " Foundation",
            " Why",
            " I",
            " Am",
            " An",
            " Ag",
            "nostic",
            " by",
            " Robert",
            " G",
            ".",
            " In",
            "gers",
            "oll",
            ",",
            " [",
            "189",
            "6",
            "].",
            " Dictionary",
            " of",
            " the",
            " History",
            " of",
            " Ideas",
            ":",
            " Ag",
            "nost",
            "icism",
            " Ag",
            "nost",
            "icism",
            " from",
            " INTER",
            "S",
            "Âł",
            "–",
            " Inter",
            "disciplinary",
            " Encyclopedia",
            " of",
            " Religion",
            " and",
            " Science",
            " Ag",
            "nost"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.039,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.245,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            " En",
            "clave",
            " of",
            " Cab",
            "inda",
            " or",
            " F",
            "LEC",
            " (",
            "Hen",
            "rique",
            " N",
            "'",
            "z",
            "ita",
            " Ti",
            "ago",
            ";",
            " Ant",
            "Ã³n",
            "io",
            " B",
            "ento",
            " B",
            "em",
            "be",
            ")",
            " note",
            ":",
            " F",
            "LEC",
            " is",
            " w",
            "aging",
            " a",
            " small",
            "-scale",
            ",",
            " highly",
            " faction",
            "al",
            "ized",
            ",",
            " armed",
            " struggle",
            " for",
            " the",
            " independence",
            " of",
            " Cab",
            "inda",
            " Province",
            "International",
            " organization",
            " participation",
            "A",
            "frican",
            ",",
            " Caribbean",
            " and",
            " Pacific"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.217,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 59,
          "is_repeated_datapoint": false,
          "tokens": [
            " solutions",
            " ",
            "The",
            " alk",
            "ali",
            " metals",
            " dissolve",
            " slowly",
            " in",
            " liquid",
            " ammonia",
            ",",
            " forming",
            " ammon",
            "iac",
            "al",
            " solutions",
            " of",
            " sol",
            "v",
            "ated",
            " metal",
            " c",
            "ation",
            " M",
            "+",
            " and",
            " sol",
            "v",
            "ated",
            " electron",
            " e",
            "âĪĴ",
            ",",
            " which",
            " react",
            " to",
            " form",
            " hydrogen",
            " gas",
            " and",
            " the",
            " alk",
            "ali",
            " metal",
            " am",
            "ide",
            " (",
            "M",
            "NH",
            "2",
            ",",
            " where",
            " M",
            " represents",
            " an",
            " alk",
            "ali",
            " metal",
            "):",
            " this",
            " was",
            " first"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.19,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            "d",
            "iffer",
            "ently",
            ")",
            " in",
            " paperback",
            " in",
            " ",
            "196",
            "3",
            ")",
            " Destination",
            ":",
            " Universe",
            "!",
            " (",
            "195",
            "2",
            ")",
            " The",
            " Tw",
            "isted",
            " Men",
            " (",
            "196",
            "4",
            ")",
            " Monsters",
            " (",
            "196",
            "5",
            ")",
            " (",
            "later",
            " as",
            " SF",
            " Monsters",
            " (",
            "196",
            "7",
            "))",
            " ab",
            "ridged",
            " as",
            " The",
            " Bl",
            "al",
            " (",
            "197",
            "6",
            ")",
            " A",
            " Van",
            " Vog",
            "t",
            " Omn",
            "ibus",
            " (",
            "196",
            "7",
            "),",
            " omn",
            "ibus"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "%",
            " of",
            " the",
            " population",
            " consisted",
            " of",
            " visible",
            " minorities",
            " and",
            " ",
            "6",
            ".",
            "8",
            "%",
            " of",
            " the",
            " population",
            " was",
            " Indigenous",
            ",",
            " mostly",
            " of",
            " First",
            " Nations",
            " and",
            " MÃ©t",
            "is",
            " descent",
            ".",
            " There",
            " was",
            " also",
            " a",
            " small",
            " number",
            " of",
            " In",
            "uit",
            " in",
            " the",
            " province",
            ".",
            " The",
            " Indigenous",
            " population",
            " has",
            " been",
            " growing",
            " at",
            " a",
            " faster",
            " rate",
            " than",
            " the",
            " population",
            " of",
            " Alberta",
            " as",
            " a",
            " whole",
            ".",
            "Rel",
            "igion"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " diversity",
            " of",
            " its",
            " flora",
            ".",
            " It",
            " is",
            " home",
            " to",
            " nearly",
            " ",
            "4",
            ",",
            "000",
            " p",
            "ter",
            "id",
            "oph",
            "yte",
            " and",
            " sper",
            "mat",
            "oph",
            "yte",
            " plant",
            " species",
            ".",
            "Ind",
            "igenous",
            " animal",
            " species",
            " in",
            " the",
            " state",
            " include",
            " ",
            "62",
            " mamm",
            "al",
            " species",
            ",",
            " ",
            "93",
            " rept",
            "ile",
            " species",
            ",",
            " ",
            "73",
            " amphib",
            "ian",
            " species",
            ",",
            " roughly",
            " ",
            "307",
            " native",
            " freshwater",
            " fish",
            " species",
            ",",
            " and",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "Conflict",
            " with",
            " Spain",
            "The",
            " Low",
            " Countries",
            " were",
            " part",
            " of",
            " the",
            " H",
            "aps",
            "burg",
            " inheritance",
            " and",
            " came",
            " under",
            " the",
            " Spanish",
            " monarchy",
            " in",
            " the",
            " early",
            " six",
            "teenth",
            " century",
            ".",
            " The",
            " Dutch",
            " rebel",
            "led",
            " against",
            " Philip",
            " II",
            " of",
            " Spain",
            ",",
            " who",
            " led",
            " a",
            " defense",
            " of",
            " Catholic",
            "ism",
            " during",
            " the",
            " Protestant",
            " Re",
            "formation",
            ".",
            " The",
            " main",
            " reasons",
            " for",
            " the",
            " uprising",
            " were",
            " the",
            " imposition",
            " of",
            " new",
            " taxes"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "0",
            " –",
            " Edward",
            " de",
            " Vere",
            ",",
            " ",
            "17",
            "th",
            " Earl",
            " of",
            " Oxford",
            ",",
            " English",
            " court",
            "ier",
            " and",
            " politician",
            ",",
            " Lord",
            " Great",
            " Chamber",
            "lain",
            " (",
            "d",
            ".",
            " ",
            "160",
            "4",
            ")",
            "157",
            "7",
            " –",
            " Christian",
            " IV",
            " of",
            " Denmark",
            " (",
            "d",
            ".",
            " ",
            "164",
            "8",
            ")",
            "160",
            "1",
            "–",
            "190",
            "0",
            "161",
            "2",
            " –",
            " Simone",
            " Cant",
            "ar",
            "ini",
            ",",
            " Italian",
            " painter",
            " and",
            " engr",
            "aver"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "Ð¾Ð¿Ð°Ñģ",
    "ruba",
    "ŀ",
    "izo",
    "togroup"
  ],
  "bottom_logits": [
    "rosse",
    " Brow",
    ":",
    "ino",
    " build"
  ],
  "act_min": -0.0,
  "act_max": 0.637
}
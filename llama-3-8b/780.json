{
  "index": 780,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            1.031,
            0.019,
            0.21,
            -0.0,
            0.594,
            0.03,
            -0.0,
            0.112,
            0.283,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.801,
            -0.0,
            0.222,
            0.069,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.801,
            0.344,
            -0.0,
            0.273,
            -0.0,
            0.227,
            -0.0,
            0.301,
            0.047,
            0.111,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.011,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.934,
            -0.0,
            0.128,
            0.151,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " buyer",
            "'s",
            " interest",
            " informed",
            " the",
            " seller",
            " that",
            " he",
            " intended",
            " to",
            " make",
            " the",
            " payments",
            " *",
            "396",
            " under",
            " the",
            " contract",
            " and",
            " demanded",
            " possession",
            ".",
            " The",
            " seller",
            " refused",
            " to",
            " accept",
            " the",
            " payments",
            ",",
            " claiming",
            " that",
            " the",
            " contract",
            " had",
            " been",
            " mutually",
            " resc",
            "inded",
            " on",
            " the",
            " buyer",
            "'s",
            " surrender",
            " of",
            " possession",
            ".\n",
            "We",
            " held",
            " that",
            " the",
            " statute",
            " of",
            " fraud",
            "s",
            " generally",
            " requires",
            " the",
            " surrender",
            " of",
            " legal",
            " and",
            " equitable",
            " interests",
            " in",
            " land",
            " to",
            " be",
            " in",
            " writing",
            ".",
            " Where",
            ",",
            " however",
            ",",
            " an",
            " oral",
            " resc",
            "ission",
            " has",
            " been",
            " executed",
            ",",
            " the",
            " statute",
            " of",
            " fraud",
            "s",
            " may",
            " not",
            " apply",
            ".",
            " In",
            " Cut",
            "wright",
            ",",
            " surrender",
            " of",
            " possession",
            " by",
            " the",
            " buyer",
            " constituted",
            " sufficient",
            " part",
            " performance",
            " of",
            " the",
            " resc",
            "ission",
            " agreement",
            " to",
            " remove",
            " it",
            " from",
            " the",
            " statute",
            " of",
            " fraud",
            "s",
            ".",
            " This",
            " exception",
            " is",
            " one",
            " of",
            " several"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            1.031,
            0.019,
            0.21,
            -0.0,
            0.594,
            0.03,
            -0.0,
            0.112,
            0.283,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.801,
            -0.0,
            0.222,
            0.069,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.801,
            0.344,
            -0.0,
            0.273,
            -0.0,
            0.227,
            -0.0,
            0.301,
            0.047,
            0.111,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.011,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.934,
            -0.0,
            0.128,
            0.151,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " buyer",
            "'s",
            " interest",
            " informed",
            " the",
            " seller",
            " that",
            " he",
            " intended",
            " to",
            " make",
            " the",
            " payments",
            " *",
            "396",
            " under",
            " the",
            " contract",
            " and",
            " demanded",
            " possession",
            ".",
            " The",
            " seller",
            " refused",
            " to",
            " accept",
            " the",
            " payments",
            ",",
            " claiming",
            " that",
            " the",
            " contract",
            " had",
            " been",
            " mutually",
            " resc",
            "inded",
            " on",
            " the",
            " buyer",
            "'s",
            " surrender",
            " of",
            " possession",
            ".\n",
            "We",
            " held",
            " that",
            " the",
            " statute",
            " of",
            " fraud",
            "s",
            " generally",
            " requires",
            " the",
            " surrender",
            " of",
            " legal",
            " and",
            " equitable",
            " interests",
            " in",
            " land",
            " to",
            " be",
            " in",
            " writing",
            ".",
            " Where",
            ",",
            " however",
            ",",
            " an",
            " oral",
            " resc",
            "ission",
            " has",
            " been",
            " executed",
            ",",
            " the",
            " statute",
            " of",
            " fraud",
            "s",
            " may",
            " not",
            " apply",
            ".",
            " In",
            " Cut",
            "wright",
            ",",
            " surrender",
            " of",
            " possession",
            " by",
            " the",
            " buyer",
            " constituted",
            " sufficient",
            " part",
            " performance",
            " of",
            " the",
            " resc",
            "ission",
            " agreement",
            " to",
            " remove",
            " it",
            " from",
            " the",
            " statute",
            " of",
            " fraud",
            "s",
            ".",
            " This",
            " exception",
            " is",
            " one",
            " of",
            " several"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.988,
            -0.0,
            0.416,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.652,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.742,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.73,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.266,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.058,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.52,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.711,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "1",
            "}",
            "^",
            "*",
            "}",
            " \\",
            "frac",
            "{",
            "1",
            "}{",
            "\\",
            "mu",
            "_m",
            "}",
            " +",
            " {\\",
            "ensure",
            "math",
            " {\\",
            "math",
            "bb",
            "{",
            "I",
            "}}",
            "}_{",
            "(",
            "x",
            "_{",
            "j",
            "}",
            "^",
            "*,",
            " x",
            "_{",
            "j",
            "+",
            "1",
            "}",
            "^",
            "*",
            "]}",
            "(",
            "x",
            ")",
            " \\",
            "frac",
            "{x",
            "_{",
            "j",
            "+",
            "1",
            "}",
            "^",
            "*-",
            "x",
            "}{",
            "x",
            "_{",
            "j",
            "+",
            "1",
            "}",
            "^",
            "*-",
            "x",
            "_{",
            "j",
            "}",
            "^",
            "*",
            "}",
            " \\",
            "frac",
            "{",
            "1",
            "}{",
            "\\",
            "mu",
            "_m",
            "};",
            "$$",
            " the",
            " two",
            " extrem",
            "al",
            " functions",
            " $",
            "V",
            "_",
            "2",
            "$",
            " and",
            " $",
            "V",
            "_m",
            "$",
            " are",
            " chosen",
            " so",
            " that",
            " $",
            "V",
            "_",
            "2",
            " \\",
            "equiv",
            " \\",
            "frac",
            "{",
            "1",
            "}{",
            "\\",
            "mu",
            "_m",
            "}$",
            " on",
            " $(",
            "\\",
            "v",
            "are",
            "psilon",
            "_m",
            ",",
            " x",
            "_",
            "2",
            "^"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.008,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.057,
            0.984,
            0.35,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.035,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " Vig",
            "il",
            "ance",
            ",",
            " or",
            " the",
            " ability",
            " to",
            " sustain",
            " attention",
            ",",
            " is",
            " an",
            " integral",
            " component",
            " of",
            " human",
            " factors",
            " research",
            ".",
            " Vig",
            "il",
            "ance",
            " task",
            " difficulty",
            " has",
            " previously",
            " been",
            " manipulated",
            " through",
            " increasing",
            " event",
            " rate",
            ".",
            " However",
            ",",
            " most",
            " research",
            " in",
            " this",
            " paradigm",
            " has",
            " utilized",
            " a",
            " sensory",
            "-based",
            " task",
            ",",
            " whereas",
            " little",
            " work",
            " has",
            " focused",
            " on",
            " these",
            " effects",
            " in",
            " relation",
            " to",
            " a",
            " cognitive",
            "-based",
            " task",
            ".",
            " In",
            " sum",
            ",",
            " ",
            "84",
            " participants",
            " completed",
            " a",
            " cognitive",
            " vigil",
            "ance",
            " task",
            " that",
            " contained",
            " either",
            " ",
            "24",
            " events",
            " per",
            " minute",
            " (",
            "low",
            " event",
            " rate",
            " condition",
            ")",
            " or",
            " ",
            "40",
            " events",
            " per",
            " minute",
            " (",
            "high",
            " event",
            " rate",
            " condition",
            ").",
            " Performance",
            " was",
            " measured",
            " through",
            " the",
            " proportion",
            " of",
            " hits",
            ",",
            " false",
            " alarms",
            ",",
            " mean",
            " response",
            " time",
            ",",
            " and",
            " signal",
            " detection",
            " analyses",
            " (",
            "i",
            ".e",
            ".,",
            " sensitivity"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.084,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.754,
            0.202,
            -0.0,
            -0.0,
            0.266,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.984,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.032,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.097,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.551,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.027,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " There",
            " were",
            " ",
            "2",
            "/",
            "287",
            " (",
            "0",
            ".",
            "70",
            "%)",
            " sudden",
            " cardiac",
            " deaths",
            " with",
            " QU",
            "AD",
            " and",
            " ",
            "13",
            "/",
            "560",
            " (",
            "2",
            ".",
            "32",
            "%)",
            " with",
            " non",
            "âĢĲ",
            "QU",
            "AD",
            ".",
            " Non",
            "card",
            "iac",
            " deaths",
            " accounted",
            " for",
            " ",
            "3",
            "/",
            "287",
            " (",
            "1",
            ".",
            "04",
            "%)",
            " deaths",
            " with",
            " QU",
            "AD",
            " and",
            " ",
            "42",
            "/",
            "560",
            " (",
            "7",
            ".",
            "5",
            "%)",
            " deaths",
            " with",
            " non",
            "âĢĲ",
            "QU",
            "AD",
            ".",
            " The",
            " cause",
            " and",
            " mode",
            " of",
            " death",
            " was",
            " unknown",
            " in",
            " ",
            "3",
            " (",
            "1",
            ".",
            "04",
            "%)",
            " patients",
            " with",
            " QU",
            "AD",
            " and",
            " in",
            " ",
            "40",
            " (",
            "7",
            ".",
            "14",
            "%)",
            " patients",
            " with",
            " non",
            "âĢĲ",
            "QU",
            "AD",
            ".",
            " Ex",
            "cluding",
            " these",
            " patients",
            ",",
            " QU",
            "AD",
            " was",
            " associated",
            " with",
            " a",
            " lower",
            " mortality",
            " from",
            " pump",
            " failure",
            " (",
            "log",
            " rank",
            " *",
            "P",
            "*"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            0.361,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.082,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.171,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.98,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " deal",
            " with",
            " you",
            " in",
            " whatever",
            " way",
            " is",
            " necessary",
            ".\"\n",
            "On",
            " the",
            " night",
            " of",
            " June",
            " ",
            "7",
            " or",
            " early",
            " morning",
            " of",
            " June",
            " ",
            "8",
            ",",
            " ",
            "196",
            "9",
            ",",
            " respondent",
            " went",
            " to",
            " his",
            " office",
            " at",
            " the",
            " Church",
            " of",
            " Scientology",
            " and",
            " took",
            " several",
            " documents",
            " from",
            " the",
            " safe",
            ".",
            " These",
            " documents",
            " were",
            " taken",
            " by",
            " him",
            " to",
            " the",
            " Internal",
            " Revenue",
            " Service",
            " in",
            " Kansas",
            " City",
            ";",
            " he",
            " used",
            " them",
            " to",
            " allege",
            " improper",
            " changes",
            " in",
            " the",
            " records",
            " of",
            " the",
            " church",
            ".",
            " He",
            " denies",
            " that",
            " any",
            " Swiss",
            " franc",
            "s",
            " were",
            " in",
            " the",
            " safe",
            " that",
            " night",
            " or",
            " that",
            " he",
            " took",
            " such",
            " Swiss",
            " franc",
            "s",
            ".",
            " Furthermore",
            ",",
            " respondent",
            " denies",
            " the",
            " allegation",
            " that",
            " he",
            " stole",
            " various",
            " travelers",
            "'",
            " checks",
            " from",
            " the",
            " safe",
            ".",
            " He",
            " admitted",
            " that",
            " some",
            " travelers",
            "'",
            " checks",
            " had",
            " his",
            " signature",
            " as",
            " an",
            " endorsement"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.066,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.036,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.003,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.973,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " it",
            " could",
            " have",
            " challenged",
            " the",
            " jur",
            "or",
            ",",
            " though",
            " it",
            " is",
            " not",
            " claimed",
            " that",
            " it",
            " would",
            " have",
            " done",
            " so",
            ".",
            " In",
            " Department",
            " of",
            " Public",
            " Works",
            " &",
            " Buildings",
            " v",
            ".",
            " Christ",
            "ensen",
            ",",
            " ",
            "25",
            " Ill",
            ".",
            "2",
            "d",
            " ",
            "273",
            ",",
            " ",
            "184",
            " NE",
            "2",
            "d",
            " ",
            "884",
            ",",
            " it",
            " was",
            " alleged",
            " that",
            " the",
            " party",
            " would",
            " not",
            " have",
            " accepted",
            " the",
            " jur",
            "or",
            " if",
            " a",
            " true",
            " answer",
            " had",
            " been",
            " given",
            ".",
            " The",
            " Supreme",
            " Court",
            " there",
            " held",
            " that",
            " the",
            " motion",
            " for",
            " a",
            " new",
            " trial",
            " would",
            " be",
            " denied",
            " unless",
            " it",
            " was",
            " shown",
            " not",
            " only",
            " that",
            " the",
            " jur",
            "or",
            " answered",
            " falsely",
            ",",
            " but",
            " also",
            " that",
            " prejudice",
            " resulted",
            ".",
            " Erie",
            " cites",
            " the",
            " case",
            " of",
            " People",
            " v",
            ".",
            " Ortiz",
            ",",
            " ",
            "320",
            " Ill",
            ".",
            " ",
            "205",
            ",",
            " ",
            "150",
            " NE",
            " ",
            "708",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.126,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.005,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.074,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.054,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.762,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.969
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "-v",
            "p",
            " using",
            " ten",
            " nodes",
            " and",
            " for",
            " a",
            " non",
            "-d",
            "istributed",
            " implementation",
            " in",
            " WE",
            "KA",
            " using",
            " a",
            " single",
            " node",
            "[]{",
            "data",
            "-label",
            "=\"",
            "fig",
            ":",
            "exec",
            "Time",
            "Vs",
            "N",
            "Inst",
            "a",
            "\"}",
            "](",
            "fig",
            "03",
            ".eps",
            "){",
            "width",
            "=\"",
            "100",
            ".",
            "000",
            "00",
            "%\"",
            "}\n\n",
            "Note",
            " that",
            ",",
            " with",
            " the",
            " aim",
            " of",
            " offering",
            " a",
            " comprehensive",
            " view",
            " of",
            " execution",
            " time",
            " behaviour",
            ",",
            " Figure",
            "Âł",
            "\\[",
            "fig",
            ":",
            "exec",
            "Time",
            "Vs",
            "N",
            "Inst",
            "a",
            "\\",
            "]",
            " shows",
            " results",
            " for",
            " sizes",
            " larger",
            " than",
            " the",
            " ",
            "100",
            "%",
            " of",
            " the",
            " datasets",
            ".",
            " To",
            " achieve",
            " these",
            " sizes",
            ",",
            " the",
            " instances",
            " in",
            " each",
            " dataset",
            " were",
            " duplicated",
            " as",
            " many",
            " times",
            " as",
            " necessary",
            ".",
            " Note",
            " also",
            " that",
            ",",
            " since",
            " EC",
            "BD",
            "L",
            "14",
            " is",
            " a",
            " very",
            " large",
            " dataset",
            ",",
            " its",
            " temporal",
            " scale",
            " is",
            " different",
            " from"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.965,
            -0.0,
            -0.0,
            -0.0,
            0.428,
            -0.0,
            0.379,
            -0.0,
            0.119,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.387,
            -0.0,
            0.017,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.27,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " direct",
            " matching",
            " of",
            " the",
            " measured",
            " M",
            "RF",
            " signal",
            " reconstructed",
            " by",
            " plain",
            " Fourier",
            " transformations",
            ",",
            " to",
            " the",
            " simulated",
            " dictionary",
            " elements",
            " is",
            " not",
            " sufficiently",
            " accurate",
            " for",
            " high",
            " unders",
            "ampling",
            " factors",
            ".[",
            "24",
            "](",
            "#",
            "m",
            "rm",
            "275",
            "94",
            "-b",
            "ib",
            "-",
            "002",
            "4",
            "){",
            "ref",
            "-type",
            "=\"",
            "ref",
            "\"},",
            " [",
            "25",
            "](",
            "#",
            "m",
            "rm",
            "275",
            "94",
            "-b",
            "ib",
            "-",
            "002",
            "5",
            "){",
            "ref",
            "-type",
            "=\"",
            "ref",
            "\"}",
            " Therefore",
            ",",
            " the",
            " quality",
            " of",
            " the",
            " reconstructed",
            " M",
            "RF",
            " data",
            " has",
            " to",
            " be",
            " improved",
            " before",
            " the",
            " matching",
            " process",
            ".\n\n",
            "Com",
            "pressed",
            " sensing",
            " (",
            "CS",
            ")",
            " has",
            " been",
            " introduced",
            " as",
            " a",
            " technique",
            " to",
            " reconstruct",
            " images",
            " from",
            " randomly",
            " unders",
            "ampled",
            " data",
            " by",
            " enforcing",
            " signal",
            " sp",
            "arsity",
            " (",
            "in",
            " the",
            " spatial",
            " dimension",
            " only",
            " or",
            " both",
            " in",
            " spatial",
            " and",
            " temporal",
            " dimensions",
            "),",
            "[",
            "26",
            "]("
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.961,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.365,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.719,
            -0.0,
            -0.0,
            -0.0,
            0.346,
            -0.0,
            -0.0,
            -0.0,
            0.076,
            -0.0,
            0.375,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.004,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.262,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.371,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.182,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " regime",
            "’s",
            " opponents",
            ",",
            " the",
            " CIA",
            " launched",
            " political",
            " warfare",
            " against",
            " Moss",
            "ad",
            "eg",
            "h",
            ".",
            " It",
            " distributed",
            " fake",
            " news",
            " via",
            " posters",
            " and",
            " newspapers",
            " that",
            " called",
            " him",
            " corrupt",
            ",",
            " anti",
            "-Isl",
            "am",
            ",",
            " and",
            " the",
            " Soviet",
            " Union",
            "’s",
            " ally",
            ",",
            " it",
            " encouraged",
            " religious",
            " leaders",
            " to",
            " criticize",
            " the",
            " prime",
            " minister",
            " from",
            " inside",
            " their",
            " mosques",
            ",",
            " and",
            " it",
            " enlisted",
            " street",
            " mobs",
            " to",
            " inc",
            "ite",
            " riots",
            " across",
            " Tehran",
            ".\n\n",
            "Success",
            " finally",
            " came",
            " on",
            " August",
            " ",
            "19",
            ".",
            " Paid",
            " infiltr",
            "ators",
            " played",
            " both",
            " sides",
            ":",
            " some",
            " posed",
            " as",
            " T",
            "ude",
            "h",
            " party",
            " members",
            " attempting",
            " to",
            " f",
            "oment",
            " revolution",
            " while",
            " others",
            " convinced",
            " the",
            " citizens",
            " to",
            " rise",
            " up",
            " against",
            " this",
            " threat",
            ".",
            " Eventually",
            ",",
            " amid",
            " growing",
            " an",
            "archy",
            ",",
            " General",
            " F",
            "az",
            "l",
            "ollah",
            " Zah",
            "edi",
            ",",
            " paid",
            " off",
            " by",
            " the",
            " CIA",
            ","
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.011,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.027,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.058,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.957,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.024,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " lower",
            " resolution",
            " scan",
            " was",
            " performed",
            " twice",
            ",",
            " the",
            " first",
            " fully",
            " sampled",
            " to",
            " serve",
            " as",
            " a",
            " reference",
            ",",
            " and",
            " the",
            " second",
            " one",
            " unders",
            "ampled",
            ".",
            " The",
            " scan",
            " time",
            " of",
            " the",
            " fully",
            " sampled",
            " scan",
            " was",
            " ",
            "7",
            ":",
            "02",
            " min",
            ",",
            " while",
            " the",
            " scan",
            " time",
            " of",
            " the",
            " unders",
            "ampled",
            " scan",
            ",",
            " in",
            " which",
            " ",
            "15",
            "%",
            " of",
            " the",
            " data",
            " was",
            " acquired",
            ",",
            " was",
            " ",
            "1",
            ":",
            "16",
            " min",
            ".",
            " The",
            " high",
            " resolution",
            " scan",
            " was",
            " only",
            " acquired",
            " as",
            " an",
            " unders",
            "ampled",
            " data",
            " set",
            ",",
            " in",
            " which",
            " ",
            "12",
            ".",
            "5",
            "%",
            " of",
            " the",
            " data",
            " was",
            " acquired",
            ",",
            " resulting",
            " in",
            " a",
            " scan",
            " time",
            " of",
            " ",
            "1",
            ":",
            "57",
            " min",
            ".",
            " In",
            " the",
            " unders",
            "ampled",
            " scans",
            " a",
            " simple",
            " variable",
            " density",
            " k",
            "âĢĲ",
            "space",
            " sampling",
            " was",
            " applied",
            ",",
            " schem",
            "atically",
            " shown",
            " in",
            " Figure"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.957,
            0.152,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.191,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.176,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "n",
            "_k",
            "}",
            " (",
            "e",
            "_",
            "1",
            ")]",
            "}",
            " \\",
            "le",
            " {",
            "n",
            "^{",
            "1",
            "+",
            "3",
            "\\v",
            "are",
            "psilon",
            "}",
            " \\",
            "over",
            " \\",
            "E",
            " [\\",
            "beta",
            "_n",
            "(e",
            "_",
            "1",
            ")]",
            "}$",
            " (",
            "the",
            " last",
            " inequality",
            " following",
            " from",
            " the",
            " estimate",
            " of",
            " $\\",
            "E",
            " [\\",
            "beta",
            "_n",
            "(e",
            "_",
            "1",
            ")]",
            "$",
            " in",
            " Proposition",
            " \\",
            "[",
            "p",
            ":",
            "beta",
            "-g",
            "amma",
            "\\",
            "]).",
            " In",
            " view",
            " of",
            " Proposition",
            " \\",
            "[",
            "p",
            ":",
            "beta",
            "-g",
            "amma",
            "\\",
            "],",
            " and",
            " since",
            " $\\",
            "v",
            "are",
            "psilon",
            "$",
            " can",
            " be",
            " as",
            " small",
            " as",
            " possible",
            ",",
            " this",
            " gives",
            " the",
            " lower",
            " bound",
            " in",
            " (\\",
            "[",
            "null",
            "rec",
            "\\",
            "])",
            " of",
            " The",
            "orem",
            " \\",
            "[",
            "t",
            ":null",
            "rec",
            "\\",
            "].\n\n",
            "To",
            " prove",
            " the",
            " upper",
            " bound",
            ",",
            " we",
            " note",
            " that",
            " $\\",
            "alpha",
            "_{",
            "n",
            ",\\",
            "lambda"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.125,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.283,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.07,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.953,
            0.075,
            0.19,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.065,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "    ",
            " http",
            "://",
            "www",
            ".apache",
            ".org",
            "/licenses",
            "/LICENSE",
            "-",
            "2",
            ".",
            "0",
            "\n",
            " *\n",
            " *",
            " Unless",
            " required",
            " by",
            " applicable",
            " law",
            " or",
            " agreed",
            " to",
            " in",
            " writing",
            ",",
            " software",
            "\n",
            " *",
            " distributed",
            " under",
            " the",
            " License",
            " is",
            " distributed",
            " on",
            " an",
            " \"",
            "AS",
            " IS",
            "\"",
            " BASIS",
            ",\n",
            " *",
            " WITHOUT",
            " WARRANTIES",
            " OR",
            " CONDITIONS",
            " OF",
            " ANY",
            " KIND",
            ",",
            " either",
            " express",
            " or",
            " implied",
            ".\n",
            " *",
            " See",
            " the",
            " License",
            " for",
            " the",
            " specific",
            " language",
            " governing",
            " permissions",
            " and",
            "\n",
            " *",
            " limitations",
            " under",
            " the",
            " License",
            ".\n",
            " */\n\n",
            "package",
            " com",
            ".apple",
            ".foundation",
            "db",
            ".record",
            ".metadata",
            ";\n\n",
            "import",
            " com",
            ".apple",
            ".foundation",
            "db",
            ".record",
            ".provider",
            ".foundation",
            "db",
            ".F",
            "DB",
            "Record",
            "Version",
            ";\n",
            "import",
            " com",
            ".apple",
            ".foundation",
            "db",
            ".t",
            "uple",
            ".T",
            "uple",
            ";\n",
            "import",
            " com",
            ".google",
            ".protobuf",
            ".ByteString",
            ";\n",
            "import",
            " com",
            ".google",
            ".protobuf",
            ".Des",
            "criptors",
            ";\n",
            "import",
            " com",
            ".google",
            ".protobuf",
            ".Protocol",
            "Message"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.088,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.953,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.365,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.013,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.064,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.352,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.062,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " if",
            " use",
            " of",
            " CO",
            "X",
            "-",
            "2",
            " inhibitors",
            " were",
            " to",
            " exert",
            " a",
            " conf",
            "ounding",
            " effect",
            " on",
            " the",
            " observed",
            " CO",
            "X",
            "-",
            "2",
            " genotype",
            "/",
            "colon",
            " cancer",
            " association",
            ",",
            " our",
            " inability",
            " to",
            " control",
            " for",
            " such",
            " conf",
            "ounding",
            " is",
            " likely",
            " to",
            " lead",
            " to",
            " an",
            " under",
            "est",
            "imation",
            ",",
            " rather",
            " than",
            " an",
            " over",
            "est",
            "imation",
            ",",
            " of",
            " the",
            " risk",
            " associated",
            " with",
            " the",
            " put",
            "ative",
            " high",
            "-",
            "activity",
            " genotype",
            ".",
            " This",
            " is",
            " because",
            " use",
            " of",
            " CO",
            "X",
            "-",
            "2",
            " inhibitors",
            " is",
            " likely",
            " to",
            " be",
            " more",
            " common",
            " among",
            " subjects",
            " with",
            " more",
            " severe",
            " symptoms",
            " of",
            " inflammation",
            ",",
            " possibly",
            " due",
            " to",
            " the",
            " possession",
            " of",
            " the",
            " high",
            " activity",
            " *",
            "CO",
            "X",
            "-",
            "2",
            "*",
            " genotype",
            ".",
            " Another",
            " weakness",
            " of",
            " the",
            " present",
            " study",
            " is",
            " our",
            " relatively",
            " small",
            " number",
            " of",
            " cancer",
            " cases",
            ",",
            " which",
            " may",
            " result"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.949,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.52,
            -0.0,
            0.015,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.201,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.068,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " exists",
            " in",
            " any",
            " of",
            " your",
            " receipts",
            ".\n",
            "The",
            " downside",
            " to",
            " this",
            " is",
            " that",
            " if",
            " the",
            " application",
            "'s",
            " name",
            " changed",
            " it",
            " won",
            "'t",
            " find",
            " it",
            " since",
            " your",
            " receipt",
            " will",
            " contain",
            " the",
            " application",
            "'s",
            " old",
            " name",
            ".",
            " You",
            " could",
            " try",
            " searching",
            " for",
            " the",
            " seller",
            "'s",
            " name",
            ",",
            " but",
            " that",
            " might",
            " change",
            " as",
            " well",
            ".\n",
            "Another",
            " way",
            " to",
            " do",
            " this",
            " is",
            " to",
            " look",
            " at",
            " your",
            " iTunes",
            " purchase",
            " history",
            ".",
            " While",
            " this",
            " will",
            " have",
            " the",
            " application",
            "'s",
            " current",
            " name",
            " (",
            "un",
            "like",
            " in",
            " email",
            " arch",
            "iving",
            "),",
            " there",
            " is",
            " no",
            " easy",
            " way",
            " to",
            " search",
            " through",
            " it",
            ".\n",
            "Another",
            " difference",
            " between",
            " the",
            " two",
            " methods",
            " is",
            " that",
            " the",
            " Purchase",
            " History",
            " will",
            " contain",
            " app",
            " updates",
            " you",
            " downloaded",
            ",",
            " while",
            " the",
            " receipt",
            " emails",
            " will",
            " not",
            ".\n",
            "Update",
            ":",
            " It",
            " seems",
            " that",
            " as",
            " of",
            " May",
            ","
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            0.945,
            0.4,
            0.126,
            0.136,
            -0.0,
            0.108,
            0.134,
            -0.0,
            0.144,
            -0.0,
            0.132,
            0.144,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.266,
            -0.0,
            0.242,
            0.089,
            -0.0,
            0.02,
            0.258,
            -0.0,
            -0.0,
            0.026,
            0.177,
            -0.0,
            0.112,
            -0.0,
            0.453,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.342,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.05,
            -0.0,
            -0.0,
            0.727,
            0.222,
            0.252,
            0.186,
            -0.0,
            -0.0,
            0.112,
            0.067,
            -0.0,
            -0.0,
            0.115,
            0.016,
            0.064,
            0.113,
            0.065,
            0.062,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.379,
            0.124,
            -0.0,
            0.023,
            0.153,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.336,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.504,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.52,
            -0.0,
            0.154,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            0.135,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "42",
            " and",
            " ",
            "576",
            "?\n",
            "18",
            "\n",
            "What",
            " is",
            " the",
            " highest",
            " common",
            " factor",
            " of",
            " ",
            "480",
            "555",
            " and",
            " ",
            "156",
            "645",
            "?\n",
            "265",
            "5",
            "\n",
            "What",
            " is",
            " the",
            " highest",
            " common",
            " divisor",
            " of",
            " ",
            "996",
            "76",
            " and",
            " ",
            "20",
            "?\n",
            "4",
            "\n",
            "What",
            " is",
            " the",
            " greatest",
            " common",
            " factor",
            " of",
            " ",
            "216",
            "84",
            " and",
            " ",
            "358",
            "8",
            "?\n",
            "156",
            "\n",
            "What",
            " is",
            " the",
            " greatest",
            " common",
            " factor",
            " of",
            " ",
            "219",
            "52",
            " and",
            " ",
            "106",
            "4",
            "?\n",
            "56",
            "\n",
            "Calculate",
            " the",
            " highest",
            " common",
            " divisor",
            " of",
            " ",
            "786",
            "78",
            " and",
            " ",
            "483",
            "6",
            ".\n",
            "186",
            "\n",
            "What",
            " is",
            " the",
            " greatest",
            " common",
            " factor",
            " of",
            " ",
            "756",
            " and",
            " ",
            "138",
            "60",
            "?\n",
            "252",
            "\n",
            "What",
            " is",
            " the",
            " highest",
            " common",
            " divisor",
            " of",
            " ",
            "127",
            "5",
            " and",
            " ",
            "493",
            "?\n",
            "17",
            "\n",
            "What",
            " is",
            " the",
            " highest"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.941,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.131,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.416,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.082,
            -0.0,
            -0.0,
            -0.0,
            0.338,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.178,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.41,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " would",
            " help",
            " him",
            " get",
            " over",
            ",",
            " and",
            " there",
            "'s",
            " nothing",
            " more",
            " sensational",
            " for",
            " selling",
            " a",
            " drink",
            " than",
            " setting",
            " it",
            " on",
            " fire",
            ".",
            " Here",
            "'s",
            " our",
            " interpretation",
            ".\n\n",
            "Advertisement",
            " -",
            " Continue",
            " Reading",
            " Below",
            "\n\n",
            "Charles",
            " Dickens",
            "'s",
            " Punch",
            " Ritual",
            "\n\n",
            "For",
            " ",
            "12",
            " to",
            " ",
            "16",
            " people",
            "\n\n",
            "Step",
            " ",
            "1",
            ":",
            " Three",
            " hours",
            " before",
            " your",
            " party",
            ",",
            " peel",
            " ",
            "3",
            " le",
            "mons",
            " with",
            " a",
            " sw",
            "ivel",
            "-bl",
            "aded",
            " vegetable",
            " pe",
            "eler",
            ",",
            " trying",
            " to",
            " end",
            " up",
            " with",
            " three",
            " long",
            " spir",
            "als",
            " of",
            " peel",
            ".",
            " Put",
            " them",
            " in",
            " a",
            " ",
            "3",
            "-",
            " or",
            " ",
            "4",
            "-qu",
            "art",
            " fire",
            "proof",
            " bowl",
            " with",
            " ",
            "3",
            "/",
            "4",
            " cup",
            " dem",
            "er",
            "ara",
            " sugar",
            " or",
            " other",
            " raw",
            " sugar",
            ".",
            " M",
            "uddle",
            " the",
            " pe",
            "els",
            " and",
            " the",
            " sugar",
            " together",
            " and",
            " let",
            " sit",
            ".\n\n"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.941,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.394,
            -0.0,
            -0.0,
            -0.0,
            0.424,
            -0.0,
            0.512,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.385,
            -0.0,
            -0.0,
            -0.0,
            0.416,
            -0.0,
            0.492,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.389,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.009,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.086,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " which",
            ",",
            " by",
            " Proposition",
            " \\",
            "[",
            "p",
            ":",
            "con",
            "centration",
            "\\",
            "],",
            " implies",
            " $$",
            "\\",
            "E",
            "\\",
            "left",
            "[",
            " (",
            "Z",
            "_{",
            "j",
            ",",
            " \\",
            "theta",
            "})",
            "^",
            "2",
            " \\",
            "right",
            "]",
            " \\",
            "le",
            " c",
            "_{",
            "38",
            "}",
            " \\",
            ",\n",
            "   ",
            " \\",
            "left",
            "(",
            " \\",
            "E",
            " Z",
            "_{",
            "j",
            ",",
            " \\",
            "theta",
            "}",
            " \\",
            "right",
            ")^",
            "{\\",
            "k",
            "appa",
            "-\n",
            "   ",
            " \\",
            "v",
            "are",
            "psilon",
            "}",
            " .\n",
            "   ",
            " \\",
            "label",
            "{",
            "c",
            "38",
            "}",
            "$$",
            "\n\n",
            "Therefore",
            ",",
            " (\\",
            "[",
            "51",
            "\\",
            "])",
            " yields",
            " that",
            " $$",
            "\\",
            "E",
            "(Z",
            "_{",
            "j",
            "+",
            "1",
            ",",
            " \\",
            "theta",
            "})",
            " \\",
            "ge",
            " \\",
            "theta",
            "+",
            " (",
            "1",
            "-\\",
            "theta",
            ")",
            " \\",
            "E",
            "(Z",
            "_{",
            "j",
            ",",
            " \\",
            "theta",
            "})",
            " -",
            " c",
            "_{",
            "38",
            "}",
            " \\",
            ",",
            " (\\",
            "E",
            " Z",
            "_{"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.938,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "     ",
            " self",
            "._",
            "error",
            "(err",
            ");\n",
            "   ",
            " })\n",
            "   ",
            " .",
            "on",
            "('",
            "ab",
            "orted",
            "',",
            " function",
            "()",
            " {\n",
            "     ",
            " self",
            ".emit",
            "('",
            "ab",
            "orted",
            "');\n",
            "     ",
            " self",
            "._",
            "error",
            "(new",
            " Error",
            "('",
            "Request",
            " aborted",
            "'));\n",
            "   ",
            " })\n",
            "   ",
            " .",
            "on",
            "('",
            "data",
            "',",
            " function",
            "(buffer",
            ")",
            " {\n",
            "     ",
            " self",
            ".write",
            "(buffer",
            ");\n",
            "   ",
            " })\n",
            "   ",
            " .",
            "on",
            "('",
            "end",
            "',",
            " function",
            "()",
            " {\n",
            "     ",
            " if",
            " (",
            "self",
            ".error",
            ")",
            " {\n",
            "       ",
            " return",
            ";\n",
            "     ",
            " }\n\n",
            "     ",
            " var",
            " err",
            " =",
            " self",
            "._",
            "parser",
            ".end",
            "();\n",
            "     ",
            " if",
            " (",
            "err",
            ")",
            " {\n",
            "       ",
            " self",
            "._",
            "error",
            "(err",
            ");\n",
            "     ",
            " }\n",
            "   ",
            " });\n\n",
            " ",
            " return",
            " this",
            ";\n",
            "};\n\n",
            "Incoming",
            "Form",
            ".prototype",
            ".write",
            "Headers",
            " =",
            " function",
            "(headers",
            ")",
            " {\n",
            " ",
            " this",
            ".headers",
            " =",
            " headers",
            ";\n",
            " ",
            " this",
            "._",
            "parse",
            "Content",
            "Length"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.938,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.773,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "cm",
            " around",
            " tum",
            "our",
            " and",
            " ",
            "1",
            "cm",
            " to",
            " the",
            " normal",
            " tissue",
            " as",
            " determined",
            " by",
            " MRI",
            ".",
            " A",
            "--",
            "J",
            " are",
            " corresponding",
            " hist",
            "ologic",
            " images",
            " (",
            "HE",
            ",",
            " ÃĹ",
            "200",
            ")",
            " of",
            " line",
            " a",
            "--",
            "j",
            ".",
            " No",
            " tum",
            "our",
            " cells",
            " were",
            " found",
            " on",
            " the",
            " plane",
            " a",
            ",",
            " b",
            ",",
            " c",
            " (",
            "Fig",
            "ures",
            " A",
            ",",
            " B",
            ",",
            " C",
            ").",
            "](",
            "rado",
            "-",
            "46",
            "-",
            "03",
            "-",
            "189",
            "f",
            "2",
            "){",
            "#",
            "f",
            "2",
            "-r",
            "ado",
            "-",
            "46",
            "-",
            "03",
            "-",
            "189",
            "}\n\n",
            "![",
            "Post",
            "operative",
            " assessment",
            " of",
            " pro",
            "sth",
            "esis",
            ".",
            " A",
            " female",
            ",",
            " ",
            "19",
            "-year",
            "-old",
            " patient",
            " with",
            " oste",
            "os",
            "ar",
            "coma",
            " in",
            " the",
            " dist",
            "al",
            " fem",
            "ur",
            ".",
            " Pre",
            "operative",
            " anterior",
            "-post",
            "erior",
            " plain",
            " film",
            " (",
            "A",
            ")",
            " and",
            " post",
            "operative",
            " anterior",
            "-post"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            0.934,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " the",
            " several",
            " provisions",
            " set",
            " out",
            " in",
            " the",
            " contract",
            " should",
            " not",
            " control",
            " under",
            " these",
            " circumstances",
            ".",
            " The",
            " effect",
            " of",
            " these",
            " documents",
            " might",
            " be",
            " that",
            " Erie",
            " could",
            " not",
            " be",
            " required",
            " to",
            " perform",
            " the",
            " tests",
            " and",
            " effect",
            " the",
            " start",
            "-up",
            " of",
            " the",
            " boiler",
            ",",
            " but",
            " they",
            " should",
            " not",
            " control",
            " liability",
            " where",
            " under",
            " the",
            " evidence",
            " it",
            " might",
            " be",
            " reasonable",
            " to",
            " conclude",
            " that",
            " they",
            " did",
            ",",
            " in",
            " fact",
            ",",
            " undertake",
            " and",
            " perform",
            " the",
            " work",
            ".",
            " The",
            " contract",
            " provision",
            " quoted",
            " does",
            " not",
            " attempt",
            " to",
            " exclude",
            " negligence",
            " of",
            " Erie",
            " employ",
            "es",
            ".\n",
            "E",
            "rie",
            " discusses",
            " Count",
            " I",
            " of",
            " the",
            " complaint",
            " as",
            " involving",
            " the",
            " principles",
            " of",
            " res",
            " ips",
            "a",
            " lo",
            "quit",
            "ur",
            " under",
            " a",
            " pleading",
            " of",
            " general",
            " negligence",
            ".",
            " These",
            " principles",
            " are",
            " thoroughly",
            " discussed",
            " in",
            " Met",
            "z",
            " v",
            ".",
            " Central",
            " Illinois",
            " Electric",
            " &",
            " Gas"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.04,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.594,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.033,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.566,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.432,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.934,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.93,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.754,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ".png",
            " \"",
            "fig",
            ":",
            "\"){",
            "width",
            "=\"",
            "45",
            ".",
            "000",
            "00",
            "%",
            "\"}",
            "   ",
            " ![",
            "Example",
            " ",
            "2",
            ":",
            " The",
            " $",
            "L",
            "_",
            "2",
            "$",
            "-",
            "norm",
            " of",
            " the",
            " error",
            " as",
            " a",
            " function",
            " of",
            " $",
            "s",
            "$",
            " for",
            " different",
            " values",
            " of",
            " $\\",
            "gamma",
            "$.",
            " Each",
            " line",
            " corresponds",
            " to",
            " a",
            " spline",
            " of",
            " different",
            " degree",
            ":",
            " solid",
            " lines",
            " correspond",
            " to",
            " the",
            " polynomial",
            " spl",
            "ines",
            ";",
            " non",
            " solid",
            " lines",
            " correspond",
            " to",
            " fractional",
            " spl",
            "ines",
            ".",
            "[]{",
            "data",
            "-label",
            "=\"",
            "fig",
            ":L",
            "2",
            "_error",
            "_",
            "2",
            "\"}",
            "](",
            "Fig",
            "_L",
            "2",
            "Error",
            "_g",
            "am",
            "0",
            "p",
            "75",
            "_ex",
            "2",
            ".png",
            " \"",
            "fig",
            ":",
            "\"){",
            "width",
            "=\"",
            "45",
            ".",
            "000",
            "00",
            "%\"",
            "}\n",
            "  ",
            " ![",
            "Example",
            " ",
            "2",
            ":",
            " The",
            " $",
            "L",
            "_",
            "2",
            "$",
            "-",
            "norm",
            " of",
            " the",
            " error",
            " as",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.04,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.594,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.033,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.566,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.432,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.934,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.93,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.754,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ".png",
            " \"",
            "fig",
            ":",
            "\"){",
            "width",
            "=\"",
            "45",
            ".",
            "000",
            "00",
            "%",
            "\"}",
            "   ",
            " ![",
            "Example",
            " ",
            "2",
            ":",
            " The",
            " $",
            "L",
            "_",
            "2",
            "$",
            "-",
            "norm",
            " of",
            " the",
            " error",
            " as",
            " a",
            " function",
            " of",
            " $",
            "s",
            "$",
            " for",
            " different",
            " values",
            " of",
            " $\\",
            "gamma",
            "$.",
            " Each",
            " line",
            " corresponds",
            " to",
            " a",
            " spline",
            " of",
            " different",
            " degree",
            ":",
            " solid",
            " lines",
            " correspond",
            " to",
            " the",
            " polynomial",
            " spl",
            "ines",
            ";",
            " non",
            " solid",
            " lines",
            " correspond",
            " to",
            " fractional",
            " spl",
            "ines",
            ".",
            "[]{",
            "data",
            "-label",
            "=\"",
            "fig",
            ":L",
            "2",
            "_error",
            "_",
            "2",
            "\"}",
            "](",
            "Fig",
            "_L",
            "2",
            "Error",
            "_g",
            "am",
            "0",
            "p",
            "75",
            "_ex",
            "2",
            ".png",
            " \"",
            "fig",
            ":",
            "\"){",
            "width",
            "=\"",
            "45",
            ".",
            "000",
            "00",
            "%\"",
            "}\n",
            "  ",
            " ![",
            "Example",
            " ",
            "2",
            ":",
            " The",
            " $",
            "L",
            "_",
            "2",
            "$",
            "-",
            "norm",
            " of",
            " the",
            " error",
            " as",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.094,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.644,
            -0.0,
            -0.0,
            0.122,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.016,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.93,
            0.326,
            -0.0,
            -0.0,
            0.204,
            -0.0,
            -0.0,
            0.114,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.004,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " ",
            "150",
            "313",
            "6",
            ",",
            " ",
            "175",
            "368",
            "3",
            "?\n",
            "2",
            "*k",
            "**",
            "2",
            " +",
            " ",
            "250",
            "521",
            "*k",
            " -",
            " ",
            "62",
            "\n",
            "What",
            " is",
            " the",
            " x",
            "'t",
            "h",
            " term",
            " of",
            " -",
            "750",
            ",",
            " -",
            "351",
            ",",
            " ",
            "232",
            "6",
            ",",
            " ",
            "842",
            "1",
            ",",
            " ",
            "190",
            "74",
            "?\n",
            "190",
            "*x",
            "**",
            "3",
            " -",
            " x",
            "**",
            "2",
            " -",
            " ",
            "928",
            "*x",
            " -",
            " ",
            "11",
            "\n",
            "What",
            " is",
            " the",
            " b",
            "'t",
            "h",
            " term",
            " of",
            " -",
            "320",
            "3",
            ",",
            " -",
            "474",
            "3",
            ",",
            " -",
            "463",
            "7",
            ",",
            " -",
            "288",
            "5",
            ",",
            " ",
            "513",
            ",",
            " ",
            "555",
            "7",
            "?\n",
            "823",
            "*b",
            "**",
            "2",
            " -",
            " ",
            "400",
            "9",
            "*b",
            " -",
            " ",
            "17",
            "\n",
            "What",
            " is",
            " the",
            " m",
            "'t",
            "h",
            " term",
            " of",
            " -",
            "262",
            "326",
            ",",
            " -",
            "262",
            "274",
            ",",
            " -"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.629,
            0.291,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.262,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.379,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.066,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.097,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.93,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "-",
            "03",
            "-",
            "189",
            "}\n\n",
            "######",
            " \n\n",
            "Les",
            "ion",
            " features",
            " in",
            " six",
            " patients",
            "\n\n",
            " ",
            " **",
            "NO",
            ".",
            "**",
            "  ",
            " **",
            "Primary",
            " tumor",
            "**",
            "  ",
            " **",
            "Sex",
            "**",
            "  ",
            " **",
            "Age",
            "(y",
            ")**",
            "  ",
            " **",
            "T",
            "umor",
            " characteristics",
            "**",
            "  ",
            " **",
            "T",
            "umor",
            " edge",
            " disparity",
            " between",
            " CT",
            " and",
            " MR",
            "(cm",
            ")**",
            "          \n",
            " ",
            " ---------",
            " ----------------",
            "---",
            " ---------",
            " ------------",
            " ----------------",
            "-----------",
            " ------------------------------------------------",
            " ------",
            " -----\n",
            " ",
            " ",
            "1",
            "        ",
            " O",
            "ste",
            "os",
            "ar",
            "coma",
            "       ",
            " M",
            "        ",
            " ",
            "20",
            "          ",
            " Pro",
            "x",
            "imal",
            " Fem",
            "ur",
            "             ",
            " ",
            "6",
            ".",
            "5",
            "                                             ",
            " ",
            "6",
            ".",
            "0",
            "   ",
            " ",
            "0",
            ".",
            "5",
            "\n",
            " ",
            " ",
            "2",
            "        ",
            " Ch",
            "ond",
            "ros",
            "ar",
            "coma",
            "     ",
            " F",
            "        ",
            " ",
            "29",
            "          ",
            " Pro",
            "x",
            "imal",
            " Fem",
            "ur",
            "             ",
            " ",
            "7",
            ".",
            "1",
            "                                             ",
            " ",
            "5"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.018,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.93,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.389,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.531,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " spectral",
            " col",
            "location",
            " method",
            ".",
            " ,",
            " ",
            "36",
            "(",
            "1",
            "):",
            "A",
            "40",
            "–",
            "A",
            "62",
            ",",
            " ",
            "201",
            "4",
            ".\n\n",
            "[^",
            "1",
            "]:",
            " [*",
            "Dept",
            ".",
            " S",
            "BA",
            "I",
            ",",
            " University",
            " of",
            " Roma",
            " ”",
            "La",
            " S",
            "api",
            "enza",
            "”",
            "*",
            "]{",
            "},",
            " Via",
            " A",
            ".",
            " Scar",
            "pa",
            " ",
            "16",
            ",",
            " ",
            "001",
            "61",
            " Roma",
            ",",
            " Italy",
            ".",
            " e",
            "-mail",
            ":",
            " [",
            "l",
            "aura",
            ".",
            "pez",
            "za",
            "@",
            "sb",
            "ai",
            ".uni",
            "roma",
            "1",
            ".it",
            "]{",
            "}\n\n",
            "[^",
            "2",
            "]:",
            " [*",
            "Dept",
            ".",
            " S",
            "BA",
            "I",
            ",",
            " University",
            " of",
            " Roma",
            " ”",
            "La",
            " S",
            "api",
            "enza",
            "”",
            "*",
            "]{",
            "},",
            " Via",
            " A",
            ".",
            " Scar",
            "pa",
            " ",
            "16",
            ",",
            " ",
            "001",
            "61",
            " Roma",
            ",",
            " Italy",
            ".",
            " e",
            "-mail",
            ":\n",
            "<|begin_of_text|>",
            "Âĵ",
            "I",
            " can",
            "’t",
            " express",
            " how",
            " extremely",
            " pleased",
            " we",
            " are"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.93,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.387,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.365,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.365,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.024,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "pre",
            "viously",
            " in",
            " Hot",
            " Val",
            "ves",
            "),",
            " and",
            " ex",
            "-P",
            "VC",
            "2",
            " members",
            ",",
            " bass",
            "ist",
            " Russell",
            " Webb",
            ",",
            " keyboard",
            "ist",
            " Billy",
            " Mc",
            "Is",
            "aac",
            " and",
            " drummer",
            " Kenny",
            " H",
            "ys",
            "lop",
            ".",
            " Their",
            " next",
            " single",
            ",",
            " \"",
            "Sign",
            " of",
            " the",
            " Times",
            "\"",
            " was",
            " released",
            " shortly",
            " afterwards",
            " in",
            " Ar",
            "ista",
            " Records",
            ".\n\n",
            "Track",
            " list",
            "\n",
            " Side",
            " A",
            ":",
            " \"",
            "St",
            "uck",
            " With",
            " You",
            "\"\n",
            " Side",
            " B",
            ":",
            " \"",
            "No",
            " Angels",
            "\"\n\n",
            "Person",
            "nel",
            "\n",
            "Will",
            "ie",
            " Gardner",
            ":",
            " lead",
            " vocals",
            ",",
            " lead",
            " guitar",
            ".\n",
            "Russ",
            "ell",
            " Webb",
            ":",
            " bass",
            " guitar",
            ".\n",
            "Billy",
            " Mc",
            "Is",
            "aac",
            ":",
            " keyboards",
            ".\n",
            "K",
            "enny",
            " H",
            "ys",
            "lop",
            ":",
            " drums",
            ".\n\n",
            "References",
            "\n\n",
            "Category",
            ":",
            "197",
            "8",
            " singles",
            "\n",
            "Category",
            ":",
            "Z",
            "ones",
            " (",
            "band",
            ")",
            " songs",
            "\n",
            "Category",
            ":",
            "De",
            "but",
            " singles"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.005,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.715,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.926,
            0.02,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.283,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.256,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.652,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ")\n",
            "    ",
            " *",
            "     ",
            " ==",
            " Arrays",
            ".equals",
            "(T",
            "uple",
            ".from",
            "List",
            "(to",
            "Tuple",
            "App",
            "ropriate",
            "List",
            "(list",
            "1",
            ")).",
            "pack",
            "(),",
            " Tuple",
            ".from",
            "List",
            "(to",
            "Tuple",
            "App",
            "ropriate",
            "List",
            "(list",
            "2",
            ")).",
            "pack",
            "())\n",
            "    ",
            " *",
            " }</",
            "pre",
            ">\n",
            "    ",
            " *\n",
            "    ",
            " *",
            " <",
            "p",
            ">\n",
            "    ",
            " *",
            " for",
            " any",
            " two",
            " lists",
            " {@",
            "code",
            " list",
            "1",
            "}",
            " and",
            " {@",
            "code",
            " list",
            "2",
            "}.\n",
            "    ",
            " *",
            " </",
            "p",
            ">\n",
            "    ",
            " *\n",
            "    ",
            " *",
            " @",
            "param",
            " values",
            " the",
            " list",
            " of",
            " values",
            " to",
            " normalized",
            "\n",
            "    ",
            " *",
            " @",
            "return",
            " a",
            " new",
            " list",
            " containing",
            " the",
            " normalized",
            " elements",
            " of",
            " {@",
            "code",
            " values",
            "}\n",
            "    ",
            " */\n",
            "   ",
            " @",
            "Nonnull",
            "\n",
            "   ",
            " static",
            " List",
            "<Object",
            ">",
            " to",
            "Tuple",
            "Equivalent",
            "List",
            "(@",
            "Nonnull",
            " List",
            "<?>",
            " values",
            ")",
            " {\n",
            "       ",
            " List",
            "<Object",
            ">",
            " tuple",
            "Equivalent",
            "List"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.005,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.715,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.926,
            0.02,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.283,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.256,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.652,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ")\n",
            "    ",
            " *",
            "     ",
            " ==",
            " Arrays",
            ".equals",
            "(T",
            "uple",
            ".from",
            "List",
            "(to",
            "Tuple",
            "App",
            "ropriate",
            "List",
            "(list",
            "1",
            ")).",
            "pack",
            "(),",
            " Tuple",
            ".from",
            "List",
            "(to",
            "Tuple",
            "App",
            "ropriate",
            "List",
            "(list",
            "2",
            ")).",
            "pack",
            "())\n",
            "    ",
            " *",
            " }</",
            "pre",
            ">\n",
            "    ",
            " *\n",
            "    ",
            " *",
            " <",
            "p",
            ">\n",
            "    ",
            " *",
            " for",
            " any",
            " two",
            " lists",
            " {@",
            "code",
            " list",
            "1",
            "}",
            " and",
            " {@",
            "code",
            " list",
            "2",
            "}.\n",
            "    ",
            " *",
            " </",
            "p",
            ">\n",
            "    ",
            " *\n",
            "    ",
            " *",
            " @",
            "param",
            " values",
            " the",
            " list",
            " of",
            " values",
            " to",
            " normalized",
            "\n",
            "    ",
            " *",
            " @",
            "return",
            " a",
            " new",
            " list",
            " containing",
            " the",
            " normalized",
            " elements",
            " of",
            " {@",
            "code",
            " values",
            "}\n",
            "    ",
            " */\n",
            "   ",
            " @",
            "Nonnull",
            "\n",
            "   ",
            " static",
            " List",
            "<Object",
            ">",
            " to",
            "Tuple",
            "Equivalent",
            "List",
            "(@",
            "Nonnull",
            " List",
            "<?>",
            " values",
            ")",
            " {\n",
            "       ",
            " List",
            "<Object",
            ">",
            " tuple",
            "Equivalent",
            "List"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.02,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.011,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.057,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.922,
            0.307,
            0.059,
            0.138,
            0.052,
            0.194,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "/group",
            ")",
            "                                                   ",
            " ",
            "1",
            " mg",
            "                                                                  ",
            " ",
            "1",
            " day",
            "              ",
            " Healthy",
            " animals",
            "                                                                                                                                ",
            "                                                                             ",
            " âĨĳ",
            " M",
            "Ã¸",
            " expression",
            " of",
            " D",
            "ect",
            "in",
            "-",
            "1",
            " in",
            " G",
            "ALT",
            " cells",
            ";",
            " âĨĳ",
            " T",
            "LR",
            "2",
            " expression",
            " in",
            " P",
            "eyer",
            "\\'",
            "s",
            " patch",
            " dend",
            "ritic",
            " cells",
            "                                                                ",
            "                                                    ",
            " \\",
            "[",
            "[@",
            "B",
            "29",
            "]\\",
            "]\n\n",
            "                                                                                                                                ",
            "                                                                                                                                ",
            "                                                                                                                                ",
            "                                                                                                                                ",
            "                                                                                                                                ",
            "                                  ",
            "\n\n",
            "                                                                          ",
            " â",
            "ĻĤ",
            " W",
            "istar",
            " rats",
            " (",
            "7",
            "/group",
            ")",
            "                                                    ",
            " ",
            "5",
            "%",
            " of",
            " diet",
            " days",
            " ",
            "1",
            "-",
            "4",
            ",",
            " ",
            "10",
            "%",
            " of",
            " diet",
            " days",
            " ",
            "5",
            "-",
            "25",
            "                            ",
            " ",
            "26",
            " days",
            "            ",
            " Inject",
            "ed",
            " IP",
            " *",
            "E",
            ".",
            " coli",
            "*L",
            "PS",
            " day",
            " ",
            "25",
            "                                                                                                                                ",
            "                                                             ",
            " âĨĵ",
            " liver",
            " ALT",
            ",",
            " AST",
            ",",
            " and",
            " LD",
            "H",
            " enzyme",
            " levels",
            ";",
            " âĨĳ",
            " ED",
            "2",
            "-positive"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.039,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.039,
            -0.0,
            -0.0,
            -0.0,
            0.922,
            0.334,
            0.328,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.582,
            0.26,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.028,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " these",
            " GR",
            "Fs",
            ",",
            " following",
            " the",
            " same",
            " procedure",
            " as",
            " outlined",
            " above",
            ",",
            " and",
            " subsequently",
            " perform",
            " lens",
            "ing",
            " reconstruction",
            ",",
            " just",
            " as",
            " for",
            " the",
            " reconstructed",
            " $",
            "N",
            "$",
            "-",
            "body",
            " $\\",
            "k",
            "appa",
            "$",
            " maps",
            ".",
            " These",
            " noisy",
            " GR",
            "F",
            "-only",
            " recon",
            "structions",
            " allow",
            " us",
            " to",
            " examine",
            " the",
            " effect",
            " of",
            " reconstruction",
            " (",
            "in",
            " particular",
            " the",
            " non",
            "-G",
            "aussian",
            "ity",
            " of",
            " the",
            " reconstruction",
            " noise",
            " itself",
            "),",
            " as",
            " well",
            " as",
            " to",
            " determine",
            " the",
            " level",
            " of",
            " non",
            "-G",
            "aussian",
            "ity",
            " in",
            " the",
            " noisy",
            " $\\",
            "k",
            "appa",
            "$",
            " maps",
            ".\n\n",
            "Inter",
            "polation",
            "\n",
            "------------",
            "-\n\n",
            "![",
            "\\[",
            "fig",
            ":",
            "interp",
            "\\",
            "]",
            " Fraction",
            "al",
            " differences",
            " between",
            " interpolated",
            " and",
            " “",
            "true",
            "”",
            " results",
            " for",
            " the",
            " fid",
            "uc",
            "ial",
            " power",
            " spectrum",
            " (",
            "top",
            "),",
            " PDF",
            " (",
            "middle",
            "),",
            " and",
            " peak",
            " counts",
            " (",
            "bottom",
            ")."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.805,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.543,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.06,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.902,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.918,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.416,
            -0.0,
            -0.0,
            -0.0,
            0.393,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.205,
            -0.0,
            -0.0,
            0.486,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.042,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " The",
            " aim",
            " of",
            " this",
            " European",
            " Heart",
            " R",
            "hythm",
            " Association",
            " (",
            "EH",
            "RA",
            ")",
            " survey",
            " was",
            " to",
            " evaluate",
            " clinical",
            " practice",
            " regarding",
            " management",
            " of",
            " VT",
            " among",
            " the",
            " European",
            " countries",
            ".",
            " An",
            " electronic",
            " questionnaire",
            " was",
            " sent",
            " to",
            " members",
            " of",
            " the",
            " EH",
            "RA",
            " Elect",
            "roph",
            "ys",
            "iology",
            " Research",
            " Network",
            ".",
            " Responses",
            " were",
            " received",
            " from",
            " ",
            "88",
            " centres",
            " in",
            " ",
            "12",
            " countries",
            ".",
            " The",
            " results",
            " have",
            " shown",
            " that",
            " management",
            " of",
            " VT",
            "s",
            " is",
            " very",
            " heterogeneous",
            " across",
            " the",
            " participating",
            " centres",
            ".",
            " Ind",
            "ications",
            ",",
            " per",
            "ipro",
            "ced",
            "ural",
            " management",
            ",",
            " and",
            " ab",
            "lation",
            " strategies",
            " vary",
            " substantially",
            ".",
            " This",
            " EP",
            " Wire",
            " survey",
            " has",
            " revealed",
            " that",
            " cath",
            "eter",
            " ab",
            "lation",
            " is",
            " the",
            " first",
            "-line",
            " therapy",
            " for",
            " the",
            " treatment",
            " of",
            " recurrent",
            " mon",
            "omorphic",
            " stable",
            " VT",
            " in",
            " patients",
            " without",
            " structural",
            " heart",
            " disease",
            " as",
            " well",
            " as",
            " in",
            " patients"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.91,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.447,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.389,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.457,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " $\\",
            "in",
            "fty",
            "$.",
            " These",
            " approx",
            "imations",
            " are",
            " given",
            " in",
            " the",
            " sense",
            " of",
            " the",
            " Le",
            " Cam",
            " distance",
            ",",
            " under",
            " some",
            " smooth",
            "ness",
            " conditions",
            " on",
            " the",
            " unknown",
            " L",
            "Ã©",
            "vy",
            " density",
            ".",
            " All",
            " the",
            " asympt",
            "otic",
            " equival",
            "ences",
            " are",
            " established",
            " by",
            " constructing",
            " explicit",
            " Mark",
            "ov",
            " kernels",
            " that",
            " can",
            " be",
            " used",
            " to",
            " reproduce",
            " one",
            " experiment",
            " from",
            " the",
            " other",
            ".'\n",
            "address",
            ":\n",
            "-",
            " '*",
            "Labor",
            "atoire",
            " L",
            "JK",
            ",",
            " Univers",
            "itÃ©",
            " Joseph",
            " Fourier",
            " U",
            "MR",
            " ",
            "522",
            "4",
            " ",
            "51",
            ",",
            " Rue",
            " des",
            " Math",
            "Ã©",
            "mat",
            "iques",
            ",",
            " Saint",
            " Martin",
            " d",
            "’",
            "H",
            "Ã¨res",
            " BP",
            " ",
            "53",
            " ",
            "380",
            "41",
            " Gren",
            "oble",
            " Ced",
            "ex",
            " ",
            "09",
            "*",
            "'\n",
            "-",
            " '",
            "Cor",
            "respond",
            "ing",
            " Author",
            ",",
            " E",
            "ster",
            ".M",
            "ari",
            "ucci",
            "@",
            "imag",
            ".fr",
            "'\n",
            "author",
            ":\n",
            "-",
            " E",
            "ster"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.828,
            0.299,
            0.205,
            -0.0,
            0.14,
            0.079,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.891,
            0.185,
            0.09,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "819",
            "6",
            "*b",
            " -",
            " ",
            "819",
            "4",
            "*b",
            ",",
            " b",
            " -",
            " ",
            "2",
            "*y",
            " =",
            " ",
            "6",
            " for",
            " b",
            ".\n",
            "0",
            "\n",
            "S",
            "olve",
            " ",
            "5",
            "*t",
            " =",
            " ",
            "154",
            "*z",
            " -",
            " ",
            "123",
            "*z",
            " -",
            " ",
            "377",
            ",",
            " -",
            "4",
            "*z",
            " -",
            " ",
            "4",
            "*t",
            " =",
            " -",
            "44",
            " for",
            " z",
            ".\n",
            "12",
            "\n",
            "S",
            "olve",
            " s",
            " =",
            " -",
            "2",
            "*t",
            " -",
            " ",
            "3",
            "*t",
            " -",
            " ",
            "56",
            ",",
            " ",
            "5",
            "*t",
            " +",
            " ",
            "456",
            "*s",
            " +",
            " ",
            "274",
            "*s",
            " =",
            " -",
            "785",
            " for",
            " t",
            ".\n",
            "-",
            "11",
            "\n",
            "S",
            "olve",
            " f",
            " -",
            " ",
            "2",
            " =",
            " -",
            "2",
            "*u",
            ",",
            " -",
            "5",
            "*u",
            " =",
            " -",
            "5",
            "*f",
            " -",
            " ",
            "370",
            "80",
            " +",
            " ",
            "371",
            "50",
            " for",
            " f",
            ".\n",
            "10",
            "\n",
            "S",
            "olve",
            " ",
            "0",
            "*z",
            " +",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.883,
            0.32,
            0.175,
            -0.0,
            0.606,
            0.438,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.602,
            -0.0,
            -0.0,
            0.42,
            -0.0,
            -0.0,
            0.523,
            0.356,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.75,
            0.379,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " Regarding",
            " the",
            " data",
            ",",
            " RDD",
            " partitions",
            " are",
            " distributed",
            " across",
            " the",
            " worker",
            " nodes",
            ",",
            " and",
            " the",
            " number",
            " of",
            " tasks",
            " launched",
            " by",
            " the",
            " driver",
            " for",
            " each",
            " executor",
            " is",
            " set",
            " according",
            " to",
            " the",
            " number",
            " of",
            " RDD",
            " partitions",
            " residing",
            " in",
            " the",
            " worker",
            ".\n\n",
            "Two",
            " types",
            " of",
            " operations",
            " can",
            " be",
            " executed",
            " on",
            " an",
            " RDD",
            ",",
            " namely",
            ",",
            " actions",
            " and",
            " transformations",
            ".",
            " Of",
            " the",
            " *",
            "actions",
            "*,",
            " which",
            " allow",
            " results",
            " to",
            " be",
            " obtained",
            " from",
            " a",
            " Spark",
            " cluster",
            ",",
            " perhaps",
            " the",
            " most",
            " important",
            " is",
            " $",
            "collect",
            "$,",
            " which",
            " returns",
            " an",
            " array",
            " with",
            " all",
            " the",
            " elements",
            " in",
            " the",
            " RDD",
            ".",
            " This",
            " operation",
            " has",
            " to",
            " be",
            " done",
            " with",
            " care",
            ",",
            " to",
            " avoid",
            " exceeding",
            " the",
            " maximum",
            " memory",
            " available",
            " to",
            " the",
            " driver",
            ".",
            " Other",
            " important",
            " actions",
            " include",
            " $",
            "reduce",
            "$,",
            " $",
            "sum",
            "$,",
            " $",
            "aggregate",
            "$",
            " and",
            " $"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.371,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.828,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.277,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.844,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.859,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.106,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.84,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " class",
            ".",
            " However",
            ",",
            " this",
            " stability",
            " is",
            " turning",
            " into",
            " its",
            " opposite",
            ".\n\n",
            "On",
            " Sunday",
            ",",
            " ",
            "14",
            " January",
            " ",
            "201",
            "8",
            ",",
            " tens",
            "-of",
            "-th",
            "ousands",
            " of",
            " activists",
            " from",
            " different",
            " labour",
            " and",
            " left",
            "-wing",
            " organisations",
            " came",
            " to",
            " the",
            " Berlin",
            " Socialist",
            " Memorial",
            " Cemetery",
            " in",
            " the",
            " Eastern",
            " suburb",
            " of",
            " Friedrich",
            "sf",
            "el",
            "de",
            " to",
            " commemorate",
            " the",
            " murder",
            " of",
            " the",
            " outstanding",
            " German",
            " revolution",
            "aries",
            " and",
            " Marx",
            "ists",
            " Rosa",
            " Lux",
            "emb",
            "urg",
            " and",
            " Karl",
            " Lie",
            "bk",
            "ne",
            "cht",
            " on",
            " ",
            "15",
            " January",
            " ",
            "191",
            "9",
            ".\n\n",
            "Early",
            " on",
            " Monday",
            " morning",
            ",",
            " ",
            "20",
            " November",
            ",",
            " the",
            " leaders",
            " of",
            " the",
            " German",
            ",",
            " right",
            "-wing",
            ",",
            " liberal",
            " Free",
            " Democratic",
            " Party",
            " (",
            "F",
            "DP",
            ")",
            " suddenly",
            " declared",
            " their",
            " exit",
            " from",
            " preliminary",
            " coalition",
            " talks",
            " and",
            " walked",
            " out",
            " of",
            " the",
            " room",
            ".",
            " The",
            " negotiations",
            " with",
            " Chancellor"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.856,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.237,
            0.338,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.25,
            0.301,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.256,
            0.301,
            -0.0,
            0.398,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.073,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " by",
            " stressing",
            " on",
            " the",
            " gener",
            "ality",
            " of",
            " this",
            " scenario",
            ".",
            " First",
            ",",
            " the",
            " vortex",
            " patterns",
            " do",
            " not",
            " rely",
            " on",
            " the",
            " perfect",
            " rotational",
            " symmetry",
            " of",
            " the",
            " boundaries",
            ".",
            " As",
            " illustrated",
            " in",
            " [",
            "Sup",
            "plementary",
            " Fig",
            ".",
            " ",
            "2",
            ",",
            "](",
            "#",
            "S",
            "1",
            "){",
            "ref",
            "-type",
            "=\"",
            "sup",
            "plementary",
            "-material",
            "\"}",
            " the",
            " same",
            " spatial",
            " organization",
            " is",
            " observed",
            " for",
            " a",
            " variety",
            " of",
            " convex",
            " polygon",
            "al",
            " geomet",
            "ries",
            ".",
            " However",
            ",",
            " strongly",
            " an",
            "is",
            "otropic",
            ",",
            " and",
            "/or",
            " strongly",
            " non",
            "-",
            "conv",
            "ex",
            " conf",
            "in",
            "ements",
            " can",
            " yield",
            " other",
            " self",
            "-",
            "organized",
            " states",
            " such",
            " as",
            " vortex",
            " arrays",
            ",",
            " which",
            " we",
            " will",
            " characterize",
            " elsewhere",
            ".",
            " Second",
            ",",
            " neither",
            " the",
            " nature",
            " of",
            " the",
            " rep",
            "ulsive",
            " cou",
            "plings",
            " nor",
            " the",
            " symmetry",
            " of",
            " the",
            " interactions",
            " yielding",
            " collective",
            " motion",
            " are",
            " crucial",
            ",",
            " thereby",
            " making",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.832,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "](",
            "#",
            "jah",
            "325",
            "87",
            "-b",
            "ib",
            "-",
            "002",
            "4",
            "){",
            "ref",
            "-type",
            "=\"",
            "ref",
            "\"}",
            " Unfortunately",
            ",",
            " the",
            " present",
            " study",
            " does",
            " not",
            " address",
            " vector",
            " locations",
            " or",
            " how",
            " vector",
            " configurations",
            " changed",
            " during",
            " follow",
            "âĢĲ",
            "up",
            ".",
            " It",
            " is",
            " hoped",
            " that",
            " ongoing",
            " prospective",
            " studies",
            "[",
            "25",
            "](",
            "#",
            "jah",
            "325",
            "87",
            "-b",
            "ib",
            "-",
            "002",
            "5",
            "){",
            "ref",
            "-type",
            "=\"",
            "ref",
            "\"}",
            " may",
            " shed",
            " further",
            " light",
            " on",
            " this",
            " issue",
            ".",
            " We",
            " did",
            " not",
            " collect",
            " data",
            " as",
            " on",
            " Q",
            "âĢĲ",
            "LV",
            " as",
            " an",
            " aid",
            " for",
            " targeting",
            " LV",
            " lead",
            " positions",
            ",",
            " but",
            " it",
            " is",
            " possible",
            " that",
            " this",
            " approach",
            " could",
            " influence",
            " outcomes",
            ".\n\n",
            "Con",
            "clusions",
            " {",
            "#",
            "jah",
            "325",
            "87",
            "-",
            "sec",
            "-",
            "003",
            "2",
            "}\n",
            "===========",
            "\n\n",
            "In",
            " this",
            " study",
            " of",
            " real",
            "âĢĲ",
            "world",
            " clinical",
            " practice",
            ",",
            " we",
            " have",
            " shown"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.494,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.496,
            -0.0,
            0.711,
            0.139,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.809,
            0.303,
            -0.0,
            -0.0,
            -0.0,
            0.428,
            -0.0,
            -0.0,
            -0.0,
            0.184,
            0.228,
            0.178,
            -0.0,
            0.617,
            -0.0,
            0.684,
            0.322,
            0.059,
            -0.0,
            0.012,
            0.161,
            -0.0,
            -0.0,
            0.559,
            0.181,
            0.081,
            0.097,
            0.068,
            -0.0,
            0.106,
            -0.0,
            0.598,
            0.356,
            0.093,
            -0.0,
            0.034,
            0.09,
            -0.0,
            -0.0,
            -0.0,
            0.629,
            0.121,
            0.009,
            0.076,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.562,
            0.283,
            0.146,
            -0.0,
            0.207,
            -0.0,
            0.245,
            0.106,
            -0.0,
            -0.0,
            -0.0,
            0.426,
            0.122,
            -0.0,
            0.16,
            -0.0,
            -0.0,
            -0.0,
            0.373,
            -0.0,
            0.181,
            -0.0,
            -0.0,
            0.204,
            0.118,
            0.157,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.691,
            -0.0,
            -0.0,
            0.504,
            0.162,
            0.068,
            0.169,
            -0.0,
            0.038,
            -0.0,
            -0.0,
            -0.0,
            0.478,
            -0.0,
            0.16
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "ann",
            "elling",
            " of",
            " the",
            " generated",
            " photons",
            " into",
            " the",
            " desired",
            " mode",
            ".",
            " There",
            " is",
            " therefore",
            " a",
            " *",
            "trade",
            "off",
            "*",
            " relation",
            " between",
            " $\\",
            "eta",
            "_{",
            "\\",
            "mathrm",
            "{",
            "in",
            "}}",
            "$",
            " and",
            " $\\",
            "eta",
            "_{",
            "\\",
            "mathrm",
            "{",
            "esc",
            "}}",
            "$",
            " with",
            " respect",
            " to",
            " $\\",
            "k",
            "appa",
            "_{",
            "\\",
            "mathrm",
            "{",
            "ex",
            "}}",
            "$,",
            " and",
            " $\\",
            "k",
            "appa",
            "_{",
            "\\",
            "mathrm",
            "{",
            "ex",
            "}}",
            "$",
            " should",
            " be",
            " optimized",
            " to",
            " maximize",
            " the",
            " overall",
            " efficiency",
            ".",
            " This",
            " trade",
            "off",
            " relation",
            " has",
            " not",
            " been",
            " examined",
            " in",
            " previous",
            " studies",
            ",",
            " where",
            " the",
            " internal",
            " loss",
            " rate",
            " $\\",
            "k",
            "appa",
            "_{",
            "\\",
            "mathrm",
            "{",
            "in",
            "}}",
            "$",
            " has",
            " not",
            " been",
            " treated",
            " explicitly",
            ".",
            " Additionally",
            ",",
            " previous",
            " studies",
            " on",
            " the",
            " photon",
            "-generation",
            " efficiency",
            " have",
            " not",
            " taken",
            " account",
            " of",
            " a",
            " rep",
            "umping",
            " process",
            ",",
            " where",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.75,
            -0.0,
            -0.0,
            0.307,
            -0.0,
            -0.0,
            0.121,
            -0.0,
            0.239,
            -0.0,
            -0.0,
            0.574,
            -0.0,
            0.504,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.11,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.157,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.342,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.508,
            -0.0,
            0.173,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " processes",
            " have",
            " major",
            " implications",
            " for",
            " human",
            " health",
            ";",
            " between",
            " them",
            " impacting",
            " birth",
            " defects",
            ",",
            " cancer",
            " and",
            " the",
            " deg",
            "enerative",
            " effects",
            " of",
            " human",
            " aging",
            ".",
            " For",
            " example",
            ",",
            " defects",
            " in",
            " cell",
            " differentiation",
            " during",
            " embryo",
            " development",
            " result",
            " in",
            " human",
            " birth",
            " defects",
            ".",
            " Sen",
            "esc",
            "ence",
            " and",
            " differentiation",
            " programs",
            " are",
            " both",
            " characterized",
            " by",
            " profound",
            " changes",
            " in",
            " chrom",
            "atin",
            " structure",
            ",",
            " and",
            ",",
            " in",
            " both",
            " cases",
            ",",
            " this",
            " is",
            " thought",
            " to",
            " contribute",
            " to",
            " the",
            " altered",
            " cell",
            " phenotype",
            ".",
            " We",
            " are",
            " using",
            " sen",
            "esc",
            "ence",
            " as",
            " a",
            " model",
            " system",
            " to",
            " study",
            " these",
            " changes",
            " in",
            " chrom",
            "atin",
            " structure",
            " and",
            " their",
            " contribution",
            " to",
            " two",
            " hall",
            "marks",
            " of",
            " both",
            " sen",
            "esc",
            "ence",
            " and",
            " terminal",
            " differentiation",
            ",",
            " repression",
            " of",
            " proliferation",
            "-prom",
            "oting",
            " genes",
            " and",
            " cell",
            " cycle",
            " exit",
            ".",
            " Recently",
            ",",
            " we",
            " showed",
            " that",
            " the",
            " chrom",
            "atin"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.048,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.75,
            0.34,
            -0.0,
            0.193,
            -0.0,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.75,
            0.342,
            -0.0,
            0.193,
            -0.0,
            0.512,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.05,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.381,
            -0.0,
            0.385,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.275,
            0.273,
            -0.0,
            0.19,
            -0.0,
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.073,
            -0.0,
            -0.0,
            0.695,
            0.31,
            0.231
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "3",
            " with",
            " the",
            " last",
            " passenger",
            " train",
            " running",
            " on",
            " Saturday",
            " ",
            "19",
            " September",
            " ",
            "195",
            "3",
            ".",
            " It",
            " was",
            " on",
            " the",
            " southern",
            " section",
            " of",
            " the",
            " Bur",
            "ry",
            " Port",
            " and",
            " G",
            "wend",
            "ra",
            "eth",
            " Valley",
            " Railway",
            " with",
            " Pemb",
            "rey",
            " to",
            " the",
            " north",
            " and",
            " Bur",
            "ry",
            " Port",
            " as",
            " the",
            " term",
            "u",
            "inus",
            " of",
            " the",
            " passenger",
            " line",
            ".\n\n",
            "The",
            " line",
            " had",
            " been",
            " built",
            " on",
            " the",
            " course",
            " of",
            " an",
            " old",
            " canal",
            " with",
            " resulting",
            " tight",
            " curves",
            ",",
            " low",
            " bridge",
            " clearance",
            " and",
            " a",
            " tendency",
            " to",
            " flooding",
            ".",
            " The",
            " freight",
            " service",
            " continued",
            " for",
            " coal",
            " traffic",
            " on",
            " the",
            " C",
            "w",
            "mm",
            "aw",
            "r",
            " branch",
            " to",
            " Kid",
            "w",
            "elly",
            " until",
            " ",
            "199",
            "6",
            " by",
            " which",
            " time",
            " the",
            " last",
            " of",
            " the",
            " local",
            " col",
            "li",
            "eries",
            " had",
            " closed",
            " down",
            " and",
            " the",
            " wash",
            "ery",
            " closure",
            " followed",
            ".\n\n",
            "P",
            "emb",
            "rey"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.711,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.086,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.66,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.734,
            0.402,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.73,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.652,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.135,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.613,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.137,
            -0.0,
            -0.0,
            -0.0,
            0.116,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.131,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.559,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " but",
            " I",
            " try",
            " to",
            " keep",
            " it",
            " covered",
            ".\n\n",
            "My",
            " sweet",
            " daughter",
            " helped",
            " me",
            " get",
            " the",
            " food",
            " in",
            " order",
            ".",
            " (",
            "B",
            "less",
            " you",
            "!)",
            " We",
            " ate",
            ",",
            " ch",
            "atted",
            ",",
            " I",
            " held",
            " the",
            " baby",
            "...",
            " lots",
            ",",
            " sat",
            " outside",
            " and",
            " sw",
            "elter",
            "ed",
            ",",
            " some",
            " had",
            " after",
            " dinner",
            " coffee",
            ",",
            " some",
            " had",
            " wine",
            ".",
            " The",
            " baby",
            " had",
            " liquid",
            " gold",
            ",",
            " (",
            "bre",
            "ast",
            " milk",
            ")",
            " which",
            " he",
            " shared",
            " with",
            " me",
            ",",
            " (",
            "ref",
            "lux",
            ")",
            " several",
            " times",
            ".",
            " He",
            "'s",
            " very",
            " generous",
            " that",
            " way",
            ".",
            " I",
            " tried",
            " to",
            " convince",
            " him",
            " I",
            " didn",
            "'t",
            " need",
            " it",
            ",",
            " to",
            " keep",
            " it",
            " for",
            " himself",
            ".",
            " No",
            " way",
            ",",
            " he",
            " insisted",
            " on",
            " sharing",
            ".",
            " Shares",
            " with",
            " anyone",
            " close",
            ".",
            " He",
            " shared",
            " a",
            " couple",
            " of",
            " other",
            " things",
            ",",
            " too",
            ",",
            " I"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.73,
            -0.0,
            -0.0,
            -0.0,
            0.707,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.01,
            -0.0,
            -0.0,
            0.715,
            -0.0,
            -0.0,
            0.629,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " hold",
            " back",
            ",",
            " some",
            " of",
            " these",
            " women",
            ".",
            " The",
            " photographs",
            " are",
            " filthy",
            " but",
            " they",
            "’re",
            " not",
            " really",
            " my",
            " thing",
            " to",
            " be",
            " honest",
            ".",
            " All",
            " I",
            "’ll",
            " say",
            " is",
            " I",
            " appreciate",
            " the",
            " loyalty",
            ".",
            " So",
            " thank",
            " you",
            ".”\n\n",
            "âĢ¢",
            " Boy",
            " George",
            " has",
            " been",
            " describing",
            " his",
            " reception",
            " when",
            " he",
            " arrived",
            " in",
            " prison",
            " in",
            " ",
            "200",
            "9",
            ",",
            " ready",
            " to",
            " start",
            " a",
            " four",
            " month",
            " sentence",
            ".",
            " It",
            " seems",
            " (",
            "and",
            " this",
            " may",
            " shock",
            " some",
            " of",
            " you",
            ")",
            " that",
            " the",
            " introduction",
            " of",
            " a",
            " gay",
            " pop",
            " star",
            " to",
            " a",
            " tense",
            " environment",
            " did",
            " not",
            " bring",
            " out",
            " the",
            " best",
            " in",
            " some",
            " of",
            " his",
            " fellow",
            " inmates",
            ".",
            " (",
            "via",
            " Pink",
            " News",
            ")\n\n",
            "âĢ¢",
            " This",
            " probably",
            " won",
            "’t",
            " come",
            " as",
            " a",
            " surprise",
            ",",
            " but",
            " when",
            " Dion",
            "ne",
            " Brom",
            "field",
            ",",
            " Amy",
            " Wine",
            "house",
            "‘s",
            " god",
            "daughter"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.089,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "Track",
            ",",
            " the",
            " browser",
            " based",
            " CMS",
            " for",
            " App",
            "ell",
            "ate",
            " Courts",
            "\n\n\n\n\n\n\n\n\n\n\n",
            "č\n",
            "\t\t\tč\n\t\t\tč\n",
            "\t\t\t\tč\n",
            "\t\t\t\tč\n",
            "\t\t\t\t",
            "\t",
            "Case",
            " Search",
            "č\n",
            "\t\t\t\tč\n",
            "\t\t\tč\n",
            "\t\t\t\tč\n",
            "\t\t\t\tč\n",
            "\t\t\t\t",
            "\t",
            "Participant",
            " Search",
            "č\n",
            "\t\t\t\tč\n",
            "\t\t\tč\n\t\t\tč\n",
            "\t\t",
            "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
            "\n",
            "<|begin_of_text|>",
            "Q",
            ":\n\n",
            "unable",
            " to",
            " display",
            " array",
            " result",
            "\n\n",
            "I",
            " got",
            " the",
            " following",
            " array",
            ".",
            " now",
            " I",
            " get",
            " the",
            " single",
            " records",
            " but",
            " when",
            " is",
            " their",
            " array",
            " records",
            " then",
            " it",
            " doesn",
            "'t",
            " work",
            ".",
            " I",
            " tried",
            " with",
            " OR",
            " condition",
            " but",
            " it",
            " doesn",
            "'t",
            " work",
            ".\n",
            "$this",
            "->",
            "db",
            "->",
            "get",
            "_where",
            "('",
            "genre",
            "',",
            "array",
            "('",
            "genre",
            "_id",
            "'=>$",
            "row",
            "['",
            "genre",
            "_id",
            "']))",
            "->",
            "row",
            "()->",
            "name",
            ";\n",
            "//",
            "I",
            " get",
            " F",
            "oll",
            "wo",
            "ing",
            " Records",
            "\n",
            "Array",
            "(\n",
            "[",
            "0",
            "]",
            " =>",
            " Array",
            "\n",
            "   ",
            " (\n",
            "       ",
            " [",
            "movie",
            "_id",
            "]"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.037,
            0.141,
            -0.0,
            0.469,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.082,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.087,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.092,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.008,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " ",
            "305",
            " P",
            ".",
            "3",
            "d",
            " ",
            "420",
            ",",
            " ",
            "423",
            " (",
            "qu",
            "oting",
            " People",
            " v",
            ".\n\n",
            " ",
            " Ross",
            "man",
            ",",
            " ",
            "140",
            " P",
            ".",
            "3",
            "d",
            " ",
            "172",
            ",",
            " ",
            "174",
            " (",
            "Col",
            "o",
            ".",
            " App",
            ".",
            " ",
            "200",
            "6",
            "))",
            ".\n\n",
            "Â¶",
            " ",
            "52",
            "  ",
            " “",
            "We",
            " review",
            " sentencing",
            " decisions",
            " that",
            " are",
            " within",
            " the",
            " statutory",
            "\n\n",
            " ",
            " range",
            " for",
            " an",
            " abuse",
            " of",
            " discretion",
            ".”",
            " People",
            " v",
            ".",
            " Tor",
            "rez",
            ",",
            " ",
            "201",
            "3",
            " CO",
            "A",
            " ",
            "37",
            ",\n\n",
            " ",
            " Â¶",
            " ",
            "71",
            ",",
            " ",
            "316",
            " P",
            ".",
            "3",
            "d",
            " ",
            "25",
            ",",
            " ",
            "37",
            ".",
            " However",
            ",",
            " where",
            " the",
            " defendant",
            " contends",
            " that",
            "\n\n",
            " ",
            " a",
            " court",
            " exceeded",
            " its",
            " statutory",
            " sentencing",
            " authority",
            ",",
            " our",
            " inquiry",
            "\n\n",
            " ",
            " involves",
            " statutory",
            " interpretation",
            ".",
            " Jenkins",
            ",",
            " Â¶",
            " "
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.447,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.416,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.365,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.562,
            -0.0,
            -0.0,
            -0.0,
            0.31,
            -0.0,
            -0.0,
            -0.0,
            0.566,
            -0.0,
            -0.0,
            -0.0,
            0.299,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ")}",
            "-",
            "1",
            "\\",
            "big",
            ")^",
            "2",
            "\\n",
            "u",
            "_",
            "2",
            "(dy",
            ")<",
            "\\",
            "in",
            "fty",
            ",$",
            " then",
            " $$",
            "H",
            "^",
            "2",
            "(P",
            "_T",
            "^",
            "1",
            ",P",
            "_T",
            "^",
            "2",
            ")\\",
            "le",
            "q",
            " \\",
            "frac",
            "{T",
            "}{",
            "2",
            "}",
            "H",
            "^",
            "2",
            "(\\",
            "nu",
            "_",
            "1",
            ",\\",
            "nu",
            "_",
            "2",
            ").",
            "$$",
            "\n\n",
            "We",
            " conclude",
            " the",
            " Appendix",
            " with",
            " a",
            " technical",
            " statement",
            " about",
            " the",
            " Le",
            " Cam",
            " distance",
            " for",
            " finite",
            " variation",
            " models",
            ".\n\n",
            "\\[",
            "ch",
            "4",
            "LC",
            "\\",
            "]",
            " $$",
            "\\",
            "Delta",
            "({",
            "\\",
            "ensure",
            "math",
            " {\\",
            "math",
            "scr",
            "{",
            "P",
            "}}",
            "}_",
            "n",
            "^",
            "{\\",
            "nu",
            "_",
            "0",
            "},{",
            "\\",
            "ensure",
            "math",
            " {\\",
            "math",
            "scr",
            "{",
            "P",
            "}}",
            "}_{",
            "n",
            ",F",
            "V",
            "}",
            "^",
            "{\\",
            "nu",
            "_",
            "0",
            "})",
            "=",
            "0",
            ".$",
            "$\n\n",
            "Consider",
            " the",
            " Mark",
            "ov",
            " kernels"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.081,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.488,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "fer",
            " transfer",
            " chamber",
            " is",
            " too",
            " high",
            ".\n",
            "Furthermore",
            ",",
            " the",
            " conventional",
            " equipments",
            " cannot",
            " sufficiently",
            " reduce",
            " variations",
            " of",
            " wa",
            "fer",
            " properties",
            " such",
            " as",
            " sheet",
            " resistance",
            " from",
            " wa",
            "fer",
            " to",
            " wa",
            "fer",
            ",",
            " especially",
            " when",
            " the",
            " w",
            "af",
            "ers",
            " are",
            " processed",
            " in",
            " a",
            " high",
            " temperature",
            " sil",
            "icide",
            " C",
            "VD",
            " chamber",
            ".",
            " It",
            " is",
            " possible",
            " to",
            " reduce",
            " the",
            " variations",
            " of",
            " the",
            " sheet",
            " resistance",
            " by",
            " decreasing",
            " the",
            " pressure",
            " in",
            " the",
            " load",
            " lock",
            " chamber",
            " below",
            " the",
            " above",
            "-",
            "mentioned",
            " level",
            ".",
            " However",
            ",",
            " the",
            " pumping",
            " operation",
            " must",
            " be",
            " continued",
            " for",
            " three",
            " hours",
            " or",
            " more",
            ".",
            "<|begin_of_text|>",
            ".theme",
            "-d",
            "usk",
            ",.",
            "theme",
            "-m",
            "id",
            "night",
            " {\n",
            "   ",
            " .",
            "hl",
            "js",
            " {\n",
            "     ",
            " display",
            ":",
            " block",
            ";\n",
            "     ",
            " overflow",
            "-x",
            ":",
            " auto",
            ";\n",
            "     ",
            " background",
            ":",
            " #",
            "232",
            "323",
            ";\n",
            "     ",
            " color",
            ":",
            " #"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.465,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " live",
            " in",
            " our",
            " residence",
            " from",
            " late",
            " July",
            " through",
            " September",
            " ",
            "200",
            "4",
            "\";",
            " and",
            " (",
            "ii",
            ")",
            " a",
            " statement",
            " by",
            " St",
            "acie",
            " Brit",
            "tingham",
            " (",
            "Bur",
            "ton",
            "'s",
            " sister",
            ")",
            " that",
            " she",
            " was",
            " not",
            " interviewed",
            " before",
            " the",
            " day",
            " of",
            " trial",
            " concerning",
            " her",
            " testimony",
            ",",
            " and",
            " that",
            " the",
            " alleged",
            " victim",
            " did",
            " not",
            " live",
            " in",
            " her",
            " parent",
            "'s",
            " residence",
            " from",
            " late",
            " July",
            " through",
            " September",
            " ",
            "200",
            "4",
            " and",
            " that",
            " that",
            " issue",
            " was",
            " not",
            " raised",
            " in",
            " questioning",
            " during",
            " her",
            " testimony",
            " at",
            " trial",
            ".",
            " Also",
            " included",
            " was",
            " a",
            " statement",
            " by",
            " Eric",
            " Morris",
            " that",
            " (",
            "i",
            ")",
            " \"",
            "he",
            " was",
            " not",
            " contacted",
            ",",
            " interviewed",
            " or",
            " called",
            " as",
            " a",
            " witness",
            " concerning",
            " the",
            " fact",
            " that",
            " the",
            " alleged",
            " victim",
            " .",
            " .",
            " .",
            " did",
            " not",
            " live",
            " at",
            " Marvin",
            " Burton",
            ",",
            " Sr",
            ".",
            " and",
            " Viv",
            "ian",
            " Burton"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.432,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.381,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.024,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.045,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.022,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " and",
            " thus",
            " have",
            " a",
            " model",
            " class",
            " for",
            " the",
            " Notebook",
            ".",
            " However",
            ",",
            " something",
            " feels",
            " \"",
            "off",
            "\"",
            " as",
            " it",
            " has",
            " a",
            " very",
            " low",
            " number",
            " of",
            " members",
            ".\n",
            "The",
            " Notebook",
            " is",
            " composed",
            " of",
            " categories",
            ",",
            " which",
            " are",
            " composed",
            " of",
            " To",
            "-do",
            " lists",
            ",",
            " which",
            " are",
            " composed",
            " of",
            " Items",
            ".",
            " \n",
            "What",
            " I",
            " cannot",
            " place",
            " is",
            " whether",
            " this",
            " is",
            " a",
            " case",
            " poor",
            " analysis",
            " (",
            "e",
            ".g",
            ".",
            " there",
            " are",
            " more",
            " members",
            " and",
            " responsibilities",
            " I",
            " am",
            " just",
            " missing",
            " them",
            "..",
            ")",
            " or",
            " perhaps",
            " a",
            " code",
            " smell",
            " that",
            " the",
            " class",
            " is",
            " not",
            " needed",
            " (",
            "in",
            " that",
            " case",
            " I",
            "'m",
            " not",
            " sure",
            " what",
            " to",
            " do",
            " as",
            " I",
            " could",
            " just",
            " have",
            " a",
            " list",
            " of",
            " categories",
            " in",
            " that",
            " controller",
            ",",
            " but",
            " then",
            " I",
            " don",
            "'t",
            " have",
            " a",
            " notebook",
            " entity",
            " model",
            "led",
            " which",
            " seems"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.101,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.422,
            -0.0,
            0.233,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.19,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.017,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.168,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.022,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "2",
            ".",
            "2",
            "\n",
            "re",
            "ponse",
            " fa",
            "us",
            "se",
            " ",
            "2",
            ".",
            "3",
            "\n",
            "re",
            "ponse",
            " fa",
            "us",
            "se",
            " ",
            "3",
            ".",
            "1",
            "\n",
            "re",
            "ponse",
            " fa",
            "us",
            "se",
            " ",
            "3",
            ".",
            "2",
            "\n",
            "re",
            "ponse",
            " fa",
            "us",
            "se",
            " ",
            "3",
            ".",
            "3",
            "\n\n",
            ",",
            " categorie",
            " =",
            " \n",
            "Ch",
            "im",
            "ie",
            "\n",
            "question",
            " =",
            " \n",
            "Question",
            " ",
            "2",
            "\n",
            "bon",
            "ne",
            " re",
            "ponse",
            " =",
            " \n",
            "re",
            "ponse",
            " correct",
            "e",
            " ",
            "2",
            "\n",
            "ma",
            "uv",
            "aises",
            " re",
            "ponse",
            " =",
            " \n",
            "re",
            "ponse",
            " fa",
            "us",
            "se",
            " ",
            "1",
            ".",
            "1",
            "\n",
            "re",
            "ponse",
            " fa",
            "us",
            "se",
            " ",
            "1",
            ".",
            "2",
            "\n",
            "re",
            "ponse",
            " fa",
            "us",
            "se",
            " ",
            "1",
            ".",
            "3",
            "\n",
            "re",
            "ponse",
            " fa",
            "us",
            "se",
            " ",
            "2",
            ".",
            "1",
            "\n",
            "re",
            "ponse",
            " fa",
            "us",
            "se",
            " ",
            "2"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.111,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.112,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.414
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "4",
            " March",
            " ",
            "201",
            "2",
            "\n\n",
            "P",
            "enny",
            " Blacks",
            " challenge",
            " this",
            " week",
            " is",
            " CASE",
            "-",
            "IT",
            " and",
            " this",
            " is",
            " my",
            " take",
            " on",
            " the",
            " challenge",
            ".I",
            "'ve",
            " used",
            " my",
            " Butterfly",
            " Kitty",
            " stamp",
            " and",
            " coloured",
            " it",
            " with",
            " C",
            "opic",
            " Pens",
            ".F",
            "lower",
            " punch",
            " is",
            " one",
            " of",
            " the",
            " N",
            "ell",
            "ie",
            " Sn",
            "ellen",
            " ones",
            ",",
            " Sen",
            "it",
            "ment",
            " and",
            " punched",
            " label",
            " is",
            " from",
            " Stamp",
            "in",
            " Up",
            ".My",
            " lovely",
            " friend",
            " Val",
            " and",
            " her",
            " husband",
            " come",
            " to",
            " visit",
            " on",
            " Friday",
            " and",
            " we",
            " always",
            " have",
            " a",
            " bit",
            " of",
            " a",
            " '",
            "show",
            " and",
            " tell",
            "'",
            " of",
            " our",
            " craft",
            "y",
            " things",
            " we",
            " have",
            " done",
            " and",
            " Val",
            " very",
            " kindly",
            " let",
            " me",
            " use",
            " one",
            " of",
            " her",
            " new",
            " Go",
            " K",
            "reate",
            " dies",
            " which",
            " was",
            " a",
            " scal",
            "lop",
            " circle",
            " which",
            " just",
            " about",
            " went",
            " through",
            " my",
            " Big",
            "shot",
            ".."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.256,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.303,
            -0.0,
            -0.0,
            0.244,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.324,
            -0.0,
            -0.0,
            0.026,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " was",
            " painted",
            " across",
            " a",
            " ",
            "150",
            "Âł",
            "Î¼",
            "m",
            " aperture",
            " in",
            " a",
            " Del",
            "rin",
            " cu",
            "vette",
            " (",
            "War",
            "ner",
            " Instruments",
            ",",
            " CT",
            ",",
            " USA",
            ")",
            " which",
            " separated",
            " two",
            " chambers",
            " with",
            " a",
            " volume",
            " of",
            " ",
            "1",
            "Âłm",
            "L",
            ".",
            " The",
            " *",
            "cis",
            "*",
            " (",
            "extr",
            "acellular",
            ")",
            " chamber",
            " contained",
            " buffer",
            " B",
            " (",
            "10",
            "Âłm",
            "M",
            " Hep",
            "es",
            ",",
            " ",
            "150",
            "Âłm",
            "M",
            " K",
            "Cl",
            ")",
            " at",
            " pH",
            " ",
            "7",
            ".",
            "0",
            " whilst",
            " the",
            " *",
            "trans",
            "*",
            " buffer",
            " contained",
            " buffer",
            " B",
            " at",
            " pH",
            " ",
            "4",
            ".",
            "0",
            ".",
            " Bil",
            "ayer",
            " formation",
            " was",
            " verified",
            " with",
            " capacit",
            "ance",
            " measurements",
            ".",
            " The",
            " re",
            "const",
            "it",
            "uted",
            " ves",
            "icle",
            " suspension",
            " (",
            "5",
            "Âł",
            "Î¼",
            "L",
            ")",
            " was",
            " added",
            " to",
            " the",
            " *",
            "cis",
            "*",
            " chamber",
            " and",
            " the",
            " trans",
            "mem",
            "brane",
            " current",
            " was",
            " measured",
            " using"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.05,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " end",
            ";;\n",
            "f",
            "();\n",
            "Where",
            "();\n",
            "Where",
            "With",
            "Vars",
            "();\n",
            "quit",
            ";\n\n\n",
            "f",
            ":=",
            "function",
            "()",
            " local",
            " i",
            ";",
            " for",
            " i",
            " in",
            " ",
            "1",
            " do",
            " return",
            " ",
            "1",
            ";",
            " od",
            ";",
            " return",
            " ",
            "2",
            ";",
            " end",
            ";;\n",
            "f",
            "();\n",
            "Where",
            "();\n",
            "Where",
            "With",
            "Vars",
            "();\n",
            "quit",
            ";\n\n\n",
            "f",
            ":=",
            "function",
            "()",
            " local",
            " i",
            ";",
            " for",
            " i",
            " in",
            " true",
            " do",
            " return",
            " ",
            "1",
            ";",
            " od",
            ";",
            " return",
            " ",
            "2",
            ";",
            " end",
            ";;\n",
            "f",
            "();\n",
            "Where",
            "();\n",
            "Where",
            "With",
            "Vars",
            "();\n",
            "quit",
            ";\n\n",
            "f",
            ":=",
            "function",
            "(x",
            ")",
            " local",
            " i",
            ",j",
            ";",
            " for",
            " i",
            " in",
            " true",
            " do",
            " return",
            " ",
            "1",
            ";",
            " od",
            ";",
            " return",
            " ",
            "2",
            ";",
            " end",
            ";;\n",
            "f",
            "([",
            "1",
            ",",
            "2",
            ",",
            "3",
            "]);\n",
            "Where",
            "();\n",
            "Where",
            "With",
            "Vars",
            "();\n",
            "quit",
            ";\n\n",
            "f",
            ":=",
            "function",
            "(x"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.009,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "ated",
            " damages",
            " bears",
            " no",
            " reasonable",
            " relationship",
            " to",
            " the",
            " actual",
            " damage",
            " or",
            " is",
            " so",
            " gross",
            "ly",
            " excessive",
            " as",
            " to",
            " be",
            " entirely",
            " disproportionate",
            " to",
            " any",
            " possible",
            " loss",
            " that",
            " might",
            " have",
            " been",
            " contemplated",
            " that",
            " it",
            " shocks",
            " the",
            " conscience",
            ",",
            " the",
            " stip",
            "ulation",
            " will",
            " not",
            " be",
            " enforced",
            ".\n",
            "War",
            "ner",
            " v",
            ".",
            " R",
            "asm",
            "ussen",
            ",",
            " ",
            "704",
            " P",
            ".",
            "2",
            "d",
            " ",
            "559",
            ",",
            " ",
            "561",
            " (",
            "Ut",
            "ah",
            " ",
            "198",
            "5",
            ")",
            " (",
            "c",
            "itations",
            " omitted",
            ").\n",
            "In",
            " support",
            " of",
            " their",
            " contention",
            " that",
            " the",
            " liquid",
            "ated",
            " damages",
            " are",
            " not",
            " excessive",
            " compared",
            " to",
            " actual",
            " damages",
            ",",
            " the",
            " sellers",
            " assert",
            " that",
            " they",
            " offered",
            " evidence",
            " of",
            " actual",
            " damages",
            " in",
            " excess",
            " of",
            " $",
            "15",
            ",",
            "000",
            ".",
            " However",
            ",",
            " the",
            " trial",
            " court",
            " disagreed",
            " and",
            " found",
            " the",
            " amount",
            " of",
            " liquid",
            "ated",
            " damages",
            " excessive",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " remain",
            " a",
            " problem",
            " for",
            " women",
            " of",
            " child",
            "bearing",
            " age",
            " and",
            " children",
            " aged",
            " under",
            " ",
            "6",
            " years",
            " (",
            "11",
            ",",
            " ",
            "12",
            ").",
            " While",
            " vitamin",
            " B",
            "12",
            " deficiency",
            " is",
            " not",
            " monitored",
            " as",
            " well",
            " as",
            " other",
            " micron",
            "ut",
            "rients",
            ",",
            " an",
            " incidence",
            " greater",
            " than",
            " ",
            "10",
            " percent",
            " is",
            " reported",
            " for",
            " vulnerable",
            " groups",
            " in",
            " some",
            " countries",
            ",",
            " such",
            " as",
            " women",
            " aged",
            " ",
            "13",
            " to",
            " ",
            "49",
            " in",
            " Colombia",
            ",",
            " and",
            " children",
            " aged",
            " ",
            "6",
            " months",
            " to",
            " ",
            "5",
            " years",
            " in",
            " Guatemala",
            ".",
            " Rates",
            " of",
            " vitamin",
            " and",
            " mineral",
            " deficiencies",
            " can",
            " vary",
            " greatly",
            " between",
            " countries",
            ".",
            " For",
            " example",
            ",",
            " vitamin",
            " A",
            " deficiency",
            " in",
            " young",
            " children",
            " has",
            " been",
            " virtually",
            " erad",
            "icated",
            " in",
            " Guatemala",
            " and",
            " Nicaragua",
            ",",
            " yet",
            " is",
            " a",
            " severe",
            " public",
            " health",
            " problem",
            " in",
            " Colombia",
            ",",
            " Mexico",
            ",",
            " and",
            " Haiti",
            " (",
            "13",
            ").\n\n"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "ries",
    "Ð¾Ð³ÐµÐ½",
    "á»ĭch",
    "zim",
    "achuset"
  ],
  "bottom_logits": [
    " Romero",
    "readcr",
    "aye",
    " Gia",
    "ent"
  ],
  "act_min": -0.0,
  "act_max": 1.031
}

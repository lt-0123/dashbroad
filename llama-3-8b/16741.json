{
  "index": 16741,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            1.023,
            0.024,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " advances",
            " of",
            " Zeus",
            " and",
            " became",
            " a",
            " free",
            " floating",
            " island",
            " of",
            " the",
            " same",
            " name",
            ".",
            " When",
            " Let",
            "o",
            " got",
            " pregnant",
            ",",
            " Hera",
            " was",
            " told",
            " that",
            " Let",
            "o",
            " will",
            " give",
            " birth",
            " to",
            " a",
            " son",
            " who",
            " would",
            " become",
            " to",
            " Zeus",
            " more",
            " dear",
            "er",
            " than",
            " A",
            "res",
            ".",
            " En",
            "r",
            "aged",
            " by",
            " this",
            ",",
            " Hera",
            " watched",
            " over",
            " the",
            " heavens",
            " and",
            " sent",
            " out",
            " A",
            "res",
            " and",
            " Iris",
            " to"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.906,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.918,
            -0.0,
            -0.0,
            -0.0,
            1.016,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.887,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "Authors",
            " rely",
            " on",
            " advance",
            " fees",
            ",",
            " royalty",
            " payments",
            ",",
            " adaptation",
            " of",
            " work",
            " to",
            " a",
            " screenplay",
            ",",
            " and",
            " fees",
            " collected",
            " from",
            " giving",
            " speeches",
            ".",
            "A",
            " standard",
            " contract",
            " for",
            " an",
            " author",
            " will",
            " usually",
            " include",
            " provision",
            " for",
            " payment",
            " in",
            " the",
            " form",
            " of",
            " an",
            " advance",
            " and",
            " royalties",
            ".",
            " Advance",
            ":",
            " a",
            " lump",
            " sum",
            " paid",
            " before",
            " publication",
            ".",
            " An",
            " advance",
            " must",
            " be",
            " earned",
            " out",
            " before",
            " royalties",
            " are"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.996,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " advance",
            ".",
            " He",
            " has",
            " ab",
            "d",
            "icated",
            " his",
            " intellectual",
            " liberty",
            ".\"",
            "In",
            " the",
            " ",
            "192",
            "0",
            "s",
            ",",
            " G",
            "ide",
            " became",
            " an",
            " inspiration",
            " for",
            " such",
            " writers",
            " as",
            " Albert",
            " Cam",
            "us",
            " and",
            " Jean",
            "-P",
            "aul",
            " S",
            "art",
            "re",
            ".",
            " In",
            " ",
            "192",
            "3",
            ",",
            " he",
            " published",
            " a",
            " book",
            " on",
            " F",
            "y",
            "odor",
            " Dost",
            "oy",
            "ev",
            "sky",
            ".",
            " But",
            ",",
            " when",
            " he",
            " defended",
            " homosexuality",
            " in"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.977,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 53,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " place",
            " the",
            " astronauts",
            " back",
            " into",
            " lunar",
            " orbit",
            ".",
            " This",
            " design",
            " meant",
            " the",
            " spacecraft",
            " could",
            " be",
            " launched",
            " by",
            " a",
            " single",
            " Saturn",
            " V",
            " rocket",
            " that",
            " was",
            " then",
            " under",
            " development",
            ".",
            "Techn",
            "ologies",
            " and",
            " techniques",
            " required",
            " for",
            " Apollo",
            " were",
            " developed",
            " by",
            " Project",
            " Gemini",
            ".",
            " The",
            " Apollo",
            " project",
            " was",
            " enabled",
            " by",
            " NASA",
            "'s",
            " adoption",
            " of",
            " new",
            " advances",
            " in",
            " semiconductor",
            " electronic",
            " technology",
            ",",
            " including",
            " metal",
            "–",
            "oxide"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.969,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " name",
            " became",
            " associated",
            " with",
            " advances",
            " in",
            " automotive",
            " technology",
            ".",
            "In",
            " ",
            "198",
            "5",
            ",",
            " with",
            " the",
            " Auto",
            " Union",
            " and",
            " NS",
            "U",
            " brands",
            " effectively",
            " dead",
            ",",
            " the",
            " company",
            "'s",
            " official",
            " name",
            " was",
            " now",
            " shortened",
            " to",
            " simply",
            " Audi",
            " AG",
            ".",
            " At",
            " the",
            " same",
            " time",
            " the",
            " company",
            "'s",
            " headquarters",
            " moved",
            " back",
            " to",
            " Ing",
            "ol",
            "stadt",
            " and",
            " two",
            " new",
            " wholly",
            " owned",
            " subsidiaries",
            ";",
            " Auto",
            " Union",
            " GmbH",
            " and"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.965,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 7,
          "is_repeated_datapoint": false,
          "tokens": [
            " states",
            ".",
            "Some",
            " of",
            " the",
            " most",
            " striking",
            " advances",
            " in",
            " early",
            " anatomy",
            " and",
            " physiology",
            " took",
            " place",
            " in",
            " H",
            "ellen",
            "istic",
            " Alexandria",
            ".",
            " Two",
            " of",
            " the",
            " most",
            " famous",
            " anatom",
            "ists",
            " and",
            " phys",
            "i",
            "ologists",
            " of",
            " the",
            " third",
            " century",
            " were",
            " Her",
            "ophil",
            "us",
            " and",
            " Er",
            "as",
            "istr",
            "atus",
            ".",
            " These",
            " two",
            " physicians",
            " helped",
            " pioneer",
            " human",
            " dis",
            "section",
            " for",
            " medical",
            " research",
            ",",
            " using",
            " the",
            " cad",
            "avers",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.965,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            " not",
            " until",
            " the",
            " age",
            " of",
            " Alexandria",
            " under",
            " the",
            " P",
            "to",
            "lem",
            "ies",
            " that",
            " advances",
            " in",
            " biology",
            " can",
            " be",
            " again",
            " found",
            ".",
            "The",
            " first",
            " medical",
            " teacher",
            " at",
            " Alexandria",
            ",",
            " Her",
            "ophil",
            "us",
            " of",
            " Ch",
            "al",
            "ced",
            "on",
            ",",
            " corrected",
            " Aristotle",
            ",",
            " placing",
            " intelligence",
            " in",
            " the",
            " brain",
            ",",
            " and",
            " connected",
            " the",
            " nervous",
            " system",
            " to",
            " motion",
            " and",
            " sensation",
            ".",
            " Her",
            "ophil",
            "us",
            " also",
            " distinguished",
            " between",
            " veins"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.961,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " became",
            " a",
            " key",
            " base",
            " for",
            " further",
            " advances",
            " south",
            " along",
            " the",
            " Mississippi",
            " River",
            ".",
            " Only",
            " the",
            " fortress",
            " city",
            " of",
            " V",
            "icks",
            "burg",
            ",",
            " Mississippi",
            ",",
            " prevented",
            " Union",
            " control",
            " of",
            " the",
            " entire",
            " river",
            ".",
            "B",
            "rag",
            "g",
            "'s",
            " second",
            " invasion",
            " of",
            " Kentucky",
            " in",
            " the",
            " Confederate",
            " Heart",
            "land",
            " Offensive",
            " included",
            " initial",
            " successes",
            " such",
            " as",
            " Kirby",
            " Smith",
            "'s",
            " triumph",
            " at",
            " the",
            " Battle",
            " of",
            " Richmond",
            " and",
            " the",
            " capture"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.957,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            " gave",
            " rise",
            " to",
            " a",
            " new",
            " field",
            " of",
            " molecular",
            " anatomy",
            ".",
            "Equ",
            "ally",
            " important",
            " advances",
            " have",
            " occurred",
            " in",
            " ",
            " non",
            "-in",
            "vasive",
            " techniques",
            " for",
            " examining",
            " the",
            " interior",
            " structures",
            " of",
            " the",
            " body",
            ".",
            " X",
            "-rays",
            " can",
            " be",
            " passed",
            " through",
            " the",
            " body",
            " and",
            " used",
            " in",
            " medical",
            " radi",
            "ography",
            " and",
            " fluor",
            "os",
            "copy",
            " to",
            " differentiate",
            " interior",
            " structures",
            " that",
            " have",
            " varying",
            " degrees",
            " of",
            " op",
            "aqu",
            "eness",
            ".",
            " Magnetic"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.957,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            " gave",
            " rise",
            " to",
            " a",
            " new",
            " field",
            " of",
            " molecular",
            " anatomy",
            ".",
            "Equ",
            "ally",
            " important",
            " advances",
            " have",
            " occurred",
            " in",
            " ",
            " non",
            "-in",
            "vasive",
            " techniques",
            " for",
            " examining",
            " the",
            " interior",
            " structures",
            " of",
            " the",
            " body",
            ".",
            " X",
            "-rays",
            " can",
            " be",
            " passed",
            " through",
            " the",
            " body",
            " and",
            " used",
            " in",
            " medical",
            " radi",
            "ography",
            " and",
            " fluor",
            "os",
            "copy",
            " to",
            " differentiate",
            " interior",
            " structures",
            " that",
            " have",
            " varying",
            " degrees",
            " of",
            " op",
            "aqu",
            "eness",
            ".",
            " Magnetic"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.949,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " post",
            "hum",
            "ously",
            " as",
            " a",
            " charter",
            " member",
            " of",
            " the",
            " World",
            " Academy",
            " of",
            " Art",
            " and",
            " Science",
            " (",
            "WA",
            "AS",
            "),",
            " an",
            " organization",
            " founded",
            " by",
            " distinguished",
            " scientists",
            " and",
            " intellectuals",
            " who",
            " committed",
            " themselves",
            " to",
            " the",
            " responsible",
            " and",
            " ethical",
            " advances",
            " of",
            " science",
            ",",
            " particularly",
            " in",
            " light",
            " of",
            " the",
            " development",
            " of",
            " nuclear",
            " weapons",
            ".",
            "US",
            " citizenship",
            " ",
            "E",
            "instein",
            " became",
            " an",
            " American",
            " citizen",
            " in",
            " ",
            "194",
            "0",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.949,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " early",
            " al",
            "chemical",
            " texts",
            ".",
            "The",
            " first",
            " al",
            "chemist",
            " whose",
            " name",
            " we",
            " know",
            " was",
            " Mary",
            " the",
            " Jew",
            "ess",
            " ().",
            " Early",
            " sources",
            " claim",
            " that",
            " Mary",
            " (",
            "or",
            " Maria",
            ")",
            " devised",
            " a",
            " number",
            " of",
            " improvements",
            " to",
            " al",
            "chemical",
            " equipment",
            " and",
            " tools",
            " as",
            " well",
            " as",
            " novel",
            " techniques",
            " in",
            " chemistry",
            ".",
            " Her",
            " best",
            " known",
            " advances",
            " were",
            " in",
            " heating",
            " and",
            " dist",
            "illation",
            " processes",
            ".",
            " The",
            " laboratory",
            " water",
            "-b"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.945,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.077
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            "ant",
            " with",
            " reality",
            ".",
            " In",
            " fact",
            ",",
            " just",
            " hours",
            " after",
            " disgr",
            "aced",
            " Volkswagen",
            " CEO",
            " Martin",
            " Winter",
            "k",
            "orn",
            " admitted",
            " to",
            " cheating",
            " on",
            " emissions",
            " data",
            ",",
            " an",
            " advertisement",
            " during",
            " the",
            " ",
            "201",
            "5",
            " Prim",
            "etime",
            " Emmy",
            " Awards",
            " promoted",
            " Audi",
            "'s",
            " latest",
            " advances",
            " in",
            " low",
            " emissions",
            " technology",
            " with",
            " Ker",
            "mit",
            " the",
            " Frog",
            " stating",
            ",",
            " \"",
            "It",
            "'s",
            " not",
            " that",
            " easy",
            " being",
            " green",
            ".\"",
            "V",
            "ors"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.945,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " industrial",
            "ized",
            " countries",
            " to",
            " countries",
            " where",
            " production",
            " was",
            " cheaper",
            ".",
            " Production",
            " costs",
            " in",
            " the",
            " late",
            " ",
            "20",
            "th",
            " century",
            " changed",
            " because",
            " of",
            " advances",
            " in",
            " technology",
            ",",
            " lower",
            " energy",
            " prices",
            ",",
            " exchange",
            " rates",
            " of",
            " the",
            " United",
            " States",
            " dollar",
            ",",
            " and",
            " alum",
            "ina",
            " prices",
            ".",
            " The",
            " BR",
            "IC",
            " countries",
            "'",
            " combined",
            " share",
            " in",
            " primary",
            " production",
            " and",
            " primary",
            " consumption",
            " grew",
            " substantially",
            " in",
            " the",
            " first",
            " decade"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.941,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " film",
            " and",
            " television",
            ",",
            " but",
            " advances",
            " in",
            " robot",
            " technology",
            " now",
            " allow",
            " the",
            " design",
            " of",
            " functional",
            " and",
            " realistic",
            " humanoid",
            " robots",
            ".",
            "Ter",
            "min",
            "ology",
            "The",
            " Oxford",
            " English",
            " Dictionary",
            " traces",
            " the",
            " earliest",
            " use",
            " (",
            "as",
            " \"",
            "Android",
            "es",
            "\")",
            " to",
            " Eph",
            "ra",
            "im",
            " Chambers",
            "'",
            " ",
            "172",
            "8",
            " Cyc",
            "lo",
            "pa",
            "edia",
            ",",
            " in",
            " reference",
            " to",
            " an",
            " autom",
            "aton",
            " that",
            " St",
            ".",
            " Albert",
            "us"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.941,
            -0.0,
            -0.0
          ],
          "train_token_ind": 59,
          "is_repeated_datapoint": false,
          "tokens": [
            " bases",
            " rose",
            " from",
            " the",
            " earth",
            " and",
            " held",
            " up",
            " the",
            " rock",
            ".",
            " When",
            " Apollo",
            " and",
            " Artem",
            "is",
            " were",
            " born",
            ",",
            " their",
            " bodies",
            " sh",
            "one",
            " radi",
            "antly",
            " and",
            " a",
            " chant",
            " was",
            " sung",
            " by",
            " E",
            "ile",
            "ith",
            "y",
            "ia",
            " and",
            " L",
            "ach",
            "esis",
            ",",
            " one",
            " of",
            " the",
            " ",
            " three",
            " Mo",
            "ir",
            "ai",
            ".",
            "P",
            "seudo",
            "-H",
            "y",
            "gin",
            "us",
            "Sc",
            "orning",
            " the",
            " advances",
            " of",
            " Zeus"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.941,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.244,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            " Black",
            " Sea",
            ".",
            " However",
            ",",
            " it",
            " is",
            " clear",
            " that",
            " the",
            " Anat",
            "olian",
            " languages",
            ",",
            " the",
            " earliest",
            " att",
            "ested",
            " branch",
            " of",
            " Indo",
            "-European",
            ",",
            " have",
            " been",
            " spoken",
            " in",
            " Anat",
            "olia",
            " since",
            " at",
            " least",
            " the",
            " ",
            "19",
            "th",
            " century",
            " BCE",
            ".",
            "Recent",
            " advances",
            " in",
            " archae",
            "ogen",
            "etics",
            " have",
            " confirmed",
            " that",
            " the",
            " spread",
            " of",
            " agriculture",
            " from",
            " the",
            " Middle",
            " East",
            " to",
            " Europe",
            " was",
            " strongly",
            " correlated",
            " with",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.941,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " a",
            " plant",
            " to",
            " develop",
            " crops",
            " with",
            " more",
            " beneficial",
            " characteristics",
            " for",
            " humans",
            ",",
            " for",
            " example",
            ",",
            " larger",
            " fruits",
            " or",
            " seeds",
            ",",
            " drought",
            "-t",
            "olerance",
            ",",
            " or",
            " resistance",
            " to",
            " pests",
            ".",
            " Significant",
            " advances",
            " in",
            " plant",
            " breeding",
            " ensued",
            " after",
            " the",
            " work",
            " of",
            " genetic",
            "ist",
            " Greg",
            "or",
            " Mend",
            "el",
            ".",
            " His",
            " work",
            " on",
            " dominant",
            " and",
            " recess",
            "ive",
            " alleles",
            ",",
            " although",
            " initially",
            " largely",
            " ignored",
            " for",
            " almost",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.941,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.836,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 8,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "186",
            "2",
            " Union",
            " strategy",
            " called",
            " for",
            " simultaneous",
            " advances",
            " along",
            " four",
            " axes",
            ":",
            " McC",
            "le",
            "ll",
            "an",
            " would",
            " lead",
            " the",
            " main",
            " thrust",
            " in",
            " Virginia",
            " towards",
            " Richmond",
            ".",
            " Ohio",
            " forces",
            " would",
            " advance",
            " through",
            " Kentucky",
            " into",
            " Tennessee",
            ".",
            " The",
            " Missouri",
            " Department",
            " would",
            " drive",
            " south",
            " along",
            " the",
            " Mississippi",
            " River",
            ".",
            " The",
            " western",
            "most",
            " attack",
            " would",
            " originate",
            " from",
            " Kansas",
            ".",
            " Army",
            " of",
            " Northern",
            " Virginia",
            "The",
            " primary"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.938,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 29,
          "is_repeated_datapoint": false,
          "tokens": [
            " \"",
            "Jim",
            " Os",
            "born",
            ",",
            " executive",
            " director",
            " of",
            " the",
            " Quality",
            " of",
            " Life",
            " Technology",
            " Center",
            ",",
            " told",
            " a",
            " ",
            "200",
            "7",
            " gathering",
            " of",
            " long",
            "-term",
            " care",
            " providers",
            " that",
            " if",
            " such",
            " advances",
            " could",
            " delay",
            " all",
            " nursing",
            " home",
            " admissions",
            " by",
            " a",
            " month",
            ",",
            " societal",
            " savings",
            " could",
            " be",
            " $",
            "1",
            " billion",
            " monthly",
            "\".",
            " Short",
            "age",
            " of",
            " both",
            " paid",
            " personal",
            " assistants",
            " and",
            " available",
            " family",
            " members",
            " makes",
            " artificial",
            " assistance"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.938,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            "t",
            "reat",
            "ise",
            " on",
            " the",
            " heart",
            "\",",
            " with",
            " vessels",
            " carrying",
            " all",
            " the",
            " body",
            "'s",
            " fluids",
            " to",
            " or",
            " from",
            " every",
            " member",
            " of",
            " the",
            " body",
            ".",
            "Anc",
            "ient",
            " Greek",
            " anatomy",
            " and",
            " physiology",
            " underwent",
            " great",
            " changes",
            " and",
            " advances",
            " throughout",
            " the",
            " early",
            " medieval",
            " world",
            ".",
            " ",
            " Over",
            " time",
            ",",
            " this",
            " medical",
            " practice",
            " expanded",
            " by",
            " a",
            " continually",
            " developing",
            " understanding",
            " of",
            " the",
            " functions",
            " of",
            " organs",
            " and",
            " structures",
            " in",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.938,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            " essential",
            " to",
            " the",
            " survival",
            " and",
            " growth",
            " of",
            " ancient",
            " Egyptian",
            " civilization",
            ".",
            "Old",
            " Kingdom",
            " (",
            "268",
            "6",
            "–",
            "218",
            "1",
            " BC",
            ")",
            "Major",
            " advances",
            " in",
            " architecture",
            ",",
            " art",
            ",",
            " and",
            " technology",
            " were",
            " made",
            " during",
            " the",
            " Old",
            " Kingdom",
            ",",
            " fueled",
            " by",
            " the",
            " increased",
            " agricultural",
            " productivity",
            " and",
            " resulting",
            " population",
            ",",
            " made",
            " possible",
            " by",
            " a",
            " well",
            "-develop",
            "ed",
            " central",
            " administration",
            ".",
            " Some",
            " of",
            " ancient",
            " Egypt",
            "'s",
            " crow"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.938,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " Zeus",
            ",",
            " pointing",
            " out",
            " that",
            " Th",
            "et",
            "is",
            " was",
            " so",
            " loyal",
            " to",
            " Hera",
            "'s",
            " marriage",
            " bond",
            " that",
            " she",
            " cool",
            "ly",
            " rejected",
            " the",
            " father",
            " of",
            " gods",
            ".",
            " Th",
            "et",
            "is",
            ",",
            " although",
            " a",
            " daughter",
            " of",
            " the",
            " sea",
            "-g",
            "od",
            " N",
            "ere",
            "us",
            ",",
            " was",
            " also",
            " brought",
            " up",
            " by",
            " Hera",
            ",",
            " further",
            " explaining",
            " her",
            " resistance",
            " to",
            " the",
            " advances",
            " of",
            " Zeus",
            ".",
            " Zeus",
            " was",
            " furious"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.938,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 44,
          "is_repeated_datapoint": false,
          "tokens": [
            " on",
            " various",
            " operating",
            " systems",
            ".",
            " Te",
            "let",
            "ype",
            " machines",
            " required",
            " that",
            " a",
            " line",
            " of",
            " text",
            " be",
            " terminated",
            " with",
            " both",
            " \"",
            "car",
            "riage",
            " return",
            "\"",
            " (",
            "which",
            " moves",
            " the",
            " prin",
            "thead",
            " to",
            " the",
            " beginning",
            " of",
            " the",
            " line",
            ")",
            " and",
            " \"",
            "line",
            " feed",
            "\"",
            " (",
            "which",
            " advances",
            " the",
            " paper",
            " one",
            " line",
            " without",
            " moving",
            " the",
            " prin",
            "thead",
            ").",
            " The",
            " name",
            " \"",
            "car",
            "riage",
            " return",
            "\"",
            " comes"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.938,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " is",
            " east",
            " of",
            " the",
            " Mississippi",
            " River",
            ".",
            " The",
            " Northwest",
            " Ord",
            "inance",
            " of",
            " ",
            "178",
            "7",
            " also",
            " made",
            " great",
            " advances",
            " in",
            " the",
            " abolition",
            " of",
            " slavery",
            ".",
            " New",
            " states",
            " admitted",
            " to",
            " the",
            " union",
            " in",
            " this",
            " territory",
            " would",
            " never",
            " be",
            " slave",
            " states",
            ".",
            "No",
            " new",
            " states",
            " were",
            " admitted",
            " to",
            " the",
            " Union",
            " under",
            " the",
            " Articles",
            " of",
            " Confeder",
            "ation",
            ".",
            " The",
            " Articles",
            " provided",
            " for",
            " a",
            " blanket",
            " acceptance",
            " of"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.938,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " Zeus",
            ",",
            " pointing",
            " out",
            " that",
            " Th",
            "et",
            "is",
            " was",
            " so",
            " loyal",
            " to",
            " Hera",
            "'s",
            " marriage",
            " bond",
            " that",
            " she",
            " cool",
            "ly",
            " rejected",
            " the",
            " father",
            " of",
            " gods",
            ".",
            " Th",
            "et",
            "is",
            ",",
            " although",
            " a",
            " daughter",
            " of",
            " the",
            " sea",
            "-g",
            "od",
            " N",
            "ere",
            "us",
            ",",
            " was",
            " also",
            " brought",
            " up",
            " by",
            " Hera",
            ",",
            " further",
            " explaining",
            " her",
            " resistance",
            " to",
            " the",
            " advances",
            " of",
            " Zeus",
            ".",
            " Zeus",
            " was",
            " furious"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.93,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.007,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 21,
          "is_repeated_datapoint": false,
          "tokens": [
            "-controlled",
            " telesc",
            "opes",
            "With",
            " the",
            " development",
            " of",
            " fast",
            " Internet",
            " in",
            " the",
            " last",
            " part",
            " of",
            " the",
            " ",
            "20",
            "th",
            " century",
            " along",
            " with",
            " advances",
            " in",
            " computer",
            " controlled",
            " telescope",
            " mounts",
            " and",
            " CCD",
            " cameras",
            " \"",
            "Remote",
            " Telescope",
            "\"",
            " astronomy",
            " is",
            " now",
            " a",
            " viable",
            " means",
            " for",
            " amateur",
            " astronomers",
            " not",
            " aligned",
            " with",
            " major",
            " telescope",
            " facilities",
            " to",
            " part",
            "ake",
            " in",
            " research",
            " and",
            " deep",
            " sky",
            " imaging",
            ".",
            " This",
            " enables",
            " anyone"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.926,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            " women",
            " have",
            " abortions",
            " are",
            " diverse",
            " and",
            " vary",
            " across",
            " the",
            " world",
            ".",
            " Reasons",
            " include",
            " maternal",
            " health",
            ",",
            " an",
            " inability",
            " to",
            " afford",
            " a",
            " child",
            ",",
            " domestic",
            " violence",
            ",",
            " lack",
            " of",
            " support",
            ",",
            " feeling",
            " they",
            " are",
            " too",
            " young",
            ",",
            " wishing",
            " to",
            " complete",
            " education",
            " or",
            " advance",
            " a",
            " career",
            ",",
            " and",
            " not",
            " being",
            " able",
            " or",
            " willing",
            " to",
            " raise",
            " a",
            " child",
            " conceived",
            " as",
            " a",
            " result",
            " of",
            " rape",
            " or",
            " incest"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.926
          ],
          "train_token_ind": 62,
          "is_repeated_datapoint": false,
          "tokens": [
            " father",
            ".",
            " For",
            " this",
            " reason",
            ",",
            " the",
            " two",
            " gods",
            " withdrew",
            " their",
            " pursuit",
            ",",
            " and",
            " had",
            " her",
            " wed",
            " Pe",
            "le",
            "us",
            ".",
            "There",
            " is",
            " a",
            " tale",
            " which",
            " offers",
            " an",
            " alternative",
            " version",
            " of",
            " these",
            " events",
            ":",
            " In",
            " the",
            " Arg",
            "onaut",
            "ica",
            " (",
            "4",
            ".",
            "760",
            ")",
            " Zeus",
            "'",
            " sister",
            " and",
            " wife",
            " Hera",
            " all",
            "udes",
            " to",
            " Th",
            "et",
            "is",
            "'",
            " ch",
            "aste",
            " resistance",
            " to",
            " the",
            " advances"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.926,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 15,
          "is_repeated_datapoint": false,
          "tokens": [
            " part",
            "ing",
            " when",
            " the",
            " char",
            "i",
            "ots",
            " bore",
            " down",
            " and",
            " then",
            " reform",
            "ing",
            ".",
            " The",
            " advance",
            " was",
            " successful",
            " and",
            " broke",
            " D",
            "arius",
            "'s",
            " center",
            ",",
            " causing",
            " the",
            " latter",
            " to",
            " flee",
            " once",
            " again",
            ".",
            "When",
            " faced",
            " with",
            " opponents",
            " who",
            " used",
            " unfamiliar",
            " fighting",
            " techniques",
            ",",
            " such",
            " as",
            " in",
            " Central",
            " Asia",
            " and",
            " India",
            ",",
            " Alexander",
            " adapted",
            " his",
            " forces",
            " to",
            " his",
            " opponents",
            "'",
            " style",
            ".",
            " Thus",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.926,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " the",
            " associated",
            " stabil",
            "izing",
            " surface",
            ".",
            " Their",
            " development",
            " was",
            " a",
            " critical",
            " advance",
            " in",
            " the",
            " history",
            " of",
            " aircraft",
            ",",
            " which",
            " had",
            " until",
            " that",
            " point",
            " been",
            " uncont",
            "rollable",
            " in",
            " flight",
            ".",
            "A",
            "eros",
            "pace",
            " engineers",
            " develop",
            " control",
            " systems",
            " for",
            " a",
            " vehicle",
            "'s",
            " orientation",
            " (",
            "att",
            "itude",
            ")",
            " about",
            " its",
            " center",
            " of",
            " mass",
            ".",
            " The",
            " control",
            " systems",
            " include",
            " actu",
            "ators",
            ",",
            " which",
            " exert",
            " forces",
            " in"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.926,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 15,
          "is_repeated_datapoint": false,
          "tokens": [
            " part",
            "ing",
            " when",
            " the",
            " char",
            "i",
            "ots",
            " bore",
            " down",
            " and",
            " then",
            " reform",
            "ing",
            ".",
            " The",
            " advance",
            " was",
            " successful",
            " and",
            " broke",
            " D",
            "arius",
            "'s",
            " center",
            ",",
            " causing",
            " the",
            " latter",
            " to",
            " flee",
            " once",
            " again",
            ".",
            "When",
            " faced",
            " with",
            " opponents",
            " who",
            " used",
            " unfamiliar",
            " fighting",
            " techniques",
            ",",
            " such",
            " as",
            " in",
            " Central",
            " Asia",
            " and",
            " India",
            ",",
            " Alexander",
            " adapted",
            " his",
            " forces",
            " to",
            " his",
            " opponents",
            "'",
            " style",
            ".",
            " Thus",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.01,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.922,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            " success",
            " of",
            " Egypt",
            " as",
            " it",
            " would",
            " allow",
            " for",
            " more",
            " advances",
            " in",
            " science",
            " and",
            " technology",
            ".",
            " This",
            " change",
            " in",
            " alphabet",
            ",",
            " he",
            " believed",
            ",",
            " would",
            " solve",
            " the",
            " problems",
            " inherent",
            " with",
            " Arabic",
            ",",
            " such",
            " as",
            " a",
            " lack",
            " of",
            " written",
            " vowels",
            " and",
            " difficulties",
            " writing",
            " foreign",
            " words",
            " that",
            " made",
            " it",
            " difficult",
            " for",
            " non",
            "-native",
            " speakers",
            " to",
            " learn",
            ".",
            " Ahmad",
            " L",
            "utf",
            "i",
            " As",
            " Say",
            "id",
            " and",
            " Muhammad"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.867,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            " underground",
            " factories",
            ".",
            " These",
            " factories",
            " were",
            " death",
            "-tr",
            "aps",
            ";",
            " discipline",
            " was",
            " brutal",
            ",",
            " with",
            " regular",
            " executions",
            ".",
            " There",
            " were",
            " so",
            " many",
            " corpses",
            " at",
            " the",
            " D",
            "ora",
            " underground",
            " factory",
            ",",
            " for",
            " example",
            ",",
            " that",
            " the",
            " crem",
            "atorium",
            " was",
            " overwhelmed",
            ".",
            " Spe",
            "er",
            "'s",
            " own",
            " staff",
            " described",
            " the",
            " conditions",
            " there",
            " as",
            " \"",
            "hell",
            "\".",
            "The",
            " largest",
            " technological",
            " advance",
            " under",
            " Spe",
            "er",
            "'s",
            " command",
            " came"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.828,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 7,
          "is_repeated_datapoint": false,
          "tokens": [
            " did",
            " not",
            " improve",
            " the",
            " harvest",
            ".",
            " To",
            " advance",
            " on",
            " Rome",
            " would",
            " have",
            " required",
            " supplies",
            " which",
            " were",
            " not",
            " available",
            " in",
            " Italy",
            ",",
            " and",
            " taking",
            " the",
            " city",
            " would",
            " not",
            " have",
            " improved",
            " At",
            "til",
            "a",
            "'s",
            " supply",
            " situation",
            ".",
            " Therefore",
            ",",
            " it",
            " was",
            " more",
            " profitable",
            " for",
            " At",
            "til",
            "a",
            " to",
            " conclude",
            " peace",
            " and",
            " retreat",
            " to",
            " his",
            " homeland",
            ".",
            "Furthermore",
            ",",
            " an",
            " East",
            " Roman",
            " force",
            " had",
            " crossed"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.699,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.805,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            " focuses",
            " on",
            " environment",
            ".",
            " In",
            " the",
            " conventional",
            " sector",
            ",",
            " mobility",
            " represent",
            " ",
            "54",
            "%",
            " of",
            " all",
            " patents",
            " fill",
            "ings",
            ",",
            " and",
            " is",
            " an",
            " indication",
            " of",
            " increased",
            " interest",
            " in",
            " advanced",
            " mobility",
            " assist",
            "ive",
            " product",
            " categories",
            ",",
            " such",
            " as",
            " advanced",
            " prost",
            "hetics",
            ",",
            " walking",
            " aids",
            ",",
            " wheel",
            "ch",
            "airs",
            ",",
            " and",
            " ex",
            "os",
            "keleton",
            "s",
            ".",
            "In",
            " the",
            " past",
            ",",
            " the",
            " top",
            " patent",
            " offices",
            " for"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.762,
            0.044,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            " HÃ¶",
            "yÃ¼k",
            ",",
            " and",
            " Y",
            "um",
            "uk",
            "te",
            "pe",
            ".",
            " Ãĩ",
            "atal",
            "h",
            "Ã¶",
            "yÃ¼k",
            " (",
            "7",
            ".",
            "000",
            " BCE",
            ")",
            " is",
            " considered",
            " the",
            " most",
            " advanced",
            " of",
            " these",
            ".",
            " Ne",
            "olithic",
            " Anat",
            "olia",
            " has",
            " been",
            " proposed",
            " as",
            " the",
            " homeland",
            " of",
            " the",
            " Indo",
            "-European",
            " language",
            " family",
            ",",
            " although",
            " lingu",
            "ists",
            " tend",
            " to",
            " favour",
            " a",
            " later",
            " origin",
            " in",
            " the",
            " ste",
            "pp",
            "es",
            " north",
            " of",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.656,
            -0.0,
            -0.0,
            -0.0,
            0.68,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " Latin",
            " American",
            " trade",
            " union",
            " conf",
            "ederation",
            " Atlas",
            " languages",
            ",",
            " Ber",
            "ber",
            " languages",
            " spoken",
            " in",
            " the",
            " Atlas",
            " Mountains",
            " of",
            " Morocco",
            " AT",
            "LAS",
            " Network",
            ",",
            " a",
            " network",
            " of",
            " European",
            " special",
            " police",
            " units",
            " Atlas",
            " Uran",
            "ium",
            " Mill",
            " Atlas",
            " Corporation",
            ",",
            " a",
            " private",
            " military",
            " company",
            " by",
            " Call",
            " of",
            " Duty",
            ":",
            " Advanced",
            " Warfare",
            "See",
            " also",
            " Advanced",
            " Technology",
            " Large",
            "-A",
            "p",
            "erture",
            " Space"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.644,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 58,
          "is_repeated_datapoint": false,
          "tokens": [
            " about",
            " their",
            " lives",
            " and",
            " experiences",
            " as",
            " children",
            " of",
            " immigrants",
            ",",
            " exposing",
            " the",
            " marginal",
            "ization",
            " experienced",
            " by",
            " most",
            " ethnic",
            " minorities",
            " in",
            " Germany",
            ",",
            " and",
            " the",
            " feelings",
            " of",
            " frustration",
            " and",
            " resentment",
            " that",
            " being",
            " denied",
            " a",
            " German",
            " identity",
            " can",
            " cause",
            ".",
            " The",
            " song",
            " \"",
            "F",
            "rem",
            "d",
            " im",
            " eigenen",
            " Land",
            "\"",
            " (",
            "Foreign",
            " in",
            " your",
            " own",
            " nation",
            ")",
            " was",
            " released",
            " by",
            " Advanced",
            " Chemistry",
            " in",
            " November",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.644,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            " less",
            " techn",
            "ologically",
            " sophisticated",
            " than",
            ",",
            " F",
            "1",
            " cars",
            ",",
            " with",
            " more",
            " restrictions",
            " on",
            " technology",
            " aimed",
            " at",
            " controlling",
            " costs",
            ".",
            " While",
            " these",
            " cars",
            " are",
            " not",
            " as",
            " techn",
            "ologically",
            " advanced",
            ",",
            " they",
            " are",
            " faster",
            ",",
            " mainly",
            " because",
            " they",
            " compete",
            " on",
            " oval",
            " race",
            " tracks",
            ",",
            " being",
            " able",
            " to",
            " average",
            " a",
            " lap",
            " at",
            " ",
            "388",
            "Âł",
            "km",
            "/h",
            " (",
            "241",
            "Âłmph",
            ").",
            " The",
            " series",
            "'",
            " biggest"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.389,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.555,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 59,
          "is_repeated_datapoint": false,
          "tokens": [
            "-p",
            "icked",
            " director",
            " of",
            " submarine",
            " construction",
            " Otto",
            " Mer",
            "ker",
            " believed",
            " that",
            " the",
            " ship",
            "building",
            " industry",
            " was",
            " being",
            " held",
            " back",
            " by",
            " outdated",
            " methods",
            ",",
            " and",
            " revolutionary",
            " new",
            " approaches",
            " imposed",
            " by",
            " outsiders",
            " would",
            " dramatically",
            " improve",
            " output",
            ".",
            " This",
            " belief",
            " proved",
            " incorrect",
            ",",
            " and",
            " Spe",
            "er",
            " and",
            " Mer",
            "ker",
            "'s",
            " attempt",
            " to",
            " build",
            " the",
            " K",
            "rieg",
            "sm",
            "ar",
            "ines",
            " new",
            " generation",
            " of",
            " submarines",
            ",",
            " the",
            " Type"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.535,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.13,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " a",
            " military",
            " objective",
            ",",
            " Union",
            " armies",
            " advancing",
            " south",
            " \"",
            "enable",
            "[d",
            "]",
            " thousands",
            " of",
            " slaves",
            " to",
            " escape",
            " to",
            " freedom",
            "\".",
            " The",
            " Em",
            "anc",
            "ipation",
            " Pro",
            "clamation",
            " having",
            " stated",
            " that",
            " freed",
            "men",
            " would",
            " be",
            " \"",
            "received",
            " into",
            " the",
            " armed",
            " service",
            " of",
            " the",
            " United",
            " States",
            ",\"",
            " en",
            "listing",
            " these",
            " freed",
            "men",
            " became",
            " official",
            " policy",
            ".",
            " By",
            " the",
            " spring",
            " of",
            " ",
            "186",
            "3",
            ",",
            " Lincoln",
            " was"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.535,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 17,
          "is_repeated_datapoint": false,
          "tokens": [
            "ure",
            "gard",
            " assumed",
            " command",
            " of",
            " the",
            " army",
            ".",
            " He",
            " resumed",
            " leading",
            " the",
            " Confederate",
            " assault",
            ",",
            " which",
            " continued",
            " advancing",
            " and",
            " pushed",
            " the",
            " U",
            ".S",
            ".",
            " forces",
            " back",
            " to",
            " a",
            " final",
            " defensive",
            " line",
            " near",
            " the",
            " Tennessee",
            " river",
            ".",
            " With",
            " his",
            " army",
            " exhausted",
            " and",
            " daylight",
            " almost",
            " gone",
            ",",
            " Bea",
            "ure",
            "gard",
            " called",
            " off",
            " the",
            " final",
            " Confederate",
            " attack",
            " around",
            " ",
            "190",
            "0",
            " hours",
            ",",
            " figuring",
            " he",
            " could"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.012,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.029,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.531,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "200",
            "7",
            ",",
            " the",
            " Alger",
            "ian",
            " Air",
            " Force",
            " signed",
            " a",
            " deal",
            " with",
            " Russia",
            " to",
            " purchase",
            " ",
            "49",
            " Mi",
            "G",
            "-",
            "29",
            "S",
            "MT",
            " and",
            " ",
            "6",
            " Mi",
            "G",
            "-",
            "29",
            "UB",
            "T",
            " at",
            " an",
            " estimated",
            " cost",
            " of",
            " $",
            "1",
            ".",
            "9",
            "Âłb",
            "illion",
            ".",
            " Russia",
            " is",
            " also",
            " building",
            " two",
            " ",
            "636",
            "-type",
            " diesel",
            " submarines",
            " for",
            " Algeria",
            ".",
            "Human",
            " rights",
            "Al",
            "ger"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.002,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.512,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 58,
          "is_repeated_datapoint": false,
          "tokens": [
            " routing",
            " the",
            " opposing",
            " army",
            ".",
            " At",
            " the",
            " decisive",
            " encounter",
            " with",
            " D",
            "arius",
            " at",
            " Ga",
            "ug",
            "am",
            "ela",
            ",",
            " D",
            "arius",
            " equipped",
            " his",
            " char",
            "i",
            "ots",
            " with",
            " sc",
            "y",
            "thes",
            " on",
            " the",
            " wheels",
            " to",
            " break",
            " up",
            " the",
            " ph",
            "alan",
            "x",
            " and",
            " equipped",
            " his",
            " cavalry",
            " with",
            " p",
            "ikes",
            ".",
            " Alexander",
            " arranged",
            " a",
            " double",
            " ph",
            "alan",
            "x",
            ",",
            " with",
            " the",
            " center",
            " advancing",
            " at",
            " an",
            " angle",
            ","
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            0.383,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " RNA",
            " and",
            " transmitting",
            " of",
            " traits",
            " to",
            " offspring",
            " through",
            " genes",
            ".",
            " Carbon",
            "ic",
            " acid",
            " is",
            " important",
            " for",
            " maintenance",
            " of",
            " pH",
            " equilibrium",
            " in",
            " the",
            " body",
            ".",
            "Human",
            " bodies",
            " contain",
            " a",
            " variety",
            " of",
            " organic",
            " and",
            " in",
            "organic",
            " compounds",
            ",",
            " among",
            " those",
            " dic",
            "ar",
            "box",
            "y",
            "lic",
            " acids",
            " play",
            " an",
            " essential",
            " role",
            " in",
            " many",
            " biological",
            " behaviors",
            ".",
            " Many",
            " of",
            " those",
            " acids",
            " are",
            " amino",
            " acids",
            ",",
            " which"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.279,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 44,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            "8",
            "%).",
            "Major",
            " industries",
            " Energy",
            " –",
            " There",
            " are",
            " significant",
            " energy",
            "-related",
            " infrastructure",
            ",",
            " presence",
            " and",
            " expertise",
            " in",
            " Aber",
            "de",
            "ens",
            "hire",
            ".",
            " Peter",
            "head",
            " is",
            " an",
            " important",
            " centre",
            " for",
            " the",
            " energy",
            " industry",
            ".",
            " Peter",
            "head",
            " Port",
            " includes",
            " an",
            " extensive",
            " new",
            " quay",
            " with",
            " an",
            " adjacent",
            " lay",
            "down",
            " area",
            " at",
            " Smith",
            " Qu",
            "ay",
            ",",
            " is",
            " a",
            " major",
            " support",
            " location",
            " for",
            " North",
            " Sea",
            " oil"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.27,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.268,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " United",
            " States",
            ")",
            " Apple",
            "seed",
            " Ex",
            " Mach",
            "ina",
            " (",
            "200",
            "7",
            ",",
            " Japan",
            "),",
            " The",
            " Legend",
            " of",
            " Zelda",
            ":",
            " The",
            " Wind",
            " W",
            "aker",
            " (",
            "200",
            "2",
            ",",
            " Japan",
            "),",
            " The",
            " Legend",
            " of",
            " Zelda",
            ":",
            " Breath",
            " of",
            " the",
            " Wild",
            " (",
            "201",
            "7",
            ",",
            " Japan",
            ")",
            " Mach",
            "in",
            "ima",
            " –",
            " Films",
            " created",
            " by",
            " screen",
            " capturing",
            " in",
            " video",
            " games",
            " and",
            " virtual",
            " worlds",
            ".",
            " The",
            " term"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.241,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 27,
          "is_repeated_datapoint": false,
          "tokens": [
            " by",
            " the",
            " linguistic",
            " data",
            ".",
            " Most",
            " scholars",
            " more",
            " narrowly",
            " place",
            " the",
            " homeland",
            " near",
            " the",
            " geographic",
            " center",
            " of",
            " its",
            " present",
            " distribution",
            ",",
            " \"",
            "in",
            " the",
            " southeastern",
            " Sahara",
            " or",
            " adjacent",
            " Horn",
            " of",
            " Africa",
            ".\"",
            " The",
            " Afro",
            "asi",
            "atic",
            " languages",
            " spoken",
            " in",
            " Africa",
            " are",
            " not",
            " more",
            " closely",
            " related",
            " to",
            " each",
            " other",
            " than",
            " they",
            " are",
            " to",
            " Sem",
            "itic",
            ",",
            " as",
            " one",
            " would",
            " expect",
            " if",
            " only",
            " Sem",
            "itic"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.23
          ],
          "train_token_ind": 62,
          "is_repeated_datapoint": false,
          "tokens": [
            "-to",
            "-right",
            " scripts",
            ".",
            " Sequ",
            "ences",
            " of",
            " digits",
            " such",
            " as",
            " telephone",
            " numbers",
            " are",
            " read",
            " from",
            " left",
            " to",
            " right",
            ",",
            " but",
            " numbers",
            " are",
            " spoken",
            " in",
            " the",
            " traditional",
            " Arabic",
            " fashion",
            ",",
            " with",
            " units",
            " and",
            " tens",
            " reversed",
            " from",
            " the",
            " modern",
            " English",
            " usage",
            ".",
            " For",
            " example",
            ",",
            " ",
            "24",
            " is",
            " said",
            " \"",
            "four",
            " and",
            " twenty",
            "\"",
            " just",
            " like",
            " in",
            " the",
            " German",
            " language",
            " (",
            "vier",
            "und",
            "zw",
            "anz"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.166,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 48,
          "is_repeated_datapoint": false,
          "tokens": [
            " runners",
            " nor",
            " are",
            " they",
            " particularly",
            " adept",
            " at",
            " fighting",
            " off",
            " predators",
            ".",
            " Therefore",
            ",",
            " when",
            " threatened",
            ",",
            " the",
            " a",
            "ard",
            "wolf",
            " may",
            " attempt",
            " to",
            " mis",
            "lead",
            " its",
            " foe",
            " by",
            " doubling",
            " back",
            " on",
            " its",
            " tracks",
            ".",
            " If",
            " confronted",
            ",",
            " it",
            " may",
            " raise",
            " its",
            " mane",
            " in",
            " an",
            " attempt",
            " to",
            " appear",
            " more",
            " menacing",
            ".",
            " It",
            " also",
            " emits",
            " a",
            " foul",
            "-sm",
            "elling",
            " liquid",
            " from",
            " its",
            " anal",
            " glands",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " and",
            " Fr",
            "anks",
            ".",
            " Celt",
            " tribes",
            " settled",
            " in",
            " modern",
            "-day",
            " Switzerland",
            " between",
            " ",
            "150",
            "0",
            " and",
            " ",
            "100",
            "0",
            " BC",
            ".",
            " The",
            " Ra",
            "eti",
            " lived",
            " in",
            " the",
            " eastern",
            " regions",
            ",",
            " while",
            " the",
            " west",
            " was",
            " occupied",
            " by",
            " the",
            " Hel",
            "vet",
            "ii",
            " and",
            " the",
            " Al",
            "lob",
            "ro",
            "ges",
            " settled",
            " in",
            " the",
            " Rh",
            "Ã´",
            "ne",
            " valley",
            " and",
            " in",
            " Sav",
            "oy",
            ".",
            " The",
            " Lig",
            "ures",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " are",
            " laid",
            " and",
            " may",
            " increase",
            " the",
            " supply",
            " of",
            " oxygen",
            " to",
            " the",
            " embryo",
            " through",
            " photos",
            "ynthesis",
            ".",
            " They",
            " seem",
            " to",
            " both",
            " speed",
            " up",
            " the",
            " development",
            " of",
            " the",
            " larvae",
            " and",
            " reduce",
            " mortality",
            ".",
            " In",
            " the",
            " wood",
            " frog",
            " (",
            "R",
            "ana",
            " s",
            "ylv",
            "atica",
            "),",
            " the",
            " interior",
            " of",
            " the",
            " glob",
            "ular",
            " egg",
            " cluster",
            " has",
            " been",
            " found",
            " to",
            " be",
            " up",
            " to",
            " ",
            " warmer",
            " than",
            " its",
            " surroundings",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " greenhouse",
            " gas",
            " emissions",
            " by",
            " ",
            "45",
            "%",
            " and",
            " achieve",
            " carbon",
            " neutrality",
            " by",
            " ",
            "205",
            "0",
            " which",
            ",",
            " along",
            " with",
            " national",
            " policies",
            ",",
            " will",
            " help",
            " to",
            " mitigate",
            " the",
            " impacts",
            " of",
            " the",
            " climate",
            " change",
            ".",
            " The",
            " country",
            " has",
            " a",
            " moderate",
            " and",
            " improving",
            " performance",
            " in",
            " the",
            " Environmental",
            " Performance",
            " Index",
            " with",
            " an",
            " overall",
            " ranking",
            " of",
            " ",
            "62",
            " out",
            " of",
            " ",
            "180",
            " countries",
            " in",
            " ",
            "202",
            "2",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " extent",
            " of",
            " the",
            " volcan",
            "ism",
            " has",
            " been",
            " estimated",
            " to",
            " ",
            " of",
            " which",
            " ",
            " covered",
            " what",
            " is",
            " now",
            " northern",
            " and",
            " central",
            " Brazil",
            ".",
            "The",
            " formation",
            " of",
            " the",
            " Central",
            " American",
            " I",
            "sth",
            "mus",
            " closed",
            " the",
            " Central",
            " American",
            " Se",
            "away",
            " at",
            " the",
            " end",
            " of",
            " the",
            " P",
            "li",
            "ocene",
            " ",
            "2",
            ".",
            "8",
            "Âł",
            "Ma",
            " ago",
            ".",
            " The",
            " formation",
            " of",
            " the",
            " ist",
            "hm",
            "us",
            " resulted",
            " in",
            " the"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    ".netbeans",
    "gae",
    "icket",
    "erate",
    "aar"
  ],
  "bottom_logits": [
    "ddit",
    " ä¸",
    "vat",
    "@$",
    "15"
  ],
  "act_min": -0.0,
  "act_max": 1.023
}
{
  "index": 9978,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.005,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.945
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " website",
            " of",
            " the",
            " International",
            " Aluminium",
            " Institute",
            " E",
            "medicine",
            " –",
            " Aluminium",
            " ",
            " ",
            "Chem",
            "ical",
            " elements",
            "Post",
            "-transition",
            " metals",
            "Al",
            "uminium",
            "Elect",
            "rical",
            " conduct",
            "ors",
            "Py",
            "rote",
            "chn",
            "ic",
            " fuels",
            "Air",
            "ship",
            " technology",
            "Reduc",
            "ing",
            " agents",
            "E",
            "-number",
            " additives",
            "Native",
            " element",
            " minerals",
            "Chem",
            "ical",
            " elements",
            " with",
            " face",
            "-centered",
            " cubic",
            " structure",
            "<|begin_of_text|>",
            "Advanced"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.945,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.871,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " revive",
            " and",
            " recreate",
            " concepts",
            " of",
            " identity",
            " in",
            " connection",
            " to",
            " traditional",
            " ethnic",
            " origins",
            ".",
            "Advanced",
            " Chemistry",
            " helped",
            " to",
            " found",
            " the",
            " German",
            " chapter",
            " of",
            " the",
            " Z",
            "ulu",
            " nation",
            ".",
            "The",
            " rivalry",
            " between",
            " Advanced",
            " Chemistry",
            " and",
            " Die",
            " Fant",
            "ast",
            "ischen",
            " V",
            "ier",
            " has",
            " served",
            " to",
            " highlight",
            " a",
            " dich",
            "otomy",
            " in",
            " the",
            " routes",
            " that",
            " hip",
            " hop",
            " has",
            " taken",
            " in",
            " becoming",
            " a",
            " part",
            " of",
            " the",
            " German",
            " sounds"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.945,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.871,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " revive",
            " and",
            " recreate",
            " concepts",
            " of",
            " identity",
            " in",
            " connection",
            " to",
            " traditional",
            " ethnic",
            " origins",
            ".",
            "Advanced",
            " Chemistry",
            " helped",
            " to",
            " found",
            " the",
            " German",
            " chapter",
            " of",
            " the",
            " Z",
            "ulu",
            " nation",
            ".",
            "The",
            " rivalry",
            " between",
            " Advanced",
            " Chemistry",
            " and",
            " Die",
            " Fant",
            "ast",
            "ischen",
            " V",
            "ier",
            " has",
            " served",
            " to",
            " highlight",
            " a",
            " dich",
            "otomy",
            " in",
            " the",
            " routes",
            " that",
            " hip",
            " hop",
            " has",
            " taken",
            " in",
            " becoming",
            " a",
            " part",
            " of",
            " the",
            " German",
            " sounds"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.005,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.945
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " website",
            " of",
            " the",
            " International",
            " Aluminium",
            " Institute",
            " E",
            "medicine",
            " –",
            " Aluminium",
            " ",
            " ",
            "Chem",
            "ical",
            " elements",
            "Post",
            "-transition",
            " metals",
            "Al",
            "uminium",
            "Elect",
            "rical",
            " conduct",
            "ors",
            "Py",
            "rote",
            "chn",
            "ic",
            " fuels",
            "Air",
            "ship",
            " technology",
            "Reduc",
            "ing",
            " agents",
            "E",
            "-number",
            " additives",
            "Native",
            " element",
            " minerals",
            "Chem",
            "ical",
            " elements",
            " with",
            " face",
            "-centered",
            " cubic",
            " structure",
            "<|begin_of_text|>",
            "Advanced"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.941,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            " Atlas",
            ",",
            " a",
            " computer",
            " used",
            " at",
            " the",
            " Lawrence",
            " Liver",
            "more",
            " National",
            " Laboratory",
            " in",
            " ",
            "200",
            "6",
            " Abb",
            "rev",
            "iated",
            " Test",
            " Language",
            " for",
            " All",
            " Systems",
            " (",
            "AT",
            "LAS",
            "),",
            " a",
            " computer",
            " language",
            " for",
            " equipment",
            " testing",
            " Advanced",
            " Technology",
            " Leisure",
            " Application",
            " Simulator",
            " (",
            "AT",
            "LAS",
            "),",
            " a",
            " hydraulic",
            " motion",
            " simulator",
            " used",
            " in",
            " theme",
            " parks",
            " ASP",
            ".NET",
            " AJAX",
            " (",
            "formerly",
            " \"",
            "Atlas",
            "\"),",
            " a"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.93,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "'s",
            " hope",
            " of",
            " actually",
            " being",
            " recognized",
            " as",
            " German",
            " citizens",
            " and",
            " not",
            " foreigners",
            ",",
            " despite",
            " their",
            " various",
            " other",
            " ethnic",
            " and",
            " cultural",
            " ties",
            ".",
            "In",
            "flu",
            "ences",
            "Advanced",
            " Chemistry",
            "'s",
            " work",
            " was",
            " rooted",
            " in",
            " German",
            " history",
            " and",
            " the",
            " country",
            "'s",
            " specific",
            " political",
            " realities",
            ".",
            " However",
            ",",
            " they",
            " also",
            " drew",
            " inspiration",
            " from",
            " African",
            "-American",
            " hip",
            "-hop",
            " acts",
            " like",
            " A",
            " Tribe",
            " Called",
            " Quest",
            " and",
            " Public",
            " Enemy"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.922,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " Ple",
            "i",
            "ades",
            " Advanced",
            " Top",
            "ographic",
            " Laser",
            " Al",
            "tim",
            "eter",
            " System",
            " (",
            "AT",
            "LAS",
            "),",
            " a",
            " space",
            "-based",
            " lid",
            "ar",
            " instrument",
            " on",
            " IC",
            "ES",
            "at",
            "-",
            "2",
            " Aster",
            "oid",
            " Ter",
            "restrial",
            "-",
            "impact",
            " Last",
            " Alert",
            " System",
            " (",
            "AT",
            "LAS",
            ")",
            "Math",
            "ematics",
            " Atlas",
            " (",
            "top",
            "ology",
            "),",
            " a",
            " set",
            " of",
            " charts",
            " A",
            " set",
            " of",
            " charts",
            " which",
            " covers",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.918,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " are",
            " confused",
            " by",
            " Advanced",
            " Chemistry",
            "'s",
            " elic",
            "itation",
            " of",
            " a",
            " German",
            " identity",
            " politics",
            " to",
            " which",
            " they",
            " technically",
            " do",
            " not",
            " belong",
            ".",
            " This",
            " cultural",
            " binary",
            " illustrates",
            " that",
            " rap",
            " has",
            " taken",
            " different",
            " routes",
            " in",
            " Germany",
            " and",
            " that",
            ",",
            " even",
            " among",
            " an",
            " already",
            " isolated",
            " immigrant",
            " population",
            ",",
            " there",
            " is",
            " still",
            " dis",
            "unity",
            " and",
            ",",
            " especially",
            ",",
            " disagreement",
            " on",
            " the",
            " relative",
            " importance",
            " of",
            " assim",
            "ilation",
            " versus",
            " cultural"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.906,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            "'s",
            " more",
            " exciting",
            " to",
            " experience",
            " my",
            " fellow",
            " Germans",
            " in",
            " new",
            " contexts",
            "...",
            "For",
            " me",
            ",",
            " it",
            "'s",
            " interesting",
            " to",
            " see",
            " what",
            " the",
            " kids",
            " try",
            " to",
            " do",
            " that",
            "'s",
            " different",
            " from",
            " what",
            " I",
            " know",
            ".\"",
            " ",
            " Advanced",
            " Chemistry",
            " were",
            " the",
            " first",
            " to",
            " use",
            " the",
            " term",
            " \"",
            "Af",
            "ro",
            "-G",
            "erman",
            "\"",
            " in",
            " a",
            " hip",
            " hop",
            " context",
            ".",
            " ",
            " This",
            " was",
            " part",
            " of",
            " the",
            " pro"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.902,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            " injury",
            ".",
            " A",
            " variety",
            " of",
            " large",
            " scale",
            " medical",
            " studies",
            " are",
            " being",
            " conducted",
            " in",
            " space",
            " via",
            " the",
            " National",
            " Space",
            " Bi",
            "omedical",
            " Research",
            " Institute",
            " (",
            "NS",
            "B",
            "RI",
            ")",
            " to",
            " address",
            " these",
            " issues",
            ".",
            " Prom",
            "inent",
            " among",
            " these",
            " is",
            " the",
            " Advanced",
            " Diagnostic",
            " Ul",
            "trasound",
            " in",
            " Micro",
            "gravity",
            " Study",
            " in",
            " which",
            " astronauts",
            " (",
            "including",
            " former",
            " ISS",
            " commanders",
            " Ler",
            "oy",
            " Ch",
            "iao",
            " and",
            " G",
            "enn",
            "ady",
            " Pad"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.898,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            " citizenship",
            ",",
            " and",
            " Toni",
            " L",
            ",",
            " Lingu",
            "ist",
            ",",
            " and",
            " Torch",
            " are",
            " of",
            " Italian",
            ",",
            " Ghana",
            "ian",
            ",",
            " and",
            " Hait",
            "ian",
            " backgrounds",
            ",",
            " respectively",
            ".",
            "In",
            "flu",
            "enced",
            " by",
            " North",
            " American",
            " socially",
            " conscious",
            " rap",
            " and",
            " the",
            " Native",
            " tongues",
            " movement",
            ",",
            " Advanced",
            " Chemistry",
            " is",
            " regarded",
            " as",
            " one",
            " of",
            " the",
            " main",
            " pioneers",
            " in",
            " German",
            " hip",
            " hop",
            ".",
            " They",
            " were",
            " one",
            " of",
            " the",
            " first",
            " groups",
            " to"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.879,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.894,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            "igrant",
            " sentiment",
            " emerged",
            ",",
            " as",
            " well",
            " as",
            " attacks",
            " on",
            " the",
            " homes",
            " of",
            " refugees",
            " in",
            " the",
            " early",
            " ",
            "199",
            "0",
            "s",
            ".",
            " ",
            " Advanced",
            " Chemistry",
            " came",
            " to",
            " prominence",
            " in",
            " the",
            " wake",
            " of",
            " these",
            " actions",
            " because",
            " of",
            " their",
            " pro",
            "-mult",
            "icultural",
            " society",
            " stance",
            " in",
            " their",
            " music",
            ".",
            " ",
            " Advanced",
            " Chemistry",
            "'s",
            " attitudes",
            " rev",
            "olve",
            " around",
            " their",
            " attempts",
            " to",
            " create",
            " a",
            " distinct",
            " \"",
            "G",
            "erm",
            "anness"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.879,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.894,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            "igrant",
            " sentiment",
            " emerged",
            ",",
            " as",
            " well",
            " as",
            " attacks",
            " on",
            " the",
            " homes",
            " of",
            " refugees",
            " in",
            " the",
            " early",
            " ",
            "199",
            "0",
            "s",
            ".",
            " ",
            " Advanced",
            " Chemistry",
            " came",
            " to",
            " prominence",
            " in",
            " the",
            " wake",
            " of",
            " these",
            " actions",
            " because",
            " of",
            " their",
            " pro",
            "-mult",
            "icultural",
            " society",
            " stance",
            " in",
            " their",
            " music",
            ".",
            " ",
            " Advanced",
            " Chemistry",
            "'s",
            " attitudes",
            " rev",
            "olve",
            " around",
            " their",
            " attempts",
            " to",
            " create",
            " a",
            " distinct",
            " \"",
            "G",
            "erm",
            "anness"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.891,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            "In",
            " ",
            "196",
            "9",
            ",",
            " the",
            " institute",
            " established",
            " the",
            " A",
            "FI",
            " Conserv",
            "atory",
            " for",
            " Advanced",
            " Film",
            " Studies",
            " at",
            " Gre",
            "ystone",
            ",",
            " the",
            " D",
            "ohen",
            "y",
            " Mansion",
            " in",
            " Beverly",
            " Hills",
            ",",
            " California",
            ".",
            " The",
            " first",
            " class",
            " included",
            " filmmakers",
            " Ter",
            "rence",
            " Mal",
            "ick",
            ",",
            " Caleb",
            " Des",
            "ch",
            "anel",
            ",",
            " and",
            " Paul",
            " Sch",
            "r",
            "ader",
            ".",
            " That",
            " program",
            " grew",
            " into",
            " the",
            " A",
            "FI",
            " Conserv",
            "atory",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.852,
            -0.0,
            -0.0,
            -0.0,
            0.891,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " Latin",
            " American",
            " trade",
            " union",
            " conf",
            "ederation",
            " Atlas",
            " languages",
            ",",
            " Ber",
            "ber",
            " languages",
            " spoken",
            " in",
            " the",
            " Atlas",
            " Mountains",
            " of",
            " Morocco",
            " AT",
            "LAS",
            " Network",
            ",",
            " a",
            " network",
            " of",
            " European",
            " special",
            " police",
            " units",
            " Atlas",
            " Uran",
            "ium",
            " Mill",
            " Atlas",
            " Corporation",
            ",",
            " a",
            " private",
            " military",
            " company",
            " by",
            " Call",
            " of",
            " Duty",
            ":",
            " Advanced",
            " Warfare",
            "See",
            " also",
            " Advanced",
            " Technology",
            " Large",
            "-A",
            "p",
            "erture",
            " Space"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.852,
            -0.0,
            -0.0,
            -0.0,
            0.891,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " Latin",
            " American",
            " trade",
            " union",
            " conf",
            "ederation",
            " Atlas",
            " languages",
            ",",
            " Ber",
            "ber",
            " languages",
            " spoken",
            " in",
            " the",
            " Atlas",
            " Mountains",
            " of",
            " Morocco",
            " AT",
            "LAS",
            " Network",
            ",",
            " a",
            " network",
            " of",
            " European",
            " special",
            " police",
            " units",
            " Atlas",
            " Uran",
            "ium",
            " Mill",
            " Atlas",
            " Corporation",
            ",",
            " a",
            " private",
            " military",
            " company",
            " by",
            " Call",
            " of",
            " Duty",
            ":",
            " Advanced",
            " Warfare",
            "See",
            " also",
            " Advanced",
            " Technology",
            " Large",
            "-A",
            "p",
            "erture",
            " Space"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.887,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " Duty",
            ":",
            " Advanced",
            " Warfare",
            "Br",
            "ands",
            " and",
            " enterprises",
            " Atlas",
            " (",
            "ap",
            "pliance",
            " company",
            "),",
            " in",
            " Belarus",
            " Atlas",
            " (",
            "restaurant",
            "),",
            " a",
            " Mich",
            "elin",
            "-star",
            "red",
            " restaurant",
            " in",
            " Atlanta",
            " Atlas",
            " Consortium",
            ",",
            " a",
            " group",
            " of",
            " technology",
            " companies",
            " Atlas",
            " Cop",
            "co",
            ",",
            " a",
            " Swedish",
            " company",
            " founded",
            " in",
            " ",
            "187",
            "3",
            " Atlas",
            " Corporation",
            ",",
            " an",
            " investment",
            " company",
            " Atlas",
            " Ele"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.879,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.887,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            "cape",
            ".",
            " ",
            " While",
            " Die",
            " Fant",
            "ast",
            "ischen",
            " V",
            "ier",
            " may",
            " be",
            " said",
            " to",
            " view",
            " hip",
            " hop",
            " primarily",
            " as",
            " an",
            " aesthetic",
            " art",
            " form",
            ",",
            " ",
            " Advanced",
            " Chemistry",
            " understand",
            " hip",
            " hop",
            " as",
            " being",
            " in",
            "extr",
            "ic",
            "ably",
            " linked",
            " to",
            " the",
            " social",
            " and",
            " political",
            " circumstances",
            " under",
            " which",
            " it",
            " is",
            " created",
            ".",
            " ",
            " For",
            " Advanced",
            " Chemistry",
            ",",
            " hip",
            " hop",
            " is",
            " a",
            " “",
            "vehicle",
            " of",
            " general",
            " human"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.879,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.887,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            "cape",
            ".",
            " ",
            " While",
            " Die",
            " Fant",
            "ast",
            "ischen",
            " V",
            "ier",
            " may",
            " be",
            " said",
            " to",
            " view",
            " hip",
            " hop",
            " primarily",
            " as",
            " an",
            " aesthetic",
            " art",
            " form",
            ",",
            " ",
            " Advanced",
            " Chemistry",
            " understand",
            " hip",
            " hop",
            " as",
            " being",
            " in",
            "extr",
            "ic",
            "ably",
            " linked",
            " to",
            " the",
            " social",
            " and",
            " political",
            " circumstances",
            " under",
            " which",
            " it",
            " is",
            " created",
            ".",
            " ",
            " For",
            " Advanced",
            " Chemistry",
            ",",
            " hip",
            " hop",
            " is",
            " a",
            " “",
            "vehicle",
            " of",
            " general",
            " human"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.887,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " Duty",
            ":",
            " Advanced",
            " Warfare",
            "Br",
            "ands",
            " and",
            " enterprises",
            " Atlas",
            " (",
            "ap",
            "pliance",
            " company",
            "),",
            " in",
            " Belarus",
            " Atlas",
            " (",
            "restaurant",
            "),",
            " a",
            " Mich",
            "elin",
            "-star",
            "red",
            " restaurant",
            " in",
            " Atlanta",
            " Atlas",
            " Consortium",
            ",",
            " a",
            " group",
            " of",
            " technology",
            " companies",
            " Atlas",
            " Cop",
            "co",
            ",",
            " a",
            " Swedish",
            " company",
            " founded",
            " in",
            " ",
            "187",
            "3",
            " Atlas",
            " Corporation",
            ",",
            " an",
            " investment",
            " company",
            " Atlas",
            " Ele"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.883,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " then",
            " as",
            " the",
            " Center",
            " for",
            " Advanced",
            " Film",
            " Studies",
            ".",
            " Also",
            " created",
            " in",
            " the",
            " early",
            " years",
            " were",
            " a",
            " rep",
            "ert",
            "ory",
            " film",
            " exhibition",
            " program",
            " at",
            " the",
            " Kennedy",
            " Center",
            " for",
            " the",
            " Performing",
            " Arts",
            " and",
            " the",
            " A",
            "FI",
            " Catalog",
            " of",
            " Feature",
            " Films",
            " —",
            " a",
            " scholarly",
            " source",
            " for",
            " American",
            " film",
            " history",
            ".",
            " The",
            " institute",
            " moved",
            " to",
            " its",
            " current",
            " eight",
            "-acre",
            " Hollywood",
            " campus",
            " in",
            " ",
            "198",
            "1",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.883,
            -0.0,
            -0.0
          ],
          "train_token_ind": 60,
          "is_repeated_datapoint": false,
          "tokens": [
            "3",
            " -",
            " \"",
            "Wel",
            "cher",
            " Pf",
            "ad",
            " fÃ¼h",
            "rt",
            " zur",
            " Geschichte",
            "\"",
            " (",
            "12",
            "\"/",
            "M",
            "CD",
            ",",
            " M",
            "Z",
            "EE",
            ")",
            " ",
            "199",
            "4",
            " -",
            " \"",
            "Operation",
            " Â§",
            " ",
            "3",
            "\"",
            " (",
            "12",
            "\"/",
            "M",
            "CD",
            ")",
            " ",
            "199",
            "4",
            " -",
            " \"",
            "Dir",
            " fe",
            "h",
            "lt",
            " der",
            " Funk",
            "!\"",
            " (",
            "12",
            "\"/",
            "M",
            "CD",
            ")",
            " ",
            "199",
            "5",
            " -",
            " Advanced",
            " Chemistry",
            " ("
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.883,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            " defiance",
            ".",
            " According",
            " to",
            " German",
            " hip",
            " hop",
            " enthusiast",
            " ",
            "9",
            "@",
            "home",
            ",",
            " Advanced",
            " Chemistry",
            " is",
            " part",
            " of",
            " a",
            " \"",
            "hip",
            "-hop",
            " movement",
            " [",
            "which",
            "]",
            " took",
            " a",
            " clear",
            " stance",
            " for",
            " the",
            " minorities",
            " and",
            " against",
            " the",
            " [",
            "m",
            "arg",
            "inal",
            "ization",
            "]",
            " of",
            " immigrants",
            " who",
            "...",
            "might",
            " be",
            " German",
            " on",
            " paper",
            ",",
            " but",
            " not",
            " in",
            " real",
            " life",
            ",\"",
            " which",
            " speaks",
            " to",
            " the",
            " group"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.883,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            " rap",
            " in",
            " German",
            " (",
            "although",
            " their",
            " name",
            " is",
            " in",
            " English",
            ").",
            " Furthermore",
            ",",
            " their",
            " songs",
            " tackled",
            " controversial",
            " social",
            " and",
            " political",
            " issues",
            ",",
            " distinguishing",
            " them",
            " from",
            " early",
            " German",
            " hip",
            " hop",
            " group",
            " \"",
            "Die",
            " Fant",
            "ast",
            "ischen",
            " V",
            "ier",
            "\"",
            " (",
            "The",
            " Fantastic",
            " Four",
            "),",
            " ",
            " which",
            " had",
            " a",
            " more",
            " light",
            "-hearted",
            ",",
            " playful",
            ",",
            " party",
            " image",
            ".",
            "Career",
            "Advanced",
            " Chemistry",
            " frequently",
            " r",
            "apped"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.883,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            " rap",
            " in",
            " German",
            " (",
            "although",
            " their",
            " name",
            " is",
            " in",
            " English",
            ").",
            " Furthermore",
            ",",
            " their",
            " songs",
            " tackled",
            " controversial",
            " social",
            " and",
            " political",
            " issues",
            ",",
            " distinguishing",
            " them",
            " from",
            " early",
            " German",
            " hip",
            " hop",
            " group",
            " \"",
            "Die",
            " Fant",
            "ast",
            "ischen",
            " V",
            "ier",
            "\"",
            " (",
            "The",
            " Fantastic",
            " Four",
            "),",
            " ",
            " which",
            " had",
            " a",
            " more",
            " light",
            "-hearted",
            ",",
            " playful",
            ",",
            " party",
            " image",
            ".",
            "Career",
            "Advanced",
            " Chemistry",
            " frequently",
            " r",
            "apped"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.859,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            " Chemistry",
            " is",
            " a",
            " German",
            " hip",
            " hop",
            " group",
            " from",
            " He",
            "idelberg",
            ",",
            " a",
            " scenic",
            " city",
            " in",
            " Bad",
            "en",
            "-W",
            "Ã¼",
            "rt",
            "tem",
            "berg",
            ",",
            " South",
            " Germany",
            ".",
            " Advanced",
            " Chemistry",
            " was",
            " founded",
            " in",
            " ",
            "198",
            "7",
            " by",
            " Toni",
            " L",
            ",",
            " Lingu",
            "ist",
            ",",
            " Gee",
            "-One",
            ",",
            " DJ",
            " Mike",
            " MD",
            " (",
            "Mike",
            " Dip",
            "pon",
            ")",
            " and",
            " MC",
            " Torch",
            ".",
            " Each",
            " member",
            " of",
            " the",
            " group",
            " holds",
            " German"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.852,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 58,
          "is_repeated_datapoint": false,
          "tokens": [
            " about",
            " their",
            " lives",
            " and",
            " experiences",
            " as",
            " children",
            " of",
            " immigrants",
            ",",
            " exposing",
            " the",
            " marginal",
            "ization",
            " experienced",
            " by",
            " most",
            " ethnic",
            " minorities",
            " in",
            " Germany",
            ",",
            " and",
            " the",
            " feelings",
            " of",
            " frustration",
            " and",
            " resentment",
            " that",
            " being",
            " denied",
            " a",
            " German",
            " identity",
            " can",
            " cause",
            ".",
            " The",
            " song",
            " \"",
            "F",
            "rem",
            "d",
            " im",
            " eigenen",
            " Land",
            "\"",
            " (",
            "Foreign",
            " in",
            " your",
            " own",
            " nation",
            ")",
            " was",
            " released",
            " by",
            " Advanced",
            " Chemistry",
            " in",
            " November",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.852,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " Einstein",
            " at",
            " the",
            " Institute",
            " for",
            " Advanced",
            " Study",
            " at",
            " Princeton",
            ".",
            "Following",
            " an",
            " episode",
            " of",
            " acute",
            " mental",
            " illness",
            " at",
            " about",
            " the",
            " age",
            " of",
            " twenty",
            ",",
            " Einstein",
            "'s",
            " son",
            " Edu",
            "ard",
            " was",
            " diagnosed",
            " with",
            " schizophrenia",
            ".",
            " He",
            " spent",
            " the",
            " remainder",
            " of",
            " his",
            " life",
            " either",
            " in",
            " the",
            " care",
            " of",
            " his",
            " mother",
            " or",
            " in",
            " temporary",
            " confinement",
            " in",
            " an",
            " asylum",
            ".",
            " After",
            " her",
            " death",
            ",",
            " he",
            " was",
            " committed"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.848,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " The",
            " Institute",
            " for",
            " Advanced",
            " Study",
            " Albert",
            " –",
            " The",
            " Digital",
            " Repository",
            " of",
            " the",
            " I",
            "AS",
            ",",
            " which",
            " contains",
            " many",
            " digit",
            "ized",
            " original",
            " documents",
            " and",
            " photographs",
            " ",
            "187",
            "9",
            " births",
            "195",
            "5",
            " deaths",
            "20",
            "th",
            "-century",
            " American",
            " engineers",
            "20",
            "th",
            "-century",
            " American",
            " physicists",
            "20",
            "th",
            "-century",
            " American",
            " writers",
            "American",
            " ag",
            "nost",
            "ics",
            "American",
            " democratic",
            " social",
            "ists"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.844,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " Ada",
            " Lov",
            "el",
            "ace",
            "'s",
            " birth",
            " was",
            " celebrated",
            " with",
            " a",
            " number",
            " of",
            " events",
            ",",
            " including",
            ":",
            " The",
            " Ada",
            " Lov",
            "el",
            "ace",
            " B",
            "ic",
            "ent",
            "enary",
            " Lect",
            "ures",
            " on",
            " Comput",
            "ability",
            ",",
            " Israel",
            " Institute",
            " for",
            " Advanced",
            " Studies",
            ",",
            " ",
            "20",
            " December",
            " ",
            "201",
            "5",
            " –",
            " ",
            "31",
            " January",
            " ",
            "201",
            "6",
            ".",
            " Ada",
            " Lov",
            "el",
            "ace",
            " Symposium",
            ",",
            " University",
            " of",
            " Oxford",
            ",",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.844,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 8,
          "is_repeated_datapoint": false,
          "tokens": [
            " took",
            " up",
            " a",
            " position",
            " at",
            " the",
            " Institute",
            " for",
            " Advanced",
            " Study",
            ",",
            " noted",
            " for",
            " having",
            " become",
            " a",
            " refuge",
            " for",
            " scientists",
            " fleeing",
            " Nazi",
            " Germany",
            ".",
            " At",
            " the",
            " time",
            ",",
            " most",
            " American",
            " universities",
            ",",
            " including",
            " Harvard",
            ",",
            " Princeton",
            " and",
            " Yale",
            ",",
            " had",
            " minimal",
            " or",
            " no",
            " Jewish",
            " faculty",
            " or",
            " students",
            ",",
            " as",
            " a",
            " result",
            " of",
            " their",
            " Jewish",
            " quotas",
            ",",
            " which",
            " lasted",
            " until",
            " the",
            " late",
            " ",
            "194",
            "0"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.381,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.844,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 29,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "193",
            "5",
            ",",
            " he",
            " arrived",
            " at",
            " the",
            " decision",
            " to",
            " remain",
            " permanently",
            " in",
            " the",
            " United",
            " States",
            " and",
            " apply",
            " for",
            " citizenship",
            ".",
            "E",
            "instein",
            "'s",
            " affiliation",
            " with",
            " the",
            " Institute",
            " for",
            " Advanced",
            " Study",
            " would",
            " last",
            " until",
            " his",
            " death",
            " in",
            " ",
            "195",
            "5",
            ".",
            " He",
            " was",
            " one",
            " of",
            " the",
            " four",
            " first",
            " selected",
            " (",
            "along",
            " with",
            " John",
            " von",
            " Ne",
            "umann",
            ",",
            " Kurt",
            " GÃ¶",
            "del",
            ",",
            " and",
            " Herm"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.844,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 11,
          "is_repeated_datapoint": false,
          "tokens": [
            "-imm",
            "igrant",
            " political",
            " message",
            " they",
            " sent",
            " via",
            " their",
            " music",
            ".",
            "While",
            " Advanced",
            " Chemistry",
            "'s",
            " use",
            " of",
            " the",
            " German",
            " language",
            " in",
            " their",
            " rap",
            " allows",
            " them",
            " to",
            " make",
            " claims",
            " to",
            " authenticity",
            " and",
            " true",
            " German",
            " heritage",
            ",",
            " bolster",
            "ing",
            " pro",
            "-imm",
            "igration",
            " sentiment",
            ",",
            " their",
            " style",
            " can",
            " also",
            " be",
            " problematic",
            " for",
            " immigrant",
            " notions",
            " of",
            " any",
            " real",
            " ethnic",
            " roots",
            ".",
            " Indeed",
            ",",
            " part",
            " of",
            " the",
            " Turkish",
            " ethnic"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.84,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 48,
          "is_repeated_datapoint": false,
          "tokens": [
            "20",
            "th",
            "-century",
            " French",
            " mathematic",
            "ians",
            "21",
            "st",
            "-century",
            " French",
            " mathematic",
            "ians",
            "Math",
            "ematic",
            "al",
            " analysts",
            "D",
            "ifferential",
            " geom",
            "eters",
            "Fields",
            " Medal",
            "ists",
            "Cl",
            "ay",
            " Research",
            " Award",
            " recipients",
            "Ãī",
            "cole",
            " Norm",
            "ale",
            " Sup",
            "Ã©rie",
            "ure",
            " alumni",
            "Ac",
            "ademic",
            " staff",
            " of",
            " the",
            " Coll",
            "Ã¨ge",
            " de",
            " France",
            "In",
            "stitute",
            " for",
            " Advanced",
            " Study",
            " visiting",
            " scholars",
            "Foreign",
            " associates"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.816,
            -0.0,
            -0.0
          ],
          "train_token_ind": 60,
          "is_repeated_datapoint": false,
          "tokens": [
            " emanc",
            "ipation",
            ",”",
            ".",
            " ",
            " In",
            " their",
            " undertaking",
            " of",
            " social",
            " and",
            " political",
            " issues",
            ",",
            " the",
            " band",
            " introduced",
            " the",
            " term",
            " \"",
            "Af",
            "ro",
            "-G",
            "erman",
            "\"",
            " into",
            " the",
            " context",
            " of",
            " German",
            " hip",
            " hop",
            ",",
            " and",
            " the",
            " theme",
            " of",
            " race",
            " is",
            " highlighted",
            " in",
            " much",
            " of",
            " their",
            " music",
            ".",
            "With",
            " the",
            " release",
            " of",
            " the",
            " single",
            " “",
            "F",
            "rem",
            "d",
            " im",
            " eigenen",
            " Land",
            "”,",
            " Advanced",
            " Chemistry",
            " separated"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.633,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 33,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "196",
            "6",
            "),",
            " nem",
            "esis",
            " the",
            " Green",
            " Goblin",
            " discovers",
            " Spider",
            "-Man",
            "'s",
            " secret",
            " identity",
            " and",
            " reveals",
            " his",
            " own",
            " to",
            " the",
            " captive",
            " hero",
            ".",
            " Rom",
            "ita",
            "'s",
            " Spider",
            "-Man",
            " –",
            " more",
            " polished",
            " and",
            " heroic",
            "-looking",
            " than",
            " Dit",
            "ko",
            "'s",
            " –",
            " became",
            " the",
            " model",
            " for",
            " two",
            " decades",
            ".",
            " The",
            " Lee",
            "-R",
            "om",
            "ita",
            " era",
            " saw",
            " the",
            " introduction",
            " of",
            " such",
            " characters",
            " as",
            " Daily",
            " Bug",
            "le"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " the",
            " world",
            ",",
            " an",
            " advanced",
            " robotic",
            " dis",
            "as",
            "sembler",
            " and",
            " sorter",
            " designed",
            " by",
            " Apple",
            " Engineers",
            " in",
            " California",
            " specifically",
            " for",
            " recycling",
            " outdated",
            " or",
            " broken",
            " iPhones",
            ".",
            " Re",
            "uses",
            " and",
            " rec",
            "ycles",
            " parts",
            " from",
            " traded",
            " in",
            " products",
            ".",
            "Apple",
            " announced",
            " on",
            " August",
            " ",
            "16",
            ",",
            " ",
            "201",
            "6",
            ",",
            " that",
            " Lens",
            " Technology",
            ",",
            " one",
            " of",
            " its",
            " major",
            " suppliers",
            " in",
            " China",
            ",",
            " has",
            " committed",
            " to"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.586,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0
          ],
          "train_token_ind": 61,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " existing",
            " devices",
            " or",
            " the",
            " creation",
            " of",
            " new",
            " products",
            ".",
            "In",
            " the",
            " WI",
            "PO",
            " published",
            " ",
            "202",
            "1",
            " report",
            " on",
            " Technology",
            " Trends",
            ",",
            " assist",
            "ive",
            " products",
            " are",
            " grouped",
            " into",
            " either",
            " conventional",
            " or",
            " emerging",
            " technologies",
            ".",
            " Con",
            "ventional",
            " assisting",
            " technology",
            " tracks",
            " innovation",
            " within",
            " well",
            "-established",
            " assist",
            "ive",
            " products",
            ",",
            " whereas",
            " emerging",
            " assist",
            "ive",
            " technology",
            " refers",
            " to",
            " more",
            " advanced",
            " products",
            ".",
            " These",
            " identified",
            " advanced",
            " assist"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.281,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " In",
            " more",
            " advanced",
            " training",
            ",",
            " ",
            " will",
            " sometimes",
            " apply",
            " ",
            " to",
            " regain",
            " balance",
            " and",
            " pin",
            " or",
            " throw",
            " .",
            " refers",
            " to",
            " the",
            " act",
            " of",
            " receiving",
            " a",
            " technique",
            ".",
            " Good",
            " ",
            " involves",
            " attention",
            " to",
            " the",
            " technique",
            ",",
            " the",
            " partner",
            ",",
            " and",
            " the",
            " immediate",
            " environment",
            "—it",
            " is",
            " considered",
            " an",
            " active",
            " part",
            " of",
            " the",
            " process",
            " of",
            " learning",
            " a",
            "ik",
            "ido",
            ".",
            " The",
            " method",
            " of",
            " falling",
            " itself",
            " is"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.578,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 58,
          "is_repeated_datapoint": false,
          "tokens": [
            " tad",
            "po",
            "les",
            " lack",
            " lids",
            ",",
            " but",
            " at",
            " metam",
            "orph",
            "osis",
            ",",
            " the",
            " cor",
            "nea",
            " becomes",
            " more",
            " dome",
            "-shaped",
            ",",
            " the",
            " lens",
            " becomes",
            " fl",
            "atter",
            ",",
            " and",
            " eyel",
            "ids",
            " and",
            " associated",
            " glands",
            " and",
            " duct",
            "s",
            " develop",
            ".",
            " The",
            " adult",
            " eyes",
            " are",
            " an",
            " improvement",
            " on",
            " in",
            "verte",
            "brate",
            " eyes",
            " and",
            " were",
            " a",
            " first",
            " step",
            " in",
            " the",
            " development",
            " of",
            " more",
            " advanced",
            " verte",
            "brate",
            " eyes",
            "."
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.44,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.443,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 49,
          "is_repeated_datapoint": false,
          "tokens": [
            " Courts",
            " of",
            " the",
            " States",
            " and",
            " Territories",
            ".",
            " Appeals",
            " to",
            " the",
            " High",
            " Court",
            " are",
            " by",
            " special",
            " leave",
            " only",
            ",",
            " which",
            " is",
            " generally",
            " only",
            " granted",
            " in",
            " cases",
            " of",
            " public",
            " importance",
            ",",
            " matters",
            " involving",
            " the",
            " interpretation",
            " of",
            " the",
            " Commonwealth",
            " Constitution",
            ",",
            " or",
            " where",
            " the",
            " law",
            " has",
            " been",
            " inconsist",
            "ently",
            " applied",
            " across",
            " the",
            " States",
            " and",
            " Territories",
            ".[",
            "19",
            "]",
            " Therefore",
            ",",
            " in",
            " the",
            " vast",
            " majority",
            " of",
            " cases"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.379,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.398,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " Library",
            " of",
            " Medicine",
            " (",
            "N",
            "LM",
            ")",
            " funded",
            " by",
            " the",
            " US",
            " Federal",
            " Government",
            ".",
            " With",
            " marked",
            "-up",
            " maps",
            " of",
            " the",
            " United",
            " States",
            ",",
            " TO",
            "X",
            "MAP",
            " enables",
            " users",
            " to",
            " visually",
            " explore",
            " data",
            " from",
            " the",
            " United",
            " States",
            " Environmental",
            " Protection",
            " Agency",
            "'s",
            " (",
            "E",
            "PA",
            ")",
            " To",
            "x",
            "ics",
            " Release",
            " Inventory",
            " and",
            " Super",
            "fund",
            " Basic",
            " Research",
            " Programs",
            ".",
            " TO",
            "X",
            "MAP",
            "'s",
            " chemical",
            " and",
            " environmental"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.394,
            -0.0,
            -0.0
          ],
          "train_token_ind": 60,
          "is_repeated_datapoint": false,
          "tokens": [
            " was",
            " entrenched",
            " in",
            " several",
            " other",
            " European",
            " languages",
            ",",
            " such",
            " as",
            " French",
            ",",
            " German",
            ",",
            " and",
            " Dutch",
            ".",
            " In",
            " ",
            "182",
            "8",
            ",",
            " an",
            " American",
            " le",
            "xic",
            "ographer",
            ",",
            " Noah",
            " Webster",
            ",",
            " entered",
            " only",
            " the",
            " aluminum",
            " spelling",
            " in",
            " his",
            " American",
            " Dictionary",
            " of",
            " the",
            " English",
            " Language",
            ".",
            " In",
            " the",
            " ",
            "183",
            "0",
            "s",
            ",",
            " the",
            " ",
            " spelling",
            " gained",
            " usage",
            " in",
            " the",
            " United",
            " States",
            ";",
            " by"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.385,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 15,
          "is_repeated_datapoint": false,
          "tokens": [
            "United",
            " Kingdom",
            "The",
            " English",
            " doctrine",
            ",",
            " which",
            " was",
            " at",
            " one",
            " time",
            " adopted",
            " in",
            " the",
            " United",
            " States",
            ",",
            " asserted",
            " that",
            " allegiance",
            " was",
            " ind",
            "el",
            "ible",
            ":",
            " \"",
            "N",
            "emo",
            " pot",
            "est",
            " ex",
            "u",
            "ere",
            " patri",
            "am",
            "\".",
            " As",
            " the",
            " law",
            " stood",
            " prior",
            " to",
            " ",
            "187",
            "0",
            ",",
            " every",
            " person",
            " who",
            " by",
            " birth",
            " or",
            " natural",
            "isation",
            " satisfied",
            " the",
            " conditions",
            " set",
            " forth",
            ",",
            " even"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.381,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " field",
            " of",
            " space",
            " exploration",
            ".",
            " He",
            " was",
            " determined",
            " that",
            " the",
            " United",
            " States",
            " should",
            " compete",
            ",",
            " and",
            " sought",
            " a",
            " challenge",
            " that",
            " maxim",
            "ized",
            " its",
            " chances",
            " of",
            " winning",
            ".",
            "The",
            " Soviet",
            " Union",
            " had",
            " heavier",
            "-l",
            "ifting",
            " carrier",
            " rockets",
            ",",
            " which",
            " meant",
            " Kennedy",
            " needed",
            " to",
            " choose",
            " a",
            " goal",
            " that",
            " was",
            " beyond",
            " the",
            " capacity",
            " of",
            " the",
            " existing",
            " generation",
            " of",
            " rocket",
            "ry",
            ",",
            " one",
            " where",
            " the",
            " US"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.379,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " slightly",
            " bigger",
            " than",
            " France",
            " and",
            " smaller",
            " than",
            " Myanmar",
            ",",
            " and",
            " about",
            " the",
            " size",
            " of",
            " Texas",
            " in",
            " the",
            " United",
            " States",
            ".",
            " There",
            " is",
            " no",
            " coastline",
            ",",
            " as",
            " Afghanistan",
            " is",
            " land",
            "locked",
            ".",
            " Afghanistan",
            " shares",
            " its",
            " longest",
            " land",
            " border",
            " (",
            "the",
            " Dur",
            "and",
            " Line",
            ")",
            " with",
            " Pakistan",
            " to",
            " the",
            " east",
            " and",
            " south",
            ",",
            " followed",
            " by",
            " borders",
            " with",
            " Taj",
            "ik",
            "istan",
            " to",
            " the",
            " northeast",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.371,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 17,
          "is_repeated_datapoint": false,
          "tokens": [
            " Strait",
            ",",
            " with",
            " Big",
            " Di",
            "om",
            "ede",
            " in",
            " Russia",
            " and",
            " Little",
            " Di",
            "om",
            "ede",
            " in",
            " the",
            " United",
            " States",
            ".",
            " The",
            " Ale",
            "ut",
            "ian",
            " Islands",
            " are",
            " an",
            " island",
            " chain",
            " extending",
            " west",
            "ward",
            " from",
            " the",
            " Al",
            "askan",
            " Peninsula",
            " toward",
            " Russia",
            "'s",
            " Kom",
            "and",
            "ors",
            "ki",
            " Islands",
            " and",
            " Kam",
            "chat",
            "ka",
            " Peninsula",
            ".",
            " Most",
            " of",
            " them",
            " are",
            " always",
            " associated",
            " with",
            " North",
            " America",
            ",",
            " except",
            " for",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.359,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.359,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " include",
            " the",
            " following",
            ".",
            "Pre",
            "par",
            "ations",
            "In",
            "sign",
            "ia",
            " ",
            "The",
            " Apollo",
            " ",
            "11",
            " mission",
            " emblem",
            " was",
            " designed",
            " by",
            " Collins",
            ",",
            " who",
            " wanted",
            " a",
            " symbol",
            " for",
            " \"",
            "peace",
            "ful",
            " lunar",
            " landing",
            " by",
            " the",
            " United",
            " States",
            "\".",
            " At",
            " Lov",
            "ell",
            "'s",
            " suggestion",
            ",",
            " he",
            " chose",
            " the",
            " bald",
            " eagle",
            ",",
            " the",
            " national",
            " bird",
            " of",
            " the",
            " United",
            " States",
            ",",
            " as",
            " the",
            " symbol",
            ".",
            " Tom"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.27,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            " Sym",
            "ons",
            ".",
            " The",
            " literary",
            " critic",
            " Edmund",
            " Wilson",
            " described",
            " her",
            " prose",
            " as",
            " ban",
            "al",
            " and",
            " her",
            " character",
            "isations",
            " as",
            " superficial",
            ".",
            "In",
            " ",
            "201",
            "1",
            ",",
            " Christie",
            " was",
            " named",
            " by",
            " the",
            " digital",
            " crime",
            " drama",
            " TV",
            " channel",
            " Al",
            "ibi",
            " as",
            " the",
            " second",
            " most",
            " financially",
            " successful",
            " crime",
            " writer",
            " of",
            " all",
            " time",
            " in",
            " the",
            " United",
            " Kingdom",
            ",",
            " after",
            " James",
            " Bond",
            " author",
            " Ian",
            " Fleming",
            ",",
            " with",
            " total"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.199,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 8,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " create",
            " a",
            " foundation",
            " dedicated",
            " to",
            " the",
            " \"",
            "adv",
            "ancement",
            " of",
            " the",
            " visual",
            " arts",
            "\".",
            " War",
            "hol",
            " had",
            " so",
            " many",
            " possessions",
            " that",
            " it",
            " took",
            " So",
            "the",
            "by",
            "'s",
            " nine",
            " days",
            " to",
            " auction",
            " his",
            " estate",
            " after",
            " his",
            " death",
            ";",
            " the",
            " auction",
            " gross",
            "ed",
            " more",
            " than",
            " US",
            "$",
            "20",
            "Âł",
            "million",
            ".",
            "In",
            " ",
            "198",
            "7",
            ",",
            " in",
            " accordance",
            " with",
            " War",
            "hol",
            "'s",
            " will",
            ","
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " shared",
            " by",
            " virtually",
            " all",
            " human",
            " cultures",
            ").",
            " They",
            " use",
            " many",
            " different",
            " methods",
            " of",
            " study",
            ",",
            " but",
            " modern",
            " population",
            " genetics",
            ",",
            " participant",
            " observation",
            " and",
            " other",
            " techniques",
            " often",
            " take",
            " anthrop",
            "ologists",
            " \"",
            "into",
            " the",
            " field",
            ",\"",
            " which",
            " means",
            " traveling",
            " to",
            " a",
            " community",
            " in",
            " its",
            " own",
            " setting",
            ",",
            " to",
            " do",
            " something",
            " called",
            " \"",
            "field",
            "work",
            ".\"",
            " On",
            " the",
            " biological",
            " or",
            " physical",
            " side",
            ",",
            " human",
            " measurements",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " Prize",
            " of",
            " the",
            " Ec",
            "umen",
            "ical",
            " Jury",
            " at",
            " the",
            " Cannes",
            " Film",
            " Festival",
            ".",
            " In",
            " a",
            " question",
            " and",
            " answer",
            " session",
            " at",
            " the",
            " Edinburgh",
            " Film",
            "house",
            " on",
            " ",
            "11",
            " February",
            " ",
            "198",
            "1",
            ",",
            " T",
            "ark",
            "ovsky",
            " trench",
            "antly",
            " rejected",
            " suggestions",
            " that",
            " the",
            " film",
            " was",
            " either",
            " im",
            "pen",
            "etr",
            "ably",
            " mysterious",
            " or",
            " a",
            " political",
            " alleg",
            "ory",
            ".",
            "In",
            " ",
            "197",
            "9",
            ",",
            " T",
            "ark"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " (",
            "Memory",
            ":",
            " Allen",
            " Gins",
            "berg",
            ")",
            " Cherry",
            " Valley",
            " Edition",
            "s",
            ",",
            " ",
            "198",
            "2",
            "  ",
            " ",
            " Morgan",
            ",",
            " Bill",
            " (",
            "ed",
            ".),",
            " I",
            " G",
            "reet",
            " You",
            " at",
            " the",
            " Beginning",
            " of",
            " a",
            " Great",
            " Career",
            ":",
            " The",
            " Selected",
            " Correspond",
            "ence",
            " of",
            " Lawrence",
            " Fer",
            "ling",
            "h",
            "etti",
            " and",
            " Allen",
            " Gins",
            "berg",
            ",",
            " ",
            "195",
            "5",
            "–",
            "199",
            "7",
            ".",
            " San",
            " Francisco",
            ":",
            " City",
            " Lights",
            " Publishers"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "k",
            "ic",
            ",",
            " Mong",
            "olic",
            ",",
            " and",
            " T",
            "ung",
            "usic",
            ")",
            " together",
            " with",
            " Japon",
            "ic",
            " and",
            " Korean",
            "ic",
            ",",
            " which",
            " they",
            " refer",
            " to",
            " as",
            " the",
            " Tran",
            "se",
            "uras",
            "ian",
            " languages",
            ".",
            " Their",
            " results",
            " include",
            " the",
            " following",
            " phy",
            "logen",
            "etic",
            " tree",
            ":",
            "Mart",
            "ine",
            " Rob",
            "be",
            "ets",
            " (",
            "202",
            "0",
            ")",
            " argues",
            " that",
            " early",
            " Tran",
            "se",
            "uras",
            "ian",
            " speakers",
            " were",
            " originally",
            " agricultural",
            "ists",
            " in"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " mo",
            "les",
            " of",
            " a",
            " base",
            " have",
            " been",
            " added",
            " to",
            " an",
            " acid",
            ".",
            " It",
            " is",
            " often",
            " wrongly",
            " assumed",
            " that",
            " neutral",
            "ization",
            " should",
            " result",
            " in",
            " a",
            " solution",
            " with",
            " pH",
            " ",
            "7",
            ".",
            "0",
            ",",
            " which",
            " is",
            " only",
            " the",
            " case",
            " with",
            " similar",
            " acid",
            " and",
            " base",
            " strengths",
            " during",
            " a",
            " reaction",
            ".",
            "Neutral",
            "ization",
            " with",
            " a",
            " base",
            " weaker",
            " than",
            " the",
            " acid",
            " results",
            " in",
            " a",
            " weak",
            "ly",
            " acidic"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "ãĥ¼ãĥ«",
    "_tC",
    "_mC",
    "edo",
    " strstr"
  ],
  "bottom_logits": [
    "jaw",
    "mdi",
    " ",
    "843",
    "rais"
  ],
  "act_min": -0.0,
  "act_max": 0.945
}
{
  "index": 29884,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            1.383,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " advanced",
            " primary",
            " and",
            " then",
            " secondary",
            " school",
            " education",
            ".",
            "In",
            " ",
            "189",
            "4",
            ",",
            " Herm",
            "ann",
            " and",
            " Jak",
            "ob",
            "'s",
            " company",
            " tender",
            "ed",
            " for",
            " a",
            " contract",
            " to",
            " install",
            " electric",
            " lighting",
            " in",
            " Munich",
            ",",
            " but",
            " without",
            " success",
            "—they",
            " lacked",
            " the",
            " capital",
            " that",
            " would",
            " have",
            " been",
            " required",
            " to",
            " update",
            " their",
            " technology",
            " from",
            " direct",
            " current",
            " to",
            " the",
            " more",
            " efficient",
            ",",
            " alternating",
            " current",
            " alternative",
            ".",
            " The",
            " failure",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.367,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " Ple",
            "i",
            "ades",
            " Advanced",
            " Top",
            "ographic",
            " Laser",
            " Al",
            "tim",
            "eter",
            " System",
            " (",
            "AT",
            "LAS",
            "),",
            " a",
            " space",
            "-based",
            " lid",
            "ar",
            " instrument",
            " on",
            " IC",
            "ES",
            "at",
            "-",
            "2",
            " Aster",
            "oid",
            " Ter",
            "restrial",
            "-",
            "impact",
            " Last",
            " Alert",
            " System",
            " (",
            "AT",
            "LAS",
            ")",
            "Math",
            "ematics",
            " Atlas",
            " (",
            "top",
            "ology",
            "),",
            " a",
            " set",
            " of",
            " charts",
            " A",
            " set",
            " of",
            " charts",
            " which",
            " covers",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.344,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            " Atlas",
            ",",
            " a",
            " computer",
            " used",
            " at",
            " the",
            " Lawrence",
            " Liver",
            "more",
            " National",
            " Laboratory",
            " in",
            " ",
            "200",
            "6",
            " Abb",
            "rev",
            "iated",
            " Test",
            " Language",
            " for",
            " All",
            " Systems",
            " (",
            "AT",
            "LAS",
            "),",
            " a",
            " computer",
            " language",
            " for",
            " equipment",
            " testing",
            " Advanced",
            " Technology",
            " Leisure",
            " Application",
            " Simulator",
            " (",
            "AT",
            "LAS",
            "),",
            " a",
            " hydraulic",
            " motion",
            " simulator",
            " used",
            " in",
            " theme",
            " parks",
            " ASP",
            ".NET",
            " AJAX",
            " (",
            "formerly",
            " \"",
            "Atlas",
            "\"),",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.219,
            -0.0,
            -0.0,
            -0.0,
            1.305,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " Latin",
            " American",
            " trade",
            " union",
            " conf",
            "ederation",
            " Atlas",
            " languages",
            ",",
            " Ber",
            "ber",
            " languages",
            " spoken",
            " in",
            " the",
            " Atlas",
            " Mountains",
            " of",
            " Morocco",
            " AT",
            "LAS",
            " Network",
            ",",
            " a",
            " network",
            " of",
            " European",
            " special",
            " police",
            " units",
            " Atlas",
            " Uran",
            "ium",
            " Mill",
            " Atlas",
            " Corporation",
            ",",
            " a",
            " private",
            " military",
            " company",
            " by",
            " Call",
            " of",
            " Duty",
            ":",
            " Advanced",
            " Warfare",
            "See",
            " also",
            " Advanced",
            " Technology",
            " Large",
            "-A",
            "p",
            "erture",
            " Space"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.219,
            -0.0,
            -0.0,
            -0.0,
            1.305,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " Latin",
            " American",
            " trade",
            " union",
            " conf",
            "ederation",
            " Atlas",
            " languages",
            ",",
            " Ber",
            "ber",
            " languages",
            " spoken",
            " in",
            " the",
            " Atlas",
            " Mountains",
            " of",
            " Morocco",
            " AT",
            "LAS",
            " Network",
            ",",
            " a",
            " network",
            " of",
            " European",
            " special",
            " police",
            " units",
            " Atlas",
            " Uran",
            "ium",
            " Mill",
            " Atlas",
            " Corporation",
            ",",
            " a",
            " private",
            " military",
            " company",
            " by",
            " Call",
            " of",
            " Duty",
            ":",
            " Advanced",
            " Warfare",
            "See",
            " also",
            " Advanced",
            " Technology",
            " Large",
            "-A",
            "p",
            "erture",
            " Space"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            1.297,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " Duty",
            ":",
            " Advanced",
            " Warfare",
            "Br",
            "ands",
            " and",
            " enterprises",
            " Atlas",
            " (",
            "ap",
            "pliance",
            " company",
            "),",
            " in",
            " Belarus",
            " Atlas",
            " (",
            "restaurant",
            "),",
            " a",
            " Mich",
            "elin",
            "-star",
            "red",
            " restaurant",
            " in",
            " Atlanta",
            " Atlas",
            " Consortium",
            ",",
            " a",
            " group",
            " of",
            " technology",
            " companies",
            " Atlas",
            " Cop",
            "co",
            ",",
            " a",
            " Swedish",
            " company",
            " founded",
            " in",
            " ",
            "187",
            "3",
            " Atlas",
            " Corporation",
            ",",
            " an",
            " investment",
            " company",
            " Atlas",
            " Ele"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.297,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.195,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " revive",
            " and",
            " recreate",
            " concepts",
            " of",
            " identity",
            " in",
            " connection",
            " to",
            " traditional",
            " ethnic",
            " origins",
            ".",
            "Advanced",
            " Chemistry",
            " helped",
            " to",
            " found",
            " the",
            " German",
            " chapter",
            " of",
            " the",
            " Z",
            "ulu",
            " nation",
            ".",
            "The",
            " rivalry",
            " between",
            " Advanced",
            " Chemistry",
            " and",
            " Die",
            " Fant",
            "ast",
            "ischen",
            " V",
            "ier",
            " has",
            " served",
            " to",
            " highlight",
            " a",
            " dich",
            "otomy",
            " in",
            " the",
            " routes",
            " that",
            " hip",
            " hop",
            " has",
            " taken",
            " in",
            " becoming",
            " a",
            " part",
            " of",
            " the",
            " German",
            " sounds"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.297,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.195,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " revive",
            " and",
            " recreate",
            " concepts",
            " of",
            " identity",
            " in",
            " connection",
            " to",
            " traditional",
            " ethnic",
            " origins",
            ".",
            "Advanced",
            " Chemistry",
            " helped",
            " to",
            " found",
            " the",
            " German",
            " chapter",
            " of",
            " the",
            " Z",
            "ulu",
            " nation",
            ".",
            "The",
            " rivalry",
            " between",
            " Advanced",
            " Chemistry",
            " and",
            " Die",
            " Fant",
            "ast",
            "ischen",
            " V",
            "ier",
            " has",
            " served",
            " to",
            " highlight",
            " a",
            " dich",
            "otomy",
            " in",
            " the",
            " routes",
            " that",
            " hip",
            " hop",
            " has",
            " taken",
            " in",
            " becoming",
            " a",
            " part",
            " of",
            " the",
            " German",
            " sounds"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.289,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            "'s",
            " more",
            " exciting",
            " to",
            " experience",
            " my",
            " fellow",
            " Germans",
            " in",
            " new",
            " contexts",
            "...",
            "For",
            " me",
            ",",
            " it",
            "'s",
            " interesting",
            " to",
            " see",
            " what",
            " the",
            " kids",
            " try",
            " to",
            " do",
            " that",
            "'s",
            " different",
            " from",
            " what",
            " I",
            " know",
            ".\"",
            " ",
            " Advanced",
            " Chemistry",
            " were",
            " the",
            " first",
            " to",
            " use",
            " the",
            " term",
            " \"",
            "Af",
            "ro",
            "-G",
            "erman",
            "\"",
            " in",
            " a",
            " hip",
            " hop",
            " context",
            ".",
            " ",
            " This",
            " was",
            " part",
            " of",
            " the",
            " pro"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            1.289,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " are",
            " confused",
            " by",
            " Advanced",
            " Chemistry",
            "'s",
            " elic",
            "itation",
            " of",
            " a",
            " German",
            " identity",
            " politics",
            " to",
            " which",
            " they",
            " technically",
            " do",
            " not",
            " belong",
            ".",
            " This",
            " cultural",
            " binary",
            " illustrates",
            " that",
            " rap",
            " has",
            " taken",
            " different",
            " routes",
            " in",
            " Germany",
            " and",
            " that",
            ",",
            " even",
            " among",
            " an",
            " already",
            " isolated",
            " immigrant",
            " population",
            ",",
            " there",
            " is",
            " still",
            " dis",
            "unity",
            " and",
            ",",
            " especially",
            ",",
            " disagreement",
            " on",
            " the",
            " relative",
            " importance",
            " of",
            " assim",
            "ilation",
            " versus",
            " cultural"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.273,
            -0.0,
            -0.0
          ],
          "train_token_ind": 60,
          "is_repeated_datapoint": false,
          "tokens": [
            "3",
            " -",
            " \"",
            "Wel",
            "cher",
            " Pf",
            "ad",
            " fÃ¼h",
            "rt",
            " zur",
            " Geschichte",
            "\"",
            " (",
            "12",
            "\"/",
            "M",
            "CD",
            ",",
            " M",
            "Z",
            "EE",
            ")",
            " ",
            "199",
            "4",
            " -",
            " \"",
            "Operation",
            " Â§",
            " ",
            "3",
            "\"",
            " (",
            "12",
            "\"/",
            "M",
            "CD",
            ")",
            " ",
            "199",
            "4",
            " -",
            " \"",
            "Dir",
            " fe",
            "h",
            "lt",
            " der",
            " Funk",
            "!\"",
            " (",
            "12",
            "\"/",
            "M",
            "CD",
            ")",
            " ",
            "199",
            "5",
            " -",
            " Advanced",
            " Chemistry",
            " ("
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.258,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.273,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            "igrant",
            " sentiment",
            " emerged",
            ",",
            " as",
            " well",
            " as",
            " attacks",
            " on",
            " the",
            " homes",
            " of",
            " refugees",
            " in",
            " the",
            " early",
            " ",
            "199",
            "0",
            "s",
            ".",
            " ",
            " Advanced",
            " Chemistry",
            " came",
            " to",
            " prominence",
            " in",
            " the",
            " wake",
            " of",
            " these",
            " actions",
            " because",
            " of",
            " their",
            " pro",
            "-mult",
            "icultural",
            " society",
            " stance",
            " in",
            " their",
            " music",
            ".",
            " ",
            " Advanced",
            " Chemistry",
            "'s",
            " attitudes",
            " rev",
            "olve",
            " around",
            " their",
            " attempts",
            " to",
            " create",
            " a",
            " distinct",
            " \"",
            "G",
            "erm",
            "anness"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.258,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.273,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            "igrant",
            " sentiment",
            " emerged",
            ",",
            " as",
            " well",
            " as",
            " attacks",
            " on",
            " the",
            " homes",
            " of",
            " refugees",
            " in",
            " the",
            " early",
            " ",
            "199",
            "0",
            "s",
            ".",
            " ",
            " Advanced",
            " Chemistry",
            " came",
            " to",
            " prominence",
            " in",
            " the",
            " wake",
            " of",
            " these",
            " actions",
            " because",
            " of",
            " their",
            " pro",
            "-mult",
            "icultural",
            " society",
            " stance",
            " in",
            " their",
            " music",
            ".",
            " ",
            " Advanced",
            " Chemistry",
            "'s",
            " attitudes",
            " rev",
            "olve",
            " around",
            " their",
            " attempts",
            " to",
            " create",
            " a",
            " distinct",
            " \"",
            "G",
            "erm",
            "anness"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.266,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.227,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "cape",
            ".",
            " ",
            " While",
            " Die",
            " Fant",
            "ast",
            "ischen",
            " V",
            "ier",
            " may",
            " be",
            " said",
            " to",
            " view",
            " hip",
            " hop",
            " primarily",
            " as",
            " an",
            " aesthetic",
            " art",
            " form",
            ",",
            " ",
            " Advanced",
            " Chemistry",
            " understand",
            " hip",
            " hop",
            " as",
            " being",
            " in",
            "extr",
            "ic",
            "ably",
            " linked",
            " to",
            " the",
            " social",
            " and",
            " political",
            " circumstances",
            " under",
            " which",
            " it",
            " is",
            " created",
            ".",
            " ",
            " For",
            " Advanced",
            " Chemistry",
            ",",
            " hip",
            " hop",
            " is",
            " a",
            " “",
            "vehicle",
            " of",
            " general",
            " human"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.266,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.227,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "cape",
            ".",
            " ",
            " While",
            " Die",
            " Fant",
            "ast",
            "ischen",
            " V",
            "ier",
            " may",
            " be",
            " said",
            " to",
            " view",
            " hip",
            " hop",
            " primarily",
            " as",
            " an",
            " aesthetic",
            " art",
            " form",
            ",",
            " ",
            " Advanced",
            " Chemistry",
            " understand",
            " hip",
            " hop",
            " as",
            " being",
            " in",
            "extr",
            "ic",
            "ably",
            " linked",
            " to",
            " the",
            " social",
            " and",
            " political",
            " circumstances",
            " under",
            " which",
            " it",
            " is",
            " created",
            ".",
            " ",
            " For",
            " Advanced",
            " Chemistry",
            ",",
            " hip",
            " hop",
            " is",
            " a",
            " “",
            "vehicle",
            " of",
            " general",
            " human"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.258,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " the",
            " world",
            ",",
            " an",
            " advanced",
            " robotic",
            " dis",
            "as",
            "sembler",
            " and",
            " sorter",
            " designed",
            " by",
            " Apple",
            " Engineers",
            " in",
            " California",
            " specifically",
            " for",
            " recycling",
            " outdated",
            " or",
            " broken",
            " iPhones",
            ".",
            " Re",
            "uses",
            " and",
            " rec",
            "ycles",
            " parts",
            " from",
            " traded",
            " in",
            " products",
            ".",
            "Apple",
            " announced",
            " on",
            " August",
            " ",
            "16",
            ",",
            " ",
            "201",
            "6",
            ",",
            " that",
            " Lens",
            " Technology",
            ",",
            " one",
            " of",
            " its",
            " major",
            " suppliers",
            " in",
            " China",
            ",",
            " has",
            " committed",
            " to"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.258,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            " citizenship",
            ",",
            " and",
            " Toni",
            " L",
            ",",
            " Lingu",
            "ist",
            ",",
            " and",
            " Torch",
            " are",
            " of",
            " Italian",
            ",",
            " Ghana",
            "ian",
            ",",
            " and",
            " Hait",
            "ian",
            " backgrounds",
            ",",
            " respectively",
            ".",
            "In",
            "flu",
            "enced",
            " by",
            " North",
            " American",
            " socially",
            " conscious",
            " rap",
            " and",
            " the",
            " Native",
            " tongues",
            " movement",
            ",",
            " Advanced",
            " Chemistry",
            " is",
            " regarded",
            " as",
            " one",
            " of",
            " the",
            " main",
            " pioneers",
            " in",
            " German",
            " hip",
            " hop",
            ".",
            " They",
            " were",
            " one",
            " of",
            " the",
            " first",
            " groups",
            " to"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.242,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            " defiance",
            ".",
            " According",
            " to",
            " German",
            " hip",
            " hop",
            " enthusiast",
            " ",
            "9",
            "@",
            "home",
            ",",
            " Advanced",
            " Chemistry",
            " is",
            " part",
            " of",
            " a",
            " \"",
            "hip",
            "-hop",
            " movement",
            " [",
            "which",
            "]",
            " took",
            " a",
            " clear",
            " stance",
            " for",
            " the",
            " minorities",
            " and",
            " against",
            " the",
            " [",
            "m",
            "arg",
            "inal",
            "ization",
            "]",
            " of",
            " immigrants",
            " who",
            "...",
            "might",
            " be",
            " German",
            " on",
            " paper",
            ",",
            " but",
            " not",
            " in",
            " real",
            " life",
            ",\"",
            " which",
            " speaks",
            " to",
            " the",
            " group"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.242,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "'s",
            " hope",
            " of",
            " actually",
            " being",
            " recognized",
            " as",
            " German",
            " citizens",
            " and",
            " not",
            " foreigners",
            ",",
            " despite",
            " their",
            " various",
            " other",
            " ethnic",
            " and",
            " cultural",
            " ties",
            ".",
            "In",
            "flu",
            "ences",
            "Advanced",
            " Chemistry",
            "'s",
            " work",
            " was",
            " rooted",
            " in",
            " German",
            " history",
            " and",
            " the",
            " country",
            "'s",
            " specific",
            " political",
            " realities",
            ".",
            " However",
            ",",
            " they",
            " also",
            " drew",
            " inspiration",
            " from",
            " African",
            "-American",
            " hip",
            "-hop",
            " acts",
            " like",
            " A",
            " Tribe",
            " Called",
            " Quest",
            " and",
            " Public",
            " Enemy"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.242,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            "In",
            " ",
            "196",
            "9",
            ",",
            " the",
            " institute",
            " established",
            " the",
            " A",
            "FI",
            " Conserv",
            "atory",
            " for",
            " Advanced",
            " Film",
            " Studies",
            " at",
            " Gre",
            "ystone",
            ",",
            " the",
            " D",
            "ohen",
            "y",
            " Mansion",
            " in",
            " Beverly",
            " Hills",
            ",",
            " California",
            ".",
            " The",
            " first",
            " class",
            " included",
            " filmmakers",
            " Ter",
            "rence",
            " Mal",
            "ick",
            ",",
            " Caleb",
            " Des",
            "ch",
            "anel",
            ",",
            " and",
            " Paul",
            " Sch",
            "r",
            "ader",
            ".",
            " That",
            " program",
            " grew",
            " into",
            " the",
            " A",
            "FI",
            " Conserv",
            "atory",
            ","
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.242,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "'s",
            " hope",
            " of",
            " actually",
            " being",
            " recognized",
            " as",
            " German",
            " citizens",
            " and",
            " not",
            " foreigners",
            ",",
            " despite",
            " their",
            " various",
            " other",
            " ethnic",
            " and",
            " cultural",
            " ties",
            ".",
            "In",
            "flu",
            "ences",
            "Advanced",
            " Chemistry",
            "'s",
            " work",
            " was",
            " rooted",
            " in",
            " German",
            " history",
            " and",
            " the",
            " country",
            "'s",
            " specific",
            " political",
            " realities",
            ".",
            " However",
            ",",
            " they",
            " also",
            " drew",
            " inspiration",
            " from",
            " African",
            "-American",
            " hip",
            "-hop",
            " acts",
            " like",
            " A",
            " Tribe",
            " Called",
            " Quest",
            " and",
            " Public",
            " Enemy"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.242,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            "In",
            " ",
            "196",
            "9",
            ",",
            " the",
            " institute",
            " established",
            " the",
            " A",
            "FI",
            " Conserv",
            "atory",
            " for",
            " Advanced",
            " Film",
            " Studies",
            " at",
            " Gre",
            "ystone",
            ",",
            " the",
            " D",
            "ohen",
            "y",
            " Mansion",
            " in",
            " Beverly",
            " Hills",
            ",",
            " California",
            ".",
            " The",
            " first",
            " class",
            " included",
            " filmmakers",
            " Ter",
            "rence",
            " Mal",
            "ick",
            ",",
            " Caleb",
            " Des",
            "ch",
            "anel",
            ",",
            " and",
            " Paul",
            " Sch",
            "r",
            "ader",
            ".",
            " That",
            " program",
            " grew",
            " into",
            " the",
            " A",
            "FI",
            " Conserv",
            "atory",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.227,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.164,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " that",
            " are",
            " making",
            " the",
            " advanced",
            " technology",
            "—",
            " and",
            " the",
            " advanced",
            " manufacturing",
            " that",
            " goes",
            " with",
            " that",
            "—",
            " that",
            " quite",
            " frankly",
            " is",
            " essential",
            " to",
            " our",
            " innovation",
            ".\"",
            ",",
            " Apple",
            " uses",
            " components",
            " from",
            " ",
            "43",
            " countries",
            ".",
            " The",
            " majority",
            " of",
            " assembling",
            " is",
            " done",
            " by",
            " Taiwanese",
            " original",
            " design",
            " manufacturer",
            " firms",
            " Fox",
            "conn",
            ",",
            " Peg",
            "atron",
            ",",
            " W",
            "ist",
            "ron",
            " and",
            " Comp",
            "al",
            " Electronics",
            " with",
            " factories",
            " mostly",
            " located"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.227,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            " rap",
            " in",
            " German",
            " (",
            "although",
            " their",
            " name",
            " is",
            " in",
            " English",
            ").",
            " Furthermore",
            ",",
            " their",
            " songs",
            " tackled",
            " controversial",
            " social",
            " and",
            " political",
            " issues",
            ",",
            " distinguishing",
            " them",
            " from",
            " early",
            " German",
            " hip",
            " hop",
            " group",
            " \"",
            "Die",
            " Fant",
            "ast",
            "ischen",
            " V",
            "ier",
            "\"",
            " (",
            "The",
            " Fantastic",
            " Four",
            "),",
            " ",
            " which",
            " had",
            " a",
            " more",
            " light",
            "-hearted",
            ",",
            " playful",
            ",",
            " party",
            " image",
            ".",
            "Career",
            "Advanced",
            " Chemistry",
            " frequently",
            " r",
            "apped"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.227,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            " Chemistry",
            " is",
            " a",
            " German",
            " hip",
            " hop",
            " group",
            " from",
            " He",
            "idelberg",
            ",",
            " a",
            " scenic",
            " city",
            " in",
            " Bad",
            "en",
            "-W",
            "Ã¼",
            "rt",
            "tem",
            "berg",
            ",",
            " South",
            " Germany",
            ".",
            " Advanced",
            " Chemistry",
            " was",
            " founded",
            " in",
            " ",
            "198",
            "7",
            " by",
            " Toni",
            " L",
            ",",
            " Lingu",
            "ist",
            ",",
            " Gee",
            "-One",
            ",",
            " DJ",
            " Mike",
            " MD",
            " (",
            "Mike",
            " Dip",
            "pon",
            ")",
            " and",
            " MC",
            " Torch",
            ".",
            " Each",
            " member",
            " of",
            " the",
            " group",
            " holds",
            " German"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.219,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 27,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " silver",
            " or",
            " gold",
            ".",
            " C",
            "une",
            "iform",
            " records",
            ",",
            " dated",
            " ,",
            " found",
            " in",
            " Anat",
            "olia",
            " at",
            " the",
            " Assy",
            "rian",
            " colony",
            " of",
            " Kan",
            "esh",
            ",",
            " use",
            " an",
            " advanced",
            " system",
            " of",
            " trading",
            " computations",
            " and",
            " credit",
            " lines",
            ".",
            "H",
            "itt",
            "ite",
            " Anat",
            "olia",
            " (",
            "18",
            "th",
            "–",
            "12",
            "th",
            " century",
            " BCE",
            ")",
            "Unlike",
            " the",
            " Ak",
            "k",
            "adians",
            " and",
            " Assy",
            "rians",
            ",",
            " whose",
            " Anat",
            "olian",
            " trading"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.219,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 58,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " US",
            "),",
            " Be",
            "ow",
            "ulf",
            " (",
            "200",
            "7",
            ",",
            " US",
            "),",
            " A",
            " Christmas",
            " Carol",
            " (",
            "200",
            "9",
            ",",
            " US",
            "),",
            " The",
            " Adventures",
            " of",
            " T",
            "int",
            "in",
            " (",
            "201",
            "1",
            ",",
            " US",
            ")",
            " k",
            "och",
            "adi",
            "iyan",
            " (",
            "201",
            "4",
            ",",
            " India",
            ")",
            " Computer",
            " animation",
            " is",
            " used",
            " primarily",
            " for",
            " animation",
            " that",
            " attempts",
            " to",
            " resemble",
            " real",
            " life",
            ",",
            " using",
            " advanced",
            " rendering",
            " that",
            " mim",
            "ics"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.211,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " then",
            " as",
            " the",
            " Center",
            " for",
            " Advanced",
            " Film",
            " Studies",
            ".",
            " Also",
            " created",
            " in",
            " the",
            " early",
            " years",
            " were",
            " a",
            " rep",
            "ert",
            "ory",
            " film",
            " exhibition",
            " program",
            " at",
            " the",
            " Kennedy",
            " Center",
            " for",
            " the",
            " Performing",
            " Arts",
            " and",
            " the",
            " A",
            "FI",
            " Catalog",
            " of",
            " Feature",
            " Films",
            " —",
            " a",
            " scholarly",
            " source",
            " for",
            " American",
            " film",
            " history",
            ".",
            " The",
            " institute",
            " moved",
            " to",
            " its",
            " current",
            " eight",
            "-acre",
            " Hollywood",
            " campus",
            " in",
            " ",
            "198",
            "1",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.211
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " website",
            " of",
            " the",
            " International",
            " Aluminium",
            " Institute",
            " E",
            "medicine",
            " –",
            " Aluminium",
            " ",
            " ",
            "Chem",
            "ical",
            " elements",
            "Post",
            "-transition",
            " metals",
            "Al",
            "uminium",
            "Elect",
            "rical",
            " conduct",
            "ors",
            "Py",
            "rote",
            "chn",
            "ic",
            " fuels",
            "Air",
            "ship",
            " technology",
            "Reduc",
            "ing",
            " agents",
            "E",
            "-number",
            " additives",
            "Native",
            " element",
            " minerals",
            "Chem",
            "ical",
            " elements",
            " with",
            " face",
            "-centered",
            " cubic",
            " structure",
            "<|begin_of_text|>",
            "Advanced"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.005,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.203,
            -0.0,
            -0.0
          ],
          "train_token_ind": 60,
          "is_repeated_datapoint": false,
          "tokens": [
            " emanc",
            "ipation",
            ",”",
            ".",
            " ",
            " In",
            " their",
            " undertaking",
            " of",
            " social",
            " and",
            " political",
            " issues",
            ",",
            " the",
            " band",
            " introduced",
            " the",
            " term",
            " \"",
            "Af",
            "ro",
            "-G",
            "erman",
            "\"",
            " into",
            " the",
            " context",
            " of",
            " German",
            " hip",
            " hop",
            ",",
            " and",
            " the",
            " theme",
            " of",
            " race",
            " is",
            " highlighted",
            " in",
            " much",
            " of",
            " their",
            " music",
            ".",
            "With",
            " the",
            " release",
            " of",
            " the",
            " single",
            " “",
            "F",
            "rem",
            "d",
            " im",
            " eigenen",
            " Land",
            "”,",
            " Advanced",
            " Chemistry",
            " separated"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            1.203,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " In",
            " more",
            " advanced",
            " training",
            ",",
            " ",
            " will",
            " sometimes",
            " apply",
            " ",
            " to",
            " regain",
            " balance",
            " and",
            " pin",
            " or",
            " throw",
            " .",
            " refers",
            " to",
            " the",
            " act",
            " of",
            " receiving",
            " a",
            " technique",
            ".",
            " Good",
            " ",
            " involves",
            " attention",
            " to",
            " the",
            " technique",
            ",",
            " the",
            " partner",
            ",",
            " and",
            " the",
            " immediate",
            " environment",
            "—it",
            " is",
            " considered",
            " an",
            " active",
            " part",
            " of",
            " the",
            " process",
            " of",
            " learning",
            " a",
            "ik",
            "ido",
            ".",
            " The",
            " method",
            " of",
            " falling",
            " itself",
            " is"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.203,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 11,
          "is_repeated_datapoint": false,
          "tokens": [
            "-imm",
            "igrant",
            " political",
            " message",
            " they",
            " sent",
            " via",
            " their",
            " music",
            ".",
            "While",
            " Advanced",
            " Chemistry",
            "'s",
            " use",
            " of",
            " the",
            " German",
            " language",
            " in",
            " their",
            " rap",
            " allows",
            " them",
            " to",
            " make",
            " claims",
            " to",
            " authenticity",
            " and",
            " true",
            " German",
            " heritage",
            ",",
            " bolster",
            "ing",
            " pro",
            "-imm",
            "igration",
            " sentiment",
            ",",
            " their",
            " style",
            " can",
            " also",
            " be",
            " problematic",
            " for",
            " immigrant",
            " notions",
            " of",
            " any",
            " real",
            " ethnic",
            " roots",
            ".",
            " Indeed",
            ",",
            " part",
            " of",
            " the",
            " Turkish",
            " ethnic"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.148,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            " HÃ¶",
            "yÃ¼k",
            ",",
            " and",
            " Y",
            "um",
            "uk",
            "te",
            "pe",
            ".",
            " Ãĩ",
            "atal",
            "h",
            "Ã¶",
            "yÃ¼k",
            " (",
            "7",
            ".",
            "000",
            " BCE",
            ")",
            " is",
            " considered",
            " the",
            " most",
            " advanced",
            " of",
            " these",
            ".",
            " Ne",
            "olithic",
            " Anat",
            "olia",
            " has",
            " been",
            " proposed",
            " as",
            " the",
            " homeland",
            " of",
            " the",
            " Indo",
            "-European",
            " language",
            " family",
            ",",
            " although",
            " lingu",
            "ists",
            " tend",
            " to",
            " favour",
            " a",
            " later",
            " origin",
            " in",
            " the",
            " ste",
            "pp",
            "es",
            " north",
            " of",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.133,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            " asked",
            " about",
            " the",
            " allegations",
            ",",
            " an",
            " Apple",
            " representative",
            " referred",
            " the",
            " reporter",
            " to",
            " a",
            " section",
            " of",
            " the",
            " company",
            " policy",
            " for",
            " law",
            " enforcement",
            " guidelines",
            ",",
            " which",
            " stated",
            ",",
            " \"",
            "We",
            " review",
            " every",
            " data",
            " request",
            " for",
            " legal",
            " suff",
            "iciency",
            " and",
            " use",
            " advanced",
            " systems",
            " and",
            " processes",
            " to",
            " validate",
            " law",
            " enforcement",
            " requests",
            " and",
            " detect",
            " abuse",
            ".\"",
            "Corporate",
            " affairs",
            "Leaders",
            "hip",
            "Senior",
            " management",
            " ",
            "As",
            " of",
            " March"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.109,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            " As",
            " well",
            " as",
            " breathing",
            " with",
            " lungs",
            ",",
            " they",
            " resp",
            "ire",
            " through",
            " the",
            " many",
            " folds",
            " in",
            " their",
            " thin",
            " skin",
            ",",
            " which",
            " has",
            " cap",
            "ill",
            "aries",
            " close",
            " to",
            " the",
            " surface",
            ".",
            "The",
            " sub",
            "order",
            " Sal",
            "am",
            "andro",
            "idea",
            " contains",
            " the",
            " advanced",
            " sal",
            "am",
            "anders",
            ".",
            " They",
            " differ",
            " from",
            " the",
            " crypt",
            "ob",
            "r",
            "anch",
            "ids",
            " by",
            " having",
            " fused",
            " pre",
            "art",
            "icular",
            " bones",
            " in",
            " the",
            " lower",
            " jaw"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.008,
            -0.0
          ],
          "train_token_ind": 61,
          "is_repeated_datapoint": false,
          "tokens": [
            " formal",
            " elements",
            " for",
            " their",
            " own",
            " sake",
            ",",
            " and",
            " as",
            " m",
            "imes",
            "is",
            " or",
            " representation",
            ".",
            " Art",
            " as",
            " m",
            "imes",
            "is",
            " has",
            " deep",
            " roots",
            " in",
            " the",
            " philosophy",
            " of",
            " Aristotle",
            ".",
            " Leo",
            " Tol",
            "st",
            "oy",
            " identified",
            " art",
            " as",
            " a",
            " use",
            " of",
            " indirect",
            " means",
            " to",
            " communicate",
            " from",
            " one",
            " person",
            " to",
            " another",
            ".",
            " Bened",
            "etto",
            " Cro",
            "ce",
            " and",
            " R",
            ".",
            " G",
            ".",
            " Coll",
            "ing",
            "wood",
            " advanced",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.891,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.922,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 48,
          "is_repeated_datapoint": false,
          "tokens": [
            " up",
            ".",
            " The",
            " phrase",
            " \"",
            "as",
            " queer",
            " as",
            " a",
            " clock",
            "work",
            " orange",
            "\"",
            " is",
            " good",
            " old",
            " East",
            " London",
            " slang",
            " and",
            " it",
            " didn",
            "'t",
            " seem",
            " to",
            " me",
            " necessary",
            " to",
            " explain",
            " it",
            ".",
            " Now",
            ",",
            " obviously",
            ",",
            " I",
            " have",
            " to",
            " give",
            " it",
            " an",
            " extra",
            " meaning",
            ".",
            " I",
            "'ve",
            " implied",
            " an",
            " extra",
            " dimension",
            ".",
            " I",
            "'ve",
            " implied",
            " the",
            " junction",
            " of",
            " the",
            " organic",
            ",",
            " the",
            " lively",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.902,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 53,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            " (",
            "c",
            "lem",
            "ency",
            "),",
            " but",
            " also",
            " ",
            " (",
            "anger",
            ")",
            " and",
            " ",
            " (",
            "over",
            "-des",
            "ire",
            " for",
            " glory",
            ").",
            "Em",
            "peror",
            " Julian",
            " in",
            " his",
            " satire",
            " called",
            " \"",
            "The",
            " Ca",
            "es",
            "ars",
            "\",",
            " describes",
            " a",
            " contest",
            " between",
            " the",
            " previous",
            " Roman",
            " em",
            "per",
            "ors",
            ",",
            " with",
            " Alexander",
            " the",
            " Great",
            " called",
            " in",
            " as",
            " an",
            " extra",
            " contestant",
            ",",
            " in",
            " the",
            " presence",
            " of",
            " the",
            " assembled",
            " gods"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.898,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.08,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.08,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            " chimney",
            " can",
            " greatly",
            " influence",
            " the",
            " construction",
            " of",
            " the",
            " roof",
            " supports",
            ",",
            " creating",
            " an",
            " extra",
            " need",
            " for",
            " care",
            " in",
            " choosing",
            " the",
            " materials",
            ".",
            " The",
            " builders",
            " can",
            " make",
            " an",
            " ad",
            "obe",
            " chimney",
            " by",
            " stacking",
            " simple",
            " ad",
            "obe",
            " bricks",
            " in",
            " a",
            " similar",
            " fashion",
            " as",
            " the",
            " surrounding",
            " walls",
            ".",
            "In",
            " ",
            "192",
            "7",
            ",",
            " the",
            " Uniform",
            " Building",
            " Code",
            " (",
            "UB",
            "C",
            ")",
            " was",
            " adopted",
            " in",
            " the",
            " United"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.848,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            " wearing",
            " the",
            " correct",
            " clothes",
            ",",
            " regardless",
            " of",
            " who",
            " they",
            " were",
            ",",
            " as",
            " at",
            " the",
            " Palace",
            " of",
            " Vers",
            "ailles",
            ",",
            " where",
            " the",
            " appropriate",
            " extra",
            " accessories",
            " (",
            "silver",
            " shoe",
            " buck",
            "les",
            " and",
            " a",
            " sword",
            ")",
            " could",
            " be",
            " hired",
            " from",
            " shops",
            " outside",
            ".",
            "Special",
            " arrangements",
            " were",
            " made",
            " to",
            " allow",
            " the",
            " public",
            " to",
            " see",
            " many",
            " royal",
            " or",
            " private",
            " collections",
            " placed",
            " in",
            " galleries",
            ",",
            " as",
            " with",
            " the",
            " Orleans"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.812,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " constitute",
            " a",
            " hom",
            "olog",
            "ous",
            " series",
            " of",
            " organic",
            " compounds",
            " in",
            " which",
            " the",
            " members",
            " differ",
            " in",
            " molecular",
            " mass",
            " by",
            " multiples",
            " of",
            " ",
            "14",
            ".",
            "03",
            "Âł",
            "u",
            " (",
            "the",
            " total",
            " mass",
            " of",
            " each",
            " such",
            " meth",
            "ylene",
            "-",
            "bridge",
            " unit",
            ",",
            " which",
            " comprises",
            " a",
            " single",
            " carbon",
            " atom",
            " of",
            " mass",
            " ",
            "12",
            ".",
            "01",
            "Âł",
            "u",
            " and",
            " two",
            " hydrogen",
            " atoms",
            " of",
            " mass",
            " ~",
            "1",
            ".",
            "01"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.809,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            " each",
            " carbon",
            " added",
            " to",
            " the",
            " chain",
            ";",
            " this",
            " rule",
            " applies",
            " to",
            " other",
            " hom",
            "olog",
            "ous",
            " series",
            ".",
            "A",
            " straight",
            "-chain",
            " alk",
            "ane",
            " will",
            " have",
            " a",
            " boiling",
            " point",
            " higher",
            " than",
            " a",
            " bran",
            "ched",
            "-chain",
            " alk",
            "ane",
            " due",
            " to",
            " the",
            " greater",
            " surface",
            " area",
            " in",
            " contact",
            ",",
            " and",
            " thus",
            " greater",
            " van",
            " der",
            " Wa",
            "als",
            " forces",
            ",",
            " between",
            " adjacent",
            " molecules",
            ".",
            " For",
            " example",
            ",",
            " compare",
            " is",
            "ob"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.766,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 17,
          "is_repeated_datapoint": false,
          "tokens": [
            " example",
            " of",
            " group",
            " trends",
            " in",
            " properties",
            " in",
            " the",
            " periodic",
            " table",
            ",",
            " with",
            " elements",
            " exhibiting",
            " well",
            "-character",
            "ised",
            " hom",
            "olog",
            "ous",
            " behaviour",
            ".",
            " This",
            " family",
            " of",
            " elements",
            " is",
            " also",
            " known",
            " as",
            " the",
            " lithium",
            " family",
            " after",
            " its",
            " leading",
            " element",
            ".",
            "The",
            " alk",
            "ali",
            " metals",
            " are",
            " all",
            " shiny",
            ",",
            " soft",
            ",",
            " highly",
            " reactive",
            " metals",
            " at",
            " standard",
            " temperature",
            " and",
            " pressure",
            " and",
            " readily",
            " lose",
            " their",
            " outer",
            "most",
            " electron"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.723,
            -0.0,
            -0.0,
            -0.0,
            0.742,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            " weaker",
            " than",
            " Z",
            "FC",
            ",",
            " such",
            " as",
            " second",
            "-order",
            " arithmetic",
            ".",
            "The",
            " study",
            " of",
            " topology",
            " in",
            " mathematics",
            " extends",
            " all",
            " over",
            " through",
            " point",
            " set",
            " topology",
            ",",
            " algebra",
            "ic",
            " topology",
            ",",
            " differential",
            " topology",
            ",",
            " and",
            " all",
            " the",
            " related",
            " paraph",
            "ernal",
            "ia",
            ",",
            " such",
            " as",
            " hom",
            "ology",
            " theory",
            ",",
            " hom",
            "ot",
            "opy",
            " theory",
            ".",
            " The",
            " development",
            " of",
            " abstract",
            " algebra",
            " brought",
            " with",
            " itself",
            " group",
            " theory",
            ",",
            " rings"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.001,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.707,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 59,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            " Apollo",
            " used",
            " his",
            " bow",
            " and",
            " golden",
            " arrow",
            " to",
            " shed",
            " light",
            " upon",
            " an",
            " island",
            ",",
            " where",
            " the",
            " Arg",
            "onaut",
            "s",
            " soon",
            " took",
            " shelter",
            ".",
            " This",
            " island",
            " was",
            " renamed",
            " \"",
            "An",
            "ap",
            "he",
            "\",",
            " which",
            " means",
            " \"",
            "He",
            " revealed",
            " it",
            "\".",
            "Apollo",
            " helped",
            " the",
            " Greek",
            " hero",
            " Di",
            "omed",
            "es",
            ",",
            " to",
            " escape",
            " from",
            " a",
            " great",
            " tem",
            "pest",
            " during",
            " his",
            " journey",
            " hom",
            "eward",
            ".",
            " As"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " a",
            " distraction",
            " not",
            " only",
            " for",
            " me",
            " and",
            " my",
            " family",
            ",",
            " but",
            " everyone",
            " else",
            " at",
            " Apple",
            " as",
            " well",
            "\",",
            " and",
            " explained",
            " that",
            " the",
            " break",
            " would",
            " allow",
            " the",
            " company",
            " \"",
            "to",
            " focus",
            " on",
            " delivering",
            " extraordinary",
            " products",
            "\".",
            " Though",
            " Jobs",
            " was",
            " absent",
            ",",
            " Apple",
            " recorded",
            " its",
            " best",
            " non",
            "-h",
            "oliday",
            " quarter",
            " (",
            "Q",
            "1",
            " FY",
            " ",
            "200",
            "9",
            ")",
            " during",
            " the",
            " recession",
            " with",
            " revenue",
            " of",
            " $"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.475,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 42,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " cause",
            " damage",
            " in",
            " and",
            " of",
            " themselves",
            ".",
            " For",
            " instance",
            ",",
            " Go",
            "zo",
            " Sh",
            "iod",
            "a",
            " described",
            " using",
            " ",
            " in",
            " a",
            " brawl",
            " to",
            " quickly",
            " down",
            " a",
            " gang",
            "'s",
            " leader",
            ".",
            " Others",
            " consider",
            " ,",
            " especially",
            " to",
            " the",
            " face",
            ",",
            " to",
            " be",
            " methods",
            " of",
            " distraction",
            " meant",
            " to",
            " enable",
            " other",
            " techniques",
            ";",
            " a",
            " strike",
            ",",
            " even",
            " if",
            " it",
            " is",
            " blocked",
            ",",
            " can",
            " start",
            "le",
            " the",
            " target"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.408,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " Achilles",
            " fights",
            " and",
            " kills",
            " the",
            " warrior",
            " queen",
            ",",
            " only",
            " to",
            " g",
            "rieve",
            " over",
            " her",
            " death",
            " later",
            ".",
            " Initially",
            " taken",
            " ab",
            "ack",
            ",",
            " he",
            " did",
            " not",
            " fight",
            " as",
            " intensely",
            " as",
            " usual",
            ".",
            " Once",
            " he",
            " realized",
            " that",
            " his",
            " distraction",
            " was",
            " endanger",
            "ing",
            " his",
            " life",
            ",",
            " he",
            " ref",
            "ocused",
            " and",
            " killed",
            " her",
            ".",
            "Following",
            " the",
            " death",
            " of",
            " Pat",
            "ro",
            "clus",
            ",",
            " Nest",
            "or",
            "'s",
            " son"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.32,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 59,
          "is_repeated_datapoint": false,
          "tokens": [
            "r",
            ".",
            " ",
            "364",
            "–",
            "375",
            ")",
            " was",
            " acclaimed",
            " emperor",
            " at",
            " A",
            "ncy",
            "ra",
            ",",
            " and",
            " in",
            " the",
            " next",
            " year",
            " his",
            " brother",
            " Val",
            "ens",
            " (",
            "r",
            ".",
            " ",
            "364",
            "–",
            "378",
            ")",
            " used",
            " A",
            "ncy",
            "ra",
            " as",
            " his",
            " base",
            " against",
            " the",
            " usur",
            "per",
            " Pro",
            "cop",
            "ius",
            ".",
            " When",
            " the",
            " province",
            " of",
            " Gal",
            "at",
            "ia",
            " was",
            " divided",
            " sometime",
            " in",
            " ",
            "396",
            "/",
            "99",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.299,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 36,
          "is_repeated_datapoint": false,
          "tokens": [
            " Index",
            ",",
            " Afghanistan",
            " is",
            " the",
            " ",
            "15",
            "th",
            " least",
            " developed",
            " country",
            " in",
            " the",
            " world",
            ".",
            " The",
            " average",
            " life",
            " expectancy",
            " is",
            " estimated",
            " to",
            " be",
            " around",
            " ",
            "60",
            " years",
            ".",
            " The",
            " country",
            "'s",
            " maternal",
            " mortality",
            " rate",
            " is",
            " ",
            "396",
            " deaths",
            "/",
            "100",
            ",",
            "000",
            " live",
            " births",
            " and",
            " its",
            " infant",
            " mortality",
            " rate",
            " is",
            " ",
            "66",
            " to",
            " ",
            "112",
            ".",
            "8",
            " deaths",
            " in",
            " every",
            " ",
            "1",
            ","
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " reversed",
            " and",
            " Ar",
            "sl",
            "an",
            " was",
            " imprisoned",
            " by",
            " the",
            " Byz",
            "ant",
            "ines",
            ".",
            " Roman",
            "os",
            " blunt",
            "ly",
            " answered",
            " \"",
            "The",
            " worst",
            "!\"",
            " His",
            " honesty",
            " impressed",
            " Ar",
            "sl",
            "an",
            ",",
            " who",
            " then",
            " decided",
            " to",
            " spare",
            " Roman",
            "os",
            "'s",
            " life",
            " and",
            " instead",
            " ransom",
            " him",
            " back",
            " to",
            " his",
            " homeland",
            ".",
            " After",
            " agreeing",
            " on",
            " a",
            " ransom",
            ",",
            " Al",
            "p",
            " Ar",
            "sl",
            "an",
            " sent",
            " Roman",
            "os",
            " to",
            " Constantin"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " typically",
            " composed",
            " of",
            " ",
            "5",
            "%",
            " bit",
            "umen",
            " (",
            "known",
            " as",
            " asphalt",
            " cement",
            " in",
            " the",
            " US",
            ")",
            " and",
            " ",
            "95",
            "%",
            " aggregates",
            " (",
            "stone",
            ",",
            " sand",
            ",",
            " and",
            " gravel",
            ").",
            " Due",
            " to",
            " its",
            " highly",
            " visc",
            "ous",
            " nature",
            ",",
            " bit",
            "umen",
            " must",
            " be",
            " heated",
            " so",
            " it",
            " can",
            " be",
            " mixed",
            " with",
            " the",
            " aggregates",
            " at",
            " the",
            " asphalt",
            " mixing",
            " facility",
            ".",
            " The",
            " temperature",
            " required",
            " varies",
            " depending",
            " upon"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " Del",
            "ph",
            "ic",
            " Myth",
            " and",
            " Its",
            " Origins",
            ",",
            " University",
            " of",
            " California",
            " Press",
            ",",
            " ",
            "195",
            "9",
            ".",
            " .",
            " G",
            "antz",
            ",",
            " Timothy",
            ",",
            " Early",
            " Greek",
            " Myth",
            ":",
            " A",
            " Guide",
            " to",
            " Literary",
            " and",
            " Art",
            "istic",
            " Sources",
            ",",
            " Johns",
            " Hopkins",
            " University",
            " Press",
            ",",
            " ",
            "199",
            "6",
            ",",
            " Two",
            " volumes",
            ":",
            " ",
            " (",
            "Vol",
            ".",
            " ",
            "1",
            "),",
            " ",
            " (",
            "Vol",
            ".",
            " ",
            "2",
            ").",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "ore",
            ",",
            " K",
            "anga",
            ",",
            " Roo",
            " and",
            " T",
            "igger",
            ",",
            " were",
            " incorporated",
            " into",
            " A",
            ".",
            " A",
            ".",
            " Mil",
            "ne",
            "'s",
            " stories",
            ",",
            " and",
            " two",
            " more",
            " characters",
            "Âł",
            "–",
            " Rabbit",
            " and",
            " Owl",
            "Âł",
            "–",
            " were",
            " created",
            " by",
            " Mil",
            "ne",
            "'s",
            " imagination",
            ".",
            " Christopher",
            " Robin",
            " Mil",
            "ne",
            "'s",
            " own",
            " toys",
            " are",
            " now",
            " on",
            " display",
            " in",
            " New",
            " York",
            " where",
            " ",
            "750",
            ",",
            "000",
            " people",
            " visit",
            " them"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " country",
            "'s",
            " human",
            " rights",
            " record",
            ",",
            " including",
            " increasing",
            " restrictions",
            " on",
            " civil",
            " liberties",
            ",",
            " particularly",
            " on",
            " press",
            " freedom",
            " and",
            " political",
            " repression",
            ".",
            "Et",
            "ymology",
            " ",
            "According",
            " to",
            " a",
            " modern",
            " et",
            "ymology",
            ",",
            " the",
            " term",
            " Azerbaijan",
            " derives",
            " from",
            " that",
            " of",
            " At",
            "rop",
            "ates",
            ",",
            " a",
            " Persian",
            " sat",
            "rap",
            " under",
            " the",
            " A",
            "cha",
            "emen",
            "id",
            " Empire",
            ",",
            " who",
            " was",
            " later",
            " reinst",
            "ated",
            " as",
            " the",
            " sat"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    ".GroupLayout",
    " BÃŃ",
    " massaggi",
    " pij",
    "ije"
  ],
  "bottom_logits": [
    " millions",
    " melt",
    " Earth",
    " Tan",
    " Erf"
  ],
  "act_min": -0.0,
  "act_max": 1.383
}
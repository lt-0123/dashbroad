{
  "index": 65061,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            1.102,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "Texas",
            " A",
            "&M",
            " University",
            ")",
            " Civil",
            " Service",
            " Day",
            " (",
            "India",
            ")",
            " Day",
            " of",
            " Local",
            " Self",
            "-G",
            "overnment",
            " (",
            "Russia",
            ")",
            " G",
            "rou",
            "nation",
            " Day",
            " (",
            "R",
            "ast",
            "afari",
            " movement",
            ")",
            " Hero",
            "ic",
            " Defense",
            " of",
            " Ver",
            "ac",
            "ruz",
            " (",
            "Mexico",
            ")",
            " Kang",
            " Pan",
            "-s",
            "ok",
            "'s",
            " Birthday",
            " (",
            "North",
            " Korea",
            ")",
            " Kart",
            "ini",
            " Day",
            " (",
            "Ind",
            "onesia",
            ")",
            " Local",
            " Self",
            " Government",
            " Day",
            " (",
            "Russia"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.102,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "Texas",
            " A",
            "&M",
            " University",
            ")",
            " Civil",
            " Service",
            " Day",
            " (",
            "India",
            ")",
            " Day",
            " of",
            " Local",
            " Self",
            "-G",
            "overnment",
            " (",
            "Russia",
            ")",
            " G",
            "rou",
            "nation",
            " Day",
            " (",
            "R",
            "ast",
            "afari",
            " movement",
            ")",
            " Hero",
            "ic",
            " Defense",
            " of",
            " Ver",
            "ac",
            "ruz",
            " (",
            "Mexico",
            ")",
            " Kang",
            " Pan",
            "-s",
            "ok",
            "'s",
            " Birthday",
            " (",
            "North",
            " Korea",
            ")",
            " Kart",
            "ini",
            " Day",
            " (",
            "Ind",
            "onesia",
            ")",
            " Local",
            " Self",
            " Government",
            " Day",
            " (",
            "Russia"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            1.07,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            "—",
            "Texas",
            ",",
            " Alabama",
            ",",
            " and",
            " Virginia",
            "—",
            "specific",
            "ally",
            " mentioned",
            " the",
            " plight",
            " of",
            " the",
            " \"",
            "slave",
            "holding",
            " states",
            "\"",
            " at",
            " the",
            " hands",
            " of",
            " Northern",
            " abolition",
            "ists",
            ".",
            " The",
            " rest",
            " make",
            " no",
            " mention",
            " of",
            " the",
            " slavery",
            " issue",
            " and",
            " are",
            " often",
            " brief",
            " announcements",
            " of",
            " the",
            " dissolution",
            " of",
            " ties",
            " by",
            " the",
            " legisl",
            "atures",
            ".",
            " However",
            ",",
            " at",
            " least",
            " four",
            " states",
            "—",
            "South",
            " Carolina",
            ",",
            " Mississippi"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.055,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 52,
          "is_repeated_datapoint": false,
          "tokens": [
            " criminal",
            " appeals",
            "Civil",
            "ian",
            "Court",
            " of",
            " Criminal",
            " Appeal",
            " (",
            "England",
            " and",
            " Wales",
            "),",
            " abolished",
            " ",
            "196",
            "6",
            "Court",
            " of",
            " Criminal",
            " Appeal",
            " (",
            "I",
            "reland",
            "),",
            " abolished",
            " ",
            "201",
            "4",
            " U",
            ".S",
            ".",
            " States",
            ":",
            "Alabama",
            " Court",
            " of",
            " Criminal",
            " Appeals",
            "O",
            "kl",
            "ahoma",
            " Court",
            " of",
            " Criminal",
            " Appeals",
            "T",
            "ennessee",
            " Court",
            " of",
            " Criminal",
            " Appeals",
            "Texas",
            " Court",
            " of",
            " Criminal"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.039,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.047,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            " is",
            " by",
            " far",
            " the",
            " largest",
            " state",
            " in",
            " the",
            " United",
            " States",
            ".",
            " Alaska",
            " is",
            " more",
            " than",
            " twice",
            " the",
            " size",
            " of",
            " the",
            " second",
            "-largest",
            " U",
            ".S",
            ".",
            " state",
            " (",
            "Texas",
            "),",
            " and",
            " it",
            " is",
            " larger",
            " than",
            " the",
            " next",
            " three",
            " largest",
            " states",
            " (",
            "Texas",
            ",",
            " California",
            ",",
            " and",
            " Montana",
            ")",
            " combined",
            ".",
            " Alaska",
            " is",
            " the",
            " seventh",
            " largest",
            " sub",
            "national",
            " division",
            " in",
            " the",
            " world",
            ".",
            " If",
            " it"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.039,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.047,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            " is",
            " by",
            " far",
            " the",
            " largest",
            " state",
            " in",
            " the",
            " United",
            " States",
            ".",
            " Alaska",
            " is",
            " more",
            " than",
            " twice",
            " the",
            " size",
            " of",
            " the",
            " second",
            "-largest",
            " U",
            ".S",
            ".",
            " state",
            " (",
            "Texas",
            "),",
            " and",
            " it",
            " is",
            " larger",
            " than",
            " the",
            " next",
            " three",
            " largest",
            " states",
            " (",
            "Texas",
            ",",
            " California",
            ",",
            " and",
            " Montana",
            ")",
            " combined",
            ".",
            " Alaska",
            " is",
            " the",
            " seventh",
            " largest",
            " sub",
            "national",
            " division",
            " in",
            " the",
            " world",
            ".",
            " If",
            " it"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            1.031,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.84,
            -0.0,
            0.088,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.015,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " Johnston",
            " (",
            "Texas",
            " State",
            " Cemetery",
            "),",
            " a",
            " ",
            "190",
            "3",
            " memorial",
            " sculpture",
            " by",
            " Elis",
            "abet",
            " Ney",
            " Statue",
            " of",
            " Albert",
            " Sidney",
            " Johnston",
            " (",
            "University",
            " of",
            " Texas",
            " at",
            " Austin",
            "),",
            " a",
            " statue",
            " by",
            " Pompeo",
            " Copp",
            "ini",
            " List",
            " of",
            " American",
            " Civil",
            " War",
            " generals",
            " (",
            "Conf",
            "eder",
            "ate",
            ")",
            " List",
            " of",
            " Confederate",
            " monuments",
            " and",
            " memor",
            "ials",
            "Notes",
            "References",
            " Bea",
            "ure",
            "gard",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.023,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 15,
          "is_repeated_datapoint": false,
          "tokens": [
            ")",
            " National",
            " Tree",
            " Plant",
            "ing",
            " Day",
            " (",
            "Ken",
            "ya",
            ")",
            " San",
            " Jac",
            "into",
            " Day",
            " (",
            "Texas",
            ")",
            " Queen",
            "'s",
            " Official",
            " Birthday",
            " (",
            "F",
            "alk",
            "land",
            " Islands",
            ")",
            " Tir",
            "ad",
            "entes",
            "'",
            " Day",
            " (",
            "Brazil",
            ")",
            " Vietnam",
            " Book",
            " Day",
            " (",
            "Viet",
            "nam",
            ")",
            " April",
            " ",
            "22",
            " Discovery",
            " Day",
            " (",
            "Brazil",
            ")",
            " Earth",
            " Day",
            " (",
            "International",
            " observ",
            "ance",
            ")",
            " and",
            " its",
            " related",
            " observ",
            "ance"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.016,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 39,
          "is_repeated_datapoint": false,
          "tokens": [
            "P",
            "ap",
            "ua",
            " New",
            " Guinea",
            ")",
            " Women",
            "'s",
            " Equality",
            " Day",
            " (",
            "United",
            " States",
            ")",
            " August",
            " ",
            "27",
            " Film",
            " and",
            " Movies",
            " Day",
            " (",
            "Russia",
            ")",
            " Independence",
            " Day",
            " of",
            " the",
            " Republic",
            " of",
            " Mold",
            "ova",
            " Ly",
            "ndon",
            " B",
            "aines",
            " Johnson",
            " Day",
            " (",
            "Texas",
            ",",
            " United",
            " States",
            ")",
            " National",
            " Banana",
            " L",
            "overs",
            " Day",
            " (",
            "United",
            " States",
            ")",
            " National",
            " P",
            "ots",
            " De",
            " C",
            "reme",
            " Day",
            " ("
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.016,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.012,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 21,
          "is_repeated_datapoint": false,
          "tokens": [
            " celebrates",
            " the",
            " independence",
            " of",
            " Mold",
            "ova",
            " from",
            " the",
            " USSR",
            " in",
            " ",
            "199",
            "1",
            ".",
            "Ly",
            "ndon",
            " B",
            "aines",
            " Johnson",
            " Day",
            " (",
            "Texas",
            ",",
            " United",
            " States",
            ")",
            "References",
            "External",
            " links",
            "  ",
            " ",
            "Days",
            " of",
            " the",
            " year",
            "August",
            "<|begin_of_text|>",
            "In",
            " chemistry",
            ",",
            " an",
            " alcohol",
            " is",
            " a",
            " type",
            " of",
            " organic",
            " compound",
            " that",
            " carries",
            " at",
            " least",
            " one",
            " hydro",
            "x",
            "yl",
            " ()",
            " functional",
            " group",
            " "
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            1.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " Texas",
            " Press",
            ".",
            " .",
            " .",
            " ",
            " .",
            " .",
            " Morgan",
            ",",
            " Janet",
            " P",
            ".",
            " (",
            "198",
            "4",
            ").",
            " Ag",
            "atha",
            " Christie",
            ":",
            " A",
            " Biography",
            ".",
            " London",
            ":",
            " Harper",
            "Coll",
            "ins",
            ".",
            " .",
            " Retrieved",
            " ",
            "8",
            " March",
            " ",
            "201",
            "5",
            ".",
            " Pr",
            "ich",
            "ard",
            ",",
            " Math",
            "ew",
            " (",
            "201",
            "2",
            ").",
            " The",
            " Grand",
            " Tour",
            ":",
            " Around",
            " The",
            " World",
            " With",
            " The",
            " Queen",
            " Of",
            " Mystery",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.992,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " Texas",
            ".",
            " Some",
            " of",
            " its",
            " cases",
            " have",
            " been",
            " highly",
            " controversial",
            ";",
            " the",
            " U",
            ".S",
            ".",
            " Supreme",
            " Court",
            " has",
            " overturned",
            " ",
            "24",
            " convictions",
            " in",
            " death",
            " penalty",
            " cases",
            ".",
            " It",
            " was",
            " the",
            " only",
            " state",
            " to",
            " allow",
            " judges",
            " to",
            " override",
            " jury",
            " decisions",
            " in",
            " whether",
            " or",
            " not",
            " to",
            " use",
            " a",
            " death",
            " sentence",
            ";",
            " in",
            " ",
            "10",
            " cases",
            " judges",
            " overturned",
            " sentences",
            " of",
            " life",
            " imprisonment",
            " without",
            " parole",
            " that"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.992,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " such",
            " as",
            " the",
            " Texas",
            " Court",
            " of",
            " Criminal",
            " Appeals",
            ",",
            " which",
            " only",
            " hears",
            " appeals",
            " raised",
            " in",
            " criminal",
            " cases",
            ",",
            " and",
            " the",
            " U",
            ".S",
            ".",
            " Court",
            " of",
            " Appeals",
            " for",
            " the",
            " Federal",
            " Circuit",
            ",",
            " which",
            " has",
            " general",
            " jurisdiction",
            " but",
            " derives",
            " most",
            " of",
            " its",
            " cas",
            "eload",
            " from",
            " patent",
            " cases",
            ",",
            " on",
            " one",
            " hand",
            ",",
            " and",
            " appeals",
            " from",
            " the",
            " Court",
            " of",
            " Federal",
            " Claims",
            " on",
            " the",
            " other",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.98,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            " subsequent",
            " missions",
            ",",
            " extra",
            " anti",
            "-s",
            "lo",
            "sh",
            " baff",
            "les",
            " were",
            " added",
            " to",
            " the",
            " tanks",
            " to",
            " prevent",
            " this",
            ".",
            "Arm",
            "strong",
            " acknowledged",
            " Ald",
            "rin",
            "'s",
            " completion",
            " of",
            " the",
            " post",
            "-",
            "landing",
            " checklist",
            " with",
            " \"",
            "Engine",
            " arm",
            " is",
            " off",
            "\",",
            " before",
            " responding",
            " to",
            " the",
            " CAP",
            "COM",
            ",",
            " Charles",
            " Duke",
            ",",
            " with",
            " the",
            " words",
            ",",
            " \"",
            "Houston",
            ",",
            " Tran",
            "qu",
            "ility",
            " Base",
            " here",
            ".",
            " The"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.969,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            "7",
            " –",
            " The",
            " Texas",
            " Rangers",
            " defeat",
            " the",
            " Baltimore",
            " Orioles",
            " ",
            "30",
            "–",
            "3",
            ",",
            " the",
            " most",
            " runs",
            " scored",
            " by",
            " a",
            " team",
            " in",
            " modern",
            " Major",
            " League",
            " Baseball",
            " history",
            ".",
            "201",
            "2",
            " –",
            " Ethnic",
            " clashes",
            " over",
            " grazing",
            " rights",
            " for",
            " cattle",
            " in",
            " Kenya",
            "'s",
            " T",
            "ana",
            " River",
            " District",
            " result",
            " in",
            " more",
            " than",
            " ",
            "52",
            " deaths",
            ".",
            "Birth",
            "s",
            "Pre",
            "-",
            "160",
            "0",
            "141",
            "2"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.961,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " Georgia",
            ",",
            " and",
            " Texas",
            "—",
            "also",
            " passed",
            " lengthy",
            " and",
            " detailed",
            " explanations",
            " of",
            " their",
            " reasons",
            " for",
            " se",
            "cession",
            ",",
            " all",
            " of",
            " which",
            " laid",
            " the",
            " blame",
            " squarely",
            " on",
            " the",
            " movement",
            " to",
            " abolish",
            " slavery",
            " and",
            " that",
            " movement",
            "'s",
            " influence",
            " over",
            " the",
            " politics",
            " of",
            " the",
            " Northern",
            " states",
            ".",
            " The",
            " Southern",
            " states",
            " believed",
            " slave",
            "holding",
            " was",
            " a",
            " constitutional",
            " right",
            " because",
            " of",
            " the",
            " F",
            "ug",
            "itive",
            " Slave",
            " Clause"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.957,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " France",
            " or",
            " of",
            " Texas",
            ".",
            " It",
            " lies",
            " mostly",
            " between",
            " lat",
            "itudes",
            " ",
            "4",
            "Â°",
            " and",
            " ",
            "18",
            "Â°",
            "S",
            ",",
            " and",
            " long",
            "itudes",
            " ",
            "12",
            "Â°",
            " and",
            " ",
            "24",
            "Â°E",
            ".",
            "Ang",
            "ola",
            " borders",
            " Nam",
            "ibia",
            " to",
            " the",
            " south",
            ",",
            " Zambia",
            " to",
            " the",
            " east",
            ",",
            " the",
            " Democratic",
            " Republic",
            " of",
            " the",
            " Congo",
            " to",
            " the",
            " north",
            "-east",
            " and",
            " the",
            " South",
            " Atlantic",
            " Ocean",
            " to",
            " the",
            " west"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.957,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            " known",
            " as",
            " \"",
            "The",
            " Cotton",
            " State",
            "\",",
            " Alabama",
            " ranks",
            " between",
            " eighth",
            " and",
            " tenth",
            " in",
            " national",
            " cotton",
            " production",
            ",",
            " according",
            " to",
            " various",
            " reports",
            ",",
            " with",
            " Texas",
            ",",
            " Georgia",
            " and",
            " Mississippi",
            " comprising",
            " the",
            " top",
            " three",
            ".",
            "Aqu",
            "ac",
            "ulture",
            " ",
            "Aqu",
            "ac",
            "ulture",
            " is",
            " a",
            " large",
            " part",
            " of",
            " the",
            " economy",
            " of",
            " Alabama",
            ".",
            " Al",
            "ab",
            "am",
            "ians",
            " began",
            " to",
            " practice",
            " aqu",
            "ac",
            "ulture",
            " in",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.953,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.004,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.898,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " be",
            " erected",
            " at",
            " the",
            " grave",
            " site",
            ",",
            " installed",
            " in",
            " ",
            "190",
            "5",
            ".",
            "The",
            " Texas",
            " Historical",
            " Commission",
            " has",
            " erected",
            " a",
            " historical",
            " marker",
            " near",
            " the",
            " entrance",
            " of",
            " what",
            " was",
            " once",
            " Johnston",
            "'s",
            " plantation",
            ".",
            " An",
            " adjacent",
            " marker",
            " was",
            " erected",
            " by",
            " the",
            " San",
            " Jac",
            "into",
            " Chapter",
            " of",
            " the",
            " Da",
            "ughters",
            " of",
            " The",
            " Republic",
            " of",
            " Texas",
            " and",
            " the",
            " Lee",
            ",",
            " Roberts",
            ",",
            " and",
            " Davis",
            " Chapter",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.945,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            " K",
            "PM",
            "G",
            " are",
            " some",
            " of",
            " the",
            " other",
            " companies",
            " in",
            " the",
            " financial",
            " services",
            " industry",
            " that",
            " have",
            " offices",
            " in",
            " Ant",
            "igua",
            ".",
            " The",
            " United",
            " States",
            " Securities",
            " and",
            " Exchange",
            " Commission",
            " has",
            " leveled",
            " allegations",
            " against",
            " the",
            " Ant",
            "igua",
            "-based",
            " Stanford",
            " International",
            " Bank",
            ",",
            " which",
            " is",
            " owned",
            " by",
            " the",
            " Texas",
            " billionaire",
            " Allen",
            " Stanford",
            ",",
            " of",
            " orchestr",
            "ating",
            " a",
            " massive",
            " fraud",
            " that",
            " may",
            " have",
            " resulted",
            " in",
            " the",
            " theft"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.945,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            "clamation",
            " into",
            " effect",
            " in",
            " Texas",
            " and",
            " freeing",
            " the",
            " last",
            " slaves",
            " of",
            " the",
            " Confeder",
            "acy",
            ".",
            " The",
            " anniversary",
            " of",
            " this",
            " date",
            " is",
            " now",
            " celebrated",
            " as",
            " Jun",
            "ete",
            "enth",
            ".",
            "The",
            " naval",
            " portion",
            " of",
            " the",
            " war",
            " ended",
            " more",
            " slowly",
            ".",
            " It",
            " had",
            " begun",
            " on",
            " April",
            " ",
            "11",
            ",",
            " ",
            "186",
            "5",
            ",",
            " two",
            " days",
            " after",
            " Lee",
            "'s",
            " surrender",
            ",",
            " when",
            " President",
            " Lincoln",
            " proclaimed",
            " that",
            " foreign"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.918,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.945,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            " Indian",
            " frontier",
            " of",
            " Texas",
            ".",
            " He",
            " served",
            " on",
            " the",
            " Texas",
            " frontier",
            " at",
            " Fort",
            " Mason",
            " and",
            " elsewhere",
            " in",
            " the",
            " western",
            " United",
            " States",
            ".",
            "In",
            " ",
            "185",
            "5",
            ",",
            " ",
            "14",
            "th",
            " president",
            " Franklin",
            " Pierce",
            " appointed",
            " him",
            " colon",
            "el",
            " of",
            " the",
            " new",
            " ",
            "2",
            "nd",
            " U",
            ".S",
            ".",
            " Caval",
            "ry",
            " (",
            "the",
            " unit",
            " that",
            " preceded",
            " the",
            " modern",
            " ",
            "5",
            "th",
            " U",
            ".S",
            ".),",
            " a",
            " new"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.945,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.926,
            -0.0,
            -0.0,
            -0.0,
            0.067,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            " New",
            " Orleans",
            ".",
            " In",
            " ",
            "186",
            "6",
            ",",
            " a",
            " joint",
            " resolution",
            " of",
            " the",
            " Texas",
            " Legislature",
            " was",
            " passed",
            " to",
            " have",
            " his",
            " body",
            " moved",
            " and",
            " re",
            "inter",
            "red",
            " at",
            " the",
            " Texas",
            " State",
            " Cemetery",
            " in",
            " Austin",
            ".",
            " The",
            " re",
            "-inter",
            "ment",
            " occurred",
            " in",
            " ",
            "186",
            "7",
            ".",
            " Forty",
            " years",
            " later",
            ",",
            " the",
            " state",
            " appointed",
            " Elis",
            "abet",
            " Ney",
            " to",
            " design",
            " a",
            " monument",
            " and",
            " sculpture",
            " of",
            " him",
            " to"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.945,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 15,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " slightly",
            " bigger",
            " than",
            " France",
            " and",
            " smaller",
            " than",
            " Myanmar",
            ",",
            " and",
            " about",
            " the",
            " size",
            " of",
            " Texas",
            " in",
            " the",
            " United",
            " States",
            ".",
            " There",
            " is",
            " no",
            " coastline",
            ",",
            " as",
            " Afghanistan",
            " is",
            " land",
            "locked",
            ".",
            " Afghanistan",
            " shares",
            " its",
            " longest",
            " land",
            " border",
            " (",
            "the",
            " Dur",
            "and",
            " Line",
            ")",
            " with",
            " Pakistan",
            " to",
            " the",
            " east",
            " and",
            " south",
            ",",
            " followed",
            " by",
            " borders",
            " with",
            " Taj",
            "ik",
            "istan",
            " to",
            " the",
            " northeast",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.941,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.005,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            " In",
            " the",
            " United",
            " States",
            ",",
            " Alabama",
            ",",
            " Tennessee",
            ",",
            " and",
            " Oklahoma",
            " also",
            " have",
            " separate",
            " courts",
            " of",
            " criminal",
            " appeals",
            ".",
            " Texas",
            " and",
            " Oklahoma",
            " have",
            " the",
            " final",
            " determination",
            " of",
            " criminal",
            " cases",
            " vested",
            " in",
            " their",
            " respective",
            " courts",
            " of",
            " criminal",
            " appeals",
            ",",
            " while",
            " Alabama",
            " and",
            " Tennessee",
            " allow",
            " decisions",
            " of",
            " its",
            " court",
            " of",
            " criminal",
            " appeals",
            " to",
            " be",
            " finally",
            " appealed",
            " to",
            " the",
            " state",
            " supreme",
            " court",
            ".",
            "Cour",
            "ts",
            " of"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.002,
            -0.0,
            -0.0,
            0.938,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 36,
          "is_repeated_datapoint": false,
          "tokens": [
            " square",
            " miles",
            "),",
            " the",
            " section",
            " (",
            "one",
            " square",
            " mile",
            "),",
            " and",
            " the",
            " quarter",
            " section",
            " (",
            "160",
            " acres",
            ").",
            " This",
            " system",
            " was",
            " carried",
            " forward",
            " to",
            " most",
            " of",
            " the",
            " States",
            " west",
            " of",
            " the",
            " Mississippi",
            " (",
            "excluding",
            " areas",
            " of",
            " Texas",
            " and",
            " California",
            " that",
            " had",
            " already",
            " been",
            " surveyed",
            " and",
            " divided",
            " up",
            " by",
            " the",
            " Spanish",
            " Empire",
            ").",
            " Then",
            ",",
            " when",
            " the",
            " Hom",
            "estead",
            " Act",
            " was",
            " enacted",
            " in",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.938,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            " Johnston",
            "'s",
            " statue",
            " was",
            " taken",
            " down",
            ".",
            " Plans",
            " were",
            " announced",
            " to",
            " add",
            " it",
            " to",
            " the",
            " Br",
            "isco",
            "e",
            " Center",
            " for",
            " American",
            " History",
            " on",
            " the",
            " east",
            " side",
            " of",
            " the",
            " university",
            " campus",
            ".",
            "John",
            "ston",
            " was",
            " in",
            "ducted",
            " to",
            " the",
            " Texas",
            " Military",
            " Hall",
            " of",
            " Honor",
            " in",
            " ",
            "198",
            "0",
            ".",
            "In",
            " the",
            " fall",
            " of",
            " ",
            "201",
            "8",
            ",",
            " A",
            ".",
            " S",
            ".",
            " Johnston",
            " Elementary",
            " School"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.067,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.934,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 43,
          "is_repeated_datapoint": false,
          "tokens": [
            "ically",
            " a",
            " semi",
            "-ex",
            "clave",
            " of",
            " the",
            " U",
            ".S",
            ".,",
            " Alaska",
            " is",
            " the",
            " largest",
            " ex",
            "clave",
            " in",
            " the",
            " world",
            ".",
            "Al",
            "aska",
            " is",
            " the",
            " largest",
            " U",
            ".S",
            ".",
            " state",
            " by",
            " area",
            ",",
            " comprising",
            " more",
            " total",
            " area",
            " than",
            " the",
            " next",
            " three",
            " largest",
            " states",
            " of",
            " Texas",
            ",",
            " California",
            " and",
            " Montana",
            " combined",
            " and",
            " is",
            " the",
            " seventh",
            "-largest",
            " sub",
            "national",
            " division",
            " in",
            " the",
            " world",
            ".",
            " It",
            " is"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.0,
            0.159,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.934,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.178,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.099,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.099,
            -0.0,
            -0.0,
            0.105,
            -0.0,
            -0.0,
            0.102,
            -0.0,
            -0.0,
            0.106,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.402,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 8,
          "is_repeated_datapoint": false,
          "tokens": [
            " Institute",
            " standards",
            "<|begin_of_text|>",
            "Austin",
            " is",
            " the",
            " capital",
            " of",
            " Texas",
            " in",
            " the",
            " United",
            " States",
            ".",
            "Austin",
            " may",
            " also",
            " refer",
            " to",
            ":",
            "Ge",
            "ographical",
            " locations",
            "Australia",
            " Austin",
            ",",
            " Western",
            " Australia",
            "Canada",
            " Austin",
            ",",
            " Manitoba",
            " Austin",
            ",",
            " Ontario",
            " Austin",
            ",",
            " Quebec",
            " Austin",
            " Island",
            ",",
            " Nun",
            "av",
            "ut",
            "France",
            " Saint",
            "-A",
            "ustin",
            ",",
            " ham",
            "let",
            " at",
            " la",
            " Neu"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.934,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            " naval",
            " operations",
            " that",
            " occurred",
            " near",
            " the",
            " coastal",
            " areas",
            " of",
            " the",
            " Southeast",
            " (",
            "Alabama",
            ",",
            " Florida",
            ",",
            " Louisiana",
            ",",
            " Mississippi",
            ",",
            " South",
            " Carolina",
            ",",
            " and",
            " Texas",
            ")",
            " as",
            " well",
            " as",
            " the",
            " southern",
            " part",
            " of",
            " the",
            " Mississippi",
            " River",
            " (",
            "Port",
            " Hudson",
            " and",
            " south",
            ").",
            " Union",
            " Naval",
            " activities",
            " were",
            " dictated",
            " by",
            " the",
            " Ana",
            "conda",
            " Plan",
            ".",
            "B",
            "attles",
            " ",
            "One",
            " of",
            " the",
            " earliest",
            " battles",
            " of",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.93,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 16,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "44",
            "%",
            " of",
            " the",
            " population",
            " in",
            " Mississippi",
            ",",
            " ",
            "59",
            "%",
            " of",
            " the",
            " population",
            " in",
            " Texas",
            ",",
            " ",
            "42",
            "%",
            " of",
            " the",
            " population",
            " in",
            " Louisiana",
            " (",
            "by",
            " the",
            " state",
            " Health",
            " Department",
            "),",
            " and",
            " ",
            "35",
            "%",
            " of",
            " the",
            " population",
            " in",
            " Alabama",
            ",",
            " they",
            " comprise",
            " ",
            "80",
            "%,",
            " ",
            "74",
            "%,",
            " ",
            "72",
            "%,",
            " and",
            " ",
            "70",
            "%",
            " of",
            " those",
            " receiving",
            " abortions",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.922,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            " Show",
            "\",",
            " and",
            " is",
            " currently",
            " in",
            " production",
            " and",
            " looking",
            " for",
            " funding",
            ".",
            " Netflix",
            " has",
            " produced",
            " multiple",
            " anime",
            " series",
            " in",
            " collaboration",
            " with",
            " Japanese",
            " animation",
            " studios",
            ",",
            " and",
            " in",
            " doing",
            " so",
            ",",
            " has",
            " offered",
            " a",
            " more",
            " accessible",
            " channel",
            " for",
            " distribution",
            " to",
            " Western",
            " markets",
            ".",
            "The",
            " web",
            "-based",
            " series",
            " RW",
            "BY",
            ",",
            " produced",
            " by",
            " Texas",
            "-based",
            " company",
            " Ro",
            "oster",
            " Teeth",
            ",",
            " is",
            " produced",
            " using",
            " an",
            " anime"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.91,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 58,
          "is_repeated_datapoint": false,
          "tokens": [
            " presence",
            " of",
            " robots",
            " and",
            " artificial",
            " intelligence",
            ".",
            " Barry",
            " also",
            " uses",
            " Maria",
            " Bot",
            " to",
            " demonstrate",
            " that",
            " programming",
            " a",
            " robot",
            " with",
            " life",
            "-aff",
            "irm",
            "ing",
            ",",
            " ethical",
            " framework",
            " makes",
            " them",
            " more",
            " likely",
            " to",
            " help",
            " humans",
            " to",
            " do",
            " the",
            " same",
            ".",
            "Maria",
            " Bot",
            " is",
            " an",
            " ambassador",
            " robot",
            " for",
            " good",
            " and",
            " ethical",
            " AI",
            " technology",
            ".",
            "H",
            "anson",
            " Robotics",
            ",",
            " Inc",
            ".,",
            " of",
            " Texas",
            " and",
            " KA",
            "IST",
            " produced"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.894,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.898,
            -0.0,
            -0.0,
            -0.0,
            0.003,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.91
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            "Albert",
            " Sidney",
            " Johnston",
            " at",
            " Handbook",
            " of",
            " Texas",
            " Online",
            " ",
            "180",
            "3",
            " births",
            "186",
            "2",
            " deaths",
            " ",
            "Conf",
            "eder",
            "ate",
            " States",
            " of",
            " America",
            " military",
            " personnel",
            " killed",
            " in",
            " the",
            " American",
            " Civil",
            " War",
            "Deaths",
            " from",
            " bleeding",
            "Bur",
            "ials",
            " at",
            " Texas",
            " State",
            " Cemetery",
            "Conf",
            "eder",
            "ate",
            " States",
            " Army",
            " full",
            " generals",
            "People",
            " from",
            " Washington",
            ",",
            " Kentucky",
            "Military",
            " personnel",
            " from",
            " Texas"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.898,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            "ber",
            "deen",
            ",",
            " North",
            " Carolina",
            ")",
            " Aberdeen",
            ",",
            " Ohio",
            " Aberdeen",
            ",",
            " South",
            " Dakota",
            " Aberdeen",
            " Historic",
            " District",
            " (",
            "A",
            "ber",
            "deen",
            ",",
            " South",
            " Dakota",
            ")",
            " Aberdeen",
            ",",
            " Texas",
            " Aberdeen",
            " (",
            "Dis",
            "put",
            "anta",
            ",",
            " Virginia",
            ")",
            " Aberdeen",
            " Gardens",
            " (",
            "Ham",
            "pton",
            ",",
            " Virginia",
            ")",
            " Aberdeen",
            ",",
            " Washington",
            " Aberdeen",
            " Gardens",
            ",",
            " Washington",
            " Aberdeen",
            ",",
            " West",
            " Virginia",
            "See",
            " Also"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.856,
            -0.0,
            0.879,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.018,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 16,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " about",
            " ",
            "40",
            ",",
            "000",
            " people",
            " in",
            " the",
            " Rice",
            " University",
            " football",
            " stadium",
            " in",
            " Houston",
            ",",
            " Texas",
            ".",
            " A",
            " widely",
            " quoted",
            " refrain",
            " from",
            " the",
            " middle",
            " portion",
            " of",
            " the",
            " speech",
            " reads",
            " as",
            " follows",
            ":",
            "In",
            " spite",
            " of",
            " that",
            ",",
            " the",
            " proposed",
            " program",
            " faced",
            " the",
            " opposition",
            " of",
            " many",
            " Americans",
            " and",
            " was",
            " dubbed",
            " a",
            " \"",
            "mo",
            "ond",
            "oggle",
            "\"",
            " by",
            " Nor",
            "bert",
            " Wi",
            "ener",
            ",",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.644,
            -0.0,
            0.856,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            " World",
            " Cup",
            " last",
            " July",
            " at",
            " BC",
            " Place",
            " in",
            " Vancouver",
            ",",
            " British",
            " Columbia",
            ",",
            " Canada",
            " before",
            " an",
            " undis",
            "puted",
            " AT",
            "&T",
            " Stadium",
            " audience",
            " of",
            " ",
            "101",
            ",",
            "763",
            " to",
            " open",
            " Wrestle",
            "Man",
            "ia",
            " ",
            "32",
            " in",
            " Dallas",
            ",",
            " Texas",
            ".",
            "In",
            " ",
            "201",
            "7",
            ",",
            " Jackie",
            " Evan",
            "cho",
            " released",
            " Together",
            " We",
            " Stand",
            ",",
            " a",
            " disc",
            " containing",
            " three",
            " patriotic",
            " songs",
            " including",
            " \"",
            "America",
            " the",
            " Beautiful"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.852,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            "\"",
            " according",
            " to",
            " Brand",
            "li",
            ",",
            " posed",
            " a",
            " serious",
            " threat",
            " to",
            " the",
            " safety",
            " of",
            " the",
            " mission",
            ".",
            " Brand",
            "li",
            " alerted",
            " Navy",
            " Captain",
            " Will",
            "ard",
            " S",
            ".",
            " Houston",
            " Jr",
            ".,",
            " the",
            " commander",
            " of",
            " the",
            " Fleet",
            " Weather",
            " Center",
            " at",
            " Pearl",
            " Harbor",
            ",",
            " who",
            " had",
            " the",
            " required",
            " security",
            " clearance",
            ".",
            " On",
            " their",
            " recommendation",
            ",",
            " Rear",
            " Admiral",
            " Donald",
            " C",
            ".",
            " Davis",
            ",",
            " commander",
            " of",
            " M",
            "anned",
            " Space"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.84,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.84,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " emerging",
            " provinces",
            " of",
            " the",
            " communion",
            ",",
            " but",
            " to",
            " \"",
            "disc",
            "uss",
            " matters",
            " of",
            " practical",
            " interest",
            ",",
            " and",
            " pronounce",
            " what",
            " we",
            " deem",
            " exped",
            "ient",
            " in",
            " resolutions",
            " which",
            " may",
            " serve",
            " as",
            " safe",
            " guides",
            " to",
            " future",
            " action",
            "\".",
            "Chicago",
            " Lamb",
            "eth",
            " Quadr",
            "ilateral",
            " ",
            "One",
            " of",
            " the",
            " enduring",
            "ly",
            " influential",
            " early",
            " resolutions",
            " of",
            " the",
            " conference",
            " was",
            " the",
            " so",
            "-called",
            " Chicago",
            "-L",
            "amb",
            "eth",
            " Quadr",
            "ilateral",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.208,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.785,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            "h",
            "iser",
            ",",
            " an",
            " associate",
            " of",
            " Buckley",
            "'s",
            ",",
            " the",
            " host",
            " commented",
            " that",
            " it",
            " was",
            " \"",
            "the",
            " most",
            " un",
            "har",
            "ried",
            " Krishna",
            " I",
            "'ve",
            " ever",
            " heard",
            ".\"",
            "At",
            " the",
            " ",
            "196",
            "7",
            " Human",
            " Be",
            "-In",
            " in",
            " San",
            " Francisco",
            "'s",
            " Golden",
            " Gate",
            " Park",
            ",",
            " the",
            " ",
            "196",
            "8",
            " Democratic",
            " National",
            " Convention",
            " in",
            " Chicago",
            ",",
            " and",
            " the",
            " ",
            "197",
            "0",
            " Black",
            " Panther",
            " rally",
            " at",
            " Yale"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            0.719,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " include",
            " Dallas",
            ",",
            " Low",
            "nd",
            "es",
            ",",
            " Mare",
            "ngo",
            " and",
            " Perry",
            ".\"",
            "In",
            " ",
            "197",
            "2",
            ",",
            " for",
            " the",
            " first",
            " time",
            " since",
            " ",
            "190",
            "1",
            ",",
            " the",
            " legislature",
            " completed",
            " the",
            " congressional",
            " red",
            "istrict",
            "ing",
            " based",
            " on",
            " the",
            " dec",
            "ennial",
            " census",
            ".",
            " This",
            " benefited",
            " the",
            " urban",
            " areas",
            " that",
            " had",
            " developed",
            ",",
            " as",
            " well",
            " as",
            " all",
            " in",
            " the",
            " population",
            " who",
            " had",
            " been",
            " under",
            "represented",
            " for"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.66,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " moved",
            " to",
            " Cah",
            "aba",
            " in",
            " Dallas",
            " County",
            ".",
            "C",
            "ah",
            "aba",
            ",",
            " now",
            " a",
            " ghost",
            " town",
            ",",
            " was",
            " the",
            " first",
            " permanent",
            " state",
            " capital",
            " from",
            " ",
            "182",
            "0",
            " to",
            " ",
            "182",
            "5",
            ".",
            " The",
            " Alabama",
            " Fever",
            " land",
            " rush",
            " was",
            " underway",
            " when",
            " the",
            " state",
            " was",
            " admitted",
            " to",
            " the",
            " Union",
            ",",
            " with",
            " settlers",
            " and",
            " land",
            " spec",
            "ulators",
            " pouring",
            " into",
            " the",
            " state",
            " to",
            " take",
            " advantage",
            " of",
            " fertile"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.539,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            " (",
            "b",
            ".",
            " ",
            "192",
            "3",
            ")",
            "199",
            "2",
            " –",
            " Les",
            "zek",
            " B",
            "ÅĤa",
            "Å¼y",
            "ÅĦ",
            "ski",
            ",",
            " Polish",
            " boxer",
            " (",
            "b",
            ".",
            " ",
            "194",
            "9",
            ")",
            "199",
            "3",
            " –",
            " Tex",
            " Hugh",
            "son",
            ",",
            " American",
            " baseball",
            " player",
            " (",
            "b",
            ".",
            " ",
            "191",
            "6",
            ")",
            "199",
            "4",
            " –",
            " D",
            "omen",
            "ico",
            " Mod",
            "ug",
            "no",
            ",",
            " Italian",
            " singer",
            "-song",
            "writer",
            " and",
            " politician",
            " (",
            "b",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.478,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 27,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " save",
            " lives",
            ",",
            " help",
            " people",
            ",",
            " or",
            " otherwise",
            " have",
            " the",
            " biggest",
            " benefit",
            ".",
            " People",
            " associated",
            " with",
            " the",
            " movement",
            " include",
            " philosopher",
            " Peter",
            " Singer",
            ",",
            " Facebook",
            " co",
            " founder",
            " Dustin",
            " Mos",
            "kov",
            "itz",
            ",",
            " C",
            "ari",
            " T",
            "una",
            ",",
            " Oxford",
            "-based",
            " researchers",
            " William",
            " Mac",
            "As",
            "kill",
            " and",
            " Toby",
            " Ord",
            ",",
            " and",
            " professional",
            " poker",
            " player",
            " Liv",
            " Bo",
            "eree",
            ".",
            "Gen",
            "etics",
            "OX",
            "TR",
            ",",
            " CD"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.342,
            -0.0,
            -0.0,
            -0.0,
            0.443,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.344,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.348,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.434,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            "2",
            "x",
            "LP",
            "/",
            "CD",
            ")",
            "External",
            " links",
            "Official",
            " Website",
            " of",
            " MC",
            " Torch",
            "Website",
            " of",
            " Toni",
            " L",
            " ",
            "Official",
            " Website",
            " of",
            " Lingu",
            "ist",
            "Official",
            " Website",
            " DJ",
            " Mike",
            " MD",
            " (",
            "Mike",
            " Dip",
            "pon",
            ")",
            "Website",
            " of",
            " ",
            "360",
            "Â°",
            " Records",
            "B",
            "ibli",
            "ography",
            "El",
            "-T",
            "ay",
            "eb",
            ",",
            " Fat",
            "ima",
            " “",
            "‘",
            "If",
            " You",
            " Cannot",
            " Pron",
            "ounce",
            " My",
            " Name"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.002,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.422,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            " well",
            " that",
            " res",
            "ists",
            " all",
            " efforts",
            " to",
            " extingu",
            "ish",
            " it",
            " becomes",
            " known",
            " as",
            " \"",
            "Wy",
            "att",
            "'s",
            " Torch",
            "\".",
            " Later",
            " D",
            "agn",
            "y",
            " meets",
            " him",
            " in",
            " G",
            "alt",
            "'s",
            " Gul",
            "ch",
            ".",
            "Notes",
            "References",
            "Works",
            " cited",
            "External",
            " links",
            "Website",
            " with",
            " comprehensive",
            " list",
            " of",
            " individuals",
            " mentioned",
            " in",
            " Atlas",
            " Shr",
            "ugged",
            " ",
            "F",
            "iction",
            "al",
            " social",
            "ites",
            "Lists",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.021,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.369,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 59,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " United",
            " States",
            " Mint",
            " to",
            " design",
            " and",
            " sell",
            " commem",
            "orative",
            " coins",
            " in",
            " gold",
            ",",
            " silver",
            " and",
            " clad",
            " for",
            " the",
            " ",
            "50",
            "th",
            " anniversary",
            " of",
            " the",
            " Apollo",
            " ",
            "11",
            " mission",
            ".",
            " On",
            " January",
            " ",
            "24",
            ",",
            " ",
            "201",
            "9",
            ",",
            " the",
            " Mint",
            " released",
            " the",
            " Apollo",
            " ",
            "11",
            " F",
            "ift",
            "i",
            "eth",
            " Anniversary",
            " commem",
            "orative",
            " coins",
            " to",
            " the",
            " public",
            " on",
            " its",
            " website",
            ".",
            "A",
            " documentary"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.254,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            " music",
            " of",
            " Bach",
            " are",
            " available",
            " on",
            " CD",
            ".",
            " During",
            " ",
            "193",
            "4",
            " and",
            " ",
            "193",
            "5",
            " he",
            " res",
            "ided",
            " in",
            " Britain",
            ",",
            " delivering",
            " the",
            " G",
            "iff",
            "ord",
            " Lect",
            "ures",
            " at",
            " Edinburgh",
            " University",
            ",",
            " and",
            " those",
            " on",
            " Religion",
            " in",
            " Modern",
            " Civilization",
            " at",
            " Oxford",
            " and",
            " London",
            ".",
            " He",
            " had",
            " originally",
            " conducted",
            " trials",
            " for",
            " recordings",
            " for",
            " HM",
            "V",
            " on",
            " the",
            " organ",
            " of",
            " the",
            " old",
            " Queen",
            "'s"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.245,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            " general",
            " semantics",
            " of",
            " Alfred",
            " Kor",
            "zy",
            "bs",
            "ki",
            ".",
            "He",
            " subsequently",
            " wrote",
            " a",
            " novel",
            " merging",
            " these",
            " overarching",
            " themes",
            ",",
            " The",
            " World",
            " of",
            " Ä",
            "Ģ",
            ",",
            " originally",
            " serialized",
            " in",
            " Ast",
            "ounding",
            " in",
            " ",
            "194",
            "5",
            ".",
            " Ä",
            "Ģ",
            " (",
            "often",
            " rendered",
            " as",
            " Null",
            "-A",
            "),",
            " or",
            " non",
            "-A",
            "rist",
            "otel",
            "ian",
            " logic",
            ",",
            " refers",
            " to",
            " the",
            " capacity",
            " for",
            ",",
            " and",
            " practice",
            " of",
            ",",
            " using"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.234,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            " war",
            " with",
            " UNIT",
            "A",
            " forces",
            ".",
            "In",
            " ",
            "199",
            "1",
            ",",
            " the",
            " Air",
            " Force",
            "/A",
            "ir",
            " Defense",
            " Forces",
            " had",
            " ",
            "8",
            ",",
            "000",
            " personnel",
            " and",
            " ",
            "90",
            " combat",
            "-cap",
            "able",
            " aircraft",
            ",",
            " including",
            " ",
            "22",
            " fighters",
            ",",
            " ",
            "59",
            " fighter",
            " ground",
            " attack",
            " aircraft",
            " and",
            " ",
            "16",
            " attack",
            " helicopters",
            ".",
            "N",
            "avy",
            " ",
            "The",
            " Angola",
            " Navy",
            " (",
            "M",
            "GA",
            ",",
            " Mar",
            "inha",
            " de",
            " Gu"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.046,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " is",
            " the",
            " classical",
            " A",
            "arhus",
            " T",
            "appen",
            "st",
            "reg",
            " from",
            " ",
            "187",
            "2",
            " by",
            " Carl",
            " Christian",
            " M",
            "Ã¸",
            "ller",
            " which",
            " is",
            " occasionally",
            " played",
            " at",
            " official",
            " events",
            " or",
            " at",
            " performances",
            " by",
            " local",
            " marching",
            " bands",
            " and",
            " orchest",
            "ras",
            ".",
            "M",
            "use",
            "ums",
            "A",
            "arhus",
            " has",
            " a",
            " range",
            " of",
            " museums",
            ",",
            " including",
            " two",
            " of",
            " the",
            " largest",
            " in",
            " the",
            " country",
            ",",
            " measured",
            " by",
            " the",
            " number",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " Not",
            " only",
            " the",
            " vowel",
            ",",
            " but",
            " any",
            " final",
            " conson",
            "ant",
            " is",
            " indicated",
            " by",
            " a",
            " di",
            "ac",
            "ritic",
            ".",
            " For",
            " example",
            ",",
            " the",
            " syll",
            "able",
            " [",
            "s",
            "ok",
            "]",
            " would",
            " be",
            " written",
            " as",
            " something",
            " like",
            " s",
            "Ì",
            "¥",
            "Ì",
            "½",
            ",",
            " here",
            " with",
            " an",
            " und",
            "erring",
            " representing",
            " ",
            " and",
            " an",
            " over",
            "cross",
            " representing",
            " the",
            " di",
            "ac",
            "ritic",
            " for",
            " final",
            " .",
            " Most",
            " other",
            " Ind",
            "ic"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " than",
            " his",
            " prior",
            " works",
            ".",
            "G",
            "ersh",
            "win",
            " explained",
            " in",
            " Musical",
            " America",
            ",",
            " \"",
            "My",
            " purpose",
            " here",
            " is",
            " to",
            " portray",
            " the",
            " impressions",
            " of",
            " an",
            " American",
            " visitor",
            " in",
            " Paris",
            " as",
            " he",
            " st",
            "rolls",
            " about",
            " the",
            " city",
            ",",
            " listens",
            " to",
            " the",
            " various",
            " street",
            " noises",
            ",",
            " and",
            " absorbs",
            " the",
            " French",
            " atmosphere",
            ".\"",
            "The",
            " piece",
            " is",
            " structured",
            " into",
            " five",
            " sections",
            ",",
            " which",
            " cul",
            "minate",
            " in",
            " a",
            " loose"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " Imagine",
            "ers",
            " created",
            " Great",
            " Moments",
            " with",
            " Mr",
            ".",
            " Lincoln",
            " that",
            " debuted",
            " at",
            " the",
            " ",
            "196",
            "4",
            " New",
            " York",
            " World",
            "'s",
            " Fair",
            ".",
            "Dr",
            ".",
            " William",
            " Barry",
            ",",
            " an",
            " Education",
            " Fut",
            "ur",
            "ist",
            " and",
            " former",
            " visiting",
            " West",
            " Point",
            " Professor",
            " of",
            " Philosophy",
            " and",
            " Eth",
            "ical",
            " Reason",
            "ing",
            " at",
            " the",
            " United",
            " States",
            " Military",
            " Academy",
            ",",
            " created",
            " an",
            " AI",
            " android",
            " character",
            " named",
            " \"",
            "Maria",
            " Bot",
            "\".",
            " This"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " third",
            ",",
            " The",
            " Mystery",
            " of",
            " Three",
            " Qu",
            "arters",
            ",",
            " in",
            " ",
            "201",
            "8",
            ".",
            "Port",
            "ray",
            "als",
            "Stage",
            " ",
            "The",
            " first",
            " actor",
            " to",
            " portray",
            " P",
            "oi",
            "rot",
            " was",
            " Charles",
            " La",
            "ught",
            "on",
            ".",
            " He",
            " appeared",
            " on",
            " the",
            " West",
            " End",
            " in",
            " ",
            "192",
            "8",
            " in",
            " the",
            " play",
            " Al",
            "ibi",
            " which",
            " had",
            " been",
            " adapted",
            " by",
            " Michael",
            " Morton",
            " from",
            " the",
            " novel",
            " The",
            " Murder",
            " of",
            " Roger"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "rita",
    "dain",
    "ema",
    "Ð¾Ð»Ð°Ð³",
    "inou"
  ],
  "bottom_logits": [
    " Pace",
    " Fighters",
    "ongan",
    " ",
    " rhythm"
  ],
  "act_min": -0.0,
  "act_max": 1.102
}
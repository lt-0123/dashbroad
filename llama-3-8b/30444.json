{
  "index": 30444,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            1.141,
            0.04,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "13",
            " in",
            " the",
            " periodic",
            " table",
            " of",
            " varying",
            " sto",
            "ichi",
            "omet",
            "ries",
            ",",
            " such",
            " as",
            " the",
            " sodium",
            " amalg",
            "ams",
            " with",
            " mercury",
            ",",
            " including",
            " Na",
            "5",
            "H",
            "g",
            "8",
            " and",
            " Na",
            "3",
            "H",
            "g",
            ".",
            " Some",
            " of",
            " these",
            " have",
            " ",
            "ionic",
            " characteristics",
            ":",
            " taking",
            " the",
            " alloys",
            " with",
            " gold",
            ",",
            " the",
            " most",
            " electr",
            "one",
            "g",
            "ative",
            " of",
            " metals",
            ",",
            " as",
            " an",
            " example",
            ",",
            " Na",
            "Au",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.141,
            0.117,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "13",
            " reson",
            "ances",
            " depend",
            " on",
            " the",
            " number",
            " of",
            " hydrogen",
            " atoms",
            " attached",
            " to",
            " the",
            " carbon",
            ":",
            " Î´",
            "C",
            " =",
            " ",
            "8",
            "–",
            "30",
            " (",
            "primary",
            ",",
            " methyl",
            ",",
            " –",
            "CH",
            "3",
            "),",
            " ",
            "15",
            "–",
            "55",
            " (",
            "secondary",
            ",",
            " meth",
            "ylene",
            ",",
            " –",
            "CH",
            "2",
            "–",
            "),",
            " ",
            "20",
            "–",
            "60",
            " (",
            "ter",
            "ti",
            "ary",
            ",",
            " meth",
            "yne",
            ",",
            " C",
            "–",
            "H",
            ")",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.141,
            0.049,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "13",
            " (",
            "193",
            "4",
            ",",
            " US",
            ")",
            " Gone",
            " with",
            " the",
            " Wind",
            " (",
            "193",
            "9",
            ",",
            " US",
            ")",
            " The",
            " Red",
            " Badge",
            " of",
            " Courage",
            " (",
            "195",
            "1",
            ",",
            " US",
            ")",
            " The",
            " Horse",
            " Soldiers",
            " (",
            "195",
            "9",
            ",",
            " US",
            ")",
            " Shen",
            "ando",
            "ah",
            " (",
            "196",
            "5",
            ",",
            " US",
            ")",
            " The",
            " Good",
            ",",
            " the",
            " Bad",
            " and",
            " the",
            " U",
            "gly",
            " (",
            "196",
            "6",
            ",",
            " Italy",
            "-S",
            "pain",
            "-F"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.141,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "13",
            " electrons",
            ",",
            " arranged",
            " in",
            " an",
            " electron",
            " configuration",
            " of",
            " ,",
            " with",
            " three",
            " electrons",
            " beyond",
            " a",
            " stable",
            " noble",
            " gas",
            " configuration",
            ".",
            " Accordingly",
            ",",
            " the",
            " combined",
            " first",
            " three",
            " ion",
            "ization",
            " energies",
            " of",
            " aluminium",
            " are",
            " far",
            " lower",
            " than",
            " the",
            " fourth",
            " ion",
            "ization",
            " energy",
            " alone",
            ".",
            " Such",
            " an",
            " electron",
            " configuration",
            " is",
            " shared",
            " with",
            " the",
            " other",
            " well",
            "-character",
            "ized",
            " members",
            " of",
            " its",
            " group",
            ",",
            " bor",
            "on",
            ",",
            " gall"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.141,
            0.27,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "13",
            "th",
            " Governor",
            "-General",
            " of",
            " Australia",
            " (",
            "d",
            ".",
            " ",
            "197",
            "0",
            ")",
            "189",
            "5",
            " –",
            " Frank",
            " Nick",
            "lin",
            ",",
            " Australian",
            " politician",
            ",",
            " ",
            "28",
            "th",
            " Premier",
            " of",
            " Queensland",
            " (",
            "d",
            ".",
            " ",
            "197",
            "8",
            ")",
            "190",
            "0",
            " –",
            " Cecil",
            " Howard",
            " Green",
            ",",
            " English",
            "-American",
            " ge",
            "ophys",
            "ic",
            "ist",
            " and",
            " businessman",
            ",",
            " co",
            "-founded",
            " Texas",
            " Instruments",
            " (",
            "d",
            ".",
            " ",
            "200",
            "3",
            ")"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            1.141,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "15",
            "%",
            " Shia",
            ".",
            "Af",
            "ghan",
            " Sik",
            "hs",
            " and",
            " Hindus",
            " are",
            " also",
            " found",
            " in",
            " certain",
            " major",
            " cities",
            " (",
            "nam",
            "ely",
            " Kabul",
            ",",
            " Jal",
            "al",
            "abad",
            ",",
            " Gh",
            "az",
            "ni",
            ",",
            " K",
            "and",
            "ah",
            "ar",
            ")",
            " accompanied",
            " by",
            " g",
            "urd",
            "war",
            "as",
            " and",
            " mand",
            "irs",
            ".",
            " According",
            " to",
            " Deutsche",
            " W",
            "elle",
            " in",
            " September",
            " ",
            "202",
            "1",
            ",",
            " ",
            "250",
            " remain",
            " in",
            " the",
            " country",
            " after"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.141,
            0.268,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "13",
            "–",
            "14",
            " October",
            " ",
            "201",
            "5",
            ".",
            "Ada",
            ".A",
            "da",
            ".A",
            "da",
            ",",
            " a",
            " one",
            "-w",
            "oman",
            " show",
            " about",
            " the",
            " life",
            " and",
            " work",
            " of",
            " Ada",
            " Lov",
            "el",
            "ace",
            " (",
            "using",
            " an",
            " LED",
            " dress",
            "),",
            " premiered",
            " at",
            " Edinburgh",
            " International",
            " Science",
            " Festival",
            " on",
            " ",
            "11",
            " April",
            " ",
            "201",
            "5",
            ",",
            " and",
            " continued",
            " to",
            " touring",
            " internationally",
            " to",
            " promote",
            " diversity",
            " on",
            " STEM",
            " at",
            " technology",
            " conferences",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.141,
            0.152,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "13",
            ",",
            " three",
            " days",
            " before",
            " Apollo",
            " ",
            "11",
            "'s",
            " launch",
            ",",
            " the",
            " Soviet",
            " Union",
            " launched",
            " Luna",
            " ",
            "15",
            ",",
            " which",
            " reached",
            " lunar",
            " orbit",
            " before",
            " Apollo",
            " ",
            "11",
            ".",
            " During",
            " descent",
            ",",
            " a",
            " malfunction",
            " caused",
            " Luna",
            " ",
            "15",
            " to",
            " crash",
            " in",
            " Mare",
            " Cr",
            "is",
            "ium",
            " about",
            " two",
            " hours",
            " before",
            " Armstrong",
            " and",
            " Ald",
            "rin",
            " took",
            " off",
            " from",
            " the",
            " Moon",
            "'s",
            " surface",
            " to",
            " begin",
            " their",
            " voyage"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.125,
            0.016,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "29",
            " countries",
            " that",
            " he",
            " had",
            " conquered",
            ".",
            " The",
            " region",
            " of",
            " Ar",
            "ach",
            "os",
            "ia",
            ",",
            " around",
            " K",
            "and",
            "ah",
            "ar",
            " in",
            " modern",
            "-day",
            " southern",
            " Afghanistan",
            ",",
            " used",
            " to",
            " be",
            " primarily",
            " Z",
            "oro",
            "ast",
            "rian",
            " and",
            " played",
            " a",
            " key",
            " role",
            " in",
            " the",
            " transfer",
            " of",
            " the",
            " A",
            "vest",
            "a",
            " to",
            " Pers",
            "ia",
            " and",
            " is",
            " thus",
            " considered",
            " by",
            " some",
            " to",
            " be",
            " the",
            " \"",
            "second",
            " homeland",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.125,
            0.055,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "29",
            " (",
            "International",
            " observ",
            "ance",
            ")",
            " Day",
            " of",
            " Dialogue",
            " (",
            "United",
            " States",
            ")",
            " Vacc",
            "ination",
            " Week",
            " In",
            " The",
            " Americas",
            " See",
            ":",
            " List",
            " of",
            " movable",
            " Western",
            " Christian",
            " observ",
            "ances",
            " See",
            ":",
            " List",
            " of",
            " movable",
            " Eastern",
            " Christian",
            " observ",
            "ances",
            "First",
            " Wednesday",
            " ",
            " National",
            " Day",
            " of",
            " Hope",
            " (",
            "United",
            " States",
            ")",
            "First",
            " Saturday",
            " ",
            " Ul",
            "cin",
            "j",
            " Municip",
            "ality",
            " Day",
            " (",
            "U",
            "lc"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            1.117,
            0.169,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "8",
            ",",
            " the",
            " first",
            " victory",
            " for",
            " any",
            " American",
            " military",
            " vessel",
            " in",
            " British",
            " waters",
            ".",
            " The",
            " last",
            " such",
            " victory",
            " was",
            " by",
            " the",
            " fr",
            "igate",
            " USS",
            " Alliance",
            ",",
            " commanded",
            " by",
            " Captain",
            " John",
            " Barry",
            ".",
            " On",
            " March",
            " ",
            "10",
            ",",
            " ",
            "178",
            "3",
            ",",
            " the",
            " Alliance",
            " out",
            "gun",
            "ned",
            " HMS",
            " Sy",
            "bil",
            " in",
            " a",
            " ",
            "45",
            "-minute",
            " duel",
            " while",
            " escort",
            "ing",
            " Spanish",
            " gold",
            " from",
            " Havana",
            " to"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            0.169,
            -0.0,
            -0.0,
            -0.0,
            0.038,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "8",
            ",",
            " from",
            " which",
            " they",
            " annex",
            "ed",
            " almost",
            " all",
            " the",
            " territories",
            " of",
            " Anat",
            "olia",
            ",",
            " including",
            " the",
            " east",
            " coast",
            " of",
            " the",
            " Ae",
            "ge",
            "an",
            " Sea",
            ",",
            " during",
            " the",
            " reign",
            " of",
            " Al",
            "p",
            " Ar",
            "sl",
            "an",
            ",",
            " the",
            " second",
            " Sultan",
            " of",
            " the",
            " Sel",
            "j",
            "uk",
            " Empire",
            ".",
            " After",
            " the",
            " death",
            " of",
            " his",
            " successor",
            ",",
            " Malik",
            " Shah",
            " I",
            ",",
            " the",
            " empire",
            " was",
            " divided",
            ",",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.516,
            0.069,
            0.08,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "9",
            "States",
            " of",
            " the",
            " United",
            " States",
            "States",
            " of",
            " the",
            " West",
            " Coast",
            " of",
            " the",
            " United",
            " States",
            "195",
            "9",
            " establishments",
            " in",
            " the",
            " United",
            " States",
            "Western",
            " United",
            " States",
            "Northern",
            " America",
            "En",
            "cl",
            "aves",
            " and",
            " excl",
            "aves",
            "Russia",
            "–",
            "United",
            " States",
            " relations",
            "B",
            "ering",
            "ia",
            "Ex",
            "cl",
            "aves",
            " in",
            " the",
            " United",
            " States",
            "<|begin_of_text|>",
            "A",
            "gricult",
            "ure",
            " encompasses",
            " crop"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            0.062,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "8",
            " (",
            "based",
            " on",
            " \"",
            "The",
            " Murder",
            " of",
            " Roger",
            " Ack",
            "roy",
            "d",
            "\");",
            " Shi",
            " to",
            " no",
            " Yak",
            "us",
            "oku",
            ",",
            " ",
            "202",
            "1",
            " (",
            "based",
            " on",
            " Appointment",
            " with",
            " Death",
            ")",
            " ",
            " John",
            " Malk",
            "ovich",
            " was",
            " P",
            "oi",
            "rot",
            " in",
            " the",
            " ",
            "201",
            "8",
            " BBC",
            " adaptation",
            " of",
            " The",
            " ABC",
            " Mur",
            "ders",
            ".",
            "Anime",
            " ",
            "In",
            " ",
            "200",
            "4",
            ",",
            " the",
            " Japanese",
            " public",
            " broadcaster",
            " NH"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            0.127,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.566,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "9",
            "Das",
            " Argument",
            ",",
            " a",
            " German",
            " academic",
            " journal",
            "Argument",
            " Clinic",
            ",",
            " a",
            " Mont",
            "y",
            " Python",
            " sketch",
            "A",
            " disagreement",
            " between",
            " two",
            " or",
            " more",
            " parties",
            " or",
            " the",
            " discussion",
            " of",
            " the",
            " disagreement",
            "Argument",
            " (",
            "horse",
            ")",
            "See",
            " also",
            "The",
            " Argument",
            " (",
            "dis",
            "amb",
            "ig",
            "uation",
            ")",
            "argument",
            "ation",
            "<|begin_of_text|>",
            "Apollo",
            " ",
            "11",
            " (",
            "July",
            " ",
            "16",
            "–",
            "24",
            ",",
            " ",
            "196"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            1.117,
            0.166,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "9",
            ",",
            "000",
            " inhabitants",
            " of",
            " Lip",
            "ari",
            ",",
            " almost",
            " the",
            " entire",
            " population",
            ".",
            " In",
            " ",
            "155",
            "1",
            ",",
            " the",
            " Ottoman",
            " governor",
            " of",
            " Alg",
            "iers",
            ",",
            " T",
            "urg",
            "ut",
            " Re",
            "is",
            ",",
            " enslaved",
            " the",
            " entire",
            " population",
            " of",
            " the",
            " Mal",
            "tes",
            "e",
            " island",
            " of",
            " Go",
            "zo",
            ".",
            " Barb",
            "ary",
            " pirates",
            " often",
            " attacked",
            " the",
            " Ba",
            "lear",
            "ic",
            " Islands",
            ".",
            " The",
            " threat",
            " was",
            " so",
            " severe",
            " that",
            " residents"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            0.179,
            0.034,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "8",
            "),",
            " TV",
            " movie",
            " directed",
            " by",
            " Gi",
            "anni",
            " Am",
            "el",
            "io",
            ",",
            " based",
            " on",
            " a",
            " novel",
            " Il",
            " pic",
            "colo",
            " Arch",
            "im",
            "ede",
            " (",
            "197",
            "9",
            "),",
            " TV",
            " movie",
            " directed",
            " by",
            " Gi",
            "anni",
            " Am",
            "el",
            "io",
            ",",
            " based",
            " on",
            " no",
            "ve",
            "lette",
            " \"",
            "Young",
            " Arch",
            "im",
            "edes",
            "\"",
            " Brave",
            " New",
            " World",
            " (",
            "198",
            "0",
            "),",
            " TV",
            " movie",
            " directed",
            " by",
            " B",
            "urt",
            " Br",
            "in"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            0.059,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "9",
            " he",
            " holds",
            " the",
            " L",
            "Ã©",
            "on",
            " Mot",
            "ch",
            "ane",
            " Chair",
            " at",
            " IH",
            "ES",
            ".",
            " From",
            " ",
            "198",
            "4",
            " until",
            " his",
            " retirement",
            " in",
            " ",
            "201",
            "7",
            " he",
            " held",
            " the",
            " chair",
            " of",
            " Analysis",
            " and",
            " Geometry",
            " at",
            " Coll",
            "Ã¨ge",
            " de",
            " France",
            ".",
            "In",
            " parallel",
            ",",
            " he",
            " was",
            " awarded",
            " a",
            " distinguished",
            " professor",
            "ship",
            " at",
            " Vanderbilt",
            " University",
            " between",
            " ",
            "200",
            "3",
            " and",
            " ",
            "201",
            "2",
            ",",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            0.256,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "9",
            ".",
            " The",
            " primary",
            " has",
            " a",
            " lumin",
            "osity",
            " of",
            " ",
            " and",
            " the",
            " secondary",
            " has",
            " a",
            " lumin",
            "osity",
            " of",
            " ;",
            " the",
            " primary",
            " is",
            " an",
            " A",
            "-type",
            " star",
            " with",
            " an",
            " absolute",
            " magnitude",
            " of",
            " ",
            "0",
            ".",
            "2",
            " and",
            " the",
            " secondary",
            " is",
            " a",
            " B",
            "9",
            "-type",
            " star",
            " with",
            " an",
            " absolute",
            " magnitude",
            " of",
            " ",
            "0",
            ".",
            "4",
            ".",
            " The",
            " angle",
            " between",
            " the",
            " two",
            " components",
            " is",
            " ",
            "1"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            0.176,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "9",
            "),",
            " then",
            " in",
            " Cairo",
            " (",
            "193",
            "2",
            "),",
            " Baghdad",
            " (",
            "194",
            "8",
            "),",
            " Rab",
            "at",
            " (",
            "196",
            "0",
            "),",
            " Am",
            "man",
            " (",
            "197",
            "7",
            "),",
            " ",
            " (",
            "199",
            "3",
            "),",
            " and",
            " Tunis",
            " (",
            "199",
            "3",
            ").",
            " They",
            " review",
            " language",
            " development",
            ",",
            " monitor",
            " new",
            " words",
            " and",
            " approve",
            " inclusion",
            " of",
            " new",
            " words",
            " into",
            " their",
            " published",
            " standard",
            " dictionaries",
            ".",
            " They",
            " also",
            " publish",
            " old",
            " and",
            " historical"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            1.117,
            0.176,
            0.047,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "9",
            "),",
            " North",
            " by",
            " Northwest",
            " (",
            "195",
            "9",
            ";",
            " in",
            "ducted",
            " ",
            "199",
            "5",
            "),",
            " Psycho",
            " (",
            "196",
            "0",
            ";",
            " in",
            "ducted",
            " ",
            "199",
            "2",
            ")",
            " and",
            " The",
            " Birds",
            " (",
            "196",
            "3",
            ";",
            " in",
            "ducted",
            " ",
            "201",
            "6",
            ").",
            "In",
            " ",
            "201",
            "2",
            ",",
            " Hitch",
            "cock",
            " was",
            " selected",
            " by",
            " artist",
            " Sir",
            " Peter",
            " Blake",
            ",",
            " author",
            " of",
            " the",
            " Beatles",
            "'",
            " Sgt",
            ".",
            " Pepper",
            "'s"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            0.146,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "9",
            " –",
            " Frank",
            " Hall",
            "er",
            ",",
            " American",
            " boxer",
            " (",
            "b",
            ".",
            " ",
            "188",
            "3",
            ")",
            "194",
            "3",
            " –",
            " E",
            "ddy",
            " Ham",
            "el",
            ",",
            " American",
            " football",
            "er",
            " (",
            "b",
            ".",
            " ",
            "190",
            "2",
            ")",
            " ",
            " ",
            "194",
            "3",
            "  ",
            " –",
            " Otto",
            " Jes",
            "pers",
            "en",
            ",",
            " Danish",
            " lingu",
            "ist",
            " and",
            " academic",
            " (",
            "b",
            ".",
            " ",
            "186",
            "0",
            ")",
            " ",
            " ",
            "194",
            "3",
            "  ",
            " –",
            " Beat"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            0.2,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "9",
            ")",
            " until",
            " it",
            " was",
            " shattered",
            " by",
            " G",
            "arry",
            " Kas",
            "par",
            "ov",
            " (",
            "14",
            ").",
            " As",
            " a",
            " result",
            ",",
            " most",
            " chess",
            " professionals",
            " soon",
            " agreed",
            " that",
            " K",
            "arp",
            "ov",
            " was",
            " a",
            " legitimate",
            " world",
            " champion",
            ".",
            "In",
            " ",
            "197",
            "8",
            ",",
            " K",
            "arp",
            "ov",
            "'s",
            " first",
            " title",
            " defence",
            " was",
            " against",
            " Viktor",
            " Kor",
            "chn",
            "oi",
            ",",
            " the",
            " opponent",
            " he",
            " had",
            " defeated",
            " in",
            " the",
            " ",
            "197",
            "3"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            0.144,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "9",
            ")",
            " ",
            " ",
            "201",
            "5",
            "  ",
            " –",
            " Walter",
            " Nah",
            "Ãºn",
            " LÃ³pez",
            ",",
            " Hond",
            "uran",
            " football",
            "er",
            " (",
            "b",
            ".",
            " ",
            "197",
            "7",
            ")",
            " ",
            " ",
            "201",
            "5",
            "  ",
            " –",
            " David",
            " Nob",
            "bs",
            ",",
            " English",
            " author",
            " and",
            " screen",
            "writer",
            " (",
            "b",
            ".",
            " ",
            "193",
            "5",
            ")",
            " ",
            " ",
            "201",
            "5",
            "  ",
            " –",
            " Kay",
            "yar",
            " Kinh",
            "anna",
            " Rai",
            ",",
            " Indian",
            " journalist",
            ",",
            " author",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.017,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "9",
            " film",
            " Ant",
            "ich",
            "rist",
            " to",
            " him",
            ",",
            " and",
            ",",
            " while",
            " discussing",
            " it",
            " with",
            " critic",
            " David",
            " Jenkins",
            ",",
            " asked",
            ":",
            " \"",
            "Have",
            " you",
            " seen",
            " Mirror",
            "?",
            " I",
            " was",
            " hypnot",
            "ised",
            "!",
            " I",
            "'ve",
            " seen",
            " it",
            " ",
            "20",
            " times",
            ".",
            " It",
            "'s",
            " the",
            " closest",
            " thing",
            " I",
            "'ve",
            " got",
            " to",
            " a",
            " religion",
            " –",
            " to",
            " me",
            " he",
            " is",
            " a",
            " god",
            "\".",
            "Film",
            " festival",
            "Two",
            " film"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            1.117,
            0.166,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "9",
            ",",
            " at",
            " the",
            " Turning",
            " Stone",
            " Event",
            " Center",
            " in",
            " Ver",
            "ona",
            ",",
            " New",
            " York",
            ",",
            " the",
            " others",
            " being",
            " John",
            " Mc",
            "En",
            "roe",
            " (",
            "who",
            " had",
            " been",
            " No",
            ".",
            " ",
            "1",
            " in",
            " both",
            " singles",
            " and",
            " doubles",
            "),",
            " Tracy",
            " Austin",
            " and",
            " Jim",
            " Courier",
            " (",
            "both",
            " of",
            " whom",
            " who",
            " had",
            " been",
            " No",
            ".",
            " ",
            "1",
            " in",
            " singles",
            " but",
            " not",
            " doubles",
            ").",
            " The",
            " exhibition",
            " included",
            " a",
            " mixed"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            0.179,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "8",
            "),",
            " the",
            " name",
            " \"",
            "I",
            "sla",
            " de",
            " Or",
            "uba",
            "\"",
            " was",
            " used",
            " for",
            " the",
            " island",
            " by",
            " the",
            " Spanish",
            ".",
            " After",
            " the",
            " signing",
            ",",
            " the",
            " island",
            " was",
            " c",
            "eded",
            " to",
            " the",
            " Dutch",
            " and",
            " gradually",
            " its",
            " name",
            " changed",
            " to",
            " Ar",
            "uba",
            ".",
            "There",
            " were",
            " many",
            " different",
            " names",
            " for",
            " Ar",
            "uba",
            " used",
            " by",
            " other",
            " Amer",
            "ind",
            "ian",
            " groups",
            ",",
            " all",
            " of",
            " which",
            " could",
            " have",
            " contributed"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            0.26,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "8",
            "  ",
            " –",
            " Jessie",
            " James",
            " De",
            "cker",
            ",",
            " American",
            " singer",
            "-song",
            "writer",
            " ",
            " ",
            "198",
            "8",
            "  ",
            " –",
            " Mo",
            "amen",
            " Zak",
            "aria",
            ",",
            " Egyptian",
            " football",
            "er",
            "198",
            "9",
            " –",
            " Beth",
            "an",
            " D",
            "aint",
            "on",
            ",",
            " Welsh",
            " rugby",
            " union",
            " player",
            " ",
            " ",
            "198",
            "9",
            "  ",
            " –",
            " Miguel",
            " Ãģ",
            "ng",
            "el",
            " P",
            "once",
            ",",
            " American",
            "-M",
            "ex",
            "ican",
            " football",
            "er",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            0.166,
            -0.0,
            0.054,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "9",
            ",",
            " the",
            " London",
            " Mathematical",
            " Society",
            " in",
            " ",
            "199",
            "4",
            ",",
            " the",
            " Canadian",
            " Academy",
            " of",
            " Sciences",
            " in",
            " ",
            "199",
            "5",
            " (",
            "inc",
            "orpor",
            "ated",
            " since",
            " ",
            "200",
            "2",
            " in",
            " the",
            " Royal",
            " Society",
            " of",
            " Canada",
            "),",
            " the",
            " US",
            " National",
            " Academy",
            " of",
            " Sciences",
            " in",
            " ",
            "199",
            "7",
            ",",
            " the",
            " Russian",
            " Academy",
            " of",
            " Science",
            " in",
            " ",
            "200",
            "3",
            " and",
            " the",
            " Royal",
            " Academy",
            " of",
            " Science",
            ",",
            " Letters"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.117,
            0.169,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "8",
            ",",
            " France",
            " provided",
            " the",
            " Americans",
            " money",
            ",",
            " weapons",
            ",",
            " soldiers",
            ",",
            " and",
            " naval",
            " assistance",
            ",",
            " while",
            " French",
            " troops",
            " fought",
            " under",
            " U",
            ".S",
            ".",
            " command",
            " in",
            " North",
            " America",
            ".",
            " While",
            " Spain",
            " did",
            " not",
            " formally",
            " join",
            " the",
            " war",
            " in",
            " America",
            ",",
            " they",
            " provided",
            " access",
            " to",
            " the",
            " Mississippi",
            " River",
            " and",
            " captured",
            " British",
            " possessions",
            " on",
            " the",
            " Gulf",
            " of",
            " Mexico",
            " that",
            " denied",
            " bases",
            " to",
            " the",
            " Royal",
            " Navy"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.094,
            0.142,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "4",
            ")",
            " How",
            "l",
            " An",
            "notated",
            " (",
            "199",
            "5",
            ")",
            " Illum",
            "inated",
            " Po",
            "ems",
            " (",
            "199",
            "6",
            ")",
            " Selected",
            " Po",
            "ems",
            ":",
            " ",
            "194",
            "7",
            "–",
            "199",
            "5",
            " (",
            "199",
            "6",
            ")",
            " Death",
            " and",
            " Fame",
            ":",
            " Po",
            "ems",
            " ",
            "199",
            "3",
            "–",
            "199",
            "7",
            " (",
            "199",
            "9",
            ")",
            " Del",
            "iber",
            "ate",
            " Pro",
            "se",
            " ",
            "195",
            "2",
            "–",
            "199",
            "5",
            " (",
            "200",
            "0",
            ")"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.086,
            0.258,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "6",
            ".",
            " \"",
            "B",
            "allet",
            ":",
            " Still",
            " Another",
            " Bal",
            "anch",
            "ine",
            "-",
            "Str",
            "av",
            "insky",
            " Pearl",
            ";",
            " City",
            " T",
            "roupe",
            " Performs",
            " in",
            " Premiere",
            " Here",
            " Vari",
            "ations",
            " for",
            " H",
            "ux",
            "ley",
            " at",
            " State",
            " Theater",
            "\".",
            " The",
            " New",
            " York",
            " Times",
            ",",
            " p",
            ".",
            "Âł",
            "28",
            ".",
            " ",
            " Fir",
            "ch",
            "ow",
            ",",
            " Peter",
            ".",
            " Ald",
            "ous",
            " H",
            "ux",
            "ley",
            ":",
            " Sat",
            "ir",
            "ist",
            " and",
            " Nov",
            "elist"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.062,
            0.142,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "5",
            ")",
            "196",
            "1",
            " –",
            " J",
            "ules",
            " Bord",
            "et",
            ",",
            " Belgian",
            " microbi",
            "ologist",
            " and",
            " immun",
            "ologist",
            ",",
            " Nobel",
            " Prize",
            " laure",
            "ate",
            " (",
            "b",
            ".",
            " ",
            "187",
            "0",
            ")",
            "196",
            "3",
            " –",
            " Otto",
            " Str",
            "uve",
            ",",
            " Ukrainian",
            "-American",
            " astronom",
            "er",
            " and",
            " academic",
            " (",
            "b",
            ".",
            " ",
            "189",
            "7",
            ")",
            "197",
            "0",
            " –",
            " Maurice",
            " Stokes",
            ",",
            " American",
            " basketball",
            " player",
            " (",
            "b",
            ".",
            " ",
            "193",
            "3"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.047,
            0.268,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "1",
            ".",
            "5",
            "Âł",
            "Î¼",
            "g",
            "/L",
            " in",
            " seaw",
            "ater",
            ".",
            "Min",
            "erals",
            " with",
            " the",
            " formula",
            " M",
            "As",
            "S",
            " and",
            " M",
            "As",
            "2",
            " (",
            "M",
            " =",
            " Fe",
            ",",
            " Ni",
            ",",
            " Co",
            ")",
            " are",
            " the",
            " dominant",
            " commercial",
            " sources",
            " of",
            " arsen",
            "ic",
            ",",
            " together",
            " with",
            " real",
            "gar",
            " (",
            "an",
            " arsen",
            "ic",
            " sulf",
            "ide",
            " mineral",
            ")",
            " and",
            " native",
            " (",
            "element",
            "al",
            ")",
            " arsen",
            "ic",
            ".",
            " An"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.047,
            0.032,
            -0.0,
            -0.0,
            -0.0,
            0.002,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "7",
            " took",
            " place",
            " simultaneously",
            " in",
            " Hollywood",
            " and",
            " New",
            " York",
            ",",
            " first",
            " at",
            " the",
            " NBC",
            " International",
            " Theatre",
            " (",
            "195",
            "3",
            ")",
            " and",
            " then",
            " at",
            " the",
            " NBC",
            " Century",
            " Theatre",
            ",",
            " after",
            " which",
            " the",
            " ceremony",
            " took",
            " place",
            " solely",
            " in",
            " Los",
            " Angeles",
            ".",
            " The",
            " Oscars",
            " moved",
            " to",
            " the",
            " Santa",
            " Monica",
            " Civic",
            " Auditor",
            "ium",
            " in",
            " Santa",
            " Monica",
            ",",
            " California",
            ",",
            " in",
            " ",
            "196",
            "1",
            ".",
            " By",
            " ",
            "196"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            0.988,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "Take",
            " a",
            " Chance",
            " on",
            " Me",
            "\"",
            " (",
            "with",
            " MC",
            " K",
            "inky",
            "),",
            " and",
            " Ly",
            "ng",
            "stad",
            "'s",
            " a",
            " c",
            "app",
            "ella",
            " du",
            "et",
            " with",
            " the",
            " Real",
            " Group",
            " of",
            " \"",
            "D",
            "ancing",
            " Queen",
            "\".",
            " A",
            " second",
            " ",
            "12",
            "-track",
            " album",
            " was",
            " released",
            " in",
            " ",
            "199",
            "9",
            ",",
            " titled",
            " AB",
            "BA",
            "mania",
            ",",
            " with",
            " proceeds",
            " going",
            " to",
            " the",
            " Youth",
            " Music",
            " charity",
            " in",
            " England",
            ".",
            " It"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.848,
            0.146,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "Div",
            "itt",
            " turned",
            " it",
            " down",
            ";",
            " his",
            " crew",
            " had",
            " spent",
            " a",
            " great",
            " deal",
            " of",
            " time",
            " preparing",
            " to",
            " test",
            " the",
            " LM",
            ",",
            " and",
            " that",
            " was",
            " what",
            " he",
            " still",
            " wanted",
            " to",
            " do",
            ".",
            " S",
            "lay",
            "ton",
            " then",
            " decided",
            " to",
            " swap",
            " the",
            " prime",
            " and",
            " backup",
            " crews",
            " of",
            " the",
            " D",
            "and",
            " E",
            "missions",
            ".",
            " This",
            " swap",
            " also",
            " meant",
            " a",
            " swap",
            " of",
            " spacecraft",
            ",",
            " requiring",
            " B",
            "orman",
            "'s"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.766,
            0.097,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "b",
            ".",
            " ",
            "189",
            "6",
            ")",
            "195",
            "0",
            " –",
            " Louis",
            " Wil",
            "kins",
            ",",
            " American",
            " pole",
            " v",
            "aul",
            "ter",
            " (",
            "b",
            ".",
            " ",
            "188",
            "2",
            ")",
            "195",
            "3",
            " –",
            " I",
            "dr",
            "is",
            " Davies",
            ",",
            " Welsh",
            " poet",
            " and",
            " author",
            " (",
            "b",
            ".",
            " ",
            "190",
            "5",
            ")",
            "195",
            "9",
            " –",
            " Leo",
            " Ary",
            "eh",
            " Mayer",
            ",",
            " Polish",
            "-Israel",
            "i",
            " scholar",
            " and",
            " academic",
            " (",
            "b",
            ".",
            " ",
            "189"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.754,
            0.017,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " Independence",
            ":",
            " Patriot",
            " forces",
            " led",
            " by",
            " Sim",
            "Ã³n",
            " Bol",
            "ÃŃ",
            "var",
            " defeat",
            " the",
            " Spanish",
            " Royal",
            "ist",
            " army",
            " in",
            " the",
            " Battle",
            " of",
            " Jun",
            "ÃŃn",
            ".",
            "182",
            "5",
            " –",
            " The",
            " Bol",
            "iv",
            "ian",
            " Declaration",
            " of",
            " Independence",
            " is",
            " proclaimed",
            ".",
            "186",
            "1",
            " –",
            " Britain",
            " imposes",
            " the",
            " Lagos",
            " Treaty",
            " of",
            " C",
            "ession",
            " to",
            " suppress",
            " slavery",
            " in",
            " what",
            " is",
            " now",
            " Nigeria",
            ".",
            "186",
            "2",
            " –",
            " American",
            " Civil"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.754,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " indefinite",
            " duration",
            ".",
            " ,",
            " there",
            " were",
            " ",
            "1",
            ",",
            "397",
            ",",
            "000",
            " main",
            " telephone",
            " lines",
            " and",
            " ",
            "1",
            ",",
            "485",
            ",",
            "000",
            " internet",
            " users",
            ".",
            " There",
            " are",
            " four",
            " GSM",
            " providers",
            ":",
            " Az",
            "erc",
            "ell",
            ",",
            " ,",
            " A",
            "zer",
            "fon",
            " (",
            "N",
            "ar",
            " Mobile",
            "),",
            " Nak",
            "ht",
            "el",
            " mobile",
            " network",
            " operators",
            " and",
            " one",
            " CD",
            "MA",
            ".",
            "In",
            " the",
            " ",
            "21",
            "st",
            " century",
            " a"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            0.734,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.026,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "us",
            "ole",
            "ums",
            ".",
            " In",
            " the",
            " ",
            "19",
            "th",
            " and",
            " early",
            " ",
            "20",
            "th",
            " centuries",
            ",",
            " little",
            " monumental",
            " architecture",
            " was",
            " created",
            ",",
            " but",
            " distinctive",
            " residences",
            " were",
            " built",
            " in",
            " B",
            "aku",
            " and",
            " elsewhere",
            ".",
            " Among",
            " the",
            " most",
            " recent",
            " architectural",
            " monuments",
            ",",
            " the",
            " B",
            "aku",
            " sub",
            "ways",
            " are",
            " noted",
            " for",
            " their",
            " lavish",
            " decor",
            ".",
            "The",
            " task",
            " for",
            " modern",
            " Azerbai",
            "j",
            "ani",
            " architecture",
            " is",
            " diverse",
            " application"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.73,
            0.01,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "ian",
            " during",
            " the",
            " same",
            " era",
            ",",
            " also",
            " describes",
            " the",
            " relations",
            " between",
            " the",
            " H",
            "uns",
            " and",
            " the",
            " Eastern",
            " Roman",
            " Empire",
            ".",
            "Numer",
            "ous",
            " ecc",
            "lesi",
            "ast",
            "ical",
            " writings",
            " contain",
            " useful",
            " but",
            " scattered",
            " information",
            ",",
            " sometimes",
            " difficult",
            " to",
            " authenticate",
            " or",
            " distorted",
            " by",
            " years",
            " of",
            " hand",
            "-copy",
            "ing",
            " between",
            " the",
            " ",
            "6",
            "th",
            " and",
            " ",
            "17",
            "th",
            " centuries",
            ".",
            " The",
            " Hungarian",
            " writers",
            " of",
            " the",
            " ",
            "12"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.644,
            0.08,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " for",
            " more",
            " detail",
            ").",
            " An",
            " original",
            " voice",
            "less",
            " al",
            "ve",
            "olar",
            " lateral",
            " fr",
            "ic",
            "ative",
            " ",
            " became",
            " .",
            " ",
            "Its",
            " emph",
            "atic",
            " counterpart",
            " ",
            " was",
            " considered",
            " by",
            " Arabs",
            " to",
            " be",
            " the",
            " most",
            " unusual",
            " sound",
            " in",
            " Arabic",
            " (",
            "H",
            "ence",
            " the",
            " Classical",
            " Arabic",
            "'s",
            " app",
            "ellation",
            "  ",
            " or",
            " \"",
            "language",
            " of",
            " the",
            " \").",
            " For",
            " most",
            " modern",
            " dialect",
            "s",
            ",",
            " it",
            " has",
            " become",
            " an",
            " emph"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.566,
            0.195,
            0.027,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "1",
            " January",
            " ",
            "201",
            "1",
            ".",
            "It",
            " is",
            " still",
            " gramm",
            "atically",
            " correct",
            " to",
            " write",
            " geographical",
            " names",
            " with",
            " the",
            " letter",
            " Ãħ",
            " and",
            " local",
            " councils",
            " are",
            " allowed",
            " to",
            " use",
            " the",
            " A",
            "a",
            " spelling",
            " as",
            " an",
            " alternative",
            " and",
            " most",
            " newspapers",
            " and",
            " public",
            " institutions",
            " will",
            " accept",
            " either",
            ".",
            " Some",
            " official",
            " authorities",
            " such",
            " as",
            " the",
            " Danish",
            " Language",
            " Committee",
            ",",
            " publisher",
            " of",
            " the",
            " Danish",
            " Orth",
            "ographic",
            " Dictionary",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.555,
            0.072,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.011,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " three",
            " years",
            " later",
            ",",
            " at",
            " the",
            " ",
            "193",
            "8",
            " ceremony",
            ".",
            " Nichols",
            " was",
            " nominated",
            " for",
            " three",
            " further",
            " Academy",
            " Awards",
            " during",
            " his",
            " career",
            ".",
            "George",
            " C",
            ".",
            " Scott",
            " became",
            " the",
            " second",
            " person",
            " to",
            " refuse",
            " his",
            " award",
            " (",
            "Best",
            " Actor",
            " in",
            " ",
            "197",
            "0",
            " for",
            " Patton",
            ")",
            " at",
            " the",
            " ",
            "43",
            "rd",
            " Academy",
            " Awards",
            " ceremony",
            ".",
            " Scott",
            " described",
            " it",
            " as",
            " a",
            " \"",
            "me",
            "at",
            " parade"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            0.508,
            0.085,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.104,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            "789",
            ",",
            "024",
            " inhabitants",
            " in",
            " ",
            "201",
            "4",
            ".",
            "Eth",
            "n",
            "ically",
            ",",
            " there",
            " are",
            " three",
            " main",
            " groups",
            ",",
            " each",
            " speaking",
            " a",
            " B",
            "antu",
            " language",
            ":",
            " the",
            " Ov",
            "imb",
            "und",
            "u",
            " who",
            " represent",
            " ",
            "37",
            "%",
            " of",
            " the",
            " population",
            ",",
            " the",
            " Amb",
            "und",
            "u",
            " with",
            " ",
            "25",
            "%,",
            " and",
            " the",
            " Bak",
            "ongo",
            " ",
            "11",
            "%.",
            " Other",
            " numer",
            "ically",
            " important",
            " groups",
            " include",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.498,
            0.065,
            0.075,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " (",
            "F",
            "IA",
            ")",
            " replacing",
            " the",
            " World",
            " Championship",
            " for",
            " Sports",
            " Cars",
            " with",
            " the",
            " International",
            " Championship",
            " for",
            " GT",
            " Manufacturers",
            ".",
            "From",
            " ",
            "196",
            "2",
            " through",
            " ",
            "200",
            "3",
            ",",
            " NASCAR",
            "'s",
            " premier",
            " series",
            " was",
            " called",
            " the",
            " Winston",
            " Cup",
            " Series",
            ",",
            " sponsored",
            " by",
            " R",
            ".",
            " J",
            ".",
            " Reynolds",
            " Tobacco",
            " Company",
            " cigarette",
            " brand",
            " Winston",
            ".",
            " The",
            " changes",
            " that",
            " resulted",
            " from",
            " RJ",
            "R",
            "'s",
            " involvement",
            ",",
            " as"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.478,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "iate",
            " from",
            " the",
            " clear",
            " trends",
            " going",
            " from",
            " lithium",
            " to",
            " ca",
            "esium",
            ",",
            " such",
            " as",
            " the",
            " first",
            " ion",
            "isation",
            " energy",
            ",",
            " electron",
            " affinity",
            ",",
            " and",
            " an",
            "ion",
            " polar",
            "is",
            "ability",
            ",",
            " though",
            " due",
            " to",
            " the",
            " pa",
            "uc",
            "ity",
            " of",
            " known",
            " data",
            " about",
            " franc",
            "ium",
            " many",
            " sources",
            " give",
            " extrapol",
            "ated",
            " values",
            ",",
            " ignoring",
            " that",
            " relativ",
            "istic",
            " effects",
            " make",
            " the",
            " trend",
            " from",
            " lithium",
            " to",
            " ca",
            "esium"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.445,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.098,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "ports",
            " ",
            " total",
            ":",
            " ",
            "1",
            " (",
            "202",
            "1",
            ")",
            "International",
            " and",
            " domestic",
            " services",
            " are",
            " maintained",
            " by",
            " TA",
            "AG",
            " Angola",
            " Airlines",
            ",",
            " Aer",
            "of",
            "lot",
            ",",
            " British",
            " Airways",
            ",",
            " Brussels",
            " Airlines",
            ",",
            " L",
            "uf",
            "th",
            "ansa",
            ",",
            " Air",
            " France",
            ",",
            " Cub",
            "ana",
            ",",
            " Ethiopian",
            " Airlines",
            ",",
            " Emirates",
            ",",
            " Delta",
            " Air",
            " Lines",
            ",",
            " Royal",
            " Air",
            " Mar",
            "oc",
            ",",
            " I",
            "ber",
            "ia",
            ",",
            " H",
            "ain"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.434,
            0.005,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " after",
            " heavy",
            " rains",
            " and",
            " con",
            "gregate",
            " at",
            " a",
            " breeding",
            " site",
            ".",
            " They",
            " are",
            " attracted",
            " there",
            " by",
            " the",
            " calling",
            " of",
            " the",
            " first",
            " male",
            " to",
            " find",
            " a",
            " suitable",
            " place",
            ",",
            " perhaps",
            " a",
            " pool",
            " that",
            " forms",
            " in",
            " the",
            " same",
            " place",
            " each",
            " rainy",
            " season",
            ".",
            " The",
            " assembled",
            " frogs",
            " may",
            " call",
            " in",
            " un",
            "ison",
            " and",
            " fren",
            "z",
            "ied",
            " activity",
            " ens",
            "ues",
            ",",
            " the",
            " males",
            " scrambling",
            " to",
            " mate",
            " with"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            0.418,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " given",
            " new",
            " school",
            " buildings",
            " centrally",
            " in",
            " the",
            " new",
            " Freight",
            " Station",
            " Neighborhood",
            ",",
            " planned",
            " for",
            " development",
            " in",
            " the",
            " ",
            "202",
            "0",
            "s",
            ".",
            " In",
            " the",
            " interim",
            ",",
            " the",
            " city",
            " council",
            " supports",
            " a",
            " culture",
            ",",
            " business",
            " and",
            " education",
            " centre",
            " in",
            " the",
            " area",
            ",",
            " which",
            " may",
            " continue",
            " in",
            " the",
            " future",
            " neighbourhood",
            " in",
            " some",
            " form",
            ".",
            " The",
            " future",
            " occupants",
            " of",
            " the",
            " neighbourhood",
            " will",
            " be",
            " businesses",
            " and",
            " organisations"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.387,
            0.087,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " is",
            " ca",
            "esium",
            " at",
            " ",
            "225",
            "Âł",
            "pm",
            ".",
            "When",
            " subjected",
            " to",
            " external",
            " forces",
            ",",
            " like",
            " electrical",
            " fields",
            ",",
            " the",
            " shape",
            " of",
            " an",
            " atom",
            " may",
            " dev",
            "iate",
            " from",
            " spherical",
            " symmetry",
            ".",
            " The",
            " deformation",
            " depends",
            " on",
            " the",
            " field",
            " magnitude",
            " and",
            " the",
            " orbital",
            " type",
            " of",
            " outer",
            " shell",
            " electrons",
            ",",
            " as",
            " shown",
            " by",
            " group",
            "-the",
            "oretical",
            " considerations",
            ".",
            " As",
            "pherical",
            " deviations",
            " might",
            " be",
            " elic",
            "ited",
            " for"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.344,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " portrait",
            " appears",
            " on",
            " two",
            " denomin",
            "ations",
            " of",
            " United",
            " States",
            " currency",
            ",",
            " the",
            " penny",
            " and",
            " the",
            " $",
            "5",
            " bill",
            ".",
            " His",
            " likeness",
            " also",
            " appears",
            " on",
            " many",
            " postage",
            " stamps",
            ".",
            " While",
            " he",
            " is",
            " usually",
            " portrayed",
            " be",
            "arded",
            ",",
            " he",
            " did",
            " not",
            " grow",
            " a",
            " beard",
            " until",
            " ",
            "186",
            "0",
            " at",
            " the",
            " suggestion",
            " of",
            " ",
            "11",
            "-year",
            "-old",
            " Grace",
            " Bed",
            "ell",
            ".",
            " He",
            " was",
            " the",
            " first",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.33,
            0.136,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " const",
            "ell",
            "ations",
            ".",
            " It",
            " is",
            " found",
            " in",
            " a",
            " region",
            " often",
            " called",
            " the",
            " Sea",
            " due",
            " to",
            " its",
            " prof",
            "usion",
            " of",
            " const",
            "ell",
            "ations",
            " with",
            " wat",
            "ery",
            " associations",
            " such",
            " as",
            " C",
            "etus",
            " the",
            " whale",
            ",",
            " Pis",
            "ces",
            " the",
            " fish",
            ",",
            " and",
            " E",
            "rid",
            "anus",
            " the",
            " river",
            ".",
            "At",
            " apparent",
            " magnitude",
            " ",
            "2",
            ".",
            "9",
            ",",
            " Beta",
            " Aqu",
            "ari",
            "i",
            " is",
            " the",
            " brightest",
            " star",
            " in"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.235,
            0.082,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " chem",
            "ists",
            " Johannes",
            " Nicola",
            "us",
            " Br",
            "Ã¸",
            "n",
            "sted",
            " and",
            " Thomas",
            " Martin",
            " Low",
            "ry",
            " independently",
            " recognized",
            " that",
            " acid",
            "–",
            "base",
            " reactions",
            " involve",
            " the",
            " transfer",
            " of",
            " a",
            " proton",
            ".",
            " A",
            " Br",
            "Ã¸",
            "n",
            "sted",
            "–",
            "Low",
            "ry",
            " acid",
            " (",
            "or",
            " simply",
            " Br",
            "Ã¸",
            "n",
            "sted",
            " acid",
            ")",
            " is",
            " a",
            " species",
            " that",
            " don",
            "ates",
            " a",
            " proton",
            " to",
            " a",
            " Br",
            "Ã¸",
            "n",
            "sted",
            "–",
            "Low",
            "ry"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "achuset",
    "amax",
    "getAs",
    "Ð¸Ð½Ð¾Ðº",
    "leted"
  ],
  "bottom_logits": [
    "aj",
    "estre",
    " cause",
    " mon",
    "ispens"
  ],
  "act_min": -0.0,
  "act_max": 1.141
}
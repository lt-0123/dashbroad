{
  "index": 2265,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.011,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.879,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            " is",
            " grown",
            " locally",
            ".",
            " The",
            " principal",
            " livestock",
            " activity",
            " is",
            " domestic",
            " sheep",
            " raising",
            ".",
            " Manufacturing",
            " output",
            " consists",
            " mainly",
            " of",
            " cigarettes",
            ",",
            " cigars",
            ",",
            " and",
            " furniture",
            ".",
            " And",
            "orra",
            "'s",
            " natural",
            " resources",
            " include",
            " hydro",
            "electric",
            " power",
            ",",
            " mineral",
            " water",
            ",",
            " timber",
            ",",
            " iron",
            " ore",
            ",",
            " and",
            " lead",
            ".",
            "And",
            "orra",
            " is",
            " not",
            " a",
            " member",
            " of",
            " the",
            " European",
            " Union",
            ",",
            " but",
            " enjoys",
            " a",
            " special",
            " relationship",
            " with"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.011,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.879,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            " is",
            " grown",
            " locally",
            ".",
            " The",
            " principal",
            " livestock",
            " activity",
            " is",
            " domestic",
            " sheep",
            " raising",
            ".",
            " Manufacturing",
            " output",
            " consists",
            " mainly",
            " of",
            " cigarettes",
            ",",
            " cigars",
            ",",
            " and",
            " furniture",
            ".",
            " And",
            "orra",
            "'s",
            " natural",
            " resources",
            " include",
            " hydro",
            "electric",
            " power",
            ",",
            " mineral",
            " water",
            ",",
            " timber",
            ",",
            " iron",
            " ore",
            ",",
            " and",
            " lead",
            ".",
            "And",
            "orra",
            " is",
            " not",
            " a",
            " member",
            " of",
            " the",
            " European",
            " Union",
            ",",
            " but",
            " enjoys",
            " a",
            " special",
            " relationship",
            " with"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.875,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.05,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            " produce",
            " honey",
            " from",
            " clo",
            "ver",
            " and",
            " fire",
            "weed",
            ".",
            " Hybrid",
            " can",
            "ola",
            " also",
            " requires",
            " bee",
            " poll",
            "ination",
            ",",
            " and",
            " some",
            " bee",
            "keepers",
            " service",
            " this",
            " need",
            ".",
            "Fore",
            "stry",
            " plays",
            " a",
            " vital",
            " role",
            " in",
            " Alberta",
            "'s",
            " economy",
            ",",
            " providing",
            " over",
            " ",
            "15",
            ",",
            "000",
            " jobs",
            " and",
            " contributing",
            " billions",
            " of",
            " dollars",
            " annually",
            ".",
            " Uses",
            " for",
            " harvested",
            " timber",
            " include",
            " pulp",
            "wood",
            ",",
            " hardwood",
            ",",
            " engineered",
            " wood"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.875,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 52,
          "is_repeated_datapoint": false,
          "tokens": [
            " In",
            " contrast",
            " to",
            " the",
            " primarily",
            " agricultural",
            " economy",
            " of",
            " the",
            " previous",
            " century",
            ",",
            " this",
            " was",
            " only",
            " about",
            " one",
            " percent",
            " of",
            " the",
            " state",
            "'s",
            " gross",
            " domestic",
            " product",
            ".",
            " The",
            " number",
            " of",
            " private",
            " farms",
            " has",
            " declined",
            " at",
            " a",
            " steady",
            " rate",
            " since",
            " the",
            " ",
            "196",
            "0",
            "s",
            ",",
            " as",
            " land",
            " has",
            " been",
            " sold",
            " to",
            " developers",
            ",",
            " timber",
            " companies",
            ",",
            " and",
            " large",
            " farming",
            " conglomer",
            "ates",
            ".",
            "Non",
            "-ag"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.871,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.01,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "193",
            "6",
            ".",
            " In",
            " ",
            "194",
            "8",
            ",",
            " he",
            " published",
            " the",
            " book",
            " Post",
            "-",
            "Adobe",
            ";",
            " Simpl",
            "ified",
            " Adobe",
            " Construction",
            " Comb",
            "ining",
            " A",
            " R",
            "ugged",
            " Timber",
            " Frame",
            " And",
            " Modern",
            " St",
            "abil",
            "ized",
            " Adobe",
            ",",
            " which",
            " described",
            " his",
            " method",
            " of",
            " construction",
            ",",
            " including",
            " how",
            " to",
            " make",
            " \"",
            "Bit",
            "ud",
            "obe",
            ".\"",
            " In",
            " ",
            "193",
            "8",
            ",",
            " he",
            " served",
            " as",
            " an",
            " adviser",
            " to",
            " the",
            " architects"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.871,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.01,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "193",
            "6",
            ".",
            " In",
            " ",
            "194",
            "8",
            ",",
            " he",
            " published",
            " the",
            " book",
            " Post",
            "-",
            "Adobe",
            ";",
            " Simpl",
            "ified",
            " Adobe",
            " Construction",
            " Comb",
            "ining",
            " A",
            " R",
            "ugged",
            " Timber",
            " Frame",
            " And",
            " Modern",
            " St",
            "abil",
            "ized",
            " Adobe",
            ",",
            " which",
            " described",
            " his",
            " method",
            " of",
            " construction",
            ",",
            " including",
            " how",
            " to",
            " make",
            " \"",
            "Bit",
            "ud",
            "obe",
            ".\"",
            " In",
            " ",
            "193",
            "8",
            ",",
            " he",
            " served",
            " as",
            " an",
            " adviser",
            " to",
            " the",
            " architects"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.863,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 20,
          "is_repeated_datapoint": false,
          "tokens": [
            " petroleum",
            ",",
            " natural",
            " gas",
            ",",
            " coal",
            ",",
            " gold",
            ",",
            " precious",
            " metals",
            ",",
            " zinc",
            " and",
            " other",
            " mining",
            ",",
            " seafood",
            " processing",
            ",",
            " timber",
            " and",
            " wood",
            " products",
            ".",
            " There",
            " is",
            " also",
            " a",
            " growing",
            " service",
            " and",
            " tourism",
            " sector",
            ".",
            " Tour",
            "ists",
            " have",
            " contributed",
            " to",
            " the",
            " economy",
            " by",
            " supporting",
            " local",
            " lodging",
            ".",
            "Energy",
            "Al",
            "aska",
            " has",
            " vast",
            " energy",
            " resources",
            ",",
            " although",
            " its",
            " oil",
            " reserves",
            " have",
            " been",
            " largely"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.856,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            " with",
            " the",
            " Han",
            "se",
            "atic",
            " League",
            ".",
            " From",
            " the",
            " ",
            "15",
            "th",
            " century",
            " on",
            " the",
            " city",
            " established",
            " an",
            " independent",
            " trade",
            " route",
            " with",
            " the",
            " Baltic",
            " Sea",
            " in",
            " grain",
            " and",
            " timber",
            ",",
            " cutting",
            " out",
            " the",
            " Han",
            "se",
            "atic",
            " League",
            " as",
            " middle",
            "men",
            ".",
            " The",
            " city",
            " became",
            " the",
            " staple",
            " market",
            " of",
            " Europe",
            " for",
            " bulk",
            " cargo",
            ".",
            " This",
            " was",
            " made",
            " possible",
            " due",
            " to",
            " innovations",
            " in",
            " the",
            " h"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.856,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            " with",
            " the",
            " Han",
            "se",
            "atic",
            " League",
            ".",
            " From",
            " the",
            " ",
            "15",
            "th",
            " century",
            " on",
            " the",
            " city",
            " established",
            " an",
            " independent",
            " trade",
            " route",
            " with",
            " the",
            " Baltic",
            " Sea",
            " in",
            " grain",
            " and",
            " timber",
            ",",
            " cutting",
            " out",
            " the",
            " Han",
            "se",
            "atic",
            " League",
            " as",
            " middle",
            "men",
            ".",
            " The",
            " city",
            " became",
            " the",
            " staple",
            " market",
            " of",
            " Europe",
            " for",
            " bulk",
            " cargo",
            ".",
            " This",
            " was",
            " made",
            " possible",
            " due",
            " to",
            " innovations",
            " in",
            " the",
            " h"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.852,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            " Union",
            " squad",
            "rons",
            " wherever",
            " they",
            " threatened",
            ".",
            " But",
            " in",
            " the",
            " face",
            " of",
            " overwhelming",
            " Union",
            " superiority",
            " and",
            " the",
            " Union",
            "'s",
            " iron",
            "cl",
            "ad",
            " war",
            "ships",
            ",",
            " they",
            " were",
            " unsuccessful",
            ".",
            "In",
            " addition",
            " to",
            " ocean",
            "-going",
            " war",
            "ships",
            " coming",
            " up",
            " the",
            " Mississippi",
            ",",
            " the",
            " Union",
            " Navy",
            " used",
            " timber",
            "cl",
            "ads",
            ",",
            " tin",
            "cl",
            "ads",
            ",",
            " and",
            " armored",
            " gun",
            "boats",
            ".",
            " Sh",
            "ipy",
            "ards",
            " at",
            " Cairo"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.852,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            " Union",
            " squad",
            "rons",
            " wherever",
            " they",
            " threatened",
            ".",
            " But",
            " in",
            " the",
            " face",
            " of",
            " overwhelming",
            " Union",
            " superiority",
            " and",
            " the",
            " Union",
            "'s",
            " iron",
            "cl",
            "ad",
            " war",
            "ships",
            ",",
            " they",
            " were",
            " unsuccessful",
            ".",
            "In",
            " addition",
            " to",
            " ocean",
            "-going",
            " war",
            "ships",
            " coming",
            " up",
            " the",
            " Mississippi",
            ",",
            " the",
            " Union",
            " Navy",
            " used",
            " timber",
            "cl",
            "ads",
            ",",
            " tin",
            "cl",
            "ads",
            ",",
            " and",
            " armored",
            " gun",
            "boats",
            ".",
            " Sh",
            "ipy",
            "ards",
            " at",
            " Cairo"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.844,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " exported",
            " back",
            " to",
            " Egypt",
            ".",
            "By",
            " the",
            " Second",
            " Dynasty",
            " at",
            " latest",
            ",",
            " ancient",
            " Egyptian",
            " trade",
            " with",
            " By",
            "b",
            "los",
            " yielded",
            " a",
            " critical",
            " source",
            " of",
            " quality",
            " timber",
            " not",
            " found",
            " in",
            " Egypt",
            ".",
            " By",
            " the",
            " Fifth",
            " Dynasty",
            ",",
            " trade",
            " with",
            " P",
            "unt",
            " provided",
            " gold",
            ",",
            " aromatic",
            " res",
            "ins",
            ",",
            " ebony",
            ",",
            " ivory",
            ",",
            " and",
            " wild",
            " animals",
            " such",
            " as",
            " monkeys",
            " and",
            " bab",
            "oons",
            ".",
            " Egypt"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.844,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 52,
          "is_repeated_datapoint": false,
          "tokens": [
            " dose",
            " is",
            " approximately",
            " ",
            "20",
            "Âł",
            "grams",
            " of",
            " ash",
            ".",
            " Scrap",
            " C",
            "CA",
            " lumber",
            " from",
            " construction",
            " and",
            " demolition",
            " sites",
            " may",
            " be",
            " inadvertently",
            " used",
            " in",
            " commercial",
            " and",
            " domestic",
            " fires",
            ".",
            " Prot",
            "ocols",
            " for",
            " safe",
            " disposal",
            " of",
            " C",
            "CA",
            " lumber",
            " are",
            " not",
            " consistent",
            " throughout",
            " the",
            " world",
            ".",
            " W",
            "ides",
            "pread",
            " landfill",
            " disposal",
            " of",
            " such",
            " timber",
            " raises",
            " some",
            " concern",
            ",",
            " but",
            " other",
            " studies",
            " have",
            " shown",
            " no"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.836,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.003,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            " made",
            " by",
            " pressing",
            " the",
            " mud",
            " mixture",
            " into",
            " an",
            " open",
            " timber",
            " frame",
            ".",
            " In",
            " North",
            " America",
            ",",
            " the",
            " brick",
            " is",
            " typically",
            " about",
            " ",
            " in",
            " size",
            ".",
            " The",
            " mixture",
            " is",
            " molded",
            " into",
            " the",
            " frame",
            ",",
            " which",
            " is",
            " removed",
            " after",
            " initial",
            " setting",
            ".",
            " After",
            " drying",
            " for",
            " a",
            " few",
            " hours",
            ",",
            " the",
            " bricks",
            " are",
            " turned",
            " on",
            " edge",
            " to",
            " finish",
            " drying",
            ".",
            " Slow",
            " drying",
            " in",
            " shade",
            " reduces",
            " cracking"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.836,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            "fight",
            "ing",
            ".",
            " Napoleon",
            " allies",
            " with",
            " Frederick",
            " to",
            " sell",
            " surplus",
            " timber",
            " that",
            " P",
            "ilk",
            "ington",
            " also",
            " sought",
            ",",
            " but",
            " is",
            " enraged",
            " to",
            " learn",
            " Frederick",
            " paid",
            " him",
            " in",
            " counterfeit",
            " money",
            ".",
            " Shortly",
            " after",
            " the",
            " sw",
            "ind",
            "ling",
            ",",
            " Frederick",
            " and",
            " his",
            " men",
            " invade",
            " Animal",
            " Farm",
            ",",
            " killing",
            " many",
            " animals",
            " and",
            " destroying",
            " the",
            " wind",
            "mill",
            ".",
            " The",
            " brief",
            " alliance",
            " and",
            " subsequent",
            " invasion",
            " may",
            " all",
            "ude"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.836,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            "fight",
            "ing",
            ".",
            " Napoleon",
            " allies",
            " with",
            " Frederick",
            " to",
            " sell",
            " surplus",
            " timber",
            " that",
            " P",
            "ilk",
            "ington",
            " also",
            " sought",
            ",",
            " but",
            " is",
            " enraged",
            " to",
            " learn",
            " Frederick",
            " paid",
            " him",
            " in",
            " counterfeit",
            " money",
            ".",
            " Shortly",
            " after",
            " the",
            " sw",
            "ind",
            "ling",
            ",",
            " Frederick",
            " and",
            " his",
            " men",
            " invade",
            " Animal",
            " Farm",
            ",",
            " killing",
            " many",
            " animals",
            " and",
            " destroying",
            " the",
            " wind",
            "mill",
            ".",
            " The",
            " brief",
            " alliance",
            " and",
            " subsequent",
            " invasion",
            " may",
            " all",
            "ude"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.013,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.832,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 33,
          "is_repeated_datapoint": false,
          "tokens": [
            " kilometres",
            " south",
            " of",
            " the",
            " A",
            "arhus",
            " city",
            " centre",
            ".",
            "The",
            " centre",
            " of",
            " A",
            "arhus",
            " was",
            " originally",
            " a",
            " pagan",
            " burial",
            " site",
            " until",
            " A",
            "arhus",
            "'s",
            " first",
            " Christian",
            " church",
            ",",
            " Holy",
            " Trinity",
            " Church",
            ",",
            " a",
            " timber",
            " structure",
            ",",
            " was",
            " built",
            " upon",
            " it",
            " during",
            " the",
            " reign",
            " of",
            " Fro",
            "de",
            ",",
            " King",
            " of",
            " J",
            "ut",
            "land",
            ",",
            " around",
            " ",
            "900",
            ".",
            " The",
            " bishop",
            "ric",
            " of",
            " A",
            "arhus"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.809,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 33,
          "is_repeated_datapoint": false,
          "tokens": [
            " arsen",
            "ic",
            " could",
            " le",
            "ach",
            " out",
            " of",
            " the",
            " wood",
            " into",
            " the",
            " surrounding",
            " soil",
            " (",
            "from",
            " playground",
            " equipment",
            ",",
            " for",
            " instance",
            "),",
            " a",
            " risk",
            " is",
            " also",
            " presented",
            " by",
            " the",
            " burning",
            " of",
            " older",
            " C",
            "CA",
            " timber",
            ".",
            " The",
            " direct",
            " or",
            " indirect",
            " ingestion",
            " of",
            " wood",
            " ash",
            " from",
            " burnt",
            " C",
            "CA",
            " lumber",
            " has",
            " caused",
            " fatalities",
            " in",
            " animals",
            " and",
            " serious",
            " poison",
            "ings",
            " in",
            " humans",
            ";",
            " the",
            " lethal",
            " human"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.738,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            " inside",
            " a",
            " glass",
            " of",
            " milk",
            ",",
            " perhaps",
            " poisoned",
            ",",
            " that",
            " Grant",
            " is",
            " bringing",
            " to",
            " his",
            " wife",
            ";",
            " the",
            " light",
            " ensures",
            " that",
            " the",
            " audience",
            "'s",
            " attention",
            " is",
            " on",
            " the",
            " glass",
            ".",
            " Grant",
            "'s",
            " character",
            " is",
            " actually",
            " a",
            " killer",
            ",",
            " as",
            " per",
            " written",
            " in",
            " the",
            " book",
            ",",
            " Before",
            " the",
            " Fact",
            " by",
            " Francis",
            " I",
            "les",
            ",",
            " but",
            " the",
            " studio",
            " felt",
            " that",
            " Grant",
            "'s",
            " image",
            " would",
            " be"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.715,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 48,
          "is_repeated_datapoint": false,
          "tokens": [
            "-century",
            " American",
            " male",
            " writers",
            "20",
            "th",
            "-century",
            " American",
            " novel",
            "ists",
            "20",
            "th",
            "-century",
            " American",
            " short",
            " story",
            " writers",
            "20",
            "th",
            "-century",
            " Canadian",
            " male",
            " writers",
            "20",
            "th",
            "-century",
            " Canadian",
            " short",
            " story",
            " writers",
            "American",
            " male",
            " novel",
            "ists",
            "American",
            " male",
            " short",
            " story",
            " writers",
            "American",
            " science",
            " fiction",
            " writers",
            "An",
            "alog",
            " Science",
            " Fiction",
            " and",
            " Fact",
            " people",
            "Canadian",
            " M",
            "ennon",
            "ites"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            0.684,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " fact",
            ",",
            " her",
            " brother",
            "'s",
            " policies",
            " which",
            " directly",
            " threaten",
            " his",
            " business",
            ".",
            " When",
            " the",
            " government",
            " passes",
            " laws",
            " and",
            " decre",
            "es",
            " which",
            " make",
            " it",
            " impossible",
            " for",
            " him",
            " to",
            " continue",
            ",",
            " he",
            " sets",
            " all",
            " his",
            " oil",
            " wells",
            " on",
            " fire",
            ",",
            " leaving",
            " a",
            " single",
            " note",
            ":",
            " \"",
            "I",
            " am",
            " leaving",
            " it",
            " as",
            " I",
            " found",
            " it",
            ".",
            " Take",
            " over",
            ".",
            " It",
            "'s",
            " yours",
            ".\"",
            " One",
            " particular",
            " burning"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.684,
            -0.0,
            0.029,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " fact",
            ",",
            " assumes",
            " some",
            " degree",
            " of",
            " violence",
            " will",
            " occur",
            ",",
            " an",
            "ar",
            "cho",
            "-capital",
            "ism",
            " as",
            " formulated",
            " by",
            " Roth",
            "bard",
            " and",
            " others",
            " holds",
            " strongly",
            " to",
            " the",
            " central",
            " libertarian",
            " non",
            "ag",
            "gression",
            " axiom",
            ",",
            " sometimes",
            " non",
            "-ag",
            "gression",
            " principle",
            ".",
            " Roth",
            "bard",
            " wrote",
            ":",
            "R",
            "oth",
            "bard",
            "'s",
            " defense",
            " of",
            " the",
            " self",
            "-",
            "ownership",
            " principle",
            " stems",
            " from",
            " what",
            " he",
            " believed",
            " to",
            " be",
            " his",
            " fals"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.684,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " fact",
            " exists",
            ",",
            " is",
            " probably",
            " more",
            " complex",
            " and",
            " distant",
            " than",
            " we",
            " can",
            " imagine",
            " on",
            " the",
            " basis",
            " of",
            " our",
            " present",
            " state",
            " of",
            " knowledge",
            "\".",
            "Support",
            "ers",
            " of",
            " the",
            " Alta",
            "ic",
            " hypothesis",
            " formerly",
            " set",
            " the",
            " date",
            " of",
            " the",
            " Proto",
            "-Al",
            "ta",
            "ic",
            " language",
            " at",
            " around",
            " ",
            "400",
            "0",
            " BC",
            ",",
            " but",
            " today",
            " at",
            " around",
            " ",
            "500",
            "0",
            " BC",
            " or",
            " ",
            "600",
            "0",
            " BC",
            ".",
            " This"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.641,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 15,
          "is_repeated_datapoint": false,
          "tokens": [
            " Alabama",
            " ",
            " Alabama",
            " Quick",
            "F",
            "acts",
            " from",
            " the",
            " U",
            ".S",
            ".",
            " Census",
            " Bureau",
            " Alabama",
            " State",
            " Fact",
            " Sheet",
            " ",
            " ",
            "181",
            "9",
            " establishments",
            " in",
            " the",
            " United",
            " States",
            "Southern",
            " United",
            " States",
            "States",
            " and",
            " territories",
            " established",
            " in",
            " ",
            "181",
            "9",
            "States",
            " of",
            " the",
            " Confederate",
            " States",
            " of",
            " America",
            "States",
            " of",
            " the",
            " Gulf",
            " Coast",
            " of",
            " the",
            " United",
            " States",
            "States",
            " of",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.586,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.547,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " one",
            " of",
            " fact",
            " or",
            " of",
            " law",
            ".",
            " In",
            " reviewing",
            " an",
            " issue",
            " of",
            " fact",
            ",",
            " an",
            " appellate",
            " court",
            " ordinarily",
            " gives",
            " defer",
            "ence",
            " to",
            " the",
            " trial",
            " court",
            "'s",
            " findings",
            ".",
            " It",
            " is",
            " the",
            " duty",
            " of",
            " trial",
            " judges",
            " or",
            " j",
            "uries",
            " to",
            " find",
            " facts",
            ",",
            " view",
            " the",
            " evidence",
            " firsthand",
            ",",
            " and",
            " observe",
            " witness",
            " testimony",
            ".",
            " When",
            " reviewing",
            " lower",
            " decisions",
            " on",
            " an",
            " issue",
            " of",
            " fact",
            ",",
            " courts"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " fact",
            " that",
            " these",
            " foods",
            " are",
            " native",
            " to",
            " Ant",
            "igua",
            " and",
            " Barb",
            "uda",
            " as",
            " well",
            " as",
            " to",
            " a",
            " number",
            " of",
            " other",
            " Caribbean",
            " nations",
            ",",
            " the",
            " diet",
            " of",
            " the",
            " locals",
            " has",
            " become",
            " increasingly",
            " diverse",
            " and",
            " now",
            " also",
            " includes",
            " traditional",
            " dishes",
            " from",
            " Jamaica",
            " and",
            " Trinidad",
            ",",
            " such",
            " as",
            " jerk",
            " meats",
            " and",
            " rot",
            "i",
            ",",
            " as",
            " well",
            " as",
            " specialties",
            " from",
            " a",
            " number",
            " of",
            " other",
            " Caribbean",
            " nations"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " from",
            " the",
            " fact",
            " that",
            " on",
            " a",
            " manual",
            " typ",
            "ewriter",
            " the",
            " carriage",
            " holding",
            " the",
            " paper",
            " moves",
            " while",
            " the",
            " type",
            "bars",
            " that",
            " strike",
            " the",
            " ribbon",
            " remain",
            " stationary",
            ".",
            " ",
            " The",
            " entire",
            " carriage",
            " had",
            " to",
            " be",
            " pushed",
            " (",
            "returned",
            ")",
            " to",
            " the",
            " right",
            " in",
            " order",
            " to",
            " position",
            " the",
            " paper",
            " for",
            " the",
            " next",
            " line",
            ".",
            "DEC",
            " operating",
            " systems",
            " (",
            "OS",
            "/",
            "8",
            ",",
            " RT",
            "-",
            "11",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.586,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.547,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " one",
            " of",
            " fact",
            " or",
            " of",
            " law",
            ".",
            " In",
            " reviewing",
            " an",
            " issue",
            " of",
            " fact",
            ",",
            " an",
            " appellate",
            " court",
            " ordinarily",
            " gives",
            " defer",
            "ence",
            " to",
            " the",
            " trial",
            " court",
            "'s",
            " findings",
            ".",
            " It",
            " is",
            " the",
            " duty",
            " of",
            " trial",
            " judges",
            " or",
            " j",
            "uries",
            " to",
            " find",
            " facts",
            ",",
            " view",
            " the",
            " evidence",
            " firsthand",
            ",",
            " and",
            " observe",
            " witness",
            " testimony",
            ".",
            " When",
            " reviewing",
            " lower",
            " decisions",
            " on",
            " an",
            " issue",
            " of",
            " fact",
            ",",
            " courts"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.613,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " marked",
            " by",
            " the",
            " fact",
            " of",
            " having",
            " sensation",
            " and",
            " being",
            " alive",
            ".\"",
            "In",
            " the",
            " Catholic",
            " Church",
            ",",
            " opinion",
            " was",
            " divided",
            " on",
            " how",
            " serious",
            " abortion",
            " was",
            " in",
            " comparison",
            " with",
            " such",
            " acts",
            " as",
            " contraception",
            ",",
            " oral",
            " sex",
            ",",
            " and",
            " sex",
            " in",
            " marriage",
            " for",
            " pleasure",
            " rather",
            " than",
            " pro",
            "creation",
            ".",
            " The",
            " Catholic",
            " Church",
            " did",
            " not",
            " begin",
            " vigorously",
            " opposing",
            " abortion",
            " until",
            " the",
            " ",
            "19",
            "th",
            " century",
            ".",
            " As"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.613,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " most",
            " are",
            " thought",
            " to",
            " adhere",
            " to",
            " the",
            " Sunni",
            " Han",
            "afi",
            " school",
            ".",
            " According",
            " to",
            " Pew",
            " Research",
            " Center",
            ",",
            " as",
            " much",
            " as",
            " ",
            "90",
            "%",
            " are",
            " of",
            " the",
            " Sunni",
            " denomination",
            ",",
            " ",
            "7",
            "%",
            " Shia",
            " and",
            " ",
            "3",
            "%",
            " non",
            "-den",
            "omin",
            "ational",
            ".",
            " The",
            " CIA",
            " Fact",
            "book",
            " various",
            "ly",
            " estimates",
            " up",
            " to",
            " ",
            "89",
            ".",
            "7",
            "%",
            " Sunni",
            " or",
            " up",
            " to",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 7,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " easier",
            " to",
            " synchronize",
            " internationally",
            ".",
            " The",
            " fact",
            " that",
            " it",
            " continues",
            " to",
            " approximate",
            " UT",
            "1",
            " means",
            " that",
            " tasks",
            " such",
            " as",
            " navigation",
            " which",
            " require",
            " a",
            " source",
            " of",
            " Universal",
            " Time",
            " continue",
            " to",
            " be",
            " well",
            " served",
            " by",
            " the",
            " public",
            " broadcast",
            " of",
            " UTC",
            ".",
            "See",
            " also",
            " ",
            " Clock",
            " synchronization",
            " Time",
            " and",
            " frequency",
            " transfer",
            "Notes",
            "References",
            "Foot",
            "notes",
            "B",
            "ibli",
            "ography",
            "External"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            " The",
            " World",
            " Fact",
            "book",
            ".",
            " Central",
            " Intelligence",
            " Agency",
            ".",
            " Azerbaijan",
            " at",
            " University",
            " of",
            " Colorado",
            " at",
            " Boulder",
            " Country",
            " profile",
            " from",
            " BBC",
            " Key",
            " Development",
            " Fore",
            "casts",
            " for",
            " Azerbaijan",
            " from",
            " International",
            " Futures",
            " V",
            "isions",
            " of",
            " Azerbaijan",
            " Journal",
            " of",
            " The",
            " European",
            " Azerbaijan",
            " Society",
            "Major",
            " government",
            " resources",
            " President",
            " of",
            " Azerbaijan",
            " website",
            " Azerbaijan",
            " State",
            " Statistical",
            " Committee",
            " United",
            " Nations",
            " Office",
            " in",
            " Azerbaijan"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.594,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            " or",
            " '",
            "inactive",
            "',",
            " as",
            " a",
            " reference",
            " to",
            " the",
            " fact",
            " that",
            " the",
            " element",
            " undergo",
            "es",
            " almost",
            " no",
            " chemical",
            " reactions",
            ".",
            " The",
            " complete",
            " oct",
            "et",
            " (",
            "eight",
            " electrons",
            ")",
            " in",
            " the",
            " outer",
            " atomic",
            " shell",
            " makes",
            " arg",
            "on",
            " stable",
            " and",
            " resistant",
            " to",
            " bonding",
            " with",
            " other",
            " elements",
            ".",
            " Its",
            " triple",
            " point",
            " temperature",
            " of",
            " ",
            "83",
            ".",
            "805",
            "8",
            "ÂłK",
            " is",
            " a",
            " defining",
            " fixed",
            " point",
            " in",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.594,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " Hastings",
            " is",
            " irritated",
            " by",
            " the",
            " fact",
            " that",
            " P",
            "oi",
            "rot",
            " sometimes",
            " conce",
            "als",
            " important",
            " details",
            " of",
            " his",
            " plans",
            ",",
            " as",
            " in",
            " The",
            " Big",
            " Four",
            ".",
            " In",
            " this",
            " novel",
            ",",
            " Hastings",
            " is",
            " kept",
            " in",
            " the",
            " dark",
            " throughout",
            " the",
            " climax",
            ".",
            " This",
            " aspect",
            " of",
            " P",
            "oi",
            "rot",
            " is",
            " less",
            " evident",
            " in",
            " the",
            " later",
            " novels",
            ",",
            " partly",
            " because",
            " there",
            " is",
            " rarely",
            " a",
            " narrator",
            " to",
            " mis",
            "lead"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.594,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            " Ant",
            "igua",
            ",",
            " West",
            " Indies",
            ".",
            " Thomas",
            " Hear",
            "ne",
            ".",
            " Southampton",
            ".",
            "External",
            " links",
            "  ",
            " Ant",
            "igua",
            " and",
            " Barb",
            "uda",
            ",",
            " United",
            " States",
            " Library",
            " of",
            " Congress",
            " Ant",
            "igua",
            " and",
            " Barb",
            "uda",
            ".",
            " The",
            " World",
            " Fact",
            "book",
            ".",
            " Central",
            " Intelligence",
            " Agency",
            ".",
            " Ant",
            "igua",
            " and",
            " Barb",
            "uda",
            " from",
            " U",
            "CB",
            " Libraries",
            " Gov",
            "P",
            "ubs",
            " ",
            " Ant",
            "igua",
            " and",
            " Barb",
            "uda",
            " from",
            " the"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.582,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 8,
          "is_repeated_datapoint": false,
          "tokens": [
            " spinal",
            " system",
            ".",
            " This",
            " is",
            " demonstrated",
            " by",
            " the",
            " fact",
            " that",
            " altering",
            " the",
            " microbi",
            "ome",
            " has",
            " shown",
            " anxiety",
            "-",
            " and",
            " depression",
            "-re",
            "du",
            "cing",
            " effects",
            " in",
            " mice",
            ",",
            " but",
            " not",
            " in",
            " subjects",
            " without",
            " vag",
            "us",
            " nerves",
            ".",
            "Another",
            " key",
            " pathway",
            " is",
            " the",
            " H",
            "PA",
            " axis",
            ",",
            " as",
            " mentioned",
            " above",
            ".",
            " The",
            " microbes",
            " can",
            " control",
            " the",
            " levels",
            " of",
            " cytok",
            "ines",
            " in",
            " the",
            " body",
            ",",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.57,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 52,
          "is_repeated_datapoint": false,
          "tokens": [
            "1",
            ".",
            "02",
            " male",
            "(s",
            ")/",
            "female",
            " (",
            "201",
            "1",
            " est",
            ".)",
            "Urban",
            "ization",
            "urban",
            " population",
            ":",
            " ",
            "68",
            ".",
            "1",
            "%",
            " of",
            " total",
            " population",
            " (",
            "202",
            "2",
            " est",
            ".)",
            "4",
            ".",
            "04",
            "%",
            " annual",
            " rate",
            " of",
            " change",
            " (",
            "202",
            "0",
            "-",
            "202",
            "5",
            " est",
            ".)",
            "Health",
            "According",
            " to",
            " the",
            " CIA",
            " World",
            " Fact",
            "book",
            ",",
            " ",
            "2",
            "%",
            " of",
            " adults",
            " ("
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.566,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " Afghanistan",
            ".",
            "Af",
            "ghan",
            " Christians",
            ",",
            " who",
            " number",
            " ",
            "500",
            "–",
            "8",
            ",",
            "000",
            ",",
            " practice",
            " their",
            " faith",
            " secretly",
            " due",
            " to",
            " intense",
            " societal",
            " opposition",
            ",",
            " and",
            " there",
            " are",
            " no",
            " public",
            " churches",
            ".",
            "Urban",
            "ization",
            "As",
            " estimated",
            " by",
            " the",
            " CIA",
            " World",
            " Fact",
            "book",
            ",",
            " ",
            "26",
            "%",
            " of",
            " the",
            " population",
            " was",
            " urban",
            "ized",
            " as",
            " of",
            " ",
            "202",
            "0",
            ".",
            " This",
            " is",
            " one"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.555,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            "Business",
            " Art",
            "\"—",
            "he",
            ",",
            " in",
            " fact",
            ",",
            " wrote",
            " about",
            " his",
            " interest",
            " in",
            " thinking",
            " about",
            " art",
            " as",
            " business",
            " in",
            " The",
            " Philosophy",
            " of",
            " Andy",
            " War",
            "hol",
            " from",
            " A",
            " to",
            " B",
            " and",
            " Back",
            " Again",
            ".",
            "Fil",
            "ms",
            "War",
            "hol",
            " appeared",
            " as",
            " himself",
            " in",
            " the",
            " film",
            " Coc",
            "aine",
            " Cowboys",
            " (",
            "197",
            "9",
            ")",
            " and",
            " in",
            " the",
            " film",
            " T",
            "oot",
            "sie",
            " (",
            "198",
            "2",
            ").",
            "After"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.539,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            " used",
            " a",
            " somewhat",
            " different",
            " layout",
            " that",
            " has",
            " become",
            " de",
            " facto",
            " standard",
            " on",
            " computers",
            " following",
            " the",
            " IBM",
            " PC",
            " (",
            "198",
            "1",
            "),",
            " especially",
            " Model",
            " M",
            " (",
            "198",
            "4",
            ")",
            " and",
            " thus",
            " shift",
            " values",
            " for",
            " symbols",
            " on",
            " modern",
            " keyboards",
            " do",
            " not",
            " correspond",
            " as",
            " closely",
            " to",
            " the",
            " ASCII",
            " table",
            " as",
            " earlier",
            " keyboards",
            " did",
            ".",
            " The",
            " /",
            "?",
            " pair",
            " also",
            " dates",
            " to",
            " the",
            " No",
            ".",
            " ",
            "2"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            " is",
            " also",
            " well",
            " known",
            " for",
            " its",
            " nightlife",
            " and",
            " festival",
            " activity",
            ";",
            " with",
            " several",
            " of",
            " its",
            " night",
            "clubs",
            " (",
            ",",
            " Parad",
            "iso",
            ")",
            " among",
            " the",
            " world",
            "'s",
            " most",
            " famous",
            ".",
            " Prim",
            "arily",
            " known",
            " for",
            " its",
            " artistic",
            " heritage",
            ",",
            " elaborate",
            " canal",
            " system",
            " and",
            " narrow",
            " canal",
            " houses",
            " with",
            " g",
            "abled",
            " faÃ§",
            "ades",
            ";",
            " well",
            "-p",
            "reserved",
            " leg",
            "acies",
            " of",
            " the",
            " city",
            "'s",
            " ",
            "17",
            "th",
            "-century"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.436,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 55,
          "is_repeated_datapoint": false,
          "tokens": [
            "000",
            " Volkswagen",
            " Beet",
            "les",
            " per",
            " year",
            ".",
            " ",
            " Two",
            "-st",
            "roke",
            " engines",
            " became",
            " less",
            " popular",
            " during",
            " the",
            " ",
            "196",
            "0",
            "s",
            " as",
            " customers",
            " were",
            " more",
            " attracted",
            " to",
            " the",
            " smoother",
            " four",
            "-st",
            "roke",
            " engines",
            ".",
            " In",
            " September",
            " ",
            "196",
            "5",
            ",",
            " the",
            " DK",
            "W",
            " F",
            "102",
            " was",
            " fitted",
            " with",
            " a",
            " four",
            "-st",
            "roke",
            " engine",
            " and",
            " a",
            " fac",
            "el",
            "ift",
            " for",
            " the",
            " car",
            "'s",
            " front"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.017,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.385,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 55,
          "is_repeated_datapoint": false,
          "tokens": [
            "esy",
            ".",
            " In",
            " anger",
            ",",
            " Her",
            "acles",
            " sn",
            "atched",
            " the",
            " sacred",
            " tripod",
            " and",
            " started",
            " walking",
            " away",
            ",",
            " intending",
            " to",
            " start",
            " his",
            " own",
            " oracle",
            ".",
            " However",
            ",",
            " Apollo",
            " did",
            " not",
            " tolerate",
            " this",
            " and",
            " stopped",
            " Her",
            "acles",
            ";",
            " a",
            " duel",
            " ensued",
            " between",
            " them",
            ".",
            " Artem",
            "is",
            " rushed",
            " to",
            " support",
            " Apollo",
            ",",
            " while",
            " Athena",
            " supported",
            " Her",
            "acles",
            ".",
            " Soon",
            ",",
            " Zeus",
            " threw",
            " his",
            " thunder",
            "bolt",
            " between"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.369,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " also",
            " a",
            " ward",
            " for",
            " white",
            " patients",
            ",",
            " so",
            " that",
            " the",
            " site",
            " became",
            " like",
            " a",
            " village",
            ".",
            " The",
            " onset",
            " of",
            " famine",
            " and",
            " a",
            " dys",
            "ent",
            "ery",
            " epidemic",
            " created",
            " fresh",
            " problems",
            ".",
            " Much",
            " of",
            " the",
            " building",
            " work",
            " was",
            " carried",
            " out",
            " with",
            " the",
            " help",
            " of",
            " local",
            " people",
            " and",
            " patients",
            ".",
            " Drug",
            " advances",
            " for",
            " sleeping",
            " sickness",
            " included",
            " German",
            "in",
            " and",
            " .",
            " T",
            "ren",
            "sz",
            " conducted",
            " experiments"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.357,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.332,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " war",
            " years",
            ".",
            " Another",
            " attraction",
            " in",
            " east",
            "-central",
            " Alberta",
            " is",
            " Alberta",
            " Prairie",
            " Railway",
            " Exc",
            "ursions",
            ",",
            " a",
            " popular",
            " tourist",
            " attraction",
            " operated",
            " out",
            " of",
            " St",
            "ett",
            "ler",
            ",",
            " that",
            " offers",
            " train",
            " exc",
            "ursions",
            " into",
            " the",
            " pr",
            "airie",
            " and",
            " cat",
            "ers",
            " to",
            " tens",
            " of",
            " thousands",
            " of",
            " visitors",
            " every",
            " year",
            ".",
            "Government",
            " and",
            " politics",
            "The",
            " Government",
            " of",
            " Alberta",
            " is",
            " organized",
            " as",
            " a",
            " parliamentary",
            " democracy",
            " with"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.283,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            " making",
            " them",
            " Benef",
            "icial",
            " to",
            " the",
            " public",
            "k",
            ".",
            " The",
            " Third",
            " Edition",
            ",",
            " Dublin",
            ",",
            " Printed",
            ":",
            " And",
            " Re",
            "printed",
            " at",
            " London",
            ",",
            " for",
            " Weaver",
            " B",
            "ick",
            "erton",
            ",",
            " in",
            " De",
            "vere",
            "ux",
            "-C",
            "ourt",
            " near",
            " the",
            " Middle",
            "-T",
            "emple",
            ",",
            " ",
            "173",
            "0",
            ".",
            "Ess",
            "ays",
            " by",
            " Jonathan",
            " Swift",
            "Sat",
            "irical",
            " essays",
            "P",
            "am",
            "ph",
            "lets",
            "172",
            "9",
            " essays"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.245,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            " is",
            " –",
            " which",
            " would",
            " about",
            " rank",
            " him",
            " with",
            " Homer",
            ".\"",
            " Der",
            "le",
            "th",
            " good",
            "-h",
            "um",
            "ored",
            "ly",
            " re",
            "printed",
            " the",
            " criticism",
            " along",
            " with",
            " a",
            " photograph",
            " of",
            " himself",
            " sans",
            " sweater",
            ",",
            " on",
            " the",
            " back",
            " cover",
            " of",
            " his",
            " ",
            "194",
            "8",
            " country",
            " journal",
            ":",
            " Village",
            " Day",
            "book",
            ".",
            "A",
            " lighter",
            " side",
            " to",
            " the",
            " Sac",
            " Prairie",
            " Saga",
            " is",
            " a",
            " series",
            " of",
            " quasi",
            "-aut",
            "obi",
            "ographical"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.208,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            "Canada",
            "In",
            " ",
            "187",
            "0",
            ",",
            " ",
            "23",
            "-year",
            "-old",
            " Bell",
            " travelled",
            " with",
            " his",
            " parents",
            " and",
            " his",
            " brother",
            "'s",
            " widow",
            ",",
            " Caroline",
            " Margaret",
            " Ott",
            "away",
            ",",
            " to",
            " Paris",
            ",",
            " Ontario",
            ",",
            " to",
            " stay",
            " with",
            " Thomas",
            " Henderson",
            ",",
            " a",
            " Baptist",
            " minister",
            " and",
            " family",
            " friend",
            ".",
            " The",
            " Bell",
            " family",
            " soon",
            " purchased",
            " a",
            " farm",
            " of",
            " ",
            " at",
            " Tut",
            "elo",
            " Heights",
            " (",
            "now",
            " called",
            " Tut",
            "ela"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.205,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 29,
          "is_repeated_datapoint": false,
          "tokens": [
            " P",
            "ina",
            "ud",
            "'s",
            " Y",
            "acht",
            " Yard",
            " in",
            " West",
            "mount",
            ",",
            " Nova",
            " Scotia",
            ",",
            " to",
            " work",
            " on",
            " the",
            " ponto",
            "ons",
            " of",
            " the",
            " HD",
            "-",
            "4",
            ".",
            " P",
            "ina",
            "ud",
            " soon",
            " took",
            " over",
            " the",
            " boat",
            "yard",
            " at",
            " Bell",
            " Laboratories",
            " on",
            " Be",
            "inn",
            " Bh",
            "re",
            "agh",
            ",",
            " Bell",
            "'s",
            " estate",
            " near",
            " Bad",
            "deck",
            ",",
            " Nova",
            " Scotia",
            ".",
            " P",
            "ina",
            "ud",
            "'s",
            " experience",
            " in",
            " boat",
            "building"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.195,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            " chap",
            "els",
            " to",
            " conduct",
            " their",
            " own",
            " services",
            ".",
            " The",
            " oldest",
            " English",
            "-language",
            " church",
            " congregation",
            " in",
            " the",
            " world",
            " outside",
            " the",
            " United",
            " Kingdom",
            " is",
            " found",
            " at",
            " the",
            " Beg",
            "ijn",
            "hof",
            ".",
            " Regular",
            " services",
            " there",
            " are",
            " still",
            " offered",
            " in",
            " English",
            " under",
            " the",
            " ausp",
            "ices",
            " of",
            " the",
            " Church",
            " of",
            " Scotland",
            ".",
            " Being",
            " Calvin",
            "ists",
            ",",
            " the",
            " H",
            "ug",
            "uen",
            "ots",
            " soon",
            " integrated",
            " into",
            " the",
            " Dutch",
            " Re",
            "formed"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " mission",
            " had",
            " a",
            " prime",
            " and",
            " a",
            " backup",
            " crew",
            ".",
            " For",
            " Apollo",
            ",",
            " a",
            " third",
            " crew",
            " of",
            " astronauts",
            " was",
            " added",
            ",",
            " known",
            " as",
            " the",
            " support",
            " crew",
            ".",
            " The",
            " support",
            " crew",
            " maintained",
            " the",
            " flight",
            " plan",
            ",",
            " check",
            "lists",
            ",",
            " and",
            " mission",
            " ground",
            " rules",
            ",",
            " and",
            " ensured",
            " that",
            " the",
            " prime",
            " and",
            " backup",
            " crews",
            " were",
            " app",
            "r",
            "ised",
            " of",
            " any",
            " changes",
            ".",
            " The",
            " support",
            " crew",
            " developed",
            " procedures"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " the",
            " dark",
            " it",
            " is",
            " not",
            " considered",
            " a",
            " dream",
            " because",
            " they",
            " were",
            " awake",
            " when",
            " it",
            " occurred",
            ".",
            " Secondly",
            ",",
            " any",
            " sensory",
            " experience",
            " that",
            " is",
            " perceived",
            " while",
            " a",
            " person",
            " is",
            " asleep",
            " does",
            " not",
            " qualify",
            " as",
            " part",
            " of",
            " a",
            " dream",
            ".",
            " For",
            " example",
            ",",
            " if",
            ",",
            " while",
            " a",
            " person",
            " is",
            " sleeping",
            ",",
            " a",
            " door",
            " shuts",
            " and",
            " in",
            " their",
            " dream",
            " they",
            " hear",
            " a",
            " door",
            " is",
            " shut"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " June",
            " ",
            "200",
            "6",
            ",",
            " he",
            " became",
            " one",
            " of",
            " only",
            " four",
            " people",
            " ever",
            " to",
            " be",
            " recognized",
            " with",
            " Hon",
            "orary",
            " Citizenship",
            " by",
            " the",
            " Governor",
            " General",
            " of",
            " Canada",
            ".",
            " On",
            " ",
            "28",
            " May",
            " ",
            "200",
            "5",
            ",",
            " he",
            " received",
            " the",
            " Christmas",
            " Humph",
            "re",
            "ys",
            " Award",
            " from",
            " the",
            " Buddhist",
            " Society",
            " in",
            " the",
            " United",
            " Kingdom",
            ".",
            " Most",
            " notable",
            " was",
            " the",
            " Nobel",
            " Peace",
            " Prize",
            ",",
            " presented",
            " in",
            " Oslo"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " he",
            " had",
            " studied",
            " \"",
            "me",
            "chan",
            "ics",
            ",",
            " electricity",
            ",",
            " ac",
            "oust",
            "ics",
            ",",
            " and",
            " navigation",
            "\".",
            " Then",
            ",",
            " on",
            " ",
            "12",
            " December",
            " ",
            "191",
            "4",
            ",",
            " his",
            " father",
            ",",
            " who",
            " had",
            " been",
            " suffering",
            " from",
            " em",
            "phy",
            "se",
            "ma",
            " and",
            " kidney",
            " disease",
            ",",
            " died",
            " at",
            " the",
            " age",
            " of",
            " ",
            "52",
            ".",
            " To",
            " support",
            " himself",
            " and",
            " his",
            " mother",
            " —",
            " his",
            " older",
            " siblings",
            " had",
            " left"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " may",
            " also",
            " be",
            " an",
            " effective",
            " strategy",
            " that",
            " therapists",
            " may",
            " use",
            " to",
            " improve",
            " function",
            " in",
            " patients",
            " with",
            " at",
            "ax",
            "ia",
            ".",
            " Training",
            " likely",
            " needs",
            " to",
            " be",
            " intense",
            " and",
            " focused",
            "—as",
            " indicated",
            " by",
            " one",
            " study",
            " performed",
            " with",
            " stroke",
            " patients",
            " experiencing",
            " limb",
            " at",
            "ax",
            "ia",
            " who",
            " underwent",
            " intensive",
            " upper",
            " limb",
            " re",
            "training",
            ".",
            " Their",
            " therapy",
            " consisted",
            " of",
            " constraint",
            "-induced",
            " movement",
            " therapy",
            " which",
            " resulted",
            " in",
            " improvements",
            " of"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "alama",
    "portun",
    "ÑĨÐ¾",
    "elson",
    "essel"
  ],
  "bottom_logits": [
    "aine",
    " quarter",
    " health",
    " ent",
    " fun"
  ],
  "act_min": -0.0,
  "act_max": 0.879
}
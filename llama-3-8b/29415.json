{
  "index": 29415,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            1.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.133,
            -0.0,
            0.051,
            -0.0,
            -0.0,
            -0.0,
            1.211,
            0.006,
            -0.0,
            -0.0,
            -0.0,
            1.227,
            -0.0,
            0.08,
            -0.0,
            -0.0,
            -0.0,
            1.234,
            -0.0,
            -0.0,
            -0.0,
            1.227,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.227,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.227,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            1.219,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.227,
            -0.0,
            0.035,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " family",
            " But",
            "om",
            "aceae",
            " ",
            " family",
            " C",
            "ym",
            "odo",
            "ce",
            "aceae",
            " family",
            " Hydro",
            "char",
            "it",
            "aceae",
            " family",
            " J",
            "unc",
            "ag",
            "in",
            "aceae",
            " family",
            " Ma",
            "undi",
            "aceae",
            " family",
            " Pos",
            "id",
            "oni",
            "aceae",
            " family",
            " Pot",
            "amo",
            "get",
            "on",
            "aceae",
            " family",
            " R",
            "up",
            "pi",
            "aceae",
            " family",
            " Sche",
            "uch",
            "zer",
            "i",
            "aceae",
            " family",
            " T",
            "of",
            "ield",
            "i",
            "aceae"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.5,
            -0.0,
            -0.0,
            -0.0,
            0.734,
            0.336,
            -0.0,
            -0.0,
            -0.0,
            0.797,
            0.32,
            0.036,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.181,
            -0.0,
            -0.0,
            0.273,
            0.208,
            -0.0,
            0.017,
            -0.0,
            -0.0,
            -0.0,
            0.007,
            -0.0,
            -0.0,
            0.52,
            -0.0,
            0.224,
            0.005,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.664,
            0.633,
            -0.0,
            -0.0,
            0.832,
            0.093,
            0.211,
            -0.0,
            0.111,
            -0.0,
            0.463,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            0.256,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " family",
            " Z",
            "oster",
            "aceae",
            "Ph",
            "y",
            "log",
            "eny",
            " ",
            "Cl",
            "ad",
            "ogram",
            " showing",
            " the",
            " orders",
            " of",
            " monoc",
            "ots",
            " (",
            "L",
            "ilian",
            "ae",
            " sens",
            "u",
            " Chase",
            " &",
            " Re",
            "veal",
            ")",
            " based",
            " on",
            " molecular",
            " phy",
            "logen",
            "etic",
            " evidence",
            ":",
            "References",
            "Further",
            " reading",
            " ",
            " B",
            ".",
            " C",
            ".",
            " J",
            ".",
            " du",
            " Mort",
            "ier",
            " ",
            "182",
            "9",
            ".",
            " Analy",
            "se",
            " des",
            " Famil",
            "les",
            " de"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.042,
            -0.0,
            0.09,
            -0.0,
            0.087,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.116,
            -0.0,
            -0.0,
            0.805,
            0.148,
            -0.0,
            -0.0,
            -0.0,
            0.547,
            -0.0,
            -0.0,
            -0.0,
            0.139,
            -0.0,
            0.209,
            -0.0,
            0.067,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.012,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.168,
            0.035,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.04,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " same",
            " neuron",
            ",",
            " when",
            " it",
            " is",
            " known",
            " as",
            " an",
            " aut",
            "apse",
            ".",
            "Ax",
            "onal",
            " var",
            "icos",
            "ities",
            "In",
            " the",
            " normally",
            " developed",
            " brain",
            ",",
            " along",
            " the",
            " shaft",
            " of",
            " some",
            " ax",
            "ons",
            " are",
            " located",
            " pre",
            "-s",
            "yn",
            "aptic",
            " bout",
            "ons",
            " also",
            " known",
            " as",
            " ax",
            "onal",
            " var",
            "icos",
            "ities",
            " and",
            " these",
            " have",
            " been",
            " found",
            " in",
            " regions",
            " of",
            " the",
            " hippoc",
            "ampus",
            " that",
            " function",
            " in"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.307,
            -0.0,
            0.024,
            -0.0,
            0.676,
            0.183,
            -0.0,
            0.324,
            0.112,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.19,
            -0.0,
            0.185,
            -0.0,
            -0.0,
            0.044,
            0.003,
            -0.0,
            0.246,
            -0.0,
            0.059,
            -0.0,
            -0.0,
            -0.0,
            0.248,
            -0.0,
            -0.0,
            -0.0,
            0.336,
            0.123,
            -0.0,
            -0.0,
            0.069,
            -0.0,
            0.438,
            -0.0,
            -0.0,
            -0.0,
            0.058,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.049,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.021,
            0.089,
            -0.0,
            -0.0,
            0.015,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " Cyrus",
            "'s",
            " tomb",
            ".",
            "After",
            "wards",
            ",",
            " Alexander",
            " travelled",
            " to",
            " E",
            "cb",
            "at",
            "ana",
            " to",
            " retrieve",
            " the",
            " bulk",
            " of",
            " the",
            " Persian",
            " treasure",
            ".",
            " There",
            ",",
            " his",
            " closest",
            " friend",
            ",",
            " Hep",
            "ha",
            "estion",
            ",",
            " died",
            " of",
            " illness",
            " or",
            " poisoning",
            ".",
            " Hep",
            "ha",
            "estion",
            "'s",
            " death",
            " devastated",
            " Alexander",
            " and",
            " he",
            " ordered",
            " the",
            " preparation",
            " of",
            " an",
            " expensive",
            " funeral",
            " py",
            "re",
            " in",
            " Babylon",
            " along",
            " with",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.042,
            0.027,
            -0.0,
            -0.0,
            0.218,
            -0.0,
            -0.0,
            0.115,
            -0.0,
            0.328,
            -0.0,
            -0.0,
            0.044,
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.172,
            0.106,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.104,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.026,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.104,
            -0.0,
            -0.0,
            0.008,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.906,
            0.011,
            0.082,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " Russian",
            " Revolution",
            " and",
            " early",
            " Communist",
            " Russia",
            " influenced",
            " the",
            " portrayal",
            " of",
            " her",
            " villains",
            ".",
            " Beyond",
            " We",
            " the",
            " Living",
            ",",
            " which",
            " is",
            " set",
            " in",
            " Russia",
            ",",
            " this",
            " influence",
            " can",
            " be",
            " seen",
            " in",
            " the",
            " ideas",
            " and",
            " rhetoric",
            " of",
            " Ell",
            "sworth",
            " Too",
            "hey",
            " in",
            " The",
            " Fountain",
            "head",
            ",",
            " and",
            " in",
            " the",
            " destruction",
            " of",
            " the",
            " economy",
            " in",
            " Atlas",
            " Shr",
            "ugged",
            ".",
            "Rand",
            "'s",
            " descriptive",
            " style",
            " echoes"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            1.406,
            0.109,
            0.026,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.463,
            -0.0,
            0.106,
            -0.0,
            -0.0,
            -0.0,
            0.146,
            -0.0,
            -0.0,
            0.171,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.531,
            0.059,
            -0.0,
            0.117,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.113,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.27,
            -0.0,
            -0.0,
            0.048,
            -0.0,
            -0.0,
            -0.0,
            0.41,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " different",
            " collo",
            "qu",
            "ial",
            " dialect",
            "s",
            ".",
            " When",
            " speaking",
            " ext",
            "empor",
            "aneously",
            " (",
            "i",
            ".e",
            ".",
            " making",
            " up",
            " the",
            " language",
            " on",
            " the",
            " spot",
            ",",
            " as",
            " in",
            " a",
            " normal",
            " discussion",
            " among",
            " people",
            "),",
            " speakers",
            " tend",
            " to",
            " dev",
            "iate",
            " somewhat",
            " from",
            " the",
            " strict",
            " literary",
            " language",
            " in",
            " the",
            " direction",
            " of",
            " the",
            " collo",
            "qu",
            "ial",
            " varieties",
            ".",
            " There",
            " is",
            " a",
            " continuous",
            " range",
            " of",
            " \"",
            "in",
            "-between"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.17,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.003,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.039,
            -0.0,
            -0.0,
            -0.0,
            0.332,
            -0.0,
            -0.0,
            -0.0,
            0.078,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.758,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " south",
            "-central",
            " Anat",
            "olia",
            " in",
            " the",
            " century",
            " or",
            " so",
            " after",
            " the",
            " fall",
            " of",
            " the",
            " H",
            "itt",
            "ite",
            " empire",
            ",",
            " and",
            " some",
            " of",
            " the",
            " Sy",
            "ro",
            "-H",
            "itt",
            "ite",
            " states",
            " in",
            " this",
            " region",
            " became",
            " an",
            " amalg",
            "am",
            " of",
            " H",
            "itt",
            "ites",
            " and",
            " Ar",
            "ame",
            "ans",
            ".",
            " These",
            " became",
            " known",
            " as",
            " Sy",
            "ro",
            "-H",
            "itt",
            "ite",
            " states",
            ".",
            "Neo",
            "-Ass",
            "y",
            "rian",
            " Empire"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.068,
            -0.0,
            -0.0,
            0.218,
            -0.0,
            -0.0,
            0.097,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.594,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.35,
            -0.0,
            0.046,
            -0.0,
            -0.0,
            0.017,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.05,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.057,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.232,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " Alaska",
            " Fair",
            "banks",
            " archae",
            "ologist",
            " who",
            " unearth",
            "ed",
            " the",
            " remains",
            " at",
            " the",
            " Up",
            "ward",
            " Sun",
            " River",
            " site",
            " in",
            " ",
            "201",
            "3",
            ",",
            " named",
            " this",
            " new",
            " group",
            " Ancient",
            " B",
            "ering",
            "ians",
            ".",
            "The",
            " T",
            "ling",
            "it",
            " people",
            " developed",
            " a",
            " society",
            " with",
            " a",
            " mat",
            "r",
            "iline",
            "al",
            " kin",
            "ship",
            " system",
            " of",
            " property",
            " inheritance",
            " and",
            " descent",
            " in",
            " what",
            " is",
            " today",
            " Southeast",
            " Alaska",
            ",",
            " along",
            " with"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.072,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.299,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.26,
            0.048,
            -0.0,
            -0.0,
            -0.0,
            0.028,
            0.17,
            -0.0,
            -0.0,
            0.504,
            0.038,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.27,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.13,
            -0.0,
            -0.0,
            0.016,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.256,
            0.029,
            0.06,
            -0.0,
            -0.0,
            -0.0,
            0.009,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " Washington",
            ",",
            " D",
            ".C",
            "..",
            " These",
            " included",
            " the",
            " prestigious",
            " '",
            "Vol",
            "ta",
            " Laboratory",
            " Association",
            "'",
            " (",
            "188",
            "0",
            "),",
            " also",
            " known",
            " as",
            " the",
            " Vol",
            "ta",
            " Laboratory",
            " and",
            " as",
            " the",
            " '",
            "Alexander",
            " Graham",
            " Bell",
            " Laboratory",
            "',",
            " and",
            " which",
            " eventually",
            " led",
            " to",
            " the",
            " Vol",
            "ta",
            " Bureau",
            " (",
            "188",
            "7",
            ")",
            " as",
            " a",
            " center",
            " for",
            " studies",
            " on",
            " deaf",
            "ness",
            " which",
            " is",
            " still",
            " in",
            " operation",
            " in"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.155,
            -0.0,
            -0.0,
            -0.0,
            0.027,
            0.036,
            -0.0,
            -0.0,
            -0.0,
            0.159,
            -0.0,
            0.077,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.067,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            -0.0,
            0.015,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.089,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.072,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.034,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " bit",
            "umen",
            " as",
            " a",
            " gl",
            "aze",
            " to",
            " set",
            " in",
            " shadow",
            " or",
            " mixed",
            " with",
            " other",
            " colors",
            " to",
            " render",
            " a",
            " darker",
            " tone",
            " resulted",
            " in",
            " the",
            " eventual",
            " deterioration",
            " of",
            " many",
            " paintings",
            ",",
            " for",
            " instance",
            " those",
            " of",
            " Del",
            "acro",
            "ix",
            ".",
            " Perhaps",
            " the",
            " most",
            " famous",
            " example",
            " of",
            " the",
            " destruct",
            "iveness",
            " of",
            " bit",
            "umen",
            " is",
            " Th",
            "Ã©",
            "odore",
            " G",
            "Ã©ric",
            "ault",
            "'s",
            " Ra",
            "ft",
            " of",
            " the",
            " Med"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            1.406,
            0.042,
            -0.0,
            -0.0,
            -0.0,
            0.434,
            0.203,
            -0.0,
            0.183,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.262,
            -0.0,
            0.081,
            0.081,
            -0.0,
            0.385,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.072,
            0.067,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.069,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            0.234,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.237,
            0.087,
            -0.0,
            0.049,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.111,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.19,
            0.044,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " Serbian",
            " elite",
            ",",
            " ignited",
            " allegations",
            " of",
            " bols",
            "hev",
            "ism",
            " from",
            " Bel",
            "grade",
            ".",
            " This",
            ",",
            " in",
            " turn",
            ",",
            " led",
            " to",
            " increased",
            " pressure",
            " from",
            " Italy",
            " and",
            " cul",
            "minated",
            " in",
            " Z",
            "og",
            "'s",
            " restoration",
            " to",
            " authority",
            ".",
            " Sub",
            "sequently",
            " in",
            " ",
            "192",
            "8",
            ",",
            " Z",
            "og",
            "u",
            " transition",
            "ed",
            " Albania",
            " from",
            " a",
            " republic",
            " to",
            " a",
            " monarchy",
            " that",
            " garnered",
            " backing",
            " from",
            " Fasc",
            "ist",
            " Italy"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.077,
            -0.0,
            -0.0,
            0.008,
            -0.0,
            0.652,
            -0.0,
            -0.0,
            -0.0,
            0.0,
            -0.0,
            0.307,
            -0.0,
            -0.0,
            -0.0,
            0.048,
            -0.0,
            -0.0,
            0.256,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.31,
            0.024,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.318,
            -0.0,
            -0.0,
            -0.0,
            0.18,
            0.055,
            -0.0,
            -0.0,
            -0.0,
            0.143,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.017,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.578,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " Reality",
            " as",
            " a",
            " person",
            "—",
            "good",
            " and",
            " true",
            " and",
            " perfect",
            "—",
            "rather",
            " than",
            " an",
            " imperson",
            "al",
            " force",
            ",",
            " can",
            " we",
            " come",
            " closer",
            " to",
            " the",
            " Truth",
            ".",
            " An",
            " ultimate",
            " Person",
            " can",
            " be",
            " loved",
            ",",
            " but",
            " a",
            " cosmic",
            " force",
            " cannot",
            ".",
            " A",
            " scientist",
            " can",
            " only",
            " discover",
            " peripheral",
            " truths",
            ",",
            " but",
            " a",
            " lover",
            " is",
            " able",
            " to",
            " get",
            " at",
            " the",
            " Truth",
            ".",
            " There",
            " are",
            " many",
            " reasons"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.301,
            -0.0,
            0.602,
            -0.0,
            -0.0,
            0.379,
            -0.0,
            0.289,
            0.048,
            -0.0,
            -0.0,
            0.31,
            0.237,
            0.072,
            -0.0,
            -0.0,
            -0.0,
            0.216,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.578,
            0.164,
            -0.0,
            -0.0,
            -0.0,
            0.038,
            0.053,
            -0.0,
            0.275,
            0.076,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            0.222,
            0.016,
            -0.0,
            0.087,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " prefixes",
            " (",
            "most",
            " often",
            " /",
            "bi",
            "-/",
            " for",
            " indicative",
            " vs",
            ".",
            " un",
            "marked",
            " subj",
            "unct",
            "ive",
            ").",
            " They",
            " have",
            " also",
            " mostly",
            " lost",
            " the",
            " indefinite",
            " \"",
            "nun",
            "ation",
            "\"",
            " and",
            " the",
            " internal",
            " passive",
            ".",
            "The",
            " following",
            " is",
            " an",
            " example",
            " of",
            " a",
            " regular",
            " verb",
            " paradigm",
            " in",
            " Egyptian",
            " Arabic",
            ".",
            "Writing",
            " system",
            "  ",
            "The",
            " Arabic",
            " alphabet",
            " derives",
            " from",
            " the",
            " Ar",
            "ama",
            "ic",
            " through",
            " Nab",
            "ate"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.141,
            -0.0,
            0.215,
            0.054,
            -0.0,
            0.018,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.084,
            0.042,
            -0.0,
            -0.0,
            0.268,
            -0.0,
            0.512,
            -0.0,
            0.138,
            0.033,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.084,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.844,
            0.233,
            -0.0,
            0.256,
            -0.0,
            0.133,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.096,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.09,
            -0.0,
            -0.0,
            -0.0,
            0.029,
            -0.0,
            0.133,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.045
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " smell",
            ".",
            " The",
            " ears",
            ",",
            " which",
            " are",
            " very",
            " effective",
            ",",
            " are",
            " disproportionately",
            " long",
            ",",
            " about",
            " ",
            " long",
            ".",
            " The",
            " eyes",
            " are",
            " small",
            " for",
            " its",
            " head",
            ",",
            " and",
            " consist",
            " only",
            " of",
            " rods",
            ".",
            "Digest",
            "ive",
            " system",
            "The",
            " a",
            "ard",
            "v",
            "ark",
            "'s",
            " stomach",
            " has",
            " a",
            " muscular",
            " pyl",
            "oric",
            " area",
            " that",
            " acts",
            " as",
            " a",
            " g",
            "izzard",
            " to",
            " grind",
            " swallowed",
            " food",
            " up",
            ",",
            " thereby"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.042,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.052,
            -0.0,
            -0.0,
            -0.0,
            0.037,
            -0.0,
            -0.0,
            -0.0,
            0.52,
            -0.0,
            -0.0,
            -0.0,
            0.104,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.095,
            -0.0,
            -0.0,
            -0.0,
            0.396,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.281,
            -0.0,
            -0.0,
            0.203,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " State",
            " is",
            " in",
            " the",
            " hands",
            " of",
            " thieves",
            ",",
            " and",
            " should",
            " be",
            " liberated",
            " as",
            " quickly",
            " as",
            " possible",
            "\".",
            " Roth",
            "bard",
            " proposed",
            " that",
            " state",
            " universities",
            " be",
            " seized",
            " by",
            " the",
            " students",
            " and",
            " faculty",
            " under",
            " the",
            " hom",
            "estead",
            " principle",
            ".",
            " Roth",
            "bard",
            " also",
            " supported",
            " the",
            " ex",
            "propri",
            "ation",
            " of",
            " nomin",
            "ally",
            " \"",
            "private",
            " property",
            "\"",
            " if",
            " it",
            " is",
            " the",
            " result",
            " of",
            " state",
            "-init",
            "iated",
            " force"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            1.406,
            0.111,
            -0.0,
            0.156,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.879,
            0.287,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            0.072,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.43,
            0.173,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.019,
            0.703,
            0.239,
            0.156,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.375,
            0.001
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " lives",
            ",",
            " particularly",
            " in",
            " Anch",
            "orage",
            ".",
            "Last",
            "ing",
            " four",
            " minutes",
            " and",
            " thirty",
            "-eight",
            " seconds",
            ",",
            " the",
            " magnitude",
            " ",
            "9",
            ".",
            "2",
            " meg",
            "ath",
            "rust",
            " earthquake",
            " remains",
            " the",
            " most",
            " powerful",
            " earthquake",
            " recorded",
            " in",
            " North",
            " American",
            " history",
            ",",
            " and",
            " the",
            " second",
            " most",
            " powerful",
            " earthquake",
            " recorded",
            " in",
            " world",
            " history",
            ".",
            " ",
            " of",
            " fault",
            " rupt",
            "ured",
            " at",
            " once",
            " and",
            " moved",
            " up",
            " to",
            " ,",
            " releasing",
            " about"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.042,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.035,
            -0.0,
            0.498,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.024,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.527,
            -0.0,
            0.035,
            0.1,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.058,
            -0.0,
            0.01,
            -0.0,
            0.516,
            -0.0,
            -0.0,
            0.101,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.527,
            -0.0,
            0.289,
            -0.0,
            -0.0,
            -0.0,
            0.191,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " consistent",
            " presence",
            " of",
            " the",
            " concept",
            " of",
            " culture",
            ";",
            " not",
            " an",
            " exclusive",
            " topic",
            " but",
            " a",
            " central",
            " position",
            " in",
            " the",
            " study",
            " and",
            " a",
            " deep",
            " concern",
            " with",
            " the",
            " human",
            " condition",
            ".",
            " Milton",
            " describes",
            " three",
            " trends",
            " that",
            " are",
            " causing",
            " a",
            " fundamental",
            " shift",
            " in",
            " what",
            " character",
            "izes",
            " anthropology",
            ":",
            " dissatisfaction",
            " with",
            " the",
            " cultural",
            " relativ",
            "ist",
            " perspective",
            ",",
            " reaction",
            " against",
            " cartesian",
            " dual",
            "isms",
            " which",
            " obstruct",
            "s",
            " progress"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.379,
            -0.0,
            -0.0,
            -0.0,
            0.104,
            -0.0,
            0.447,
            -0.0,
            -0.0,
            0.119,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.494,
            0.096,
            -0.0,
            -0.0,
            -0.0,
            0.191,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.013,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.365,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            -0.0,
            0.002,
            0.08,
            -0.0,
            -0.0,
            0.09,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " continental",
            " crust",
            " along",
            " the",
            " coast",
            ".",
            " For",
            " instance",
            ",",
            " in",
            " spite",
            " of",
            " ",
            "7",
            "Âł",
            "km",
            " thick",
            " bas",
            "alt",
            ",",
            " Gunn",
            "bj",
            "orn",
            " Field",
            " in",
            " East",
            " Greenland",
            " is",
            " the",
            " highest",
            " point",
            " on",
            " the",
            " island",
            ",",
            " elevated",
            " enough",
            " that",
            " it",
            " exposes",
            " older",
            " Mes",
            "ozo",
            "ic",
            " sediment",
            "ary",
            " rocks",
            " at",
            " its",
            " base",
            ",",
            " similar",
            " to",
            " old",
            " lava",
            " fields",
            " above",
            " sediment",
            "ary",
            " rocks",
            " in",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.299,
            0.266,
            -0.0,
            -0.0,
            0.066,
            -0.0,
            0.083,
            -0.0,
            -0.0,
            -0.0,
            0.277,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            0.234,
            -0.0,
            -0.0,
            0.105,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.196,
            -0.0,
            -0.0,
            0.109,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.017,
            0.062,
            -0.0,
            -0.0,
            -0.0,
            0.934,
            0.389,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.059,
            0.084,
            -0.0,
            0.014,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " g",
            "ase",
            "ous",
            " and",
            " volatile",
            " al",
            "kan",
            "es",
            " such",
            " as",
            " eth",
            "ane",
            ",",
            " pent",
            "ane",
            ",",
            " and",
            " hex",
            "ane",
            " by",
            " plants",
            " has",
            " also",
            " been",
            " documented",
            " at",
            " low",
            " levels",
            ",",
            " though",
            " they",
            " are",
            " not",
            " generally",
            " considered",
            " to",
            " be",
            " a",
            " major",
            " component",
            " of",
            " bi",
            "ogenic",
            " air",
            " pollution",
            ".",
            "Ed",
            "ible",
            " vegetable",
            " oils",
            " also",
            " typically",
            " contain",
            " small",
            " fractions",
            " of",
            " bi",
            "ogenic",
            " al",
            "kan",
            "es",
            " with"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.443,
            -0.0,
            -0.0,
            0.988,
            -0.0,
            -0.0,
            -0.0,
            0.566,
            0.385,
            -0.0,
            -0.0,
            0.056,
            -0.0,
            -0.0,
            0.026,
            -0.0,
            -0.0,
            -0.0,
            0.118,
            0.02,
            -0.0,
            -0.0,
            -0.0,
            0.4,
            -0.0,
            -0.0,
            0.629,
            -0.0,
            -0.0,
            -0.0,
            0.036,
            -0.0,
            -0.0,
            -0.0,
            0.146,
            -0.0,
            -0.0,
            0.011,
            -0.0,
            0.119,
            -0.0,
            -0.0,
            -0.0,
            0.209,
            0.091,
            -0.0,
            -0.0,
            0.254,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.202,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.096,
            -0.0,
            0.086,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " cognitive",
            " anxiety",
            ".",
            "Co",
            "-m",
            "orb",
            "idity",
            "An",
            "xiety",
            " disorders",
            " often",
            " occur",
            " with",
            " other",
            " mental",
            " health",
            " disorders",
            ",",
            " particularly",
            " major",
            " depressive",
            " disorder",
            ",",
            " bipolar",
            " disorder",
            ",",
            " eating",
            " disorders",
            ",",
            " or",
            " certain",
            " personality",
            " disorders",
            ".",
            " It",
            " also",
            " commonly",
            " occurs",
            " with",
            " personality",
            " traits",
            " such",
            " as",
            " neuro",
            "tic",
            "ism",
            ".",
            " This",
            " observed",
            " co",
            "-",
            "occ",
            "urrence",
            " is",
            " partly",
            " due",
            " to",
            " genetic",
            " and",
            " environmental",
            " influences"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            1.406,
            0.042,
            -0.0,
            -0.0,
            0.197,
            -0.0,
            -0.0,
            -0.0,
            0.719,
            -0.0,
            -0.0,
            -0.0,
            0.551,
            0.25,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.633,
            0.009,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.022,
            0.231,
            0.965,
            -0.0,
            -0.0,
            0.424,
            0.467,
            -0.0,
            0.334,
            -0.0,
            -0.0,
            -0.0,
            0.256,
            -0.0,
            0.19,
            -0.0,
            0.582,
            -0.0,
            -0.0,
            -0.0,
            0.069,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.232,
            0.969,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            0.047,
            0.318,
            -0.0,
            -0.0,
            -0.0,
            0.652
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " Earth",
            " [#",
            "682",
            "–",
            "687",
            ";",
            " Amazing",
            " Spider",
            "-Man",
            ":",
            " Ends",
            " of",
            " the",
            " Earth",
            " #",
            "1",
            ";",
            " Av",
            "eng",
            "ing",
            " Spider",
            "-Man",
            " #",
            "8",
            "]",
            " ()",
            "Spider",
            "-Man",
            ":",
            " L",
            "izard",
            " –",
            " No",
            " Turning",
            " Back",
            " [#",
            "688",
            "–",
            "691",
            ";",
            " Unt",
            "old",
            " Tales",
            " of",
            " Spider",
            "-Man",
            " #",
            "9",
            "]",
            " ()",
            "Spider",
            "-Man",
            ":",
            " Danger",
            " Zone",
            " [#",
            "692",
            "–",
            "697",
            ";",
            " Av"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.206,
            0.058,
            -0.0,
            0.559,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.629,
            -0.0,
            0.027,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.097,
            0.186,
            -0.0,
            0.816,
            0.324,
            -0.0,
            0.781,
            -0.0,
            0.082,
            -0.0,
            0.023,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.225,
            0.136,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.089,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.045,
            -0.0,
            -0.0,
            0.085,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.165,
            -0.0,
            0.287
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " altru",
            "ism",
            ",",
            " love",
            " for",
            " one",
            " another",
            ".",
            " Ash",
            "lag",
            " focused",
            " on",
            " society",
            " and",
            " its",
            " relation",
            " to",
            " div",
            "inity",
            ".",
            "S",
            "ikh",
            "ism",
            "Al",
            "tru",
            "ism",
            " is",
            " essential",
            " to",
            " the",
            " Sikh",
            " religion",
            ".",
            " The",
            " central",
            " faith",
            " in",
            " Sikh",
            "ism",
            " is",
            " that",
            " the",
            " greatest",
            " deed",
            " anyone",
            " can",
            " do",
            " is",
            " to",
            " imb",
            "ibe",
            " and",
            " live",
            " the",
            " god",
            "ly",
            " qualities",
            " like",
            " love",
            ",",
            " affection"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            -0.0,
            -0.0,
            0.153,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.264,
            0.293,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.154,
            -0.0,
            -0.0,
            -0.0,
            0.039,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.471,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.363,
            0.081,
            0.088,
            -0.0,
            0.006,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.014,
            -0.0,
            -0.0,
            0.559,
            -0.0,
            -0.0,
            -0.0,
            0.073
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " Cyprus",
            ",",
            " who",
            " was",
            " a",
            " friend",
            " of",
            " Ag",
            "am",
            "em",
            "non",
            ".",
            " C",
            "iny",
            "ras",
            " promised",
            " to",
            " assist",
            " Ag",
            "am",
            "em",
            "non",
            " in",
            " the",
            " Trojan",
            " war",
            ",",
            " but",
            " did",
            " not",
            " keep",
            " his",
            " promise",
            ".",
            " Ag",
            "am",
            "em",
            "non",
            " cursed",
            " C",
            "iny",
            "ras",
            ".",
            " He",
            " invoked",
            " Apollo",
            " and",
            " asked",
            " the",
            " god",
            " to",
            " a",
            "venge",
            " the",
            " broken",
            " promise",
            ".",
            " Apollo",
            " then",
            " had",
            " a",
            " ly"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.042,
            -0.0,
            -0.0,
            0.406,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.582,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.42,
            0.012,
            0.065,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.077,
            -0.0,
            -0.0,
            -0.0,
            0.326,
            0.125,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.357,
            -0.0,
            0.48,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.019,
            -0.0,
            0.096,
            -0.0,
            0.344,
            -0.0,
            0.424,
            0.011,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " Congo",
            "),",
            " Ub",
            "angi",
            "-Sh",
            "ari",
            " (",
            "now",
            " the",
            " Central",
            " African",
            " Republic",
            "),",
            " briefly",
            " to",
            " Chad",
            " and",
            " then",
            " to",
            " Cameroon",
            " before",
            " returning",
            " to",
            " France",
            ".",
            " He",
            " kept",
            " a",
            " journal",
            ",",
            " which",
            " he",
            " published",
            " as",
            " Trav",
            "els",
            " in",
            " the",
            " Congo",
            " (",
            "French",
            ":",
            " Voyage",
            " au",
            " Congo",
            ")",
            " and",
            " Return",
            " from",
            " Chad",
            " (",
            "French",
            ":",
            " Ret",
            "our",
            " du",
            " T",
            "ch",
            "ad",
            ").",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.111,
            -0.0,
            -0.0,
            0.894,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.024,
            -0.0,
            -0.0,
            0.303,
            -0.0,
            0.469,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.555,
            -0.0,
            0.13,
            -0.0,
            -0.0,
            -0.0,
            0.44,
            0.084,
            -0.0,
            -0.0,
            -0.0,
            0.023,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.301,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " her",
            " own",
            ".",
            "Andrew",
            " Stock",
            "ton",
            " runs",
            " the",
            " Stock",
            "ton",
            " Found",
            "ry",
            " in",
            " Stock",
            "ton",
            ",",
            " Colorado",
            ".",
            " When",
            " he",
            " joins",
            " the",
            " strike",
            ",",
            " he",
            " opens",
            " a",
            " found",
            "ry",
            " in",
            " G",
            "alt",
            "'s",
            " Gul",
            "ch",
            ".",
            " ",
            "Mr",
            ".",
            " Thompson",
            " is",
            " the",
            " \"",
            "Head",
            " of",
            " the",
            " State",
            "\"",
            " for",
            " the",
            " United",
            " States",
            ".",
            " He",
            " is",
            " not",
            " particularly",
            " intelligent",
            " and",
            " has",
            " a",
            " very"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            1.406,
            0.146,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.009,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.11,
            -0.0,
            -0.0,
            -0.0,
            0.008,
            0.13,
            -0.0,
            -0.0,
            0.067,
            -0.0,
            -0.0,
            0.007,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.182,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.081,
            -0.0,
            0.602,
            0.081,
            0.076,
            -0.0,
            -0.0,
            0.348,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " Hitch",
            "cock",
            " as",
            " a",
            " director",
            " who",
            " relied",
            " more",
            " on",
            " pre",
            "-production",
            " than",
            " on",
            " the",
            " actual",
            " production",
            " itself",
            " has",
            " been",
            " challenged",
            " by",
            " Bill",
            " Kro",
            "hn",
            ",",
            " the",
            " American",
            " correspondent",
            " of",
            " French",
            " film",
            " magazine",
            " Cah",
            "iers",
            " du",
            " Cin",
            "Ã©",
            "ma",
            ",",
            " in",
            " his",
            " book",
            " Hitch",
            "cock",
            " at",
            " Work",
            ".",
            " After",
            " investigating",
            " script",
            " revisions",
            ",",
            " notes",
            " to",
            " other",
            " production",
            " personnel",
            " written",
            " by",
            " or",
            " to",
            " Hitch"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.042,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.03,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.031,
            -0.0,
            -0.0,
            0.059,
            -0.0,
            0.193,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.277,
            0.301,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.275,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.17,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.041,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.078,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " Hung",
            "arians",
            " says",
            " in",
            " the",
            " G",
            "esta",
            " Hung",
            "ar",
            "orum",
            ":",
            "King",
            " Matthias",
            " of",
            " Hungary",
            " (",
            "145",
            "8",
            "–",
            "149",
            "0",
            ")",
            " was",
            " happy",
            " to",
            " be",
            " described",
            " as",
            " \"",
            "the",
            " second",
            " At",
            "til",
            "a",
            "\".",
            " The",
            " Chron",
            "ica",
            " Hung",
            "ar",
            "orum",
            " by",
            " Johannes",
            " Thur",
            "Ã³",
            "czy",
            " set",
            " the",
            " goal",
            " of",
            " glor",
            "ifying",
            " At",
            "til",
            "a",
            ",",
            " which",
            " was",
            " undes",
            "erved",
            "ly"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.042,
            -0.0,
            -0.0,
            0.135,
            -0.0,
            -0.0,
            -0.0,
            0.344,
            0.13,
            -0.0,
            -0.0,
            -0.0,
            0.144,
            -0.0,
            -0.0,
            -0.0,
            0.35,
            -0.0,
            -0.0,
            0.398,
            -0.0,
            0.014,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.069,
            0.2,
            -0.0,
            0.129,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.457,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.202,
            -0.0,
            -0.0,
            0.071,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.014,
            0.117
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " Azerbaijan",
            " SSR",
            " dropped",
            " the",
            " words",
            " \"",
            "S",
            "ov",
            "iet",
            " Socialist",
            "\"",
            " from",
            " the",
            " title",
            ",",
            " adopted",
            " the",
            " \"",
            "Declaration",
            " of",
            " Sovere",
            "ignty",
            " of",
            " the",
            " Azerbaijan",
            " Republic",
            "\"",
            " and",
            " restored",
            " the",
            " flag",
            " of",
            " the",
            " Azerbaijan",
            " Democratic",
            " Republic",
            " as",
            " the",
            " state",
            " flag",
            ".",
            " As",
            " a",
            " consequence",
            " of",
            " the",
            " failed",
            " ",
            "199",
            "1",
            " Soviet",
            " coup",
            " d",
            "'Ã©t",
            "at",
            " attempt",
            " in",
            " Moscow",
            ",",
            " the",
            " Supreme"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.042,
            0.068,
            -0.0,
            0.046,
            -0.0,
            -0.0,
            -0.0,
            0.199,
            0.132,
            -0.0,
            -0.0,
            0.054,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.1,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.625,
            0.144,
            -0.0,
            0.098,
            0.279,
            -0.0,
            -0.0,
            0.136,
            -0.0,
            -0.0,
            0.232,
            -0.0,
            -0.0,
            0.438,
            0.041,
            -0.0,
            0.434,
            -0.0,
            -0.0,
            0.637,
            0.046,
            -0.0,
            -0.0,
            0.008,
            0.106,
            -0.0,
            -0.0,
            0.19,
            -0.0,
            -0.0,
            -0.0,
            0.039,
            0.018,
            -0.0,
            -0.0,
            0.389,
            -0.0,
            -0.0,
            -0.0,
            0.036,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " male",
            " and",
            " female",
            " gam",
            "etes",
            ".",
            " A",
            "sexual",
            " reproduction",
            " permits",
            " efficient",
            " population",
            " increases",
            ",",
            " but",
            " less",
            " variation",
            " is",
            " possible",
            ".",
            " Common",
            "ly",
            ",",
            " in",
            " sexual",
            " reproduction",
            " of",
            " unic",
            "ellular",
            " and",
            " colonial",
            " algae",
            ",",
            " two",
            " specialized",
            ",",
            " sexually",
            " compatible",
            ",",
            " hap",
            "loid",
            " gam",
            "etes",
            " make",
            " physical",
            " contact",
            " and",
            " fuse",
            " to",
            " form",
            " a",
            " z",
            "yg",
            "ote",
            ".",
            " To",
            " ensure",
            " a",
            " successful",
            " mating",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.106,
            0.022,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.894,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.149,
            0.1,
            -0.0,
            0.01,
            -0.0,
            -0.0,
            0.168,
            -0.0,
            -0.0,
            -0.0,
            0.032,
            0.052,
            -0.0,
            -0.0,
            0.484,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.116,
            -0.0,
            -0.0,
            0.285,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.146,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.196,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " a",
            " scientifically",
            " un",
            "validated",
            " cancer",
            " treatment",
            ".",
            "Radio",
            "is",
            "ot",
            "opes",
            " of",
            " ca",
            "esium",
            " require",
            " special",
            " precautions",
            ":",
            " the",
            " improper",
            " handling",
            " of",
            " ca",
            "esium",
            "-",
            "137",
            " gamma",
            " ray",
            " sources",
            " can",
            " lead",
            " to",
            " release",
            " of",
            " this",
            " radio",
            "is",
            "otope",
            " and",
            " radiation",
            " injuries",
            ".",
            " Perhaps",
            " the",
            " best",
            "-known",
            " case",
            " is",
            " the",
            " Go",
            "i",
            "Ã¢",
            "nia",
            " accident",
            " of",
            " ",
            "198",
            "7",
            ",",
            " in",
            " which",
            " an"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.042,
            0.031,
            -0.0,
            0.359,
            -0.0,
            -0.0,
            -0.0,
            0.969,
            0.676,
            0.396,
            0.879,
            0.188,
            -0.0,
            -0.0,
            0.141,
            0.107,
            -0.0,
            -0.0,
            0.056,
            -0.0,
            0.065,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.083,
            0.169,
            -0.0,
            -0.0,
            0.832,
            0.143,
            -0.0,
            -0.0,
            0.012,
            -0.0,
            -0.0,
            0.172,
            0.104,
            -0.0,
            0.812,
            0.136,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.152,
            0.032,
            -0.0,
            0.828,
            0.84,
            0.156,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " old",
            "\")",
            " may",
            " refer",
            " to",
            ":",
            "Places",
            "A",
            "ustria",
            " Al",
            "ten",
            "berg",
            ",",
            " a",
            " town",
            " in",
            " S",
            "ank",
            "t",
            " Andr",
            "Ã¤",
            "-W",
            "Ã¶",
            "rd",
            "ern",
            ",",
            " T",
            "ull",
            "n",
            " District",
            " Al",
            "ten",
            "berg",
            " bei",
            " Lin",
            "z",
            ",",
            " in",
            " Upper",
            " Austria",
            " Al",
            "ten",
            "berg",
            " an",
            " der",
            " R",
            "ax",
            ",",
            " in",
            " Sty",
            "ria",
            "Germany",
            " Al",
            "ten",
            "berg"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.042,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.043,
            -0.0,
            -0.0,
            -0.0,
            0.469,
            0.096,
            0.186,
            -0.0,
            0.12,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.625,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.66,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.006,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " United",
            " Nations",
            " and",
            " the",
            " Council",
            " of",
            " Europe",
            ".",
            "And",
            "orra",
            " formal",
            "ized",
            " diplomatic",
            " relations",
            " with",
            " the",
            " United",
            " States",
            " in",
            " ",
            "199",
            "6",
            ",",
            " participating",
            " in",
            " the",
            " ",
            "51",
            "st",
            " UN",
            " General",
            " Assembly",
            ".",
            " First",
            " General",
            " Synd",
            "ic",
            " Marc",
            " F",
            "orn",
            "Ã©",
            " took",
            " part",
            " on",
            " a",
            " speech",
            " in",
            " Catalan",
            " in",
            " the",
            " General",
            " Assembly",
            " to",
            " defend",
            " the",
            " reform",
            " of",
            " the",
            " organization",
            ",",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.042,
            -0.0,
            -0.0,
            -0.0,
            0.434,
            0.203,
            -0.0,
            0.183,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.262,
            -0.0,
            0.081,
            0.081,
            -0.0,
            0.385,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.072,
            0.067,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.069,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            0.234,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.237,
            0.087,
            -0.0,
            0.049,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.111,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.19,
            0.044,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " Serbian",
            " elite",
            ",",
            " ignited",
            " allegations",
            " of",
            " bols",
            "hev",
            "ism",
            " from",
            " Bel",
            "grade",
            ".",
            " This",
            ",",
            " in",
            " turn",
            ",",
            " led",
            " to",
            " increased",
            " pressure",
            " from",
            " Italy",
            " and",
            " cul",
            "minated",
            " in",
            " Z",
            "og",
            "'s",
            " restoration",
            " to",
            " authority",
            ".",
            " Sub",
            "sequently",
            " in",
            " ",
            "192",
            "8",
            ",",
            " Z",
            "og",
            "u",
            " transition",
            "ed",
            " Albania",
            " from",
            " a",
            " republic",
            " to",
            " a",
            " monarchy",
            " that",
            " garnered",
            " backing",
            " from",
            " Fasc",
            "ist",
            " Italy"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.406,
            0.042,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.085,
            -0.0,
            0.367,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.426,
            -0.0,
            -0.0,
            -0.0,
            0.014,
            -0.0,
            -0.0,
            0.03,
            0.011,
            -0.0,
            -0.0,
            -0.0,
            0.044,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.512,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.015,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " Kingdom",
            " of",
            " the",
            " Netherlands",
            " was",
            " established",
            ",",
            " providing",
            " a",
            " framework",
            " for",
            " relations",
            " between",
            " Ar",
            "uba",
            " and",
            " the",
            " rest",
            " of",
            " the",
            " Kingdom",
            ".",
            " That",
            " created",
            " the",
            " Netherlands",
            " Ant",
            "illes",
            ",",
            " which",
            " united",
            " all",
            " of",
            " the",
            " Dutch",
            " colonies",
            " in",
            " the",
            " Caribbean",
            " into",
            " one",
            " administrative",
            " structure",
            ".",
            " Many",
            " Ar",
            "ub",
            "ans",
            " were",
            " unhappy",
            " with",
            " the",
            " arrangement",
            ",",
            " however",
            ",",
            " as",
            " the",
            " new",
            " policy",
            " was"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.234,
            -0.0,
            0.103,
            -0.0,
            -0.0,
            0.375,
            -0.0,
            0.291,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.121,
            -0.0,
            -0.0,
            0.33,
            -0.0,
            -0.0,
            0.478,
            0.262,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.006,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.124,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.703,
            0.19,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.005,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "ed",
            " or",
            " t",
            "illed",
            ")",
            " regularly",
            ",",
            " generally",
            " under",
            " a",
            " system",
            " of",
            " crop",
            " rotation",
            "\".",
            " In",
            " Britain",
            ",",
            " ar",
            "able",
            " land",
            " has",
            " traditionally",
            " been",
            " contrast",
            "ed",
            " with",
            " past",
            "urable",
            " land",
            " such",
            " as",
            " he",
            "aths",
            ",",
            " which",
            " could",
            " be",
            " used",
            " for",
            " sheep",
            "-re",
            "aring",
            " but",
            " not",
            " as",
            " far",
            "mland",
            ".",
            "Ar",
            "able",
            " land",
            " is",
            " vulnerable",
            " to",
            " land",
            " degradation",
            " and",
            " some",
            " types",
            " of",
            " un",
            "-ar"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            0.793,
            -0.0,
            0.934,
            -0.0,
            0.82,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.017,
            -0.0,
            -0.0,
            0.416,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.095,
            -0.0,
            -0.0,
            0.066,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.336,
            -0.0,
            -0.0,
            -0.0,
            0.805,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.906,
            0.25,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.141,
            0.108,
            -0.0,
            0.088,
            -0.0,
            -0.0
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            " made",
            ".",
            "Film",
            "ography",
            "T",
            "ark",
            "ovsky",
            " is",
            " mainly",
            " known",
            " as",
            " a",
            " film",
            " director",
            ".",
            " During",
            " his",
            " career",
            " he",
            " directed",
            " seven",
            " feature",
            " films",
            ",",
            " as",
            " well",
            " as",
            " three",
            " shorts",
            " from",
            " his",
            " time",
            " at",
            " V",
            "GI",
            "K",
            ".",
            " His",
            " features",
            " are",
            ":",
            " Ivan",
            "'s",
            " Childhood",
            " (",
            "196",
            "2",
            ")",
            " Andre",
            "i",
            " Rub",
            "lev",
            " (",
            "196",
            "6",
            ")",
            " Solar",
            "is",
            " (",
            "197",
            "2",
            ")"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.125,
            0.124,
            0.723,
            0.053,
            -0.0,
            0.394,
            -0.0,
            -0.0,
            0.498,
            0.079,
            -0.0,
            0.602,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.287,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.219,
            0.09,
            -0.0,
            -0.0,
            0.042,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.926,
            0.844,
            -0.0,
            0.455,
            -0.0,
            0.184,
            0.684,
            -0.0,
            0.303,
            -0.0,
            -0.0,
            0.078,
            -0.0,
            -0.0,
            -0.0,
            0.03,
            -0.0,
            -0.0,
            0.535,
            -0.0,
            0.01,
            -0.0,
            0.076
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "ig",
            " (\"",
            "Hero",
            "ic",
            ",",
            " Determin",
            "ed",
            ",",
            " Merc",
            "iful",
            "\"),",
            " bestowed",
            " on",
            " the",
            " city",
            " in",
            " ",
            "194",
            "7",
            " by",
            " Queen",
            " Wil",
            "hel",
            "mina",
            ",",
            " in",
            " recognition",
            " of",
            " the",
            " city",
            "'s",
            " bravery",
            " during",
            " the",
            " Second",
            " World",
            " War",
            ".",
            "Transport",
            "Metro",
            ",",
            " tram",
            " and",
            " bus",
            "Currently",
            ",",
            " there",
            " are",
            " sixteen",
            " tram",
            " routes",
            " and",
            " five",
            " metro",
            " routes",
            ".",
            " All",
            " are",
            " operated",
            " by",
            " municipal"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.816,
            0.054,
            -0.0,
            -0.0,
            -0.0,
            0.52,
            0.146,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.453,
            0.185,
            -0.0,
            -0.0,
            0.123,
            0.396,
            -0.0,
            -0.0,
            -0.0,
            0.08,
            -0.0,
            -0.0,
            -0.0,
            0.992,
            -0.0,
            -0.0,
            -0.0,
            0.293,
            0.109,
            -0.0,
            -0.0,
            0.973,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            0.383,
            -0.0,
            -0.0,
            1.102,
            0.156,
            0.09,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.218,
            0.095,
            -0.0,
            0.812,
            0.011,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.361,
            -0.0
          ],
          "train_token_ind": 42,
          "is_repeated_datapoint": false,
          "tokens": [
            "'s",
            " Trans",
            "fig",
            "uration",
            ",",
            " popular",
            "ly",
            " known",
            " as",
            " the",
            " \"",
            "App",
            "les",
            " Feast",
            "\"",
            " (",
            "Russian",
            " Orthodox",
            " Church",
            " and",
            " Georgian",
            " Orthodox",
            " Church",
            ")",
            " Afghan",
            " Independence",
            " Day",
            " (",
            "Af",
            "ghan",
            "istan",
            ")",
            " August",
            " Revolution",
            " Comm",
            "em",
            "oration",
            " Day",
            " (",
            "Viet",
            "nam",
            ")",
            " Birthday",
            " of",
            " Crown",
            " Princess",
            " Met",
            "te",
            "-Mar",
            "it",
            " (",
            "Nor",
            "way",
            ")",
            " Manuel",
            " Luis",
            " Que",
            "z",
            "Ã³n",
            " Day",
            " (",
            "Que",
            "zon"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.078,
            0.148,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.086,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.033,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.656,
            0.228,
            0.008,
            -0.0,
            0.008,
            -0.0,
            -0.0,
            0.027,
            -0.0,
            -0.0,
            -0.0,
            0.434,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.094,
            -0.0,
            -0.0,
            -0.0,
            0.301,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " that",
            " was",
            " not",
            " theirs",
            ".",
            " Desert",
            "ion",
            " among",
            " the",
            " Germans",
            " occurred",
            " throughout",
            " the",
            " war",
            ",",
            " with",
            " the",
            " highest",
            " rate",
            " of",
            " desert",
            "ion",
            " occurring",
            " during",
            " the",
            " time",
            " between",
            " the",
            " surrender",
            " at",
            " York",
            "town",
            " and",
            " the",
            " Treaty",
            " of",
            " Paris",
            ".",
            " German",
            " reg",
            "iments",
            " were",
            " central",
            " to",
            " the",
            " British",
            " war",
            " effort",
            ";",
            " of",
            " the",
            " estimated",
            " ",
            "30",
            ",",
            "000",
            " sent",
            " to",
            " America",
            ",",
            " some",
            " ",
            "13"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.07,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.129,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.582,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.162,
            -0.0,
            0.077,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.097,
            -0.0,
            -0.0,
            0.272,
            0.352,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.132,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.171,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.293,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "'t",
            " want",
            " to",
            " switch",
            " to",
            " legal",
            " trade",
            " with",
            " New",
            " N",
            "ether",
            "land",
            ".",
            " Governor",
            " St",
            "uy",
            "ves",
            "ant",
            " needed",
            " slaves",
            " to",
            " strengthen",
            " New",
            " Amsterdam",
            "'s",
            " defenses",
            ",",
            " but",
            " he",
            " mostly",
            " received",
            " old",
            " or",
            " sick",
            " slaves",
            ",",
            " called",
            " man",
            "c",
            "arr",
            "ons",
            ",",
            " in",
            " response",
            " to",
            " his",
            " requests",
            ".",
            " The",
            " better",
            " slaves",
            " were",
            " sold",
            " elsewhere",
            " to",
            " the",
            " highest",
            " bidder",
            ".",
            " However",
            ",",
            " the",
            " people"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            1.055,
            -0.0,
            0.033,
            -0.0,
            0.914,
            0.246,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.326,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.357,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.19,
            -0.0,
            0.036,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.08,
            -0.0,
            0.177,
            0.135,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " result",
            " in",
            " history",
            ".",
            "K",
            "arp",
            "ov",
            " defended",
            " his",
            " F",
            "IDE",
            " title",
            " against",
            " the",
            " rising",
            " star",
            " G",
            "ata",
            " K",
            "ams",
            "ky",
            " (+",
            "6",
            "âĪĴ",
            "3",
            "=",
            "9",
            ")",
            " in",
            " ",
            "199",
            "6",
            ".",
            " In",
            " ",
            "199",
            "8",
            ",",
            " F",
            "IDE",
            " largely",
            " scrapped",
            " the",
            " old",
            " system",
            " of",
            " Candidates",
            "'",
            " Matches",
            ",",
            " instead",
            " having",
            " a",
            " large",
            " knockout",
            " event",
            " in",
            " which",
            " a",
            " large",
            " number",
            " of",
            " players"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.047,
            0.027,
            0.789,
            -0.0,
            0.06,
            0.283,
            -0.0,
            -0.0,
            -0.0,
            0.094,
            -0.0,
            -0.0,
            -0.0,
            0.644,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.338,
            -0.0,
            0.184,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.02,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.188,
            -0.0,
            -0.0,
            0.17,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "ax",
            ")",
            " voice",
            " or",
            " between",
            " modal",
            " voice",
            " and",
            " c",
            "reak",
            "y",
            " voice",
            ".",
            " Languages",
            " in",
            " the",
            " Pear",
            "ic",
            " branch",
            " and",
            " some",
            " in",
            " the",
            " Viet",
            "ic",
            " branch",
            " can",
            " have",
            " a",
            " three",
            "-",
            " or",
            " even",
            " four",
            "-way",
            " vo",
            "icing",
            " contrast",
            ".",
            "However",
            ",",
            " some",
            " Aust",
            "ro",
            "asi",
            "atic",
            " languages",
            " have",
            " lost",
            " the",
            " register",
            " contrast",
            " by",
            " evolving",
            " more",
            " d",
            "iph",
            "th",
            "ongs",
            " or",
            " in",
            " a",
            " few"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            1.0,
            0.262,
            0.116,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.945,
            0.223,
            -0.0,
            0.816,
            0.387,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.092,
            0.293,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.166,
            -0.0,
            0.137,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.106,
            -0.0,
            0.206,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "us",
            " toll",
            "ens",
            " and",
            " is",
            " a",
            " valid",
            " form",
            " of",
            " argument",
            ".",
            "Form",
            "al",
            " description",
            "Aff",
            "irm",
            "ing",
            " the",
            " consequ",
            "ent",
            " is",
            " the",
            " action",
            " of",
            " taking",
            " a",
            " true",
            " statement",
            " ",
            " and",
            " invalid",
            "ly",
            " concluding",
            " its",
            " converse",
            " .",
            " The",
            " name",
            " affirm",
            "ing",
            " the",
            " consequ",
            "ent",
            " derives",
            " from",
            " using",
            " the",
            " consequ",
            "ent",
            ",",
            " Q",
            ",",
            " of",
            " ,",
            " to",
            " conclude",
            " the",
            " ant",
            "eced",
            "ent",
            " P",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.828,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.393,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.08,
            -0.0,
            -0.0,
            0.048,
            -0.0,
            -0.0,
            0.02,
            0.087,
            0.118,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.391,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.547,
            0.037,
            -0.0,
            -0.0,
            -0.0,
            0.081,
            -0.0,
            -0.0,
            -0.0,
            0.035,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.984,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.469,
            0.116,
            0.195,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 49,
          "is_repeated_datapoint": false,
          "tokens": [
            " who",
            " could",
            " not",
            " complete",
            " the",
            " university",
            " program",
            " of",
            " his",
            " youth",
            ",",
            " received",
            " at",
            " least",
            " a",
            " dozen",
            " honorary",
            " degrees",
            " from",
            " academic",
            " institutions",
            ",",
            " including",
            " eight",
            " honorary",
            " LL",
            ".D",
            ".s",
            " (",
            "Doctor",
            "ate",
            " of",
            " Laws",
            "),",
            " two",
            " Ph",
            ".D",
            ".s",
            ",",
            " a",
            " D",
            ".Sc",
            ".,",
            " and",
            " an",
            " M",
            ".D",
            ".",
            ":",
            " Gall",
            "aud",
            "et",
            " College",
            " (",
            "then",
            " named",
            " National",
            " De",
            "af",
            "-M",
            "ute",
            " College",
            ")"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.977,
            0.482,
            0.05,
            -0.0,
            0.12,
            -0.0,
            -0.0,
            -0.0,
            0.143,
            0.04,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.09,
            -0.0,
            -0.0,
            0.438,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.293,
            -0.0,
            -0.0,
            0.086,
            0.039,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.377,
            -0.0,
            -0.0,
            -0.0,
            0.369,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " by",
            " structural",
            "ist",
            " and",
            " post",
            "modern",
            " theories",
            ",",
            " as",
            " well",
            " as",
            " a",
            " shift",
            " toward",
            " the",
            " analysis",
            " of",
            " modern",
            " societies",
            ".",
            " During",
            " the",
            " ",
            "197",
            "0",
            "s",
            " and",
            " ",
            "199",
            "0",
            "s",
            ",",
            " there",
            " was",
            " an",
            " ep",
            "istem",
            "ological",
            " shift",
            " away",
            " from",
            " the",
            " posit",
            "ivist",
            " traditions",
            " that",
            " had",
            " largely",
            " informed",
            " the",
            " discipline",
            ".",
            " During",
            " this",
            " shift",
            ",",
            " enduring",
            " questions",
            " about",
            " the",
            " nature",
            " and",
            " production"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            0.973,
            0.012,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.102,
            -0.0,
            0.063,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.085,
            0.262,
            0.155,
            -0.0,
            -0.0,
            0.101,
            -0.0,
            -0.0,
            0.393,
            -0.0,
            0.05,
            -0.0,
            -0.0,
            0.625,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.006,
            0.038,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.307,
            0.264,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.171,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " only",
            " recorded",
            " one",
            " album",
            " together",
            " as",
            " the",
            " Analog",
            " Brothers",
            ",",
            " a",
            " few",
            " boot",
            "legs",
            " of",
            " its",
            " live",
            " concert",
            " performances",
            ",",
            " including",
            " fre",
            "est",
            "yles",
            " with",
            " original",
            " lyrics",
            ",",
            " have",
            " occasionally",
            " surfaced",
            " online",
            ".",
            " After",
            " P",
            "imp",
            " to",
            " Eat",
            ",",
            " the",
            " Analog",
            " Brothers",
            " continued",
            " performing",
            " together",
            " in",
            " various",
            " line",
            " ups",
            ".",
            " K",
            "ool",
            " Keith",
            " and",
            " Marc",
            " Live",
            " joined",
            " with",
            " Jack",
            "y",
            " Jasper",
            " to",
            " release"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.91,
            -0.0,
            -0.0,
            0.672,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.254,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.637,
            -0.0,
            0.086,
            0.038,
            -0.0,
            -0.0,
            0.08,
            -0.0,
            -0.0,
            -0.0,
            0.264,
            -0.0,
            -0.0,
            0.272,
            -0.0,
            0.118,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.022,
            -0.0,
            -0.0,
            0.373,
            -0.0,
            0.346,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.734,
            0.152,
            -0.0,
            -0.0,
            -0.0,
            0.011,
            -0.0,
            0.262,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " highest",
            " honor",
            " (",
            "limited",
            " to",
            " living",
            " writers",
            ",",
            " no",
            " more",
            " than",
            " one",
            " annually",
            ").",
            " Writing",
            " an",
            " ob",
            "it",
            "uary",
            " of",
            " van",
            " Vog",
            "t",
            ",",
            " Robert",
            " J",
            ".",
            " Sawyer",
            ",",
            " a",
            " fellow",
            " Canadian",
            " writer",
            " of",
            " science",
            " fiction",
            ",",
            " remarked",
            ":",
            "It",
            " is",
            " generally",
            " held",
            " that",
            " a",
            " key",
            " factor",
            " in",
            " the",
            " delay",
            " was",
            " \"",
            "dam",
            "nable",
            " S",
            "FW",
            "A",
            " politics",
            "\"",
            " reflecting",
            " the",
            " concerns",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.809,
            -0.0,
            -0.0,
            0.183,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.06,
            -0.0,
            -0.0,
            0.016,
            -0.0,
            0.034,
            -0.0,
            -0.0,
            0.045,
            0.07,
            -0.0,
            -0.0,
            -0.0,
            0.469,
            -0.0,
            0.181,
            -0.0,
            -0.0,
            -0.0,
            0.4,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.234,
            0.077,
            -0.0,
            0.045,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.2,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.578,
            -0.0,
            -0.0,
            -0.0,
            0.085,
            -0.0,
            0.01,
            -0.0,
            -0.0,
            0.075,
            0.001,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " a",
            " brief",
            " but",
            " spirited",
            " resurgence",
            " in",
            " the",
            " economy",
            " and",
            " culture",
            ",",
            " but",
            " in",
            " ",
            "525",
            "BC",
            ",",
            " the",
            " powerful",
            " Pers",
            "ians",
            ",",
            " led",
            " by",
            " Camb",
            "yses",
            " II",
            ",",
            " began",
            " their",
            " conquest",
            " of",
            " Egypt",
            ",",
            " eventually",
            " capturing",
            " the",
            " ph",
            "araoh",
            " Ps",
            "amt",
            "ik",
            " III",
            " at",
            " the",
            " Battle",
            " of",
            " Pel",
            "us",
            "ium",
            ".",
            " Camb",
            "yses",
            " II",
            " then",
            " assumed",
            " the",
            " formal",
            " title",
            " of",
            " ph",
            "araoh",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.625,
            -0.0,
            0.02,
            -0.0,
            -0.0,
            0.079,
            0.133,
            -0.0,
            -0.0,
            0.054,
            -0.0,
            0.181,
            0.059,
            -0.0,
            0.104,
            -0.0,
            -0.0,
            0.09,
            -0.0,
            -0.0,
            0.18,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.758,
            0.019,
            -0.0,
            -0.0,
            0.025,
            -0.0,
            -0.0,
            -0.0,
            0.072,
            -0.0,
            -0.0,
            -0.0,
            0.089,
            -0.0,
            -0.0,
            0.449,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.447,
            -0.0,
            -0.0,
            -0.0,
            0.2,
            0.183,
            -0.0,
            -0.0,
            -0.0,
            0.06
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            "By",
            " ",
            "187",
            "5",
            ",",
            " the",
            " French",
            " conquest",
            " was",
            " complete",
            ".",
            " The",
            " war",
            " had",
            " killed",
            " approximately",
            " ",
            "825",
            ",",
            "000",
            " indigenous",
            " Alger",
            "ians",
            " since",
            " ",
            "183",
            "0",
            ".\"",
            " French",
            " losses",
            " from",
            " ",
            "183",
            "1",
            " to",
            " ",
            "185",
            "1",
            " were",
            " ",
            "92",
            ",",
            "329",
            " dead",
            " in",
            " the",
            " hospital",
            " and",
            " only",
            " ",
            "3",
            ",",
            "336",
            " killed",
            " in",
            " action",
            ".",
            " The",
            " population",
            " of",
            " Algeria",
            ",",
            " which"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.723,
            0.069,
            -0.0,
            0.162,
            0.069,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.053,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.192,
            -0.0,
            0.058,
            -0.0,
            -0.0,
            0.101,
            -0.0,
            0.043,
            0.637,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.152,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.016,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.008,
            -0.0,
            -0.0,
            -0.0,
            0.076,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " adjacent",
            " stick",
            ".",
            " The",
            " parentheses",
            " could",
            " not",
            " correspond",
            " to",
            " ",
            "9",
            " and",
            " ",
            "0",
            ",",
            " however",
            ",",
            " because",
            " the",
            " place",
            " corresponding",
            " to",
            " ",
            "0",
            " was",
            " taken",
            " by",
            " the",
            " space",
            " character",
            ".",
            " This",
            " was",
            " accommod",
            "ated",
            " by",
            " removing",
            " _",
            " (",
            "underscore",
            ")",
            " from",
            " ",
            "6",
            " and",
            " shifting",
            " the",
            " remaining",
            " characters",
            ",",
            " which",
            " correspond",
            "ed",
            " to",
            " many",
            " European",
            " typ",
            "ew",
            "riters",
            " that",
            " placed",
            " the",
            " parentheses"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            0.606,
            0.44,
            -0.0,
            0.019,
            -0.0,
            0.412,
            -0.0,
            0.012,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.102,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.574,
            -0.0,
            0.03,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.566,
            0.003,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.523,
            0.084,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.684,
            0.108,
            0.073,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.258,
            -0.0,
            -0.0,
            -0.0,
            0.156,
            -0.0,
            0.203,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "194",
            "0",
            "s",
            ",",
            " Austrian",
            " economics",
            " can",
            " be",
            " divided",
            " into",
            " two",
            " schools",
            " of",
            " economic",
            " thought",
            " and",
            " the",
            " school",
            " \"",
            "split",
            "\"",
            " to",
            " some",
            " degree",
            " in",
            " the",
            " late",
            " ",
            "20",
            "th",
            " century",
            ".",
            " One",
            " camp",
            " of",
            " Aust",
            "rians",
            ",",
            " exempl",
            "ified",
            " by",
            " M",
            "ises",
            ",",
            " regards",
            " ne",
            "oc",
            "lass",
            "ical",
            " methodology",
            " to",
            " be",
            " irre",
            "de",
            "em",
            "ably",
            " flawed",
            ";",
            " the",
            " other",
            " camp",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.68,
            -0.0,
            0.058,
            -0.0,
            0.539,
            0.44,
            0.34,
            -0.0,
            -0.0,
            0.148,
            0.625,
            -0.0,
            -0.0,
            -0.0,
            0.132,
            -0.0,
            -0.0,
            -0.0,
            0.107,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.23,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.194,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.656,
            -0.0,
            -0.0,
            0.207,
            -0.0,
            0.022,
            -0.0,
            0.504,
            0.081,
            -0.0,
            0.144,
            0.23,
            0.032,
            0.032,
            -0.0,
            0.516,
            -0.0,
            0.045,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " Roosevelt",
            "'s",
            " death",
            ".",
            " ",
            " ",
            "194",
            "5",
            "  ",
            " –",
            " World",
            " War",
            " II",
            ":",
            " The",
            " U",
            ".S",
            ".",
            " Ninth",
            " Army",
            " under",
            " General",
            " William",
            " H",
            ".",
            " Simpson",
            " crosses",
            " the",
            " El",
            "be",
            " River",
            " astr",
            "ide",
            " Mag",
            "de",
            "burg",
            ",",
            " and",
            " reaches",
            " T",
            "anger",
            "m",
            "Ã¼nde",
            "—",
            "only",
            " ",
            "50",
            " miles",
            " from",
            " Berlin",
            ".",
            "195",
            "5",
            " –",
            " The",
            " pol",
            "io",
            " vaccine",
            ",",
            " developed",
            " by",
            " Dr",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.621,
            0.08,
            -0.0,
            -0.0,
            -0.0,
            0.523,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.496,
            -0.0,
            -0.0,
            0.184,
            -0.0,
            0.438,
            -0.0,
            -0.0,
            0.174,
            -0.0,
            -0.0,
            0.594,
            0.225,
            -0.0,
            0.574,
            -0.0,
            0.054,
            -0.0,
            -0.0,
            0.406,
            0.137,
            -0.0,
            -0.0,
            -0.0,
            0.41,
            -0.0,
            -0.0,
            0.202,
            -0.0,
            -0.0,
            0.598,
            0.161,
            -0.0,
            0.644,
            -0.0,
            -0.0,
            -0.0,
            0.484,
            0.02,
            -0.0,
            -0.0,
            0.418,
            -0.0,
            -0.0,
            0.157,
            -0.0,
            -0.0,
            0.582,
            0.175,
            -0.0,
            0.523,
            -0.0,
            -0.0
          ],
          "train_token_ind": 43,
          "is_repeated_datapoint": false,
          "tokens": [
            " Ste",
            "vie",
            " Ray",
            " Vaughan",
            ",",
            " American",
            " singer",
            "-song",
            "writer",
            ",",
            " guitarist",
            ",",
            " and",
            " producer",
            " (",
            "b",
            ".",
            " ",
            "195",
            "4",
            ")",
            "199",
            "2",
            " –",
            " Beng",
            "t",
            " Hol",
            "bek",
            ",",
            " Danish",
            " folk",
            "lor",
            "ist",
            " (",
            "b",
            ".",
            " ",
            "193",
            "3",
            ")",
            "199",
            "4",
            " –",
            " Frank",
            " Jes",
            "ke",
            ",",
            " German",
            " football",
            "er",
            " (",
            "b",
            ".",
            " ",
            "196",
            "0",
            ")",
            "199",
            "6",
            " –",
            " Greg",
            " Morris",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.562,
            0.175,
            -0.0,
            -0.0,
            -0.0,
            0.044,
            -0.0,
            -0.0,
            0.582,
            0.216,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.058,
            0.022,
            -0.0,
            -0.0,
            0.398,
            0.194,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.165,
            0.239,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.204,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.144,
            -0.0,
            -0.0,
            0.469,
            -0.0,
            -0.0,
            0.124,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 8,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " Jasper",
            " National",
            " Park",
            " into",
            " British",
            " Columbia",
            ".",
            " One",
            " of",
            " the",
            " most",
            " scenic",
            " drives",
            " is",
            " along",
            " the",
            " Ice",
            "fields",
            " Parkway",
            ",",
            " which",
            " runs",
            " for",
            " ",
            " between",
            " Jasper",
            " and",
            " Lake",
            " Louise",
            ",",
            " with",
            " mountain",
            " ranges",
            " and",
            " glaciers",
            " on",
            " either",
            " side",
            " of",
            " its",
            " entire",
            " length",
            ".",
            " A",
            " third",
            " corridor",
            " stretches",
            " across",
            " southern",
            " Alberta",
            ";",
            " Highway",
            "Âł",
            "3",
            " runs",
            " between",
            " C",
            "rows",
            "nest",
            " Pass",
            " and",
            " Medicine"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.422,
            0.443,
            0.117,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.32,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.289,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.014,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.002,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.176,
            0.176,
            -0.0,
            -0.0,
            -0.0,
            0.246,
            -0.0,
            -0.0,
            0.424,
            0.104,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.434,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " both",
            " Polish",
            " Jews",
            " who",
            " had",
            " migrated",
            " to",
            " America",
            ".",
            " He",
            " had",
            " one",
            " younger",
            " sister",
            ".",
            " He",
            " was",
            " inspired",
            " to",
            " become",
            " a",
            " writer",
            " at",
            " the",
            " age",
            " of",
            " ",
            "7",
            " by",
            " his",
            " aunt",
            " and",
            " uncle",
            ",",
            " who",
            " lived",
            " with",
            " the",
            " T",
            "off",
            "lers",
            ".",
            " \"",
            "They",
            " were",
            " Depression",
            "-era",
            " literary",
            " intellectuals",
            ",\"",
            " T",
            "off",
            "ler",
            " said",
            ",",
            " \"",
            "and",
            " they",
            " always",
            " talked",
            " about",
            " exciting"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "lehem",
    "achuset",
    "Ð¼ÐµÑĤÑĮ",
    "jedn",
    "erre"
  ],
  "bottom_logits": [
    "eland",
    "SKTOP",
    "sing",
    " Sadd",
    ".ru"
  ],
  "act_min": -0.0,
  "act_max": 1.5
}
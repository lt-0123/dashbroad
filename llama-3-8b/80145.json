{
  "index": 80145,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            0.463,
            0.182,
            0.295,
            0.408,
            0.198,
            0.22,
            0.398,
            0.191,
            0.426,
            0.22,
            0.52,
            1.414,
            0.707,
            0.508,
            0.408,
            0.535,
            0.062,
            0.383,
            0.793,
            0.484,
            0.059,
            0.289,
            0.531,
            0.246,
            -0.0,
            0.898,
            0.338,
            0.527,
            0.393,
            0.758,
            0.68,
            -0.0,
            0.264,
            0.484,
            0.346,
            0.602,
            0.356,
            0.465,
            0.641,
            0.625,
            0.773,
            0.486,
            0.275,
            0.198,
            0.373,
            0.287,
            0.504,
            0.336,
            0.467,
            -0.0,
            0.277,
            0.383,
            0.252,
            0.363,
            0.338,
            0.262,
            0.049,
            0.305,
            0.328,
            -0.0,
            0.171
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            " Mutual",
            " Aid",
            ":",
            " A",
            " Factor",
            " of",
            " Evolution",
            " and",
            " Moral",
            " Phil",
            "osopher",
            " Peter",
            " Singer",
            " in",
            " his",
            " book",
            " A",
            " Darwin",
            "ian",
            " Left",
            ".",
            "Ne",
            "uro",
            "biology",
            "J",
            "orge",
            " M",
            "oll",
            " and",
            " Jordan",
            " Graf",
            "man",
            ",",
            " neuro",
            "scient",
            "ists",
            " at",
            " the",
            " National",
            " Institutes",
            " of",
            " Health",
            " and",
            " LAB",
            "S",
            "-D",
            "'",
            "Or",
            " Hospital",
            " Network",
            ",",
            " provided",
            " the",
            " first",
            " evidence",
            " for",
            " the",
            " neural",
            " bases",
            " of",
            " altru",
            "istic"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.092,
            0.163,
            0.398,
            0.5,
            -0.0,
            0.59,
            0.332,
            0.334,
            0.303,
            0.118,
            0.551,
            0.434,
            0.191,
            0.396,
            0.23,
            0.375,
            1.383,
            0.668,
            0.629,
            0.208,
            0.34,
            0.471,
            0.268,
            0.332,
            0.312,
            0.32,
            0.291,
            0.019,
            0.114,
            0.441,
            0.469,
            0.484,
            1.336,
            0.676,
            0.354,
            0.322,
            0.338,
            0.186,
            0.299,
            0.504,
            0.414,
            0.134,
            0.633,
            0.354,
            0.291,
            0.082,
            0.328,
            0.727,
            0.613,
            0.424,
            0.57,
            0.264,
            0.641,
            0.396,
            0.492,
            0.256,
            0.393,
            0.198,
            0.357,
            0.254
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " writing",
            " of",
            " his",
            " experiences",
            " in",
            " The",
            " Prelude",
            " (",
            "179",
            "9",
            ").",
            " Sch",
            "iller",
            " later",
            " wrote",
            " the",
            " play",
            " William",
            " Tell",
            " (",
            "180",
            "4",
            "),",
            " which",
            " tells",
            " the",
            " story",
            " of",
            " the",
            " legendary",
            " Swiss",
            " marks",
            "man",
            " William",
            " Tell",
            " as",
            " part",
            " of",
            " the",
            " greater",
            " Swiss",
            " struggle",
            " for",
            " independence",
            " from",
            " the",
            " H",
            "abs",
            "burg",
            " Empire",
            " in",
            " the",
            " early",
            " ",
            "14",
            "th",
            " century",
            ".",
            " At",
            " the",
            " end",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            1.383,
            0.758,
            0.234,
            0.547,
            0.404,
            0.59,
            0.887,
            0.695,
            0.322,
            -0.0,
            0.268,
            0.606,
            0.676,
            0.297,
            0.486,
            0.879,
            0.562,
            0.381,
            0.338,
            1.148,
            0.762,
            0.809,
            0.449,
            0.129,
            0.711,
            0.574,
            0.451,
            0.644,
            0.218,
            0.594,
            0.488,
            1.055,
            0.334,
            0.114,
            0.906,
            0.336,
            0.324,
            0.391,
            0.832,
            0.236,
            0.684,
            0.633,
            0.379,
            0.367,
            0.232,
            0.416,
            0.516,
            0.428,
            0.504,
            0.365
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            "Jane",
            " Good",
            "all",
            "Mar",
            "j",
            "orie",
            " Harness",
            " Good",
            "win",
            "I",
            "gor",
            " Gore",
            "v",
            "ich",
            "Har",
            "old",
            " A",
            ".",
            " Gould",
            "David",
            " Gra",
            "e",
            "ber",
            "H",
            "il",
            "ma",
            " Gran",
            "qv",
            "ist",
            "J",
            ".",
            " Patrick",
            " Gray",
            "Mar",
            "cel",
            " G",
            "ria",
            "ule",
            "Jacob",
            " Grimm",
            "Wil",
            "helm",
            " Grimm",
            "H",
            "Ab",
            "d",
            "ell",
            "ah",
            " Hamm",
            "oud",
            "i"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.092,
            0.163,
            0.398,
            0.5,
            -0.0,
            0.59,
            0.332,
            0.334,
            0.303,
            0.118,
            0.551,
            0.434,
            0.191,
            0.396,
            0.23,
            0.375,
            1.383,
            0.668,
            0.629,
            0.208,
            0.34,
            0.471,
            0.268,
            0.332,
            0.312,
            0.32,
            0.291,
            0.019,
            0.114,
            0.441,
            0.469,
            0.484,
            1.336,
            0.676,
            0.354,
            0.322,
            0.338,
            0.186,
            0.299,
            0.504,
            0.414,
            0.134,
            0.633,
            0.354,
            0.291,
            0.082,
            0.328,
            0.727,
            0.613,
            0.424,
            0.57,
            0.264,
            0.641,
            0.396,
            0.492,
            0.256,
            0.393,
            0.198,
            0.357,
            0.254
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " writing",
            " of",
            " his",
            " experiences",
            " in",
            " The",
            " Prelude",
            " (",
            "179",
            "9",
            ").",
            " Sch",
            "iller",
            " later",
            " wrote",
            " the",
            " play",
            " William",
            " Tell",
            " (",
            "180",
            "4",
            "),",
            " which",
            " tells",
            " the",
            " story",
            " of",
            " the",
            " legendary",
            " Swiss",
            " marks",
            "man",
            " William",
            " Tell",
            " as",
            " part",
            " of",
            " the",
            " greater",
            " Swiss",
            " struggle",
            " for",
            " independence",
            " from",
            " the",
            " H",
            "abs",
            "burg",
            " Empire",
            " in",
            " the",
            " early",
            " ",
            "14",
            "th",
            " century",
            ".",
            " At",
            " the",
            " end",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.032,
            0.324,
            0.235,
            0.451,
            0.59,
            0.621,
            0.422,
            0.512,
            0.237,
            -0.0,
            0.523,
            0.297,
            0.299,
            0.226,
            0.303,
            0.036,
            0.494,
            0.594,
            0.357,
            0.123,
            0.812,
            0.711,
            0.332,
            0.387,
            0.14,
            0.644,
            0.648,
            0.758,
            0.025,
            0.457,
            -0.0,
            0.486,
            0.336,
            0.31,
            0.33,
            0.289,
            0.582,
            0.381,
            0.365,
            0.473,
            0.258,
            0.361,
            0.046,
            0.249,
            0.5,
            0.734,
            -0.0,
            0.143,
            0.406,
            0.43,
            0.309,
            0.512,
            0.279,
            0.699,
            0.57,
            1.367,
            0.965,
            0.644,
            0.32,
            0.268
          ],
          "train_token_ind": 58,
          "is_repeated_datapoint": false,
          "tokens": [
            " a",
            " collection",
            " of",
            " championship",
            " caliber",
            " golf",
            " courses",
            " distributed",
            " across",
            " the",
            " state",
            ";",
            " casinos",
            " such",
            " as",
            " Victory",
            "land",
            ";",
            " amusement",
            " parks",
            " such",
            " as",
            " Alabama",
            " Splash",
            " Adventure",
            ";",
            " the",
            " River",
            "ch",
            "ase",
            " G",
            "aller",
            "ia",
            ",",
            " one",
            " of",
            " the",
            " largest",
            " shopping",
            " centers",
            " in",
            " the",
            " southeast",
            ";",
            " G",
            "unt",
            "ers",
            "ville",
            " Lake",
            ",",
            " voted",
            " the",
            " best",
            " lake",
            " in",
            " Alabama",
            " by",
            " Southern",
            " Living",
            " Magazine",
            " readers",
            ";",
            " and"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.402,
            1.062,
            0.363,
            0.516,
            -0.0,
            0.118,
            0.449,
            0.691,
            0.719,
            0.436,
            0.434,
            0.114,
            0.348,
            0.523,
            0.598,
            0.66,
            0.738,
            0.664,
            -0.0,
            0.781,
            0.463,
            -0.0,
            0.586,
            0.539,
            0.221,
            0.543,
            0.447,
            0.582,
            0.463,
            0.42,
            0.156,
            0.379,
            0.408,
            0.394,
            0.361,
            0.445,
            0.393,
            0.412,
            0.523,
            0.356,
            1.016,
            0.867,
            -0.0,
            0.625,
            0.34,
            0.566,
            0.664,
            0.625,
            0.644,
            0.781,
            0.478,
            1.359,
            0.463,
            0.35,
            0.295,
            0.723,
            0.527,
            0.754,
            0.77,
            0.59,
            0.586
          ],
          "train_token_ind": 53,
          "is_repeated_datapoint": false,
          "tokens": [
            " Lincoln",
            ",",
            " John",
            " F",
            ".",
            " Kennedy",
            ",",
            " and",
            " Ronald",
            " Reagan",
            " were",
            " the",
            " top",
            "-ranked",
            " presidents",
            " in",
            " eight",
            " public",
            " opinion",
            " surveys",
            ",",
            " according",
            " to",
            " Gallup",
            ".",
            " A",
            " ",
            "200",
            "4",
            " study",
            " found",
            " that",
            " scholars",
            " in",
            " the",
            " fields",
            " of",
            " history",
            " and",
            " politics",
            " ranked",
            " Lincoln",
            " number",
            " one",
            ",",
            " while",
            " legal",
            " scholars",
            " placed",
            " him",
            " second",
            " after",
            " George",
            " Washington",
            ".",
            "Lin",
            "coln",
            "'s",
            " assassination",
            " left",
            " him",
            " a",
            " national"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.048,
            0.031,
            0.295,
            0.1,
            0.272,
            0.067,
            0.348,
            0.256,
            0.309,
            0.527,
            -0.0,
            0.277,
            0.344,
            0.142,
            0.672,
            0.328,
            0.328,
            0.133,
            0.644,
            0.512,
            0.35,
            0.279,
            0.57,
            0.449,
            0.225,
            0.602,
            0.262,
            0.641,
            0.334,
            0.394,
            -0.0,
            0.004,
            0.555,
            0.469,
            1.359,
            0.758,
            0.551,
            0.281,
            0.754,
            0.68,
            0.59,
            0.498,
            0.036,
            0.258,
            0.672,
            0.402,
            -0.0,
            0.273,
            1.078,
            0.91,
            0.84,
            0.379,
            0.241,
            0.992,
            0.535,
            0.539,
            0.629,
            0.443,
            0.322,
            0.57,
            0.453,
            0.16
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            "ies",
            " that",
            " the",
            " Jackson",
            "ians",
            " prof",
            "essed",
            " for",
            " the",
            " common",
            " man",
            ",",
            " but",
            " he",
            " disagreed",
            " with",
            " the",
            " Jackson",
            "ian",
            " view",
            " that",
            " the",
            " government",
            " should",
            " be",
            " divorced",
            " from",
            " economic",
            " enterprise",
            ".",
            " Nevertheless",
            ",",
            " Lincoln",
            " admired",
            " Andrew",
            " Jackson",
            "'s",
            " steel",
            "iness",
            " as",
            " well",
            " as",
            " his",
            " patriotism",
            ".",
            " According",
            " to",
            " historian",
            " Sean",
            " Wil",
            "ent",
            "z",
            ":",
            "William",
            " C",
            ".",
            " Harris",
            " found",
            " that",
            " Lincoln",
            "'s",
            " \"",
            "re"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.049,
            0.357,
            0.357,
            0.119,
            0.469,
            0.469,
            0.443,
            0.381,
            0.338,
            0.215,
            0.22,
            -0.0,
            0.26,
            -0.0,
            0.414,
            -0.0,
            0.432,
            -0.0,
            0.394,
            0.488,
            0.582,
            0.404,
            0.498,
            0.434,
            0.52,
            0.49,
            0.535,
            0.287,
            0.4,
            0.707,
            0.766,
            0.43,
            0.436,
            0.373,
            0.33,
            0.691,
            0.863,
            0.633,
            0.467,
            0.602,
            0.746,
            -0.0,
            0.26,
            0.297,
            -0.0,
            0.57,
            0.291,
            0.293,
            0.84,
            -0.0,
            0.451,
            1.242,
            0.91,
            0.535,
            -0.0,
            0.412,
            1.109,
            1.352,
            0.617,
            0.762,
            0.652,
            0.418
          ],
          "train_token_ind": 58,
          "is_repeated_datapoint": false,
          "tokens": [
            " prove",
            " crucial",
            ".",
            " This",
            " territory",
            " (",
            "which",
            " became",
            " the",
            " states",
            " of",
            " Ohio",
            ",",
            " Michigan",
            ",",
            " Indiana",
            ",",
            " Illinois",
            ",",
            " Wisconsin",
            " and",
            " part",
            " of",
            " Minnesota",
            ")",
            " doubled",
            " the",
            " size",
            " of",
            " the",
            " United",
            " States",
            ".",
            "In",
            " the",
            " decades",
            " leading",
            " up",
            " to",
            " the",
            " Civil",
            " War",
            ",",
            " abolition",
            "ists",
            ",",
            " such",
            " as",
            " Theodore",
            " Parker",
            ",",
            " Ralph",
            " Wal",
            "do",
            " Emerson",
            ",",
            " Henry",
            " David",
            " Th",
            "ore",
            "au",
            " and",
            " Frederick"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.163,
            0.562,
            0.551,
            -0.0,
            0.175,
            0.443,
            0.941,
            0.621,
            0.383,
            0.66,
            -0.0,
            0.283,
            0.449,
            0.422,
            -0.0,
            0.159,
            0.117,
            0.124,
            0.324,
            0.356,
            -0.0,
            0.385,
            -0.0,
            0.289,
            0.504,
            0.562,
            0.539,
            0.085,
            0.088,
            0.598,
            0.367,
            0.146,
            0.309,
            0.352,
            0.412,
            0.508,
            0.383,
            0.488,
            0.389,
            0.459,
            0.832,
            0.75,
            0.336,
            0.106,
            0.209,
            0.613,
            0.535,
            1.352,
            0.48,
            0.586,
            -0.0,
            0.233,
            0.32,
            0.383,
            0.66,
            0.214,
            0.153,
            -0.0,
            0.293,
            0.124,
            0.547,
            -0.0
          ],
          "train_token_ind": 48,
          "is_repeated_datapoint": false,
          "tokens": [
            "\",",
            " Ash",
            "gate",
            " Press",
            ",",
            " New",
            " Critical",
            " Thinking",
            " in",
            " Philosophy",
            " Series",
            ",",
            " ",
            "200",
            "3",
            ",",
            " ",
            "314",
            "pp",
            ".",
            " T",
            "rott",
            "ier",
            ",",
            " Dan",
            "ick",
            ".",
            " L",
            "'in",
            "fluence",
            " de",
            " la",
            " philosoph",
            "ie",
            " sch",
            "openh",
            "auer",
            "ienne",
            " dans",
            " la",
            " vie",
            " et",
            " l",
            "'",
            "oe",
            "uvre",
            " de",
            " Richard",
            " Wagner",
            ";",
            " et",
            ",",
            " Qu",
            "'est",
            "-ce",
            " qui",
            " sÃ©",
            "duit",
            ",",
            " obs",
            "Ã¨",
            "de",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.285,
            0.247,
            -0.0,
            -0.0,
            -0.0,
            0.211,
            0.193,
            0.42,
            0.324,
            0.25,
            0.199,
            0.973,
            0.75,
            0.543,
            -0.0,
            0.26,
            0.887,
            0.984,
            0.35,
            0.16,
            0.488,
            0.455,
            0.459,
            0.21,
            0.213,
            0.266,
            -0.0,
            0.318,
            0.412,
            0.186,
            0.428,
            0.218,
            0.523,
            0.488,
            0.512,
            0.258,
            0.309,
            -0.0,
            0.213,
            0.688,
            0.428,
            0.342,
            0.447,
            0.609,
            0.832,
            -0.0,
            0.162,
            0.356,
            0.179,
            0.606,
            0.445,
            0.416,
            0.398,
            1.352,
            0.77,
            -0.0,
            0.465,
            0.75
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            "k",
            " Ni",
            "it",
            ",",
            " Eston",
            "ian",
            " sprint",
            "er",
            "198",
            "8",
            " –",
            " Anthony",
            " Cast",
            "on",
            "zo",
            ",",
            " American",
            " football",
            " player",
            " ",
            " ",
            "198",
            "8",
            "  ",
            " –",
            " Will",
            "ian",
            ",",
            " Brazilian",
            " football",
            "er",
            " ",
            " ",
            "198",
            "8",
            "  ",
            " –",
            " V",
            "asil",
            "ios",
            " K",
            "outs",
            "ian",
            "ik",
            "oul",
            "is",
            ",",
            " Greek",
            " football",
            "er",
            "198",
            "9",
            " –",
            " Jason",
            " Hey",
            "ward",
            ",",
            " American",
            " baseball"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            0.075,
            0.207,
            -0.0,
            0.088,
            0.172,
            -0.0,
            0.2,
            0.123,
            0.393,
            0.233,
            0.139,
            0.291,
            0.381,
            0.171,
            0.494,
            0.527,
            0.228,
            0.31,
            0.492,
            -0.0,
            0.289,
            1.352,
            -0.0,
            0.338,
            0.41,
            0.393,
            -0.0,
            0.82,
            0.652,
            0.684,
            -0.0,
            0.484,
            0.007,
            0.467,
            0.15,
            -0.0,
            0.217,
            0.871,
            0.307,
            0.381,
            0.996,
            0.668,
            0.684,
            0.543,
            0.418,
            0.754,
            -0.0,
            0.279,
            0.357,
            0.167,
            0.742,
            0.161,
            0.494,
            0.482,
            0.285,
            0.13,
            -0.0,
            0.032,
            0.613,
            -0.0,
            0.445
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " save",
            " lives",
            ",",
            " help",
            " people",
            ",",
            " or",
            " otherwise",
            " have",
            " the",
            " biggest",
            " benefit",
            ".",
            " People",
            " associated",
            " with",
            " the",
            " movement",
            " include",
            " philosopher",
            " Peter",
            " Singer",
            ",",
            " Facebook",
            " co",
            " founder",
            " Dustin",
            " Mos",
            "kov",
            "itz",
            ",",
            " C",
            "ari",
            " T",
            "una",
            ",",
            " Oxford",
            "-based",
            " researchers",
            " William",
            " Mac",
            "As",
            "kill",
            " and",
            " Toby",
            " Ord",
            ",",
            " and",
            " professional",
            " poker",
            " player",
            " Liv",
            " Bo",
            "eree",
            ".",
            "Gen",
            "etics",
            "OX",
            "TR",
            ",",
            " CD"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.058,
            0.021,
            -0.0,
            -0.0,
            0.455,
            0.052,
            0.132,
            -0.0,
            -0.0,
            0.428,
            0.295,
            -0.0,
            0.477,
            0.312,
            0.738,
            0.606,
            0.373,
            0.241,
            0.144,
            0.095,
            0.202,
            0.648,
            1.344,
            -0.0,
            -0.0,
            0.324,
            0.227,
            0.057,
            0.367,
            -0.0,
            0.428,
            0.326,
            -0.0,
            0.123,
            0.227,
            -0.0,
            0.436,
            0.447,
            0.242,
            0.224,
            0.247,
            0.414,
            0.359,
            0.26,
            0.816,
            0.652,
            0.258,
            0.41,
            0.106,
            0.324,
            0.535,
            0.478,
            0.324,
            0.222,
            0.098,
            0.216,
            0.033,
            0.396,
            0.377,
            0.42,
            0.391
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " motifs",
            " from",
            " the",
            " I",
            "li",
            "ad",
            ".",
            " The",
            " character",
            " Achilles",
            " in",
            " E",
            "nder",
            "'s",
            " Shadow",
            " (",
            "199",
            "9",
            "),",
            " by",
            " Or",
            "son",
            " Scott",
            " Card",
            ",",
            " shares",
            " his",
            " names",
            "ake",
            "'s",
            " cunning",
            " mind",
            " and",
            " ruthless",
            " attitude",
            ".",
            " Achilles",
            " is",
            " one",
            " of",
            " the",
            " main",
            " characters",
            " in",
            " Dan",
            " Simmons",
            "'s",
            " novels",
            " I",
            "li",
            "um",
            " (",
            "200",
            "3",
            ")",
            " and",
            " O",
            "ly",
            "m",
            "pos",
            " (",
            "200"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.175,
            0.414,
            0.314,
            1.078,
            1.344,
            1.039,
            -0.0,
            0.398,
            0.328,
            0.281,
            0.151,
            0.225,
            0.455,
            0.112,
            0.641,
            0.809,
            0.559,
            0.363,
            0.156,
            0.49,
            0.555,
            0.348,
            0.322,
            0.287,
            1.156,
            0.926,
            0.723,
            0.574,
            0.322,
            0.785,
            0.5,
            0.508,
            0.322,
            0.328,
            -0.0,
            0.19,
            0.216,
            0.243,
            -0.0,
            0.44,
            0.097,
            0.48,
            0.171,
            -0.0,
            0.25,
            0.201,
            0.184,
            -0.0,
            0.116,
            -0.0,
            0.088,
            0.011,
            -0.0,
            0.098,
            0.099,
            -0.0,
            -0.0,
            0.068,
            0.021,
            -0.0
          ],
          "train_token_ind": 7,
          "is_repeated_datapoint": false,
          "tokens": [
            " drawn",
            " by",
            " future",
            " industry",
            " star",
            " Todd",
            " Mc",
            "Far",
            "lane",
            ",",
            " the",
            " first",
            " regular",
            " artist",
            " on",
            " The",
            " Amazing",
            " Spider",
            "-Man",
            " since",
            " F",
            "ren",
            "z",
            "'s",
            " departure",
            ".",
            " Mc",
            "Far",
            "lane",
            " revolution",
            "ized",
            " Spider",
            "-Man",
            "'s",
            " look",
            ".",
            " His",
            " depiction",
            " –",
            " \"",
            "D",
            "it",
            "ko",
            "-esque",
            "\"",
            " poses",
            ",",
            " large",
            " eyes",
            ";",
            " wir",
            "y",
            ",",
            " cont",
            "orted",
            " limbs",
            ";",
            " and",
            " messy",
            ",",
            " kn",
            "otted",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.028,
            0.013,
            0.356,
            1.344,
            0.652,
            0.498,
            -0.0,
            0.299,
            0.275,
            0.175,
            0.23,
            0.115,
            0.283,
            0.365,
            0.539,
            0.328,
            0.432,
            -0.0,
            0.03,
            0.559,
            0.381,
            0.562,
            0.633,
            0.621,
            0.418,
            0.108,
            0.365,
            0.459,
            0.012,
            0.307,
            0.449,
            0.234,
            0.676,
            0.484,
            -0.0,
            0.357,
            0.262,
            0.083,
            0.428,
            0.389,
            0.387,
            0.422,
            0.266,
            0.291,
            0.176,
            0.241,
            0.275,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.083,
            0.25,
            -0.0,
            0.107,
            0.299,
            0.309,
            0.367,
            0.019,
            0.14,
            0.418
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " part",
            " of",
            " the",
            " planned",
            " Southern",
            " Gas",
            " Cor",
            "ridor",
            ",",
            " runs",
            " for",
            " ",
            " across",
            " Albania",
            "'s",
            " territory",
            " before",
            " entering",
            " the",
            " Alban",
            "ian",
            " Adri",
            "atic",
            " Sea",
            " Coast",
            " approximately",
            " ",
            " northwest",
            " of",
            " F",
            "ier",
            ".",
            "The",
            " water",
            " resources",
            " of",
            " Albania",
            " are",
            " particularly",
            " abundant",
            " in",
            " all",
            " the",
            " regions",
            " of",
            " the",
            " country",
            " and",
            " comprise",
            " lakes",
            ",",
            " rivers",
            ",",
            " springs",
            " and",
            " groundwater",
            " aqu",
            "ifers",
            ".",
            " The",
            " country",
            "'s",
            " available"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.096,
            0.98,
            1.344,
            0.754,
            0.328,
            0.41,
            0.367,
            0.318,
            0.383,
            -0.0,
            0.309,
            0.365,
            -0.0,
            0.332,
            0.175,
            0.224,
            0.44,
            0.316,
            0.137,
            0.328,
            0.334,
            0.578,
            -0.0,
            -0.0,
            0.369,
            0.243,
            0.188,
            0.428,
            0.781,
            0.711,
            0.59,
            0.463,
            0.408,
            0.307,
            0.081,
            0.402,
            -0.0,
            0.531,
            0.346,
            0.426,
            0.247,
            0.025,
            0.221,
            0.299,
            0.112,
            0.531,
            0.264,
            -0.0,
            0.23,
            0.26,
            0.432,
            0.332,
            0.19,
            0.389,
            0.27,
            0.252,
            0.293,
            0.275,
            0.272,
            0.719,
            0.656,
            0.183
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " John",
            " Mc",
            "Fall",
            " was",
            " selected",
            " to",
            " be",
            " the",
            " first",
            " ESA",
            " para",
            "str",
            "onaut",
            ".",
            "Other",
            " terms",
            "With",
            " the",
            " rise",
            " of",
            " space",
            " tourism",
            ",",
            " NASA",
            " and",
            " the",
            " Russian",
            " Federal",
            " Space",
            " Agency",
            " agreed",
            " to",
            " use",
            " the",
            " term",
            " \"",
            "space",
            "flight",
            " participant",
            "\"",
            " to",
            " distinguish",
            " those",
            " space",
            " travelers",
            " from",
            " professional",
            " astronauts",
            " on",
            " missions",
            " coordinated",
            " by",
            " those",
            " two",
            " agencies",
            ".",
            "While",
            " no",
            " nation",
            " other",
            " than",
            " Russia"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            0.334,
            0.305,
            0.377,
            1.195,
            0.856,
            0.93,
            0.527,
            0.375,
            1.336,
            0.801,
            0.805,
            0.461,
            0.272,
            1.008,
            0.504,
            0.151,
            -0.0,
            0.287,
            -0.0,
            0.128,
            0.201,
            0.389,
            0.326,
            0.463,
            0.52,
            0.629,
            0.508,
            0.342,
            0.249,
            0.334,
            0.309,
            0.77,
            0.617,
            0.195,
            0.309,
            0.447,
            0.227,
            0.318,
            -0.0,
            0.279,
            0.379,
            0.184,
            0.336,
            0.198,
            1.078,
            0.824,
            0.641,
            0.381,
            -0.0,
            0.484,
            -0.0,
            0.334,
            0.221,
            0.142,
            0.297,
            0.283,
            0.123,
            0.41,
            0.443,
            0.488,
            0.275,
            0.49
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            "-round",
            " losses",
            " to",
            " Chris",
            " Wood",
            "r",
            "uff",
            " and",
            " Doug",
            " Fl",
            "ach",
            " at",
            " the",
            " French",
            " Open",
            " and",
            " Wimbledon",
            ",",
            " respectively",
            ",",
            " and",
            " lost",
            " to",
            " Chang",
            " in",
            " straight",
            " sets",
            " in",
            " the",
            " Australian",
            " and",
            " US",
            " Open",
            " semi",
            "-finals",
            ".",
            " At",
            " the",
            " time",
            ",",
            " Ag",
            "assi",
            " blamed",
            " the",
            " Australian",
            " Open",
            " loss",
            " on",
            " the",
            " windy",
            " conditions",
            ",",
            " but",
            " later",
            " said",
            " in",
            " his",
            " biography",
            " that",
            " he",
            " had",
            " lost",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.272,
            0.017,
            -0.0,
            0.027,
            0.117,
            0.695,
            0.394,
            0.216,
            0.213,
            -0.0,
            0.578,
            0.113,
            0.275,
            0.069,
            0.154,
            0.33,
            0.239,
            0.166,
            0.443,
            0.235,
            0.504,
            0.539,
            0.447,
            0.707,
            0.578,
            0.283,
            0.277,
            0.155,
            0.181,
            0.258,
            -0.0,
            0.43,
            0.295,
            0.316,
            0.354,
            0.496,
            0.379,
            -0.0,
            0.136,
            1.023,
            1.336,
            0.996,
            0.648,
            0.543,
            0.346,
            0.377,
            0.371,
            0.453,
            0.11,
            0.606,
            0.801,
            0.633,
            0.235,
            0.247,
            0.148,
            0.239,
            0.408,
            0.158,
            0.114,
            0.117,
            0.18
          ],
          "train_token_ind": 42,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "198",
            "9",
            "),",
            " featuring",
            " the",
            " Green",
            " Goblin",
            " vs",
            ".",
            " the",
            " Hob",
            "g",
            "oblin",
            ";",
            " and",
            " #",
            "315",
            "–",
            "317",
            " (",
            "May",
            "–",
            "July",
            " ",
            "198",
            "9",
            "),",
            " with",
            " the",
            " return",
            " of",
            " Venom",
            ".",
            " In",
            " July",
            " ",
            "201",
            "2",
            ",",
            " Todd",
            " Mc",
            "Far",
            "lane",
            "'s",
            " original",
            " cover",
            " art",
            " for",
            " The",
            " Amazing",
            " Spider",
            "-Man",
            " No",
            ".",
            " ",
            "328",
            " sold",
            " for",
            " a",
            " bid",
            " of",
            " $"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.198,
            0.459,
            0.2,
            0.139,
            -0.0,
            0.31,
            0.252,
            0.34,
            -0.0,
            0.198,
            0.301,
            -0.0,
            0.285,
            0.338,
            -0.0,
            0.033,
            0.379,
            0.797,
            0.287,
            0.289,
            -0.0,
            0.06,
            0.287,
            0.894,
            1.328,
            0.711,
            0.412,
            0.156,
            0.151,
            0.099,
            -0.0,
            -0.0,
            0.27,
            -0.0,
            0.191,
            0.301,
            0.393,
            0.206,
            -0.0,
            0.09,
            0.273,
            0.252,
            0.324,
            0.206,
            0.277,
            0.212,
            0.475,
            0.291,
            0.239,
            0.231,
            0.201,
            1.055,
            -0.0,
            0.219,
            0.107,
            0.167,
            0.218,
            0.293,
            0.052,
            0.085,
            0.301,
            0.797
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            " wear",
            " black",
            " (",
            "the",
            " traditional",
            " funeral",
            " color",
            ")",
            " while",
            " attending",
            " his",
            " service",
            ",",
            " during",
            " which",
            " solo",
            "ist",
            " Jean",
            " MacDonald",
            " sang",
            " a",
            " verse",
            " of",
            " Robert",
            " Louis",
            " Stevenson",
            "'s",
            " \"",
            "Re",
            "qu",
            "iem",
            "\":",
            "Upon",
            " the",
            " conclusion",
            " of",
            " Bell",
            "'s",
            " funeral",
            ",",
            " for",
            " one",
            " minute",
            " at",
            " ",
            "6",
            ":",
            "25",
            "Âłp",
            ".m",
            ".",
            " Eastern",
            " Time",
            ",",
            " \"",
            "every",
            " phone",
            " on",
            " the",
            " continent",
            " of",
            " North",
            " America"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.307,
            0.797,
            0.43,
            0.652,
            0.167,
            0.555,
            0.332,
            0.09,
            0.203,
            0.322,
            1.227,
            0.05,
            0.66,
            1.328,
            -0.0,
            0.352,
            0.381,
            0.32,
            0.291,
            -0.0,
            0.363,
            0.648,
            0.598,
            0.318,
            0.637,
            0.111,
            0.441,
            0.582,
            0.602,
            0.436,
            0.396,
            0.185,
            0.547,
            0.352,
            0.389,
            0.416,
            0.354,
            -0.0,
            -0.0,
            0.59,
            0.434,
            0.436,
            0.264,
            0.393,
            0.396,
            0.443,
            0.346,
            0.449,
            0.512,
            0.451,
            0.218,
            0.455,
            0.297,
            0.387,
            0.555,
            0.578,
            0.256,
            0.326,
            0.594,
            0.523,
            0.711,
            0.68
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            "ian",
            " Ralph",
            " K",
            "etch",
            "am",
            " commented",
            " on",
            " the",
            " opinions",
            " of",
            " Patrick",
            " Henry",
            ",",
            " George",
            " Mason",
            ",",
            " and",
            " other",
            " Anti",
            "-F",
            "ederal",
            "ists",
            " who",
            " were",
            " not",
            " so",
            " eager",
            " to",
            " give",
            " up",
            " the",
            " local",
            " autonomy",
            " won",
            " by",
            " the",
            " revolution",
            ":",
            "Histor",
            "ians",
            " have",
            " given",
            " many",
            " reasons",
            " for",
            " the",
            " perceived",
            " need",
            " to",
            " replace",
            " the",
            " articles",
            " in",
            " ",
            "178",
            "7",
            ".",
            " Jill",
            "son",
            " and",
            " Wilson",
            " (",
            "199"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.27,
            0.432,
            0.35,
            0.328,
            0.396,
            0.406,
            0.322,
            0.57,
            0.316,
            0.566,
            0.402,
            0.609,
            -0.0,
            0.289,
            -0.0,
            -0.0,
            -0.0,
            0.547,
            0.232,
            0.31,
            1.328,
            0.656,
            0.461,
            1.211,
            0.574,
            0.408,
            0.186,
            0.711,
            0.312,
            0.181,
            0.473,
            0.68,
            0.451,
            0.144,
            -0.0,
            0.169,
            0.139,
            0.41,
            0.547,
            0.555,
            0.633,
            0.326,
            0.072,
            0.389,
            0.352,
            -0.0,
            0.156,
            0.289,
            0.357,
            0.477,
            0.441,
            0.248,
            0.176,
            0.082,
            0.82,
            0.535,
            0.385,
            0.268,
            0.215,
            0.084,
            0.441,
            0.371
          ],
          "train_token_ind": 21,
          "is_repeated_datapoint": false,
          "tokens": [
            "National",
            "ism",
            " was",
            " a",
            " powerful",
            " force",
            " in",
            " the",
            " early",
            " ",
            "19",
            "th",
            " century",
            ",",
            " with",
            " famous",
            " spokes",
            "men",
            " such",
            " as",
            " Andrew",
            " Jackson",
            " and",
            " Daniel",
            " Webster",
            ".",
            " While",
            " practically",
            " all",
            " Nor",
            "ther",
            "ners",
            " supported",
            " the",
            " Union",
            ",",
            " Sou",
            "ther",
            "ners",
            " were",
            " split",
            " between",
            " those",
            " loyal",
            " to",
            " the",
            " entirety",
            " of",
            " the",
            " United",
            " States",
            " (",
            "called",
            " \"",
            "Southern",
            " Union",
            "ists",
            "\")",
            " and",
            " those",
            " loyal",
            " primarily",
            " to"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.173,
            -0.0,
            0.428,
            0.73,
            0.254,
            0.691,
            -0.0,
            0.504,
            0.25,
            0.166,
            0.254,
            0.453,
            0.34,
            0.539,
            0.652,
            0.504,
            0.402,
            0.457,
            0.324,
            0.385,
            0.467,
            0.309,
            0.006,
            0.316,
            0.719,
            0.494,
            0.359,
            1.328,
            0.887,
            0.644,
            0.727,
            0.498,
            0.402,
            0.644,
            0.48,
            0.199,
            0.104,
            0.613,
            0.247,
            0.672,
            0.488,
            0.404,
            0.406,
            0.477,
            0.512,
            0.221,
            0.135,
            0.268,
            0.648,
            0.219,
            0.453,
            0.625,
            0.451,
            0.396,
            0.41,
            0.31,
            0.365,
            0.361,
            0.443,
            0.369
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " Reconstruction",
            ",",
            " when",
            " Republicans",
            " generally",
            " represented",
            " Reconstruction",
            " government",
            ",",
            " including",
            " the",
            " newly",
            " emanc",
            "ipated",
            " freed",
            "men",
            " who",
            " had",
            " gained",
            " the",
            " franchise",
            ".",
            " The",
            " three",
            " GOP",
            " lieutenant",
            " governors",
            " are",
            " Steve",
            " Wind",
            "om",
            " (",
            "199",
            "9",
            "–",
            "200",
            "3",
            "),",
            " Kay",
            " I",
            "vey",
            " (",
            "201",
            "1",
            "–",
            "201",
            "7",
            "),",
            " and",
            " Will",
            " A",
            "ins",
            "worth",
            " (",
            "201",
            "9",
            "–",
            "present",
            ").",
            "Local",
            " elections",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.077,
            0.088,
            0.318,
            -0.0,
            0.887,
            0.213,
            0.531,
            0.256,
            0.461,
            0.633,
            0.272,
            0.318,
            0.262,
            0.443,
            0.252,
            0.305,
            0.326,
            0.305,
            0.25,
            0.124,
            0.633,
            0.938,
            0.512,
            0.441,
            0.322,
            0.695,
            0.766,
            0.898,
            -0.0,
            0.42,
            0.42,
            0.338,
            0.155,
            0.758,
            0.41,
            0.404,
            0.498,
            0.424,
            0.33,
            -0.0,
            0.124,
            0.707,
            0.512,
            0.291,
            0.249,
            0.365,
            0.275,
            0.494,
            0.299,
            0.441,
            0.543,
            0.48,
            0.887,
            1.328,
            0.734,
            0.606,
            0.42,
            -0.0,
            0.652,
            0.52,
            0.369
          ],
          "train_token_ind": 55,
          "is_repeated_datapoint": false,
          "tokens": [
            " rest",
            " of",
            " Alaska",
            ".",
            "The",
            " Interstate",
            " High",
            "ways",
            " in",
            " Alaska",
            " consists",
            " of",
            " a",
            " total",
            " of",
            " .",
            " One",
            " unique",
            " feature",
            " of",
            " the",
            " Alaska",
            " Highway",
            " system",
            " is",
            " the",
            " Anton",
            " Anderson",
            " Memorial",
            " Tunnel",
            ",",
            " an",
            " active",
            " Alaska",
            " Railroad",
            " tunnel",
            " recently",
            " upgraded",
            " to",
            " provide",
            " a",
            " paved",
            " roadway",
            " link",
            " with",
            " the",
            " isolated",
            " community",
            " of",
            " Wh",
            "itt",
            "ier",
            " on",
            " Prince",
            " William",
            " Sound",
            " to",
            " the",
            " S",
            "eward",
            " Highway",
            " about",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.064,
            0.527,
            0.205,
            0.114,
            0.408,
            0.291,
            0.402,
            0.23,
            0.032,
            -0.0,
            0.418,
            0.762,
            0.477,
            0.387,
            0.535,
            0.383,
            0.047,
            0.185,
            0.01,
            -0.0,
            0.25,
            0.4,
            0.383,
            0.426,
            0.19,
            0.104,
            1.016,
            1.32,
            1.008,
            0.445,
            0.496,
            0.5,
            0.467,
            -0.0,
            0.287,
            0.125,
            -0.0,
            0.204,
            0.077,
            0.324,
            0.063,
            -0.0,
            0.777,
            0.322,
            -0.0,
            0.512,
            0.243,
            0.369,
            0.504,
            0.412,
            -0.0,
            0.297,
            -0.0,
            0.35,
            0.414,
            0.312,
            0.322,
            0.309,
            0.504,
            0.379,
            0.092,
            -0.0,
            0.758
          ],
          "train_token_ind": 27,
          "is_repeated_datapoint": false,
          "tokens": [
            "Far",
            "lane",
            " [#",
            "306",
            "–",
            "314",
            ";",
            " The",
            " Spect",
            "acular",
            " Spider",
            "-Man",
            " Annual",
            " #",
            "10",
            "]",
            " ()",
            "Leg",
            "ends",
            ",",
            " Vol",
            ".",
            " ",
            "3",
            ":",
            " Todd",
            " Mc",
            "Far",
            "lane",
            " [#",
            "315",
            "–",
            "323",
            ",",
            " ",
            "325",
            ",",
            " ",
            "328",
            "]",
            " ()",
            "Spider",
            "-Man",
            ":",
            " Venom",
            " Returns",
            " [#",
            "330",
            "–",
            "333",
            ",",
            " ",
            "344",
            "–",
            "347",
            ";",
            "Annual",
            " #",
            "25",
            "]",
            " ()",
            "Spider",
            "-Man"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.011,
            0.984,
            0.609,
            0.467,
            0.268,
            0.152,
            0.185,
            0.531,
            0.252,
            0.57,
            0.322,
            -0.0,
            0.188,
            1.32,
            0.894,
            0.699,
            0.436,
            0.1,
            0.328,
            0.691,
            0.809,
            0.299,
            0.531,
            0.275,
            0.206,
            0.172,
            0.527,
            0.212,
            0.539,
            0.301,
            0.134,
            0.092,
            0.941,
            0.711,
            0.361,
            1.117,
            0.703,
            -0.0,
            0.434,
            1.094,
            0.482,
            0.412,
            0.228,
            0.201,
            0.161,
            0.52,
            0.203,
            0.174,
            0.185,
            0.352,
            0.531,
            0.535,
            0.463,
            0.356,
            0.123,
            1.07,
            0.793,
            0.365,
            0.326
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " (",
            "Robert",
            " Bel",
            "tran",
            ")",
            " in",
            " the",
            " television",
            " series",
            " Star",
            " Trek",
            ":",
            " Voyager",
            "Michael",
            " Burn",
            "ham",
            " (",
            "S",
            "one",
            "qua",
            " Martin",
            "-G",
            "reen",
            ")",
            " in",
            " the",
            " television",
            " series",
            " Star",
            " Trek",
            ":",
            " Discovery",
            "Daniel",
            " Jackson",
            " (",
            "Michael",
            " Sh",
            "anks",
            ",",
            " James",
            " Sp",
            "ader",
            ")",
            " in",
            " the",
            " television",
            " series",
            " and",
            " film",
            " St",
            "arg",
            "ate",
            " SG",
            "-",
            "1",
            "Charlotte",
            " Lewis",
            " (",
            "Re",
            "becca"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.163,
            0.058,
            0.039,
            0.246,
            0.194,
            0.34,
            0.273,
            -0.0,
            0.625,
            0.719,
            0.516,
            0.408,
            0.57,
            0.387,
            0.57,
            0.281,
            0.258,
            0.312,
            0.856,
            1.32,
            0.059,
            0.266,
            0.809,
            0.555,
            0.59,
            0.361,
            0.157,
            0.054,
            -0.0,
            -0.0,
            0.206,
            0.402,
            0.197,
            0.356,
            0.142,
            0.125,
            0.383,
            0.256,
            0.488,
            0.322,
            0.113,
            0.252,
            0.246,
            0.208,
            0.324,
            0.574,
            0.303,
            0.291,
            0.059,
            -0.0,
            0.073,
            0.142,
            0.122,
            0.338,
            0.238,
            0.224,
            0.098,
            0.139,
            0.494,
            0.424,
            0.239,
            0.224
          ],
          "train_token_ind": 20,
          "is_repeated_datapoint": false,
          "tokens": [
            " requiring",
            " reconstruction",
            " and",
            " fill",
            " to",
            " raise",
            " the",
            " S",
            "eward",
            " Highway",
            " above",
            " the",
            " new",
            " high",
            " tide",
            " mark",
            ".",
            "In",
            " Prince",
            " William",
            " Sound",
            ",",
            " Port",
            " Val",
            "dez",
            " suffered",
            " a",
            " massive",
            " underwater",
            " landslide",
            ",",
            " resulting",
            " in",
            " the",
            " deaths",
            " of",
            " ",
            "32",
            " people",
            " between",
            " the",
            " collapse",
            " of",
            " the",
            " Val",
            "dez",
            " city",
            " harbor",
            " and",
            " docks",
            ",",
            " and",
            " inside",
            " the",
            " ship",
            " that",
            " was",
            " dock",
            "ed",
            " there",
            " at",
            " the",
            " time"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.034,
            0.945,
            0.652,
            0.879,
            0.824,
            -0.0,
            0.069,
            0.516,
            0.59,
            0.416,
            0.252,
            0.606,
            0.204,
            0.93,
            0.365,
            0.438,
            -0.0,
            -0.0,
            0.475,
            0.051,
            0.334,
            -0.0,
            0.182,
            -0.0,
            0.523,
            0.547,
            0.32,
            0.488,
            0.273,
            0.445,
            0.512,
            0.186,
            0.324,
            0.566,
            -0.0,
            0.245,
            0.396,
            0.287,
            0.809,
            0.461,
            0.4,
            0.412,
            0.211,
            0.291,
            0.287,
            1.148,
            0.996,
            0.478,
            0.146,
            0.629,
            0.504,
            0.291,
            -0.0,
            0.531,
            1.32,
            0.77,
            0.656,
            1.188,
            0.793,
            0.352
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            " at",
            " a",
            " Catholic",
            " Worker",
            " Friday",
            " Night",
            " meeting",
            ",",
            " possibly",
            " due",
            " to",
            " its",
            " associations",
            " with",
            " Thomas",
            " M",
            "erton",
            ".",
            "Insp",
            "iration",
            " from",
            " mentors",
            " and",
            " idols",
            "G",
            "ins",
            "berg",
            "'s",
            " poetry",
            " was",
            " strongly",
            " influenced",
            " by",
            " Modern",
            "ism",
            " (",
            "most",
            " importantly",
            " the",
            " American",
            " style",
            " of",
            " Modern",
            "ism",
            " pioneered",
            " by",
            " William",
            " Carlos",
            " Williams",
            "),",
            " Romantic",
            "ism",
            " (",
            "specific",
            "ally",
            " William",
            " Blake",
            " and",
            " John",
            " Ke",
            "ats",
            "),"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.305,
            0.322,
            -0.0,
            0.244,
            0.684,
            0.547,
            -0.0,
            0.473,
            0.402,
            0.467,
            0.307,
            1.164,
            0.902,
            0.457,
            0.703,
            0.391,
            1.055,
            1.32,
            0.629,
            0.766,
            0.539,
            0.221,
            0.268,
            -0.0,
            0.762,
            0.469,
            0.641,
            0.531,
            0.5,
            0.451,
            0.221,
            0.547,
            -0.0,
            0.676,
            -0.0,
            0.475,
            0.406,
            0.223,
            0.637,
            0.77,
            0.59,
            0.711,
            -0.0,
            0.375,
            0.5,
            0.617,
            0.258,
            0.215,
            0.551,
            0.691,
            0.727,
            0.414,
            0.602,
            0.246,
            0.099,
            0.385,
            0.357,
            0.277,
            0.508,
            -0.0,
            0.216,
            0.344
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " younger",
            " readers",
            " to",
            " explorer",
            " Jacques",
            " Mar",
            "quette",
            ",",
            " as",
            " well",
            " as",
            " Ralph",
            " Wal",
            "do",
            " Emerson",
            " and",
            " Henry",
            " David",
            " Th",
            "ore",
            "au",
            ".",
            " ",
            " Arg",
            "uably",
            " most",
            " important",
            " among",
            " his",
            " works",
            " for",
            " younger",
            " readers",
            ",",
            " however",
            ",",
            " is",
            " the",
            " Steve",
            " and",
            " Sim",
            " Mystery",
            " Series",
            ",",
            " also",
            " known",
            " as",
            " the",
            " Mill",
            " Creek",
            " Ir",
            "regular",
            "s",
            " series",
            ".",
            " ",
            " The",
            " ten",
            "-volume",
            " series",
            ",",
            " published",
            " between"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.001,
            -0.0,
            0.076,
            -0.0,
            0.125,
            0.196,
            0.377,
            -0.0,
            0.184,
            0.127,
            -0.0,
            0.342,
            0.243,
            0.272,
            0.193,
            0.318,
            0.252,
            0.164,
            0.338,
            0.295,
            0.242,
            0.424,
            0.369,
            0.188,
            0.367,
            0.272,
            0.318,
            0.299,
            0.233,
            0.373,
            0.391,
            0.391,
            0.478,
            0.48,
            0.424,
            0.245,
            0.504,
            0.66,
            0.559,
            1.32,
            0.539,
            -0.0,
            0.414,
            0.195,
            0.432,
            0.324,
            0.273,
            1.203,
            0.914,
            0.547,
            0.363,
            -0.0,
            0.373,
            0.266,
            0.139,
            0.512,
            0.461,
            0.381,
            0.793,
            0.617,
            0.637,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            "h",
            "iser",
            ",",
            " an",
            " associate",
            " of",
            " Buckley",
            "'s",
            ",",
            " the",
            " host",
            " commented",
            " that",
            " it",
            " was",
            " \"",
            "the",
            " most",
            " un",
            "har",
            "ried",
            " Krishna",
            " I",
            "'ve",
            " ever",
            " heard",
            ".\"",
            "At",
            " the",
            " ",
            "196",
            "7",
            " Human",
            " Be",
            "-In",
            " in",
            " San",
            " Francisco",
            "'s",
            " Golden",
            " Gate",
            " Park",
            ",",
            " the",
            " ",
            "196",
            "8",
            " Democratic",
            " National",
            " Convention",
            " in",
            " Chicago",
            ",",
            " and",
            " the",
            " ",
            "197",
            "0",
            " Black",
            " Panther",
            " rally",
            " at",
            " Yale"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.163,
            -0.0,
            0.206,
            0.387,
            0.559,
            0.508,
            0.381,
            0.856,
            0.287,
            0.31,
            0.373,
            0.262,
            0.961,
            -0.0,
            0.422,
            0.243,
            0.26,
            0.236,
            0.832,
            1.312,
            0.859,
            0.477,
            0.332,
            0.17,
            0.193,
            0.171,
            0.547,
            0.367,
            0.279,
            0.354,
            0.297,
            0.064,
            -0.0,
            0.096,
            0.314,
            0.402,
            0.457,
            0.209,
            0.139,
            0.57,
            0.348,
            0.283,
            0.449,
            -0.0,
            0.309,
            0.212,
            0.324,
            0.26,
            0.113,
            0.141,
            0.332,
            0.633,
            0.332,
            -0.0,
            0.41,
            0.352,
            0.281,
            0.211,
            -0.0,
            0.336
          ],
          "train_token_ind": 21,
          "is_repeated_datapoint": false,
          "tokens": [
            " west",
            " of",
            " the",
            " Wr",
            "ang",
            "ell",
            " Mountains",
            " also",
            " fall",
            " within",
            " the",
            " definition",
            " of",
            " South",
            " Central",
            ",",
            " as",
            " do",
            " the",
            " Prince",
            " William",
            " Sound",
            " area",
            " and",
            " the",
            " communities",
            " of",
            " Cord",
            "ova",
            " and",
            " Val",
            "dez",
            ".",
            "Sou",
            "theast",
            "Also",
            " referred",
            " to",
            " as",
            " the",
            " Pan",
            "handle",
            " or",
            " Inside",
            " Passage",
            ",",
            " this",
            " is",
            " the",
            " region",
            " of",
            " Alaska",
            " closest",
            " to",
            " the",
            " contiguous",
            " states",
            ".",
            " As",
            " such",
            ",",
            " this"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.32,
            0.254,
            0.266,
            0.295,
            0.356,
            0.215,
            0.086,
            0.044,
            0.166,
            0.188,
            0.385,
            -0.0,
            0.273,
            0.42,
            0.348,
            0.359,
            0.52,
            0.482,
            0.26,
            0.188,
            0.32,
            0.387,
            0.543,
            0.703,
            0.758,
            0.377,
            0.208,
            0.198,
            0.414,
            0.408,
            0.32,
            -0.0,
            0.303,
            0.342,
            0.354,
            1.016,
            1.312,
            0.898,
            0.44,
            0.206,
            0.494,
            -0.0,
            -0.0,
            0.346,
            0.5,
            0.475,
            0.375,
            0.402,
            0.307,
            0.352,
            0.227,
            0.676,
            0.42,
            0.477,
            0.432,
            0.412,
            0.248,
            0.478,
            0.406,
            0.484,
            0.247
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            " which",
            " continued",
            " throughout",
            " #",
            "244",
            "–",
            "245",
            " and",
            " ",
            "249",
            "–",
            "251",
            " (",
            "Sept",
            ".-",
            "Oct",
            ".",
            " ",
            "198",
            "3",
            " and",
            " Feb",
            ".-",
            "April",
            " ",
            "198",
            "4",
            ").",
            " One",
            " lasting",
            " change",
            " was",
            " the",
            " reint",
            "roduction",
            " of",
            " Mary",
            " Jane",
            " Watson",
            " as",
            " a",
            " more",
            " serious",
            ",",
            " mature",
            " woman",
            " who",
            " becomes",
            " Peter",
            "'s",
            " conf",
            "id",
            "ante",
            " after",
            " she",
            " reveals",
            " that",
            " she",
            " knows",
            " his",
            " secret",
            " identity",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.344,
            0.227,
            0.133,
            0.272,
            0.241,
            0.582,
            0.326,
            1.281,
            0.801,
            0.41,
            0.394,
            0.385,
            0.148,
            0.432,
            0.207,
            0.492,
            0.207,
            0.122,
            0.127,
            0.283,
            0.218,
            0.191,
            0.117,
            0.482,
            0.375,
            0.4,
            0.25,
            0.182,
            0.309,
            0.332,
            0.578,
            0.352,
            0.777,
            0.475,
            0.305,
            0.445,
            0.457,
            0.516,
            0.273,
            0.441,
            0.461,
            0.268,
            0.31,
            0.227,
            0.357,
            0.412,
            0.328,
            0.297,
            0.287,
            0.243,
            0.217,
            0.2,
            0.324,
            0.391,
            0.275,
            0.373,
            -0.0,
            0.116,
            0.478,
            0.283
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " a",
            " rank",
            " which",
            " had",
            " been",
            " un",
            "occupied",
            " since",
            " George",
            " Washington",
            ".",
            " Authorization",
            " for",
            " such",
            " a",
            " promotion",
            " \"",
            "with",
            " the",
            " advice",
            " and",
            " consent",
            " of",
            " the",
            " Senate",
            "\"",
            " was",
            " provided",
            " by",
            " a",
            " new",
            " bill",
            " which",
            " Lincoln",
            " signed",
            " the",
            " same",
            " day",
            " he",
            " submitted",
            " Grant",
            "'s",
            " name",
            " to",
            " the",
            " Senate",
            ".",
            " His",
            " nomination",
            " was",
            " confirmed",
            " by",
            " the",
            " Senate",
            " on",
            " March",
            " ",
            "2",
            ",",
            " ",
            "186",
            "4"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.277,
            -0.0,
            0.124,
            1.227,
            0.523,
            0.535,
            0.871,
            0.809,
            0.527,
            0.262,
            0.205,
            0.275,
            0.148,
            0.664,
            0.629,
            0.459,
            0.602,
            0.664,
            0.523,
            0.598,
            0.336,
            0.379,
            0.309,
            0.092,
            0.143,
            0.086,
            0.35,
            0.247,
            0.128,
            0.644,
            0.598,
            0.566,
            0.447,
            0.719,
            -0.0,
            0.389,
            0.153,
            0.193,
            0.104,
            0.4,
            0.31,
            0.258,
            0.346,
            0.012,
            0.149,
            0.281,
            0.318,
            -0.0,
            0.219,
            0.32,
            0.652,
            -0.0,
            0.33,
            0.234,
            0.371,
            0.252,
            0.279,
            0.33,
            0.266,
            0.228,
            0.354,
            0.33
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            "ni",
            "ak",
            ",",
            " Steve",
            " Jobs",
            " and",
            " Ronald",
            " Wayne",
            " to",
            " develop",
            " and",
            " sell",
            " W",
            "oz",
            "ni",
            "ak",
            "'s",
            " Apple",
            " I",
            " personal",
            " computer",
            ".",
            " It",
            " was",
            " incorporated",
            " by",
            " Jobs",
            " and",
            " W",
            "oz",
            "ni",
            "ak",
            " as",
            " Apple",
            " Computer",
            ",",
            " Inc",
            ".",
            " in",
            " ",
            "197",
            "7",
            ".",
            " The",
            " company",
            "'s",
            " second",
            " computer",
            ",",
            " the",
            " Apple",
            " II",
            ",",
            " became",
            " a",
            " best",
            " seller",
            " and",
            " one",
            " of",
            " the",
            " first",
            " mass"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.377,
            0.179,
            0.342,
            0.449,
            0.102,
            1.047,
            0.559,
            0.309,
            0.559,
            0.676,
            0.602,
            0.328,
            0.184,
            1.031,
            0.453,
            0.48,
            0.365,
            0.5,
            0.606,
            0.254,
            0.613,
            0.492,
            1.203,
            0.797,
            0.471,
            0.43,
            0.75,
            0.32,
            0.455,
            0.82,
            0.566,
            0.555,
            0.324,
            0.478,
            0.582,
            0.578,
            0.648,
            0.361,
            0.602,
            0.157,
            0.641,
            0.342,
            0.496,
            0.04,
            0.208,
            0.453,
            0.408,
            0.224,
            0.402,
            0.22,
            0.426,
            0.5,
            0.359,
            0.531
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            "Pres",
            "idents",
            " of",
            " the",
            " United",
            " States",
            "Republican",
            " Party",
            " (",
            "United",
            " States",
            ")",
            " presidential",
            " nominees",
            "Republican",
            " Party",
            " presidents",
            " of",
            " the",
            " United",
            " States",
            "Union",
            " (",
            "American",
            " Civil",
            " War",
            ")",
            " political",
            " leaders",
            "Wh",
            "ig",
            " Party",
            " members",
            " of",
            " the",
            " United",
            " States",
            " House",
            " of",
            " Representatives",
            " from",
            " Illinois",
            "19",
            "th",
            "-century",
            " assass",
            "inated",
            " national",
            " presidents",
            "Ass",
            "ass",
            "inated",
            " former",
            " sub",
            "national",
            " legislators"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.179,
            1.094,
            0.314,
            0.104,
            0.23,
            -0.0,
            0.332,
            0.383,
            0.668,
            0.441,
            -0.0,
            0.119,
            0.606,
            0.629,
            0.432,
            0.473,
            0.652,
            0.621,
            0.559,
            0.067,
            0.35,
            0.43,
            0.559,
            0.469,
            0.451,
            0.356,
            0.301,
            0.11,
            0.424,
            0.081,
            0.048,
            0.158,
            0.33,
            0.216,
            0.404,
            0.369,
            0.144,
            -0.0,
            0.15,
            1.156,
            0.57,
            0.356,
            0.218,
            1.164,
            0.562,
            0.264,
            0.527,
            0.239,
            0.07,
            0.457,
            0.482,
            0.33,
            -0.0,
            0.35,
            0.258,
            0.218,
            0.385,
            0.383,
            0.475,
            0.157
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            " written",
            " by",
            " Michael",
            " Green",
            ".",
            "Other",
            " ",
            " Anat",
            "oly",
            " Rav",
            "ik",
            "ovich",
            ",",
            " Zag",
            "ad",
            "ka",
            " End",
            "kh",
            "au",
            "za",
            " (",
            "End",
            " House",
            " Mystery",
            ")",
            " (",
            "198",
            "9",
            ";",
            " based",
            " on",
            " \"",
            "Per",
            "il",
            " at",
            " End",
            " House",
            "\")",
            "Te",
            "levision",
            "David",
            " Such",
            "et",
            " ",
            "David",
            " Such",
            "et",
            " starred",
            " as",
            " P",
            "oi",
            "rot",
            " in",
            " the",
            " ITV",
            " series",
            " Ag",
            "atha",
            " Christie",
            "'s",
            " P",
            "oi"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.48,
            0.312,
            0.492,
            0.369,
            0.195,
            0.174,
            0.352,
            0.332,
            -0.0,
            0.15,
            0.242,
            0.316,
            0.303,
            0.26,
            0.463,
            0.279,
            0.387,
            0.508,
            0.473,
            0.484,
            0.531,
            0.402,
            0.299,
            -0.0,
            0.398,
            0.465,
            0.699,
            -0.0,
            0.342,
            0.057,
            0.606,
            0.754,
            0.379,
            0.434,
            0.543,
            -0.0,
            0.201,
            -0.0,
            0.065,
            0.379,
            0.209,
            0.389,
            0.192,
            0.453,
            0.264,
            0.338,
            0.218,
            0.33,
            0.277,
            1.156,
            0.754,
            -0.0,
            0.256,
            0.664,
            0.543,
            0.373,
            0.461,
            0.469,
            0.277,
            -0.0,
            0.291,
            0.49
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " African",
            " American",
            " slave",
            " labor",
            ".",
            " In",
            " ",
            "186",
            "1",
            ",",
            " the",
            " state",
            " se",
            "ced",
            "ed",
            " from",
            " the",
            " United",
            " States",
            " to",
            " become",
            " part",
            " of",
            " the",
            " Confederate",
            " States",
            " of",
            " America",
            ",",
            " with",
            " Montgomery",
            " acting",
            " as",
            " its",
            " first",
            " capital",
            ",",
            " and",
            " rejo",
            "ined",
            " the",
            " Union",
            " in",
            " ",
            "186",
            "8",
            ".",
            " Following",
            " the",
            " American",
            " Civil",
            " War",
            ",",
            " Alabama",
            " would",
            " suffer",
            " decades",
            " of",
            " economic",
            " hardship",
            ",",
            " in",
            " part"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.223,
            0.02,
            -0.0,
            0.252,
            0.222,
            -0.0,
            -0.0,
            0.111,
            0.268,
            0.245,
            -0.0,
            -0.0,
            0.244,
            0.508,
            0.252,
            0.142,
            -0.0,
            0.457,
            0.369,
            0.49,
            1.133,
            0.68,
            0.582,
            -0.0,
            0.254,
            0.52,
            0.369,
            0.227,
            0.496,
            0.367,
            0.467,
            0.656,
            -0.0,
            0.504,
            0.582,
            0.469,
            0.026,
            0.52,
            0.281,
            0.371,
            -0.0,
            0.463,
            0.404,
            -0.0,
            -0.0,
            0.629,
            0.648,
            0.23,
            0.247,
            0.241,
            -0.0,
            0.232,
            0.606,
            0.328,
            0.305,
            -0.0,
            0.59,
            -0.0,
            0.496,
            0.225,
            0.305
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            " organization",
            ",",
            " such",
            " as",
            " hier",
            "arch",
            "ies",
            ",",
            " monopol",
            "ies",
            " and",
            " inequality",
            ",",
            " outweigh",
            " the",
            " benefits",
            ".",
            "Phil",
            "osoph",
            "y",
            " lecturer",
            " Andrew",
            " G",
            ".",
            " F",
            "ial",
            "a",
            " composed",
            " a",
            " list",
            " of",
            " common",
            " arguments",
            " against",
            " anarch",
            "ism",
            " which",
            " includes",
            " critiques",
            " such",
            " as",
            " that",
            " anarch",
            "ism",
            " is",
            " inn",
            "ately",
            " related",
            " to",
            " violence",
            " and",
            " destruction",
            ",",
            " not",
            " only",
            " in",
            " the",
            " pragmatic",
            " world",
            ",",
            " such",
            " as",
            " at"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.523,
            0.182,
            0.32,
            0.222,
            0.16,
            0.363,
            0.402,
            0.075,
            0.235,
            0.455,
            0.436,
            -0.0,
            0.438,
            0.188,
            0.629,
            0.856,
            0.539,
            0.183,
            0.578,
            0.365,
            0.197,
            1.023,
            0.699,
            0.75,
            0.432,
            0.498,
            0.68,
            0.648,
            0.432,
            -0.0,
            0.455,
            0.428,
            0.633,
            0.467,
            0.566,
            0.879,
            0.26,
            1.039,
            0.734,
            0.656,
            0.494,
            0.131,
            0.424,
            0.185,
            0.093,
            0.512,
            1.062,
            0.762,
            0.535,
            0.609,
            0.352,
            0.326,
            0.894,
            0.707,
            -0.0,
            0.457,
            0.711
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            " Gay",
            " Id",
            "entities",
            " in",
            " the",
            " ",
            "196",
            "0",
            "s",
            " Underground",
            " Cinema",
            ".",
            " Indianapolis",
            ":",
            " Indiana",
            " University",
            " Press",
            ".",
            "External",
            " links",
            " ",
            " Andy",
            " War",
            "hol",
            " at",
            " the",
            " National",
            " Gallery",
            " of",
            " Art",
            " War",
            "hol",
            " Foundation",
            " in",
            " New",
            " York",
            " City",
            " Andy",
            " War",
            "hol",
            " Collection",
            " in",
            " Pittsburgh",
            " The",
            " work",
            " of",
            " Andy",
            " War",
            "hol",
            " spoken",
            " about",
            " by",
            " David",
            " Cron",
            "enberg",
            " War",
            "hol",
            "stars"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.441,
            -0.0,
            0.246,
            0.887,
            0.945,
            0.527,
            0.451,
            0.363,
            0.014,
            0.688,
            0.789,
            -0.0,
            0.14,
            0.238,
            0.316,
            0.133,
            0.418,
            0.467,
            0.43,
            0.194,
            -0.0,
            0.781,
            0.938,
            -0.0,
            0.237,
            0.359,
            0.191,
            0.377,
            0.475,
            0.23,
            0.486,
            0.512,
            0.508,
            0.241,
            0.214,
            0.875,
            -0.0,
            0.434,
            0.68,
            1.0,
            0.606,
            0.402,
            0.406,
            0.316,
            1.0,
            0.488,
            0.471,
            0.465,
            0.473,
            0.738,
            0.303,
            0.18,
            0.31,
            0.119,
            0.363,
            0.389,
            0.459
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            " –",
            " Marvel",
            " Smith",
            ",",
            " American",
            " football",
            " player",
            "197",
            "9",
            " –",
            " Francesco",
            " Bell",
            "otti",
            ",",
            " Italian",
            " cyclist",
            " ",
            " ",
            "197",
            "9",
            "  ",
            " –",
            " Jaime",
            " Cor",
            "rea",
            ",",
            " Mexican",
            " football",
            "er",
            " ",
            " ",
            " ",
            "197",
            "9",
            "  ",
            " –",
            " Travis",
            " Reed",
            ",",
            " American",
            " basketball",
            " player",
            "198",
            "1",
            " –",
            " Leslie",
            " O",
            "dom",
            " Jr",
            ".,",
            " American",
            " actor",
            " and",
            " singer",
            " ",
            " ",
            "198",
            "1",
            "  "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.025,
            0.171,
            0.26,
            0.022,
            0.035,
            0.16,
            0.088,
            0.113,
            0.656,
            -0.0,
            -0.0,
            0.037,
            0.186,
            0.443,
            0.131,
            0.5,
            0.167,
            0.295,
            0.289,
            0.254,
            0.173,
            0.204,
            0.241,
            0.219,
            0.984,
            -0.0,
            0.344,
            0.447,
            0.617,
            0.488,
            0.199,
            0.52,
            0.203,
            0.375,
            0.414,
            0.279,
            0.27,
            0.254,
            0.295,
            0.124,
            0.438,
            0.551,
            0.668,
            0.18,
            0.424,
            -0.0,
            -0.0,
            0.185,
            0.467,
            0.275,
            0.062,
            0.381,
            0.148,
            0.457,
            0.148,
            0.43,
            0.289,
            0.221,
            0.297,
            0.135,
            0.299
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            "d",
            ".",
            " ",
            "199",
            "3",
            ")",
            "190",
            "2",
            " –",
            " Fernando",
            " P",
            "essa",
            ",",
            " Portuguese",
            " journalist",
            " (",
            "d",
            ".",
            " ",
            "200",
            "2",
            ")",
            "190",
            "3",
            " –",
            " John",
            " Williams",
            ",",
            " English",
            "-American",
            " actor",
            " (",
            "d",
            ".",
            " ",
            "198",
            "3",
            ")",
            "190",
            "4",
            " –",
            " Ar",
            "sh",
            "ile",
            " G",
            "ork",
            "y",
            ",",
            " Armenian",
            "-American",
            " painter",
            " and",
            " illustrator",
            " (",
            "d",
            ".",
            " ",
            "194",
            "8",
            ")",
            "190",
            "7",
            " –"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.173,
            0.303,
            -0.0,
            0.367,
            0.396,
            0.275,
            0.138,
            0.346,
            -0.0,
            0.256,
            0.516,
            -0.0,
            0.348,
            -0.0,
            0.11,
            -0.0,
            0.236,
            0.141,
            0.19,
            0.309,
            0.342,
            -0.0,
            0.35,
            0.98,
            0.57,
            0.531,
            0.478,
            0.17,
            0.334,
            0.445,
            0.428,
            0.432,
            0.32,
            0.445,
            -0.0,
            -0.0,
            0.385,
            0.535,
            0.504,
            -0.0,
            0.354,
            0.369,
            0.122,
            0.326,
            0.414,
            -0.0,
            0.268,
            -0.0,
            0.641,
            0.314,
            0.07,
            0.566,
            0.625,
            0.283,
            0.356,
            0.408,
            0.316,
            -0.0,
            0.365,
            0.361,
            0.19,
            0.215
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            "ys",
            "p",
            "ia",
            "ÅĦ",
            "ski",
            " published",
            " a",
            " national",
            " drama",
            ",",
            " based",
            " on",
            " Polish",
            " history",
            ",",
            " named",
            " Achilles",
            ".",
            " In",
            " ",
            "192",
            "1",
            ",",
            " Edward",
            " Sh",
            "anks",
            " published",
            " The",
            " Island",
            " of",
            " Youth",
            " and",
            " Other",
            " Po",
            "ems",
            ",",
            " concerned",
            " among",
            " others",
            " with",
            " Achilles",
            ".",
            " The",
            " ",
            "198",
            "3",
            " novel",
            " K",
            "assandra",
            " by",
            " Christ",
            "a",
            " Wolf",
            " also",
            " treats",
            " the",
            " death",
            " of",
            " Achilles",
            ".",
            " H",
            ".D",
            ".'"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            0.559,
            0.089,
            -0.0,
            0.216,
            0.365,
            0.918,
            -0.0,
            0.354,
            0.066,
            0.181,
            0.459,
            0.879,
            0.342,
            0.648,
            0.389,
            0.367,
            0.938,
            0.231,
            0.695,
            0.373,
            0.394,
            0.949,
            0.447,
            -0.0,
            0.301,
            0.334,
            0.169,
            0.543,
            0.408,
            0.083,
            0.5,
            0.332,
            0.428,
            0.57,
            0.809,
            0.629,
            0.373,
            0.5,
            0.348,
            0.471,
            0.268,
            0.299,
            0.412,
            0.422,
            0.447,
            0.883,
            0.57,
            -0.0,
            0.143,
            0.641,
            -0.0,
            0.33,
            0.264,
            0.314,
            0.314,
            0.68,
            0.424,
            -0.0,
            0.43,
            0.33,
            0.287
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            "sted",
            " acid",
            " and",
            " not",
            " a",
            " Lewis",
            " acid",
            ",",
            " since",
            " chem",
            "ists",
            " almost",
            " always",
            " refer",
            " to",
            " a",
            " Lewis",
            " acid",
            " explicitly",
            " as",
            " a",
            " Lewis",
            " acid",
            ".",
            "Definitions",
            " and",
            " concepts",
            "Modern",
            " definitions",
            " are",
            " concerned",
            " with",
            " the",
            " fundamental",
            " chemical",
            " reactions",
            " common",
            " to",
            " all",
            " acids",
            ".",
            "Most",
            " acids",
            " encountered",
            " in",
            " everyday",
            " life",
            " are",
            " aque",
            "ous",
            " solutions",
            ",",
            " or",
            " can",
            " be",
            " dissolved",
            " in",
            " water",
            ",",
            " so",
            " the",
            " Arr"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.26,
            0.21,
            -0.0,
            0.24,
            -0.0,
            0.43,
            0.164,
            0.555,
            0.312,
            0.463,
            0.097,
            0.436,
            0.32,
            0.668,
            0.484,
            0.412,
            0.238,
            -0.0,
            0.191,
            0.373,
            0.106,
            0.312,
            0.256,
            0.424,
            0.404,
            0.703,
            0.844,
            0.574,
            0.44,
            -0.0,
            0.198,
            0.348,
            0.391,
            0.582,
            0.346,
            0.949,
            0.703,
            0.68,
            0.504,
            0.508,
            0.547,
            0.354,
            0.215,
            0.295,
            0.04,
            0.144,
            0.346,
            0.332,
            0.41,
            0.361,
            0.346,
            0.363,
            0.396,
            0.516,
            0.25,
            0.418,
            -0.0,
            0.488,
            0.21,
            0.777
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            " Highlight",
            "ed",
            " are",
            " the",
            " struggles",
            " and",
            " tragic",
            " f",
            "ates",
            " of",
            " America",
            "'s",
            " Indians",
            " and",
            " Black",
            " slaves",
            ".",
            " For",
            " example",
            ",",
            " \"",
            "In",
            " ",
            "177",
            "9",
            " [",
            "George",
            "]",
            " Washington",
            " dispatched",
            " a",
            " contingent",
            " of",
            " soldiers",
            " to",
            " up",
            "state",
            " New",
            " York",
            " to",
            " burn",
            " Indian",
            " towns",
            " and",
            " crops",
            " and",
            " seize",
            " hostages",
            " '",
            "of",
            " every",
            " age",
            " and",
            " sex",
            ".'",
            " The",
            " following",
            " year",
            ",",
            " while",
            " serving",
            " as"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.158,
            0.42,
            0.14,
            0.406,
            0.206,
            0.216,
            0.216,
            0.396,
            0.492,
            -0.0,
            0.264,
            0.237,
            0.215,
            0.203,
            0.523,
            0.535,
            0.641,
            0.082,
            0.194,
            0.146,
            0.069,
            0.123,
            0.33,
            0.945,
            0.455,
            0.57,
            0.381,
            0.498,
            0.191,
            0.594,
            0.371,
            0.191,
            0.322,
            0.539,
            0.414,
            0.27,
            0.144,
            0.005,
            0.629,
            0.301,
            0.629,
            0.441,
            0.385,
            0.283,
            0.124,
            0.891,
            0.344,
            0.695,
            0.408,
            0.516,
            0.191,
            0.232,
            0.898,
            0.389,
            0.314,
            0.527,
            0.551,
            0.617,
            0.459
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " the",
            " ",
            "195",
            "0",
            " Christie",
            " novel",
            ".",
            "In",
            " ",
            "197",
            "0",
            ",",
            " the",
            " character",
            " of",
            " Miss",
            " Mar",
            "ple",
            " was",
            " portrayed",
            " by",
            " ",
            " in",
            " a",
            " West",
            " German",
            " television",
            " adaptation",
            " of",
            " The",
            " Murder",
            " at",
            " the",
            " Vic",
            "ar",
            "age",
            " ",
            " (",
            "M",
            "ord",
            " im",
            " Pf",
            "arr",
            "haus",
            ").",
            "H",
            "elen",
            " Hayes",
            "American",
            " stage",
            " and",
            " screen",
            " actress",
            " Helen",
            " Hayes",
            " portrayed",
            " Miss",
            " Mar",
            "ple",
            " in",
            " two"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.307,
            -0.0,
            -0.0,
            0.053,
            0.115,
            -0.0,
            0.389,
            0.264,
            0.871,
            0.523,
            0.606,
            0.356,
            0.492,
            0.24,
            0.291,
            0.801,
            0.326,
            0.734,
            0.268,
            0.512,
            0.34,
            0.367,
            0.326,
            0.168,
            0.402,
            0.875,
            0.867,
            0.906,
            -0.0,
            0.167,
            0.44,
            0.512,
            0.34,
            0.43,
            0.367,
            0.566,
            0.326,
            0.465,
            0.249,
            0.307,
            0.816,
            0.512,
            0.224,
            0.494,
            0.275,
            0.633,
            0.156,
            0.551,
            0.664,
            0.482,
            0.201,
            0.124,
            0.073,
            0.383,
            0.394,
            0.354,
            0.459,
            0.207
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            "200",
            "0",
            ",",
            " Canada",
            ")\"",
            " –",
            " bibliography",
            " at",
            " Sci",
            "Fan",
            " A",
            ".",
            " E",
            ".",
            " van",
            " Vog",
            "t",
            " Papers",
            " (",
            "MS",
            " ",
            "322",
            ")",
            " at",
            " the",
            " Kenneth",
            " Spencer",
            " Research",
            " Library",
            ",",
            " University",
            " of",
            " Kansas",
            " ",
            " ",
            " A",
            ".",
            " E",
            ".",
            " van",
            " Vog",
            "t",
            "'s",
            " fiction",
            " at",
            " Free",
            " Spec",
            "ulative",
            " Fiction",
            " Online",
            " ",
            "191",
            "2",
            " births",
            "200",
            "0",
            " deaths",
            "20",
            "th"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.414,
            0.4,
            0.167,
            0.201,
            0.123,
            0.126,
            -0.0,
            0.199,
            0.367,
            0.181,
            0.297,
            0.322,
            0.123,
            -0.0,
            0.196,
            -0.0,
            0.303,
            0.367,
            -0.0,
            0.344,
            0.277,
            -0.0,
            0.297,
            0.031,
            0.225,
            0.153,
            0.156,
            0.633,
            0.281,
            -0.0,
            0.766,
            0.379,
            0.848,
            0.688,
            0.338,
            0.156,
            0.326,
            -0.0,
            0.101,
            0.367,
            0.199,
            -0.0,
            0.295,
            0.414,
            0.24,
            -0.0,
            0.478,
            0.118,
            -0.0,
            -0.0,
            -0.0,
            0.144,
            0.186,
            0.268,
            -0.0,
            0.221,
            0.114,
            -0.0,
            0.441,
            0.21,
            -0.0,
            0.192
          ],
          "train_token_ind": 33,
          "is_repeated_datapoint": false,
          "tokens": [
            "ab",
            "ak",
            "os",
            ")).",
            " While",
            " the",
            " table",
            " stre",
            "wn",
            " with",
            " dust",
            " definition",
            " is",
            " popular",
            ",",
            " some",
            " argue",
            " evidence",
            " is",
            " insufficient",
            " for",
            " that",
            " conclusion",
            ".",
            " Greek",
            " ",
            " probably",
            " borrowed",
            " from",
            " a",
            " Northwest",
            " Sem",
            "itic",
            " language",
            " like",
            " Ph",
            "oen",
            "ician",
            ",",
            " evidenced",
            " by",
            " a",
            " cogn",
            "ate",
            " with",
            " the",
            " Hebrew",
            " word",
            " ",
            "Ê",
            "¾",
            "Äģ",
            "b",
            "Äģ",
            "q",
            " (),",
            " or",
            " \"",
            "dust",
            "\"",
            " (",
            "in",
            " the"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.012,
            0.044,
            0.277,
            0.022,
            0.069,
            0.377,
            0.33,
            -0.0,
            0.535,
            0.094,
            0.04,
            0.547,
            0.586,
            0.766,
            0.391,
            0.535,
            0.352,
            0.369,
            0.426,
            0.418,
            0.416,
            0.414,
            0.447,
            -0.0,
            0.124,
            -0.0,
            0.451,
            0.621,
            0.009,
            0.562,
            0.293,
            0.516,
            0.225,
            0.547,
            0.324,
            0.275,
            0.445,
            0.426,
            0.389,
            0.119,
            0.287,
            0.535,
            0.198,
            0.41,
            0.146,
            -0.0,
            0.48,
            0.396,
            -0.0,
            0.43,
            0.312,
            0.035,
            0.219,
            0.102,
            0.699,
            0.26,
            0.695,
            0.363,
            0.535,
            0.844,
            0.531
          ],
          "train_token_ind": 61,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " issued",
            " a",
            " proclamation",
            " that",
            " promised",
            " freedom",
            " to",
            " any",
            " Patriot",
            "-owned",
            " slaves",
            " willing",
            " to",
            " bear",
            " arms",
            ".",
            " Although",
            " the",
            " announcement",
            " helped",
            " to",
            " fill",
            " a",
            " temporary",
            " manpower",
            " shortage",
            ",",
            " white",
            " L",
            "oyal",
            "ist",
            " prejudice",
            " meant",
            " recruits",
            " were",
            " eventually",
            " redirected",
            " to",
            " non",
            "-com",
            "bat",
            "ant",
            " roles",
            ".",
            " The",
            " L",
            "oyal",
            "ists",
            "'",
            " motive",
            " was",
            " to",
            " depr",
            "ive",
            " Patriot",
            " plant",
            "ers",
            " of",
            " labor",
            " rather",
            " than",
            " to"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.151,
            0.297,
            0.629,
            0.793,
            0.547,
            0.215,
            0.508,
            -0.0,
            0.348,
            0.237,
            0.365,
            0.235,
            0.124,
            0.228,
            0.461,
            -0.0,
            0.214,
            0.119,
            -0.0,
            -0.0,
            0.093,
            0.086,
            -0.0,
            0.167,
            0.24,
            0.159,
            0.153,
            0.578,
            0.684,
            0.531,
            0.25,
            0.254,
            0.318,
            0.283,
            0.289,
            0.191,
            0.272,
            0.214,
            0.006,
            0.171,
            0.832,
            0.356,
            0.217,
            0.002,
            0.475,
            0.303,
            0.199,
            0.275,
            0.272,
            0.212,
            0.209,
            -0.0,
            0.174,
            -0.0,
            0.488,
            0.191,
            -0.0,
            -0.0,
            0.31,
            0.059,
            0.231,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            " writer",
            " Jo",
            "ost",
            " van",
            " den",
            " V",
            "ond",
            "el",
            ",",
            " as",
            " well",
            " as",
            " the",
            " Plant",
            "age",
            " neighbourhood",
            ",",
            " with",
            " the",
            " zoo",
            ",",
            " are",
            " also",
            " located",
            " outside",
            " the",
            " Gr",
            "acht",
            "eng",
            "ord",
            "el",
            ".",
            "Several",
            " parts",
            " of",
            " the",
            " city",
            " and",
            " the",
            " surrounding",
            " urban",
            " area",
            " are",
            " p",
            "olders",
            ".",
            " This",
            " can",
            " be",
            " recognised",
            " by",
            " the",
            " suffix",
            " -",
            "meer",
            " which",
            " means",
            " lake",
            ",",
            " as",
            " in",
            " A",
            "als"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.338,
            0.258,
            -0.0,
            0.307,
            0.148,
            0.06,
            -0.0,
            0.224,
            -0.0,
            0.516,
            0.112,
            0.369,
            0.101,
            0.465,
            -0.0,
            0.258,
            0.469,
            0.602,
            0.547,
            0.606,
            0.404,
            0.498,
            0.496,
            -0.0,
            0.471,
            0.212,
            0.036,
            0.44,
            0.59,
            0.453,
            0.711,
            0.301,
            0.422,
            0.226,
            0.488,
            0.116,
            -0.0,
            0.73,
            0.293,
            0.293,
            0.238,
            -0.0,
            0.262,
            0.027,
            -0.0,
            0.432,
            0.352,
            0.071,
            -0.0,
            0.508,
            0.279,
            0.197,
            -0.0,
            -0.0,
            0.432,
            0.175,
            0.389,
            0.291
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            "stances",
            " Portal",
            " –",
            " Aluminum",
            " –",
            " from",
            " the",
            " Agency",
            " for",
            " Toxic",
            " Sub",
            "stances",
            " and",
            " Disease",
            " Registry",
            ",",
            " United",
            " States",
            " Department",
            " of",
            " Health",
            " and",
            " Human",
            " Services",
            " CDC",
            " –",
            " N",
            "IOS",
            "H",
            " Pocket",
            " Guide",
            " to",
            " Chemical",
            " Haz",
            "ards",
            " –",
            " Aluminum",
            " World",
            " production",
            " of",
            " primary",
            " aluminium",
            ",",
            " by",
            " country",
            " Price",
            " history",
            " of",
            " aluminum",
            ",",
            " according",
            " to",
            " the",
            " IMF",
            " History",
            " of",
            " Aluminium",
            " –",
            " from"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.011,
            0.262,
            0.127,
            -0.0,
            -0.0,
            0.727,
            -0.0,
            0.042,
            0.146,
            0.103,
            0.061,
            0.455,
            0.299,
            0.12,
            0.14,
            -0.0,
            0.285,
            0.408,
            0.2,
            0.067,
            0.173,
            0.264,
            0.081,
            -0.0,
            0.19,
            0.108,
            0.357,
            0.312,
            0.328,
            0.334,
            0.336,
            0.191,
            0.273,
            0.264,
            0.44,
            0.582,
            0.262,
            0.412,
            0.324,
            0.281,
            0.252,
            0.167,
            -0.0,
            0.445,
            0.244,
            0.25,
            -0.0,
            0.24,
            0.281,
            0.621,
            0.336,
            0.199,
            0.27,
            0.299,
            0.161,
            0.344,
            0.5,
            0.367,
            0.17,
            0.08,
            0.279,
            0.393
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " mask",
            " at",
            " the",
            " desired",
            " facial",
            " point",
            ",",
            " driven",
            " by",
            " a",
            " DC",
            " motor",
            " with",
            " a",
            " simple",
            " pul",
            "ley",
            " and",
            " a",
            " slide",
            " screw",
            ".",
            " Apparently",
            ",",
            " the",
            " researchers",
            " can",
            " also",
            " modify",
            " the",
            " shape",
            " of",
            " the",
            " mask",
            " based",
            " on",
            " actual",
            " human",
            " faces",
            ".",
            " To",
            " \"",
            "copy",
            "\"",
            " a",
            " face",
            ",",
            " they",
            " need",
            " only",
            " a",
            " ",
            "3",
            "D",
            " scanner",
            " to",
            " determine",
            " the",
            " locations",
            " of",
            " an",
            " individual"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.03,
            -0.0,
            0.2,
            0.297,
            0.166,
            0.108,
            0.192,
            0.07,
            0.48,
            0.228,
            0.449,
            0.305,
            0.148,
            -0.0,
            0.424,
            0.268,
            0.307,
            0.239,
            0.198,
            0.641,
            0.385,
            0.262,
            0.23,
            0.084,
            0.301,
            0.357,
            0.03,
            0.457,
            -0.0,
            0.412,
            0.213,
            0.291,
            0.182,
            0.163,
            0.26,
            0.127,
            0.48,
            0.33,
            -0.0,
            -0.0,
            0.539,
            0.668,
            0.562,
            0.582,
            0.715,
            0.652,
            0.183,
            0.381,
            -0.0,
            0.688,
            0.23,
            0.482,
            0.305,
            0.334,
            0.215,
            0.312,
            0.422,
            -0.0,
            0.186,
            -0.0,
            0.132
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            "icts",
            "),",
            " the",
            " President",
            " is",
            " the",
            " leader",
            " of",
            " the",
            " winning",
            " party",
            ".",
            "The",
            " only",
            " \"",
            "relevant",
            "\"",
            " post",
            " that",
            " is",
            " not",
            " directly",
            " appointed",
            " by",
            " the",
            " President",
            " is",
            " the",
            " Vice",
            "-President",
            ",",
            " which",
            " is",
            " the",
            " second",
            " in",
            " the",
            " winning",
            " party",
            ".",
            "Jos",
            "Ã©",
            " Eduardo",
            " dos",
            " Santos",
            " stepped",
            " down",
            " as",
            " President",
            " of",
            " Angola",
            " after",
            " ",
            "38",
            " years",
            " in",
            " ",
            "201",
            "7",
            ",",
            " being",
            " peacefully",
            " succeeded"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.469,
            0.245,
            0.293,
            0.539,
            0.365,
            -0.0,
            0.14,
            0.235,
            0.166,
            0.144,
            0.193,
            0.195,
            0.293,
            -0.0,
            0.508,
            -0.0,
            -0.0,
            0.186,
            -0.0,
            -0.0,
            0.235,
            0.113,
            0.273,
            0.31,
            0.527,
            0.359,
            0.367,
            0.644,
            0.206,
            0.168,
            0.277,
            -0.0,
            0.32,
            -0.0,
            -0.0,
            0.289,
            0.152,
            0.275,
            0.256,
            0.231,
            0.112,
            0.033,
            0.609,
            0.402,
            0.432,
            0.457,
            0.129,
            0.508,
            0.43,
            0.445,
            0.256,
            0.43,
            0.445,
            0.35,
            0.633,
            0.707,
            0.699,
            0.578,
            -0.0,
            0.291,
            0.379
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            " Zeus",
            " made",
            " her",
            " choose",
            " between",
            " them",
            ",",
            " and",
            " she",
            " chose",
            " Id",
            "as",
            " on",
            " the",
            " grounds",
            " that",
            " Apollo",
            ",",
            " being",
            " immortal",
            ",",
            " would",
            " tire",
            " of",
            " her",
            " when",
            " she",
            " grew",
            " old",
            ".",
            "Sin",
            "ope",
            ",",
            " a",
            " nymph",
            ",",
            " was",
            " approached",
            " by",
            " the",
            " am",
            "orous",
            " Apollo",
            ".",
            " She",
            " made",
            " him",
            " promise",
            " that",
            " he",
            " would",
            " grant",
            " to",
            " her",
            " whatever",
            " she",
            " would",
            " ask",
            " for",
            ",",
            " and",
            " then"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.034,
            0.008,
            -0.0,
            -0.0,
            0.408,
            0.037,
            0.067,
            0.346,
            0.275,
            0.092,
            -0.0,
            -0.0,
            0.455,
            0.551,
            0.318,
            0.648,
            0.336,
            0.21,
            0.186,
            0.168,
            0.629,
            0.668,
            0.453,
            -0.0,
            0.258,
            0.164,
            0.158,
            0.268,
            -0.0,
            0.26,
            0.056,
            0.566,
            0.195,
            0.26,
            -0.0,
            -0.0,
            0.077,
            -0.0,
            0.152,
            -0.0,
            -0.0,
            0.244,
            -0.0,
            0.226,
            0.215,
            -0.0,
            0.213,
            -0.0,
            -0.0,
            0.531,
            0.684,
            0.293,
            -0.0,
            0.273,
            0.078,
            -0.0,
            0.197,
            -0.0,
            -0.0,
            0.354,
            0.2,
            0.504
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            " symbol",
            " in",
            " the",
            " Princip",
            "ality",
            " of",
            " Arb",
            "Ã«r",
            " and",
            " among",
            " notable",
            " Alban",
            "ian",
            " dyn",
            "ast",
            "ies",
            " such",
            " as",
            " the",
            " D",
            "uk",
            "ag",
            "j",
            "ini",
            ",",
            " K",
            "ast",
            "riot",
            "i",
            ",",
            " M",
            "uz",
            "aka",
            " and",
            " Th",
            "opia",
            " clans",
            ".",
            " Amid",
            " the",
            " Alban",
            "ian",
            " Renaissance",
            ",",
            " marking",
            " the",
            " resurgence",
            " of",
            " Alban",
            "ian",
            " national",
            " identity",
            " and",
            " aspirations",
            " for",
            " independence",
            ",",
            " the",
            " Alban",
            "ian",
            " eagle",
            " regained",
            " its"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.273,
            0.098,
            0.017,
            0.235,
            0.095,
            -0.0,
            0.25,
            0.32,
            -0.0,
            0.412,
            0.543,
            0.209,
            0.014,
            0.118,
            0.163,
            0.153,
            0.066,
            -0.0,
            0.059,
            0.547,
            -0.0,
            -0.0,
            0.496,
            0.318,
            -0.0,
            -0.0,
            0.111,
            0.227,
            0.112,
            0.056,
            0.293,
            0.123,
            -0.0,
            0.148,
            -0.0,
            0.25,
            0.535,
            -0.0,
            0.133,
            0.295,
            0.664,
            -0.0,
            0.158,
            0.348,
            -0.0,
            0.215,
            0.036,
            -0.0,
            0.098,
            0.084,
            0.527,
            0.508,
            0.332,
            0.064,
            0.266,
            0.344,
            0.15,
            0.375,
            0.287,
            0.559,
            0.309,
            0.162
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            " wide",
            " use",
            " of",
            " the",
            " language",
            ".",
            "Ar",
            "uba",
            " has",
            " newspapers",
            " published",
            " in",
            " P",
            "api",
            "amento",
            ":",
            " Di",
            "ario",
            ",",
            " Bon",
            " Dia",
            ",",
            " Solo",
            " di",
            " P",
            "ueblo",
            ",",
            " and",
            " A",
            "we",
            " Maint",
            "a",
            ";",
            " English",
            ":",
            " Ar",
            "uba",
            " Daily",
            ",",
            " Ar",
            "uba",
            " Today",
            ",",
            " and",
            " The",
            " News",
            ";",
            " and",
            " Dutch",
            ":",
            " Am",
            "ig",
            "oe",
            ".",
            " Ar",
            "uba",
            " has",
            " ",
            "18",
            " radio",
            " stations",
            " (",
            "two"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.124,
            0.504,
            0.037,
            -0.0,
            0.122,
            -0.0,
            -0.0,
            0.051,
            0.273,
            -0.0,
            0.328,
            0.109,
            0.273,
            0.543,
            0.272,
            0.291,
            0.373,
            0.383,
            0.165,
            0.179,
            0.116,
            0.336,
            0.471,
            0.432,
            0.363,
            -0.0,
            0.202,
            0.222,
            0.037,
            0.268,
            -0.0,
            0.176,
            0.205,
            -0.0,
            0.486,
            0.652,
            0.523,
            0.424,
            -0.0,
            0.165,
            -0.0,
            0.097,
            0.117,
            0.081,
            0.06,
            -0.0,
            0.213,
            0.159,
            0.262,
            0.13,
            -0.0,
            0.385,
            0.441,
            0.428,
            -0.0,
            0.27,
            0.164,
            0.373,
            0.644,
            0.193,
            0.629
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " fr",
            "igid",
            " zones",
            "),",
            " and",
            " includes",
            " mostly",
            " herb",
            "aceous",
            " species",
            ",",
            " although",
            " a",
            " small",
            " number",
            " of",
            " trees",
            " (",
            "such",
            " as",
            " the",
            " Lob",
            "elia",
            " deck",
            "en",
            "ii",
            ",",
            " the",
            " giant",
            " lob",
            "elia",
            ",",
            " and",
            " D",
            "end",
            "ros",
            "en",
            "ec",
            "io",
            ",",
            " giant",
            " grounds",
            "els",
            ")",
            " and",
            " shr",
            "ubs",
            " are",
            " also",
            " present",
            ".",
            "Ast",
            "era",
            "les",
            " are",
            " organisms",
            " that",
            " seem",
            " to",
            " have",
            " evolved",
            " from"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.183,
            -0.0,
            0.598,
            0.009,
            -0.0,
            0.025,
            0.273,
            0.192,
            -0.0,
            0.606,
            -0.0,
            0.166,
            -0.0,
            0.283,
            0.249,
            0.197,
            0.188,
            0.117,
            0.158,
            0.273,
            0.221,
            0.179,
            0.051,
            0.009,
            0.644,
            0.379,
            0.574,
            0.4,
            0.232,
            0.463,
            0.042,
            -0.0,
            0.369,
            0.243,
            0.154,
            0.244,
            0.309,
            0.053,
            0.539,
            0.455,
            0.279,
            0.488,
            -0.0,
            0.613,
            0.32,
            0.27,
            0.175,
            0.326,
            0.43,
            0.206,
            0.527,
            0.309,
            0.297,
            0.305,
            0.226,
            0.43,
            0.369,
            -0.0,
            0.488,
            0.52,
            0.477,
            0.228
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "cock",
            " regarded",
            " actors",
            " as",
            " \"",
            "animated",
            " props",
            "\".",
            " For",
            " Hitch",
            "cock",
            ",",
            " the",
            " actors",
            " were",
            " part",
            " of",
            " the",
            " film",
            "'s",
            " setting",
            ".",
            " He",
            " told",
            " FranÃ§ois",
            " Tr",
            "uff",
            "aut",
            ":",
            " \"",
            "The",
            " chief",
            " requisite",
            " for",
            " an",
            " actor",
            " is",
            " the",
            " ability",
            " to",
            " do",
            " nothing",
            " well",
            ",",
            " which",
            " is",
            " by",
            " no",
            " means",
            " as",
            " easy",
            " as",
            " it",
            " sounds",
            ".",
            " He",
            " should",
            " be",
            " willing",
            " to",
            " be",
            " used",
            " and"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "à¹ģà¸Ļ",
    " Hond",
    "çļ",
    " '\\''",
    "stery"
  ],
  "bottom_logits": [
    "591",
    "ogh",
    "UBLIC",
    "irut",
    " ØªÙĤÙĪ"
  ],
  "act_min": -0.0,
  "act_max": 1.414
}
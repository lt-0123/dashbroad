{
  "index": 80269,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.785,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            "ko",
            " highly",
            ".",
            " He",
            " said",
            " of",
            " D",
            "ov",
            "z",
            "hen",
            "ko",
            "'s",
            " Earth",
            ":",
            " \"",
            "I",
            " have",
            " lived",
            " a",
            " lot",
            " among",
            " very",
            " simple",
            " farmers",
            " and",
            " met",
            " extraordinary",
            " people",
            ".",
            " They",
            " spread",
            " calm",
            "ness",
            ",",
            " had",
            " such",
            " tact",
            ",",
            " they",
            " conveyed",
            " a",
            " feeling",
            " of",
            " dignity",
            " and",
            " displayed",
            " wisdom",
            " that",
            " I",
            " have",
            " seldom",
            " come",
            " across",
            " on",
            " such",
            " a",
            " scale",
            ".",
            " D",
            "ov",
            "z",
            "hen",
            "ko"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.785,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            "ko",
            " highly",
            ".",
            " He",
            " said",
            " of",
            " D",
            "ov",
            "z",
            "hen",
            "ko",
            "'s",
            " Earth",
            ":",
            " \"",
            "I",
            " have",
            " lived",
            " a",
            " lot",
            " among",
            " very",
            " simple",
            " farmers",
            " and",
            " met",
            " extraordinary",
            " people",
            ".",
            " They",
            " spread",
            " calm",
            "ness",
            ",",
            " had",
            " such",
            " tact",
            ",",
            " they",
            " conveyed",
            " a",
            " feeling",
            " of",
            " dignity",
            " and",
            " displayed",
            " wisdom",
            " that",
            " I",
            " have",
            " seldom",
            " come",
            " across",
            " on",
            " such",
            " a",
            " scale",
            ".",
            " D",
            "ov",
            "z",
            "hen",
            "ko"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.77,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            " They",
            " had",
            " an",
            " instant",
            " rapport",
            ",",
            " with",
            " Chap",
            "lin",
            " inviting",
            " Einstein",
            " and",
            " his",
            " wife",
            ",",
            " Elsa",
            ",",
            " to",
            " his",
            " home",
            " for",
            " dinner",
            ".",
            " Chap",
            "lin",
            " said",
            " Einstein",
            "'s",
            " outward",
            " persona",
            ",",
            " calm",
            " and",
            " gentle",
            ",",
            " seemed",
            " to",
            " conceal",
            " a",
            " \"",
            "high",
            "ly",
            " emotional",
            " temperament",
            "\",",
            " from",
            " which",
            " came",
            " his",
            " \"",
            "extra",
            "ordinary",
            " intellectual",
            " energy",
            "\".",
            "Ch",
            "ap",
            "lin",
            "'s",
            " film",
            ",",
            " City",
            " Lights"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.766,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            " lawsuit",
            " that",
            " eventually",
            " leads",
            " to",
            " Mid",
            "as",
            " Mull",
            "igan",
            " and",
            " Judge",
            " Narr",
            "ag",
            "ans",
            "ett",
            " joining",
            " the",
            " strike",
            ".",
            " A",
            " failed",
            " businessman",
            ",",
            " he",
            " l",
            "aments",
            " constantly",
            " that",
            " no",
            "-one",
            " ever",
            " gave",
            " him",
            " a",
            " chance",
            ".",
            "G",
            "wen",
            " I",
            "ves",
            " is",
            " Hank",
            " Re",
            "arden",
            "'s",
            " secretary",
            ",",
            " described",
            " as",
            " being",
            " in",
            " her",
            " late",
            " twenties",
            " and",
            " remaining",
            " calm",
            " and",
            " professional",
            " despite",
            " the",
            " chaos",
            " that"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.762,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            " not",
            " be",
            " the",
            " first",
            " to",
            " walk",
            " on",
            " the",
            " Moon",
            ".",
            " They",
            " argued",
            " that",
            " the",
            " first",
            " person",
            " to",
            " walk",
            " on",
            " the",
            " Moon",
            " should",
            " be",
            " like",
            " Charles",
            " Lind",
            "ber",
            "gh",
            ",",
            " a",
            " calm",
            " and",
            " quiet",
            " person",
            ".",
            " They",
            " made",
            " the",
            " decision",
            " to",
            " change",
            " the",
            " flight",
            " plan",
            " so",
            " the",
            " commander",
            " was",
            " the",
            " first",
            " to",
            " e",
            "gress",
            " from",
            " the",
            " spacecraft",
            ".",
            "Pre",
            "-launch",
            " ",
            "The",
            " ascent",
            " stage"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.762,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            " not",
            " be",
            " the",
            " first",
            " to",
            " walk",
            " on",
            " the",
            " Moon",
            ".",
            " They",
            " argued",
            " that",
            " the",
            " first",
            " person",
            " to",
            " walk",
            " on",
            " the",
            " Moon",
            " should",
            " be",
            " like",
            " Charles",
            " Lind",
            "ber",
            "gh",
            ",",
            " a",
            " calm",
            " and",
            " quiet",
            " person",
            ".",
            " They",
            " made",
            " the",
            " decision",
            " to",
            " change",
            " the",
            " flight",
            " plan",
            " so",
            " the",
            " commander",
            " was",
            " the",
            " first",
            " to",
            " e",
            "gress",
            " from",
            " the",
            " spacecraft",
            ".",
            "Pre",
            "-launch",
            " ",
            "The",
            " ascent",
            " stage"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.758,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            " military",
            " airl",
            "ift",
            " immediately",
            " began",
            " shipping",
            " relief",
            " supplies",
            " to",
            " Alaska",
            ",",
            " eventually",
            " delivering",
            " ",
            " of",
            " food",
            " and",
            " other",
            " supplies",
            ".",
            " Broadcast",
            " journalist",
            ",",
            " Gen",
            "ie",
            " Chance",
            ",",
            " assisted",
            " in",
            " recovery",
            " and",
            " relief",
            " efforts",
            ",",
            " staying",
            " on",
            " the",
            " K",
            "EN",
            "I",
            " air",
            " waves",
            " over",
            " Anch",
            "orage",
            " for",
            " more",
            " than",
            " ",
            "24",
            " continuous",
            " hours",
            " as",
            " the",
            " voice",
            " of",
            " calm",
            " from",
            " her",
            " temporary",
            " post",
            " within",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.758,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            " military",
            " airl",
            "ift",
            " immediately",
            " began",
            " shipping",
            " relief",
            " supplies",
            " to",
            " Alaska",
            ",",
            " eventually",
            " delivering",
            " ",
            " of",
            " food",
            " and",
            " other",
            " supplies",
            ".",
            " Broadcast",
            " journalist",
            ",",
            " Gen",
            "ie",
            " Chance",
            ",",
            " assisted",
            " in",
            " recovery",
            " and",
            " relief",
            " efforts",
            ",",
            " staying",
            " on",
            " the",
            " K",
            "EN",
            "I",
            " air",
            " waves",
            " over",
            " Anch",
            "orage",
            " for",
            " more",
            " than",
            " ",
            "24",
            " continuous",
            " hours",
            " as",
            " the",
            " voice",
            " of",
            " calm",
            " from",
            " her",
            " temporary",
            " post",
            " within",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.75,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " Most",
            " are",
            " calm",
            " and",
            " doc",
            "ile",
            " but",
            " should",
            " be",
            " handled",
            " carefully",
            ".",
            " G",
            "room",
            "ing",
            " is",
            " necessary",
            " to",
            " prevent",
            " the",
            " fiber",
            " from",
            " mat",
            "ting",
            " and",
            " fel",
            "ting",
            " on",
            " the",
            " rabbit",
            ".",
            " A",
            " condition",
            " called",
            " \"",
            "wo",
            "ol",
            " block",
            "\"",
            " is",
            " common",
            " in",
            " Ang",
            "ora",
            " rabbits",
            " and",
            " should",
            " be",
            " treated",
            " quickly",
            ".",
            " Sometimes",
            " they",
            " are",
            " sh",
            "orn",
            " in",
            " the",
            " summer",
            " as",
            " the",
            " long",
            " fur"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.746,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " become",
            " calm",
            " and",
            " flexible",
            " in",
            " the",
            " disadvantage",
            "ous",
            ",",
            " off",
            "-b",
            "alance",
            " positions",
            " in",
            " which",
            " ",
            " places",
            " them",
            ".",
            " This",
            " \"",
            "re",
            "ceiving",
            "\"",
            " of",
            " the",
            " technique",
            " is",
            " called",
            " .",
            " ",
            " continuously",
            " seeks",
            " to",
            " regain",
            " balance",
            " and",
            " cover",
            " vulnerabilities",
            " (",
            "e",
            ".g",
            ".,",
            " an",
            " exposed",
            " side",
            "),",
            " while",
            " ",
            " uses",
            " position",
            " and",
            " timing",
            " to",
            " keep",
            " ",
            " off",
            "-b",
            "alance",
            " and",
            " vulnerable",
            "."
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.038,
            -0.0,
            -0.0,
            -0.0,
            0.723,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.176,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.056,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " was",
            " called",
            " as",
            " Del",
            "os",
            ".",
            "H",
            "era",
            " was",
            " no",
            " more",
            " angry",
            " as",
            " Zeus",
            " had",
            " managed",
            " to",
            " calm",
            " her",
            " down",
            ",",
            " and",
            " she",
            " held",
            " no",
            " gr",
            "udge",
            " against",
            " Aster",
            "ia",
            " due",
            " to",
            " the",
            " fact",
            " that",
            " Aster",
            "ia",
            " had",
            " rejected",
            " Zeus",
            " in",
            " the",
            " past",
            ".",
            " ",
            " ",
            "P",
            "ind",
            "ar",
            "'s",
            " fragments",
            "P",
            "ind",
            "ar",
            " is",
            " the",
            " earliest",
            " source",
            " who",
            " explicitly",
            " calls"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.038,
            -0.0,
            -0.0,
            -0.0,
            0.723,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.176,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.056,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " was",
            " called",
            " as",
            " Del",
            "os",
            ".",
            "H",
            "era",
            " was",
            " no",
            " more",
            " angry",
            " as",
            " Zeus",
            " had",
            " managed",
            " to",
            " calm",
            " her",
            " down",
            ",",
            " and",
            " she",
            " held",
            " no",
            " gr",
            "udge",
            " against",
            " Aster",
            "ia",
            " due",
            " to",
            " the",
            " fact",
            " that",
            " Aster",
            "ia",
            " had",
            " rejected",
            " Zeus",
            " in",
            " the",
            " past",
            ".",
            " ",
            " ",
            "P",
            "ind",
            "ar",
            "'s",
            " fragments",
            "P",
            "ind",
            "ar",
            " is",
            " the",
            " earliest",
            " source",
            " who",
            " explicitly",
            " calls"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.719,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " sea",
            " to",
            " calm",
            ".",
            " Any",
            " other",
            " answer",
            " would",
            " cause",
            " the",
            " mer",
            "maid",
            " to",
            " turn",
            " into",
            " a",
            " raging",
            " G",
            "org",
            "on",
            " who",
            " would",
            " drag",
            " the",
            " ship",
            " to",
            " the",
            " bottom",
            " of",
            " the",
            " sea",
            ",",
            " all",
            " hands",
            " aboard",
            ".",
            "In",
            " pre",
            "-Isl",
            "amic",
            " Middle",
            " Persian",
            " (",
            "Z",
            "oro",
            "ast",
            "rian",
            ")",
            " literature",
            ",",
            " Alexander",
            " is",
            " referred",
            " to",
            " by",
            " the",
            " epith",
            "et",
            " gu",
            "j",
            "ast",
            "ak"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.719,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " sea",
            " to",
            " calm",
            ".",
            " Any",
            " other",
            " answer",
            " would",
            " cause",
            " the",
            " mer",
            "maid",
            " to",
            " turn",
            " into",
            " a",
            " raging",
            " G",
            "org",
            "on",
            " who",
            " would",
            " drag",
            " the",
            " ship",
            " to",
            " the",
            " bottom",
            " of",
            " the",
            " sea",
            ",",
            " all",
            " hands",
            " aboard",
            ".",
            "In",
            " pre",
            "-Isl",
            "amic",
            " Middle",
            " Persian",
            " (",
            "Z",
            "oro",
            "ast",
            "rian",
            ")",
            " literature",
            ",",
            " Alexander",
            " is",
            " referred",
            " to",
            " by",
            " the",
            " epith",
            "et",
            " gu",
            "j",
            "ast",
            "ak"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.535,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " volcanic",
            ",",
            " forming",
            " along",
            " island",
            " arcs",
            " generated",
            " by",
            " sub",
            "duction",
            " zones",
            " or",
            " hot",
            "spots",
            ",",
            " but",
            " may",
            " also",
            " be",
            " the",
            " result",
            " of",
            " erosion",
            ",",
            " deposition",
            ",",
            " and",
            " land",
            " elevation",
            ".",
            " Depending",
            " on",
            " their",
            " geological",
            " origin",
            ",",
            " islands",
            " forming",
            " arch",
            "ipel",
            "agos",
            " can",
            " be",
            " referred",
            " to",
            " as",
            " ocean",
            "ic",
            " islands",
            ",",
            " continental",
            " fragments",
            ",",
            " or",
            " continental",
            " islands",
            ".",
            "Ocean",
            "ic",
            " islands",
            "Ocean",
            "ic"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.516,
            -0.0
          ],
          "train_token_ind": 61,
          "is_repeated_datapoint": false,
          "tokens": [
            " D",
            ".",
            " McC",
            "urdy",
            "–",
            "B",
            "ald",
            "win",
            " and",
            " McC",
            "urdy",
            " being",
            " new",
            " engineering",
            " graduates",
            " from",
            " the",
            " University",
            " of",
            " Toronto",
            ".",
            "The",
            " A",
            "EA",
            "'s",
            " work",
            " progressed",
            " to",
            " heavier",
            "-than",
            "-air",
            " machines",
            ",",
            " applying",
            " their",
            " knowledge",
            " of",
            " k",
            "ites",
            " to",
            " gl",
            "iders",
            ".",
            " Moving",
            " to",
            " Ham",
            "monds",
            "port",
            ",",
            " the",
            " group",
            " then",
            " designed",
            " and",
            " built",
            " the",
            " Red",
            " Wing",
            ",",
            " framed",
            " in",
            " bamboo",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.504,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " has",
            " produced",
            " volcanic",
            " islands",
            ".",
            " While",
            " nine",
            " of",
            " these",
            " have",
            " collectively",
            " been",
            " nominated",
            " a",
            " World",
            " Heritage",
            " Site",
            " for",
            " their",
            " geological",
            " value",
            ",",
            " four",
            " of",
            " them",
            " are",
            " considered",
            " of",
            " \"",
            "Out",
            "standing",
            " Universal",
            " Value",
            "\"",
            " based",
            " on",
            " their",
            " cultural",
            " and",
            " natural",
            " criteria",
            ":",
            " Ã",
            "ŀ",
            "ing",
            "vell",
            "ir",
            ",",
            " Iceland",
            ";",
            " Landscape",
            " of",
            " the",
            " P",
            "ico",
            " Island",
            " Vine",
            "yard",
            " Culture",
            ",",
            " Portugal",
            ";",
            " G"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.504,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " has",
            " produced",
            " volcanic",
            " islands",
            ".",
            " While",
            " nine",
            " of",
            " these",
            " have",
            " collectively",
            " been",
            " nominated",
            " a",
            " World",
            " Heritage",
            " Site",
            " for",
            " their",
            " geological",
            " value",
            ",",
            " four",
            " of",
            " them",
            " are",
            " considered",
            " of",
            " \"",
            "Out",
            "standing",
            " Universal",
            " Value",
            "\"",
            " based",
            " on",
            " their",
            " cultural",
            " and",
            " natural",
            " criteria",
            ":",
            " Ã",
            "ŀ",
            "ing",
            "vell",
            "ir",
            ",",
            " Iceland",
            ";",
            " Landscape",
            " of",
            " the",
            " P",
            "ico",
            " Island",
            " Vine",
            "yard",
            " Culture",
            ",",
            " Portugal",
            ";",
            " G"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            "gy",
            " Peak",
            ",",
            " also",
            " known",
            " as",
            " Mt",
            ".",
            " Obama",
            " from",
            " ",
            "200",
            "8",
            " to",
            " ",
            "201",
            "6",
            ",",
            " is",
            " the",
            " highest",
            " point",
            " on",
            " both",
            " Ant",
            "igua",
            " and",
            " Barb",
            "uda",
            ".",
            " It",
            " is",
            " the",
            " rem",
            "nant",
            " of",
            " a",
            " volcanic",
            " crater",
            " and",
            " rises",
            " a",
            " total",
            " of",
            " ",
            "402",
            " meters",
            ".",
            " Bog",
            "gy",
            " Peak",
            " is",
            " located",
            " in",
            " the",
            " southwest",
            " of",
            " Ant",
            "igua",
            " (",
            "1",
            ",",
            "319"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 33,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " but",
            " there",
            " is",
            " little",
            " danger",
            " in",
            " eating",
            " fish",
            " because",
            " this",
            " arsen",
            "ic",
            " compound",
            " is",
            " nearly",
            " non",
            "-to",
            "xic",
            ".",
            "Environmental",
            " issues",
            "Ex",
            "posure",
            " ",
            "N",
            "aturally",
            " occurring",
            " sources",
            " of",
            " human",
            " exposure",
            " include",
            " volcanic",
            " ash",
            ",",
            " weather",
            "ing",
            " of",
            " minerals",
            " and",
            " ores",
            ",",
            " and",
            " mineral",
            "ized",
            " groundwater",
            ".",
            " Ar",
            "sen",
            "ic",
            " is",
            " also",
            " found",
            " in",
            " food",
            ",",
            " water",
            ",",
            " soil",
            ",",
            " and"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 33,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " but",
            " there",
            " is",
            " little",
            " danger",
            " in",
            " eating",
            " fish",
            " because",
            " this",
            " arsen",
            "ic",
            " compound",
            " is",
            " nearly",
            " non",
            "-to",
            "xic",
            ".",
            "Environmental",
            " issues",
            "Ex",
            "posure",
            " ",
            "N",
            "aturally",
            " occurring",
            " sources",
            " of",
            " human",
            " exposure",
            " include",
            " volcanic",
            " ash",
            ",",
            " weather",
            "ing",
            " of",
            " minerals",
            " and",
            " ores",
            ",",
            " and",
            " mineral",
            "ized",
            " groundwater",
            ".",
            " Ar",
            "sen",
            "ic",
            " is",
            " also",
            " found",
            " in",
            " food",
            ",",
            " water",
            ",",
            " soil",
            ",",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.492,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            " settlements",
            " along",
            " the",
            " European",
            " North",
            " Atlantic",
            " coast",
            " and",
            " retreat",
            " to",
            " the",
            " Mediterranean",
            ".",
            " Following",
            " rapid",
            " climate",
            " changes",
            " at",
            " the",
            " end",
            " of",
            " the",
            " L",
            "GM",
            " this",
            " region",
            " was",
            " rep",
            "op",
            "ulated",
            " by",
            " Mag",
            "d",
            "alen",
            "ian",
            " culture",
            ".",
            " Other",
            " hunter",
            "-g",
            "ather",
            "ers",
            " followed",
            " in",
            " waves",
            " interrupted",
            " by",
            " large",
            "-scale",
            " hazards",
            " such",
            " as",
            " the",
            " La",
            "acher",
            " See",
            " volcanic",
            " eruption",
            ",",
            " the",
            " inund",
            "ation",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.482,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            "an",
            " have",
            " safe",
            " harb",
            "ours",
            " and",
            " b",
            "ays",
            ".",
            " In",
            " ancient",
            " times",
            ",",
            " navigation",
            " through",
            " the",
            " sea",
            " was",
            " easier",
            " than",
            " travelling",
            " across",
            " the",
            " rough",
            " terrain",
            " of",
            " the",
            " Greek",
            " mainland",
            ",",
            " and",
            " to",
            " some",
            " extent",
            ",",
            " the",
            " coastal",
            " areas",
            " of",
            " Anat",
            "olia",
            ".",
            " Many",
            " of",
            " the",
            " islands",
            " are",
            " volcanic",
            ",",
            " and",
            " marble",
            " and",
            " iron",
            " are",
            " mined",
            " on",
            " other",
            " islands",
            ".",
            " The",
            " larger",
            " islands",
            " have"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.482,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 44,
          "is_repeated_datapoint": false,
          "tokens": [
            "\"",
            " and",
            " \"",
            "des",
            "erts",
            " that",
            " had",
            " become",
            " water",
            "ed",
            " by",
            " rivers",
            "\",",
            " giving",
            " as",
            " examples",
            " the",
            " growth",
            " of",
            " the",
            " Nile",
            " delta",
            " since",
            " the",
            " time",
            " of",
            " Homer",
            ",",
            " and",
            " \"",
            "the",
            " uphe",
            "aving",
            " of",
            " one",
            " of",
            " the",
            " Ae",
            "olian",
            " islands",
            ",",
            " previous",
            " to",
            " a",
            " volcanic",
            " eruption",
            ".\"",
            "'",
            "A",
            "rist",
            "otle",
            " also",
            " made",
            " many",
            " observations",
            " about",
            " the",
            " hydro",
            "logic",
            " cycle",
            " and",
            " meteor",
            "ology"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.482,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            "an",
            " have",
            " safe",
            " harb",
            "ours",
            " and",
            " b",
            "ays",
            ".",
            " In",
            " ancient",
            " times",
            ",",
            " navigation",
            " through",
            " the",
            " sea",
            " was",
            " easier",
            " than",
            " travelling",
            " across",
            " the",
            " rough",
            " terrain",
            " of",
            " the",
            " Greek",
            " mainland",
            ",",
            " and",
            " to",
            " some",
            " extent",
            ",",
            " the",
            " coastal",
            " areas",
            " of",
            " Anat",
            "olia",
            ".",
            " Many",
            " of",
            " the",
            " islands",
            " are",
            " volcanic",
            ",",
            " and",
            " marble",
            " and",
            " iron",
            " are",
            " mined",
            " on",
            " other",
            " islands",
            ".",
            " The",
            " larger",
            " islands",
            " have"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.478,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 32,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " communal",
            " land",
            " ownership",
            " by",
            " allowing",
            " residents",
            " to",
            " buy",
            " land",
            ";",
            " a",
            " move",
            " that",
            " has",
            " been",
            " criticised",
            " as",
            " promoting",
            " \"",
            "dis",
            "aster",
            " capitalism",
            "\".",
            "Ge",
            "ography",
            "L",
            "imestone",
            " formations",
            ",",
            " rather",
            " than",
            " volcanic",
            " activity",
            ",",
            " have",
            " had",
            " the",
            " most",
            " impact",
            " on",
            " the",
            " top",
            "ography",
            " of",
            " both",
            " Ant",
            "igua",
            " and",
            " Barb",
            "uda",
            ",",
            " which",
            " are",
            " both",
            " relatively",
            " low",
            "-",
            "lying",
            " islands",
            ".",
            " Bog"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.473,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " fact",
            " exists",
            ",",
            " is",
            " probably",
            " more",
            " complex",
            " and",
            " distant",
            " than",
            " we",
            " can",
            " imagine",
            " on",
            " the",
            " basis",
            " of",
            " our",
            " present",
            " state",
            " of",
            " knowledge",
            "\".",
            "Support",
            "ers",
            " of",
            " the",
            " Alta",
            "ic",
            " hypothesis",
            " formerly",
            " set",
            " the",
            " date",
            " of",
            " the",
            " Proto",
            "-Al",
            "ta",
            "ic",
            " language",
            " at",
            " around",
            " ",
            "400",
            "0",
            " BC",
            ",",
            " but",
            " today",
            " at",
            " around",
            " ",
            "500",
            "0",
            " BC",
            " or",
            " ",
            "600",
            "0",
            " BC",
            ".",
            " This"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.473,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " fact",
            ",",
            " assumes",
            " some",
            " degree",
            " of",
            " violence",
            " will",
            " occur",
            ",",
            " an",
            "ar",
            "cho",
            "-capital",
            "ism",
            " as",
            " formulated",
            " by",
            " Roth",
            "bard",
            " and",
            " others",
            " holds",
            " strongly",
            " to",
            " the",
            " central",
            " libertarian",
            " non",
            "ag",
            "gression",
            " axiom",
            ",",
            " sometimes",
            " non",
            "-ag",
            "gression",
            " principle",
            ".",
            " Roth",
            "bard",
            " wrote",
            ":",
            "R",
            "oth",
            "bard",
            "'s",
            " defense",
            " of",
            " the",
            " self",
            "-",
            "ownership",
            " principle",
            " stems",
            " from",
            " what",
            " he",
            " believed",
            " to",
            " be",
            " his",
            " fals"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.473,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.036,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " fact",
            ",",
            " her",
            " brother",
            "'s",
            " policies",
            " which",
            " directly",
            " threaten",
            " his",
            " business",
            ".",
            " When",
            " the",
            " government",
            " passes",
            " laws",
            " and",
            " decre",
            "es",
            " which",
            " make",
            " it",
            " impossible",
            " for",
            " him",
            " to",
            " continue",
            ",",
            " he",
            " sets",
            " all",
            " his",
            " oil",
            " wells",
            " on",
            " fire",
            ",",
            " leaving",
            " a",
            " single",
            " note",
            ":",
            " \"",
            "I",
            " am",
            " leaving",
            " it",
            " as",
            " I",
            " found",
            " it",
            ".",
            " Take",
            " over",
            ".",
            " It",
            "'s",
            " yours",
            ".\"",
            " One",
            " particular",
            " burning"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.473,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " fact",
            " exists",
            ",",
            " is",
            " probably",
            " more",
            " complex",
            " and",
            " distant",
            " than",
            " we",
            " can",
            " imagine",
            " on",
            " the",
            " basis",
            " of",
            " our",
            " present",
            " state",
            " of",
            " knowledge",
            "\".",
            "Support",
            "ers",
            " of",
            " the",
            " Alta",
            "ic",
            " hypothesis",
            " formerly",
            " set",
            " the",
            " date",
            " of",
            " the",
            " Proto",
            "-Al",
            "ta",
            "ic",
            " language",
            " at",
            " around",
            " ",
            "400",
            "0",
            " BC",
            ",",
            " but",
            " today",
            " at",
            " around",
            " ",
            "500",
            "0",
            " BC",
            " or",
            " ",
            "600",
            "0",
            " BC",
            ".",
            " This"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.473,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " fact",
            ",",
            " assumes",
            " some",
            " degree",
            " of",
            " violence",
            " will",
            " occur",
            ",",
            " an",
            "ar",
            "cho",
            "-capital",
            "ism",
            " as",
            " formulated",
            " by",
            " Roth",
            "bard",
            " and",
            " others",
            " holds",
            " strongly",
            " to",
            " the",
            " central",
            " libertarian",
            " non",
            "ag",
            "gression",
            " axiom",
            ",",
            " sometimes",
            " non",
            "-ag",
            "gression",
            " principle",
            ".",
            " Roth",
            "bard",
            " wrote",
            ":",
            "R",
            "oth",
            "bard",
            "'s",
            " defense",
            " of",
            " the",
            " self",
            "-",
            "ownership",
            " principle",
            " stems",
            " from",
            " what",
            " he",
            " believed",
            " to",
            " be",
            " his",
            " fals"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.471,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " due",
            " to",
            " the",
            " geographic",
            " separation",
            " from",
            " the",
            " continent",
            ".",
            " More",
            " than",
            " ",
            "300",
            " small",
            " volcanic",
            " islands",
            " make",
            " up",
            " this",
            " chain",
            ",",
            " which",
            " stretches",
            " more",
            " than",
            " ",
            " into",
            " the",
            " Pacific",
            " Ocean",
            ".",
            " Some",
            " of",
            " these",
            " islands",
            " fall",
            " in",
            " the",
            " Eastern",
            " Hemisphere",
            ",",
            " but",
            " the",
            " International",
            " Date",
            " Line",
            " was",
            " drawn",
            " west",
            " of",
            " ",
            "180",
            "Â°",
            " to",
            " keep",
            " the",
            " whole",
            " state",
            ",",
            " and",
            " thus",
            " the",
            " entire"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.467,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " islands",
            " are",
            " mainly",
            " of",
            " volcanic",
            " origin",
            ",",
            " and",
            " widely",
            " separated",
            " from",
            " any",
            " adjacent",
            " continent",
            ".",
            " The",
            " Hawaiian",
            " Islands",
            " and",
            " Gal",
            "ap",
            "agos",
            " Islands",
            " in",
            " the",
            " Pacific",
            ",",
            " and",
            " Masc",
            "are",
            "ne",
            " Islands",
            " in",
            " the",
            " south",
            " Indian",
            " Ocean",
            " are",
            " examples",
            ".",
            "Contin",
            "ental",
            " fragments",
            "Contin",
            "ental",
            " fragments",
            " correspond",
            " to",
            " land",
            " masses",
            " that",
            " have",
            " separated",
            " from",
            " a",
            " continental",
            " mass",
            " due",
            " to",
            " t",
            "ect",
            "onic"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.467,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 7,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " time",
            " in",
            " the",
            " hospital",
            "—",
            "feature",
            " prominently",
            " in",
            " his",
            " film",
            " Mirror",
            ".",
            "In",
            " his",
            " school",
            " years",
            ",",
            " T",
            "ark",
            "ovsky",
            " was",
            " a",
            " trouble",
            "maker",
            " and",
            " a",
            " poor",
            " student",
            ".",
            " He",
            " still",
            " managed",
            " to",
            " graduate",
            ",",
            " and",
            " from",
            " ",
            "195",
            "1",
            " to",
            " ",
            "195",
            "2",
            " studied",
            " Arabic",
            " at",
            " the",
            " Oriental",
            " Institute",
            " in",
            " Moscow",
            ",",
            " a",
            " branch",
            " of",
            " the",
            " Academy",
            " of",
            " Sciences",
            " of",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.465,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            " Turkey",
            ".",
            "The",
            " rocks",
            " making",
            " up",
            " the",
            " floor",
            " of",
            " the",
            " Ae",
            "ge",
            "an",
            " are",
            " mainly",
            " limestone",
            ",",
            " though",
            " often",
            " greatly",
            " altered",
            " by",
            " volcanic",
            " activity",
            " that",
            " has",
            " conv",
            "uls",
            "ed",
            " the",
            " region",
            " in",
            " relatively",
            " recent",
            " ge",
            "ologic",
            " times",
            ".",
            " Of",
            " particular",
            " interest",
            " are",
            " the",
            " rich",
            "ly",
            " coloured",
            " sed",
            "iments",
            " in",
            " the",
            " region",
            " of",
            " the",
            " islands",
            " of",
            " Sant",
            "or",
            "ini",
            " and",
            " Mil",
            "os",
            ",",
            " in"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.459,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 39,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "201",
            "8",
            " Coming",
            " Home",
            " Art",
            " &",
            " The",
            " Great",
            " Hunger",
            " exhibition",
            ",",
            " in",
            " partnership",
            " with",
            " The",
            " Great",
            " Hunger",
            " Museum",
            " of",
            " Quinn",
            "ip",
            "iac",
            " University",
            ",",
            " USA",
            ",",
            " featured",
            " Ach",
            "ill",
            "'s",
            " Desert",
            "ed",
            " Village",
            " and",
            " the",
            " island",
            " lazy",
            " beds",
            " prominently",
            " in",
            " works",
            " by",
            " Gerald",
            "ine",
            " O",
            "'Re",
            "illy",
            " and",
            " Al",
            "anna",
            " O",
            "'",
            "Kelly",
            ";",
            " also",
            " included",
            " was",
            " an",
            " ",
            "187",
            "3",
            " painting"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.445,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 48,
          "is_repeated_datapoint": false,
          "tokens": [
            " all",
            " Apple",
            " devices",
            ".",
            " Apple",
            " Voice",
            "Over",
            " includes",
            " the",
            " option",
            " to",
            " magn",
            "ify",
            " the",
            " screen",
            ",",
            " control",
            " the",
            " keyboard",
            ",",
            " and",
            " provide",
            " verbal",
            " descriptions",
            " to",
            " describe",
            " what",
            " is",
            " happening",
            " on",
            " the",
            " screen",
            ".",
            " There",
            " are",
            " thirty",
            " languages",
            " to",
            " select",
            " from",
            ".",
            " It",
            " also",
            " has",
            " the",
            " capacity",
            " to",
            " read",
            " aloud",
            " file",
            " content",
            ",",
            " as",
            " well",
            " as",
            " web",
            " pages",
            ",",
            " E",
            "-mail",
            " messages",
            ",",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.441,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            " inside",
            " a",
            " glass",
            " of",
            " milk",
            ",",
            " perhaps",
            " poisoned",
            ",",
            " that",
            " Grant",
            " is",
            " bringing",
            " to",
            " his",
            " wife",
            ";",
            " the",
            " light",
            " ensures",
            " that",
            " the",
            " audience",
            "'s",
            " attention",
            " is",
            " on",
            " the",
            " glass",
            ".",
            " Grant",
            "'s",
            " character",
            " is",
            " actually",
            " a",
            " killer",
            ",",
            " as",
            " per",
            " written",
            " in",
            " the",
            " book",
            ",",
            " Before",
            " the",
            " Fact",
            " by",
            " Francis",
            " I",
            "les",
            ",",
            " but",
            " the",
            " studio",
            " felt",
            " that",
            " Grant",
            "'s",
            " image",
            " would",
            " be"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.436,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "ts",
            ",",
            " Literature",
            ",",
            " and",
            " Culture",
            "\"",
            " category",
            " by",
            " Asian",
            "Week",
            " magazine",
            " and",
            " CNN",
            ",",
            " cited",
            " there",
            " as",
            " being",
            " among",
            " the",
            " five",
            " people",
            " who",
            " most",
            " prominently",
            " contributed",
            " to",
            " the",
            " improvement",
            " of",
            " Asia",
            " in",
            " the",
            " ",
            "20",
            "th",
            " century",
            ".",
            " His",
            " career",
            " has",
            " been",
            " honored",
            " by",
            " many",
            " retros",
            "pectives",
            ",",
            " critical",
            " studies",
            " and",
            " bi",
            "ographies",
            " in",
            " both",
            " print",
            " and",
            " video",
            ",",
            " and",
            " by",
            " releases"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.434,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            " Ste",
            "ffen",
            " Brand",
            "t",
            ",",
            " St",
            "ig",
            " T",
            "Ã¸",
            "ft",
            "ing",
            ",",
            " Flem",
            "ming",
            " J",
            "Ã¸",
            "rg",
            "ensen",
            ",",
            " Tina",
            " Dick",
            "ow",
            " and",
            " Cam",
            "illa",
            " Martin",
            ".",
            " In",
            " popular",
            " culture",
            ",",
            " the",
            " dialect",
            " features",
            " prominently",
            " in",
            " Ni",
            "els",
            " M",
            "alm",
            "ros",
            "'s",
            " movie",
            " A",
            "arhus",
            " by",
            " Night",
            " and",
            " in",
            " ",
            "90",
            "s",
            " comedy",
            " sketches",
            " by",
            " Jacob",
            " Ha",
            "uga",
            "ard",
            " and",
            " Finn",
            " N",
            "Ã¸r"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.434,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            " Ste",
            "ffen",
            " Brand",
            "t",
            ",",
            " St",
            "ig",
            " T",
            "Ã¸",
            "ft",
            "ing",
            ",",
            " Flem",
            "ming",
            " J",
            "Ã¸",
            "rg",
            "ensen",
            ",",
            " Tina",
            " Dick",
            "ow",
            " and",
            " Cam",
            "illa",
            " Martin",
            ".",
            " In",
            " popular",
            " culture",
            ",",
            " the",
            " dialect",
            " features",
            " prominently",
            " in",
            " Ni",
            "els",
            " M",
            "alm",
            "ros",
            "'s",
            " movie",
            " A",
            "arhus",
            " by",
            " Night",
            " and",
            " in",
            " ",
            "90",
            "s",
            " comedy",
            " sketches",
            " by",
            " Jacob",
            " Ha",
            "uga",
            "ard",
            " and",
            " Finn",
            " N",
            "Ã¸r"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.338,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.33,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 15,
          "is_repeated_datapoint": false,
          "tokens": [
            "8",
            ",",
            " which",
            " replaced",
            " nine",
            " regional",
            " health",
            " authorities",
            ".",
            " A",
            "HS",
            " also",
            " funds",
            " all",
            " ground",
            " ambulance",
            " services",
            " in",
            " the",
            " province",
            ",",
            " as",
            " well",
            " as",
            " the",
            " province",
            "-wide",
            " Shock",
            " Tra",
            "uma",
            " Air",
            " Rescue",
            " Service",
            " (",
            "ST",
            "ARS",
            ")",
            " air",
            " ambulance",
            " service",
            ".",
            "Transport",
            "ation",
            "Air",
            "Albert",
            "a",
            " is",
            " well",
            "-connected",
            " by",
            " air",
            ",",
            " with",
            " international",
            " airports",
            " in",
            " both",
            " Calgary",
            " and",
            " Edmonton",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.334,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 39,
          "is_repeated_datapoint": false,
          "tokens": [
            " problem",
            " of",
            " the",
            " set",
            " with",
            " no",
            " human",
            " intervention",
            " beyond",
            " inserting",
            " the",
            " question",
            " and",
            " (",
            "later",
            ")",
            " reading",
            " the",
            " answer",
            ".",
            " All",
            " three",
            " definitions",
            " are",
            " equivalent",
            ",",
            " so",
            " it",
            " doesn",
            "'t",
            " matter",
            " which",
            " one",
            " is",
            " used",
            ".",
            " Moreover",
            ",",
            " the",
            " fact",
            " that",
            " all",
            " three",
            " are",
            " equivalent",
            " is",
            " a",
            " very",
            " strong",
            " argument",
            " for",
            " the",
            " correctness",
            " of",
            " any",
            " one",
            ".\"",
            " (",
            "Ros",
            "ser",
            " ",
            "193",
            "9"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.328,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            " three",
            "-dimensional",
            " structure",
            " consists",
            " in",
            " dividing",
            " the",
            " mac",
            "rom",
            "olecule",
            " into",
            " sub",
            "units",
            " called",
            " domains",
            ".",
            " The",
            " difficulty",
            " of",
            " this",
            " task",
            " arises",
            " from",
            " the",
            " fact",
            " that",
            " different",
            " definitions",
            " of",
            " what",
            " a",
            " domain",
            " is",
            " can",
            " be",
            " used",
            " (",
            "e",
            ".g",
            ".",
            " folding",
            " autonomy",
            ",",
            " function",
            ",",
            " therm",
            "odynamic",
            " stability",
            ",",
            " or",
            " domain",
            " motions",
            "),",
            " which",
            " sometimes",
            " results",
            " in",
            " a",
            " single",
            " protein",
            " having",
            " different",
            "—"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.324,
            -0.0
          ],
          "train_token_ind": 61,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " formally",
            " object",
            " at",
            " the",
            " time",
            ",",
            " to",
            " what",
            " one",
            " views",
            " as",
            " improper",
            " action",
            " in",
            " the",
            " lower",
            " court",
            ",",
            " may",
            " result",
            " in",
            " the",
            " affirm",
            "ance",
            " of",
            " the",
            " lower",
            " court",
            "'s",
            " judgment",
            " on",
            " the",
            " grounds",
            " that",
            " one",
            " did",
            " not",
            " \"",
            "preserve",
            " the",
            " issue",
            " for",
            " appeal",
            "\"",
            " by",
            " object",
            "ing",
            ".",
            "In",
            " cases",
            " where",
            " a",
            " judge",
            " rather",
            " than",
            " a",
            " jury",
            " decided",
            " issues",
            " of",
            " fact",
            ","
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.301,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 48,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " ant",
            "imony",
            ".",
            " The",
            " uptake",
            " of",
            " ant",
            "imony",
            "(",
            "III",
            ")",
            " or",
            " ant",
            "imony",
            "(V",
            ")",
            " in",
            " the",
            " gastrointestinal",
            " tract",
            " is",
            " at",
            " most",
            " ",
            "20",
            "%.",
            " Ant",
            "imony",
            "(V",
            ")",
            " is",
            " not",
            " quant",
            "it",
            "atively",
            " reduced",
            " to",
            " ant",
            "imony",
            "(",
            "III",
            ")",
            " in",
            " the",
            " cell",
            " (",
            "in",
            " fact",
            " ant",
            "imony",
            "(",
            "III",
            ")",
            " is",
            " oxid",
            "ised",
            " to",
            " ant",
            "imony",
            "(V",
            ")",
            " instead"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.285,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 21,
          "is_repeated_datapoint": false,
          "tokens": [
            "ique",
            " Libre",
            ",",
            " meaning",
            " Free",
            " Atomic",
            " Scale",
            ").",
            "The",
            " instant",
            " that",
            " the",
            " gravitational",
            " correction",
            " started",
            " to",
            " be",
            " applied",
            " serves",
            " as",
            " the",
            " epoch",
            " for",
            " B",
            "ary",
            "cent",
            "ric",
            " Coordinate",
            " Time",
            " (",
            "TC",
            "B",
            "),",
            " Ge",
            "oc",
            "entric",
            " Coordinate",
            " Time",
            " (",
            "TC",
            "G",
            "),",
            " and",
            " Ter",
            "restrial",
            " Time",
            " (",
            "TT",
            "),",
            " which",
            " represent",
            " three",
            " fundamental",
            " time",
            " scales",
            " in",
            " the",
            " solar",
            " system",
            ".",
            " ",
            " All",
            " three"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.275,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            " thriller",
            " fiction",
            ".",
            " Of",
            " the",
            " first",
            ",",
            " Giant",
            "'s",
            " Bread",
            " published",
            " in",
            " ",
            "193",
            "0",
            ",",
            " a",
            " reviewer",
            " for",
            " The",
            " New",
            " York",
            " Times",
            " wrote",
            ",",
            " \"...",
            "her",
            " book",
            " is",
            " far",
            " above",
            " the",
            " average",
            " of",
            " current",
            " fiction",
            ",",
            " in",
            " fact",
            ",",
            " comes",
            " well",
            " under",
            " the",
            " classification",
            " of",
            " a",
            " '",
            "good",
            " book",
            "'.",
            " And",
            " it",
            " is",
            " only",
            " a",
            " satisfying",
            " novel",
            " that",
            " can",
            " claim",
            " that",
            " app"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.266,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 17,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " element",
            " undergo",
            " beta",
            " decay",
            ",",
            " though",
            " nuclear",
            " mass",
            " measurements",
            " indicate",
            " that",
            " ",
            "215",
            "At",
            " is",
            " in",
            " fact",
            " beta",
            "-st",
            "able",
            ",",
            " as",
            " it",
            " has",
            " the",
            " lowest",
            " mass",
            " of",
            " all",
            " is",
            "ob",
            "ars",
            " with",
            " A",
            "Âł",
            "=",
            "Âł",
            "215",
            ".",
            " A",
            " beta",
            " decay",
            " mode",
            " has",
            " been",
            " found",
            " for",
            " all",
            " other",
            " a",
            "stat",
            "ine",
            " isot",
            "opes",
            " except",
            " for",
            " a",
            "stat",
            "ine",
            "-",
            "213",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.201,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 21,
          "is_repeated_datapoint": false,
          "tokens": [
            " electric",
            " chair",
            ".",
            " Then",
            " you",
            "'re",
            " as",
            " happy",
            " as",
            " can",
            " be",
            " when",
            " you",
            " wake",
            " up",
            " because",
            " you",
            "'re",
            " relieved",
            ".\"",
            " During",
            " filming",
            " of",
            " North",
            " by",
            " Northwest",
            ",",
            " Hitch",
            "cock",
            " explained",
            " his",
            " reasons",
            " for",
            " recre",
            "ating",
            " the",
            " set",
            " of",
            " Mount",
            " Rush",
            "more",
            ":",
            " \"",
            "The",
            " audience",
            " responds",
            " in",
            " proportion",
            " to",
            " how",
            " realistic",
            " you",
            " make",
            " it",
            ".",
            " One",
            " of",
            " the",
            " dramatic",
            " reasons",
            " for",
            " this",
            " type"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " social",
            " choice",
            " theory",
            ",",
            " and",
            " for",
            " his",
            " interest",
            " in",
            " the",
            " problems",
            " of",
            " society",
            "'s",
            " poorest",
            " members",
            ".",
            "Other",
            " Asian",
            " Nobel",
            " Prize",
            " winners",
            " include",
            " Sub",
            "rah",
            "man",
            "yan",
            " Chand",
            "rase",
            "k",
            "har",
            ",",
            " Abd",
            "us",
            " Sal",
            "am",
            ",",
            " Mal",
            "ala",
            " Y",
            "ous",
            "af",
            "z",
            "ai",
            ",",
            " Robert",
            " A",
            "umann",
            ",",
            " Men",
            "ach",
            "em",
            " Begin",
            ",",
            " Aaron",
            " C",
            "ie",
            "chan",
            "over",
            ",",
            " Av",
            "ram",
            " H"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " honor",
            ",",
            " he",
            " built",
            " the",
            " city",
            " Cy",
            "rene",
            " and",
            " made",
            " her",
            " its",
            " ruler",
            ".",
            " She",
            " was",
            " later",
            " granted",
            " longevity",
            " by",
            " Apollo",
            " who",
            " turned",
            " her",
            " into",
            " a",
            " nymph",
            ".",
            " The",
            " couple",
            " had",
            " two",
            " sons",
            ",",
            " Arist",
            "ae",
            "us",
            ",",
            " and",
            " Id",
            "mon",
            ".",
            "Ev",
            "ad",
            "ne",
            " was",
            " a",
            " nymph",
            " daughter",
            " of",
            " Pose",
            "idon",
            " and",
            " a",
            " lover",
            " of",
            " Apollo",
            ".",
            " They",
            " had",
            " a",
            " son",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " life",
            " issues",
            ".",
            "Al",
            "leg",
            "ations",
            " of",
            " a",
            " lack",
            " of",
            " diversity",
            " ",
            "The",
            " Academy",
            " Awards",
            " have",
            " long",
            " received",
            " criticism",
            " over",
            " its",
            " lack",
            " of",
            " diversity",
            " among",
            " the",
            " nominees",
            ".",
            " This",
            " criticism",
            " is",
            " based",
            " on",
            " the",
            " statistics",
            " from",
            " every",
            " Academy",
            " Awards",
            " since",
            " ",
            "192",
            "9",
            ",",
            " which",
            " show",
            " that",
            " only",
            " ",
            "6",
            ".",
            "4",
            "%",
            " of",
            " academy",
            " award",
            " nominees",
            " have",
            " been",
            " non",
            "-white",
            " and",
            " since"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " growing",
            " use",
            " of",
            " aluminium",
            " beverage",
            " cans",
            " brought",
            " it",
            " to",
            " public",
            " awareness",
            ".",
            " Recycling",
            " involves",
            " melting",
            " the",
            " scrap",
            ",",
            " a",
            " process",
            " that",
            " requires",
            " only",
            " ",
            "5",
            "%",
            " of",
            " the",
            " energy",
            " used",
            " to",
            " produce",
            " aluminium",
            " from",
            " ore",
            ",",
            " though",
            " a",
            " significant",
            " part",
            " (",
            "up",
            " to",
            " ",
            "15",
            "%",
            " of",
            " the",
            " input",
            " material",
            ")",
            " is",
            " lost",
            " as",
            " d",
            "ross",
            " (",
            "ash",
            "-like",
            " oxide",
            ").",
            " An",
            " aluminium"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " primary",
            " is",
            " of",
            " magnitude",
            " ",
            "5",
            ".",
            "3",
            " and",
            " the",
            " secondary",
            " is",
            " of",
            " magnitude",
            " ",
            "8",
            ".",
            "5",
            ".",
            " The",
            " primary",
            " is",
            " ",
            "776",
            " light",
            "-years",
            " from",
            " Earth",
            ".",
            " The",
            " primary",
            " itself",
            " is",
            " a",
            " wide",
            " double",
            " star",
            " with",
            " a",
            " separation",
            " of",
            " ",
            "25",
            ".",
            "2",
            " arc",
            "seconds",
            ";",
            " the",
            " tertiary",
            " has",
            " a",
            " magnitude",
            " of",
            " ",
            "10",
            ".",
            "8",
            ".",
            " The",
            " primary",
            " and",
            " secondary"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "éĺħè¯»æ¬¡æķ°",
    "DataExchange",
    "avana",
    "çĽĳåĲ¬é¡µéĿ¢",
    "ÏģÎ¹Î¬"
  ],
  "bottom_logits": [
    " ",
    "y",
    " Watkins",
    "arro",
    " bore"
  ],
  "act_min": -0.0,
  "act_max": 0.785
}
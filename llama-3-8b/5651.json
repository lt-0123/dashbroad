{
  "index": 5651,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.664,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 44,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " the",
            " city",
            " as",
            " tourists",
            ".",
            " The",
            " ad",
            " shows",
            " young",
            " men",
            " being",
            " handc",
            "uffed",
            " by",
            " police",
            " and",
            " is",
            " part",
            " of",
            " a",
            " new",
            " campaign",
            " to",
            " clean",
            " up",
            " the",
            " city",
            "'s",
            " reputation",
            ".",
            " On",
            " May",
            " ",
            "25",
            ",",
            " ",
            "202",
            "3",
            ",",
            " in",
            " a",
            " bid",
            " to",
            " crackdown",
            " on",
            " wild",
            " tourist",
            " behaviour",
            ",",
            " the",
            " city",
            " banned",
            " weed",
            " smoking",
            " in",
            " public",
            " areas",
            " in",
            " and",
            " around",
            " the",
            " red"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.664,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 44,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " the",
            " city",
            " as",
            " tourists",
            ".",
            " The",
            " ad",
            " shows",
            " young",
            " men",
            " being",
            " handc",
            "uffed",
            " by",
            " police",
            " and",
            " is",
            " part",
            " of",
            " a",
            " new",
            " campaign",
            " to",
            " clean",
            " up",
            " the",
            " city",
            "'s",
            " reputation",
            ".",
            " On",
            " May",
            " ",
            "25",
            ",",
            " ",
            "202",
            "3",
            ",",
            " in",
            " a",
            " bid",
            " to",
            " crackdown",
            " on",
            " wild",
            " tourist",
            " behaviour",
            ",",
            " the",
            " city",
            " banned",
            " weed",
            " smoking",
            " in",
            " public",
            " areas",
            " in",
            " and",
            " around",
            " the",
            " red"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.551,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            "os",
            ").",
            " The",
            " maid",
            "ens",
            " participated",
            " with",
            " joyful",
            " songs",
            ".",
            " ",
            "Ch",
            "ios",
            ":",
            " An",
            " Ionic",
            " temple",
            " of",
            " Apollo",
            " Ph",
            "an",
            "ai",
            "os",
            " was",
            " built",
            " at",
            " the",
            " end",
            " of",
            " the",
            " ",
            "6",
            "th",
            " century",
            " BC",
            ".",
            " Only",
            " some",
            " small",
            " parts",
            " have",
            " been",
            " found",
            " and",
            " the",
            " capitals",
            " had",
            " floral",
            " ornament",
            ".",
            " ",
            "A",
            "ba",
            "e",
            " (",
            "Ph",
            "oc",
            "is",
            ").",
            " The",
            " temple",
            " was",
            " destroyed"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.551,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            "os",
            ").",
            " The",
            " maid",
            "ens",
            " participated",
            " with",
            " joyful",
            " songs",
            ".",
            " ",
            "Ch",
            "ios",
            ":",
            " An",
            " Ionic",
            " temple",
            " of",
            " Apollo",
            " Ph",
            "an",
            "ai",
            "os",
            " was",
            " built",
            " at",
            " the",
            " end",
            " of",
            " the",
            " ",
            "6",
            "th",
            " century",
            " BC",
            ".",
            " Only",
            " some",
            " small",
            " parts",
            " have",
            " been",
            " found",
            " and",
            " the",
            " capitals",
            " had",
            " floral",
            " ornament",
            ".",
            " ",
            "A",
            "ba",
            "e",
            " (",
            "Ph",
            "oc",
            "is",
            ").",
            " The",
            " temple",
            " was",
            " destroyed"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.523,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 17,
          "is_repeated_datapoint": false,
          "tokens": [
            "ate",
            ".",
            " There",
            " was",
            " a",
            " double",
            " row",
            " of",
            " sixteen",
            " inner",
            " columns",
            " on",
            " sty",
            "lob",
            "ates",
            ".",
            " The",
            " capitals",
            " were",
            " made",
            " from",
            " stone",
            ".",
            " ",
            "N",
            "au",
            "kr",
            "atis",
            ":",
            " An",
            " Ionic",
            " temple",
            " was",
            " built",
            " in",
            " the",
            " early",
            " ",
            "6",
            "th",
            " century",
            " BC",
            ".",
            " Only",
            " some",
            " fragments",
            " have",
            " been",
            " found",
            " and",
            " the",
            " earlier",
            " ones",
            ",",
            " made",
            " from",
            " limestone",
            ",",
            " are",
            " identified",
            " among",
            " the",
            " oldest"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.523,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            " Mess",
            "ier",
            " ",
            "31",
            " (",
            "And",
            "rom",
            "eda",
            " Galaxy",
            ")",
            " in",
            " the",
            " outskirts",
            " of",
            " its",
            " halo",
            ".",
            " Peg",
            " V",
            " was",
            " initially",
            " identified",
            " in",
            " the",
            " DES",
            "I",
            " Legacy",
            " Imaging",
            " Sur",
            "veys",
            " by",
            " the",
            " Italian",
            " amateur",
            " astronom",
            "er",
            " Gi",
            "useppe",
            " Don",
            "ati",
            "ello",
            ".",
            "Pr",
            "izes",
            " recognizing",
            " amateur",
            " astronomers",
            " ",
            " Amateur",
            " Achievement",
            " Award",
            " of",
            " Astr",
            "onom",
            "ical",
            " Society",
            " of",
            " the",
            " Pacific",
            " Cham",
            "bl",
            "iss"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " sections",
            " by",
            " a",
            " line",
            " perpendicular",
            " to",
            " them",
            ",",
            " but",
            " with",
            " the",
            " sem",
            "ic",
            "ircle",
            " at",
            " the",
            " top",
            " of",
            " the",
            " intersection",
            ";",
            " the",
            " third",
            ",",
            " sixth",
            " and",
            " ninth",
            " of",
            " these",
            " lines",
            " are",
            " marked",
            " with",
            " a",
            " cross",
            " where",
            " they",
            " intersect",
            " with",
            " the",
            " vertical",
            " line",
            ".",
            " Also",
            " from",
            " this",
            " time",
            " frame",
            ",",
            " the",
            " D",
            "arius",
            " V",
            "ase",
            " was",
            " unearth",
            "ed",
            " in",
            " ",
            "185",
            "1",
            ".",
            " It"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " sections",
            " are",
            " merely",
            " continu",
            "ations",
            " of",
            " the",
            " st",
            "rophe",
            " and",
            " ant",
            "ist",
            "rophe",
            ")",
            " and",
            ",",
            " unlike",
            " the",
            " typical",
            " par",
            "ab",
            "asis",
            ",",
            " it",
            " seems",
            " to",
            " comment",
            " on",
            " actions",
            " that",
            " occur",
            " on",
            " stage",
            " during",
            " the",
            " address",
            ".",
            " An",
            " understanding",
            " of",
            " Old",
            " Comedy",
            " conventions",
            " such",
            " as",
            " the",
            " par",
            "ab",
            "asis",
            " is",
            " necessary",
            " for",
            " a",
            " proper",
            " understanding",
            " of",
            " Arist",
            "oph",
            "anes",
            "'",
            " plays",
            ";",
            " on"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            "cer",
            "'s",
            " shop",
            " at",
            " ",
            "517",
            " High",
            " Road",
            " in",
            " Ley",
            "ton",
            "stone",
            ",",
            " which",
            " was",
            " then",
            " part",
            " of",
            " Essex",
            " (",
            "now",
            " on",
            " the",
            " outskirts",
            " of",
            " East",
            " London",
            ").",
            " He",
            " was",
            " the",
            " son",
            " of",
            " Emma",
            " Jane",
            " (",
            "n",
            "Ã©e",
            " Wh",
            "elan",
            ";",
            " ",
            "186",
            "3",
            "–",
            "194",
            "2",
            ")",
            " and",
            " William",
            " Edgar",
            " Hitch",
            "cock",
            " (",
            "186",
            "2",
            "–",
            "191",
            "4",
            "),",
            " and",
            " had",
            " an"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.504,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 7,
          "is_repeated_datapoint": false,
          "tokens": [
            " expanded",
            " AN",
            "K",
            "Am",
            "all",
            " at",
            " the",
            " outskirts",
            ",",
            " on",
            " the",
            " Istanbul",
            " Highway",
            ",",
            " which",
            " houses",
            " most",
            " of",
            " the",
            " well",
            "-known",
            " international",
            " brands",
            ".",
            " This",
            " mall",
            " is",
            " the",
            " largest",
            " throughout",
            " the",
            " Ankara",
            " region",
            ".",
            " In",
            " ",
            "201",
            "4",
            ",",
            " a",
            " few",
            " more",
            " shopping",
            " malls",
            " were",
            " open",
            " in",
            " Ankara",
            ".",
            " They",
            " are",
            " Next",
            " Level",
            " and",
            " T",
            "aurus",
            " on",
            " the",
            " Boulevard",
            " of",
            " Me",
            "vl",
            "ana"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            " before",
            ".",
            " The",
            " building",
            " now",
            " occupied",
            " by",
            " the",
            " Pr",
            "ado",
            " in",
            " Madrid",
            " was",
            " built",
            " before",
            " the",
            " French",
            " Revolution",
            " for",
            " the",
            " public",
            " display",
            " of",
            " parts",
            " of",
            " the",
            " royal",
            " art",
            " collection",
            ",",
            " and",
            " similar",
            " royal",
            " galleries",
            " open",
            " to",
            " the",
            " public",
            " existed",
            " in",
            " Vienna",
            ",",
            " Munich",
            " and",
            " other",
            " capitals",
            ".",
            " The",
            " opening",
            " of",
            " the",
            " Mus",
            "Ã©e",
            " du",
            " Lou",
            "vre",
            " during",
            " the",
            " French",
            " Revolution",
            " (",
            "in",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.498
          ],
          "train_token_ind": 62,
          "is_repeated_datapoint": false,
          "tokens": [
            " astronomical",
            " ideas",
            " on",
            " Indian",
            " astronomy",
            ".",
            "Following",
            " the",
            " conquest",
            "s",
            " of",
            " Alexander",
            " the",
            " Great",
            " in",
            " the",
            " east",
            ",",
            " H",
            "ellen",
            "istic",
            " influence",
            " on",
            " Indian",
            " art",
            " was",
            " far",
            "-ranging",
            ".",
            " In",
            " the",
            " area",
            " of",
            " architecture",
            ",",
            " a",
            " few",
            " examples",
            " of",
            " the",
            " Ionic",
            " order",
            " can",
            " be",
            " found",
            " as",
            " far",
            " as",
            " Pakistan",
            " with",
            " the",
            " J",
            "and",
            "ial",
            " temple",
            " near",
            " Tax",
            "ila",
            ".",
            " Several",
            " examples",
            " of",
            " capitals"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.488,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 53,
          "is_repeated_datapoint": false,
          "tokens": [
            " Al",
            "c",
            "me",
            "on",
            "idae",
            " at",
            " Del",
            "phi",
            ".",
            " The",
            " Corinthians",
            " were",
            " considered",
            " to",
            " be",
            " the",
            " invent",
            "ors",
            " of",
            " the",
            " Dor",
            "ic",
            " order",
            ".",
            " ",
            "N",
            "apes",
            " (",
            "Les",
            "bos",
            "):",
            " An",
            " Ae",
            "olic",
            " temple",
            " probably",
            " of",
            " Apollo",
            " Nap",
            "ai",
            "os",
            " was",
            " built",
            " in",
            " the",
            " ",
            "7",
            "th",
            " century",
            " BC",
            ".",
            " Some",
            " special",
            " capitals",
            " with",
            " floral",
            " ornament",
            " have",
            " been",
            " found",
            ",",
            " which",
            " are"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.01,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.486,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            "%",
            " of",
            " the",
            " population",
            ",",
            " did",
            " not",
            " live",
            " in",
            " an",
            " incorporated",
            " city",
            " or",
            " census",
            "-design",
            "ated",
            " place",
            ".",
            " Approximately",
            " three",
            "-quarters",
            " of",
            " that",
            " figure",
            " were",
            " people",
            " who",
            " live",
            " in",
            " urban",
            " and",
            " suburban",
            " neighborhoods",
            " on",
            " the",
            " outskirts",
            " of",
            " the",
            " city",
            " limits",
            " of",
            " K",
            "etch",
            "ikan",
            ",",
            " Kodi",
            "ak",
            ",",
            " Palmer",
            " and",
            " Was",
            "illa",
            ".",
            " C",
            "DP",
            "s",
            " have",
            " not",
            " been",
            " established",
            " for",
            " these",
            " areas"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.006,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.482,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 44,
          "is_repeated_datapoint": false,
          "tokens": [
            " Alexander",
            "\"",
            " sent",
            " his",
            " scouts",
            " with",
            " a",
            " message",
            " to",
            " the",
            " people",
            " of",
            " Babylon",
            " before",
            " entering",
            " the",
            " city",
            ":",
            " \"",
            "I",
            " shall",
            " not",
            " enter",
            " your",
            " houses",
            "\".",
            "Pers",
            "ia",
            "From",
            " Babylon",
            ",",
            " Alexander",
            " went",
            " to",
            " Sus",
            "a",
            ",",
            " one",
            " of",
            " the",
            " A",
            "cha",
            "emen",
            "id",
            " capitals",
            ",",
            " and",
            " captured",
            " its",
            " treasury",
            ".",
            " He",
            " sent",
            " the",
            " bulk",
            " of",
            " his",
            " army",
            " to",
            " the",
            " Persian",
            " ceremonial"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.482,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "acus",
            " as",
            " their",
            " assistant",
            ".",
            " When",
            " the",
            " work",
            " was",
            " completed",
            ",",
            " three",
            " snakes",
            " rushed",
            " against",
            " the",
            " wall",
            ",",
            " and",
            " though",
            " the",
            " two",
            " that",
            " attacked",
            " the",
            " sections",
            " of",
            " the",
            " wall",
            " built",
            " by",
            " the",
            " gods",
            " fell",
            " down",
            " dead",
            ",",
            " the",
            " third",
            " forced",
            " its",
            " way",
            " into",
            " the",
            " city",
            " through",
            " the",
            " portion",
            " of",
            " the",
            " wall",
            " built",
            " by",
            " Ae",
            "acus",
            ".",
            " Apollo",
            " immediately",
            " proph",
            "es",
            "ied",
            " that",
            " Troy"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.48,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 15,
          "is_repeated_datapoint": false,
          "tokens": [
            "free",
            " flight",
            ".\"",
            " In",
            " the",
            " ",
            "196",
            "0",
            "s",
            ",",
            " after",
            " employing",
            " it",
            " in",
            " some",
            " sections",
            " of",
            " K",
            "add",
            "ish",
            " (\"",
            "c",
            "aw",
            "\"",
            " for",
            " example",
            ")",
            " he",
            ",",
            " for",
            " the",
            " most",
            " part",
            ",",
            " abandoned",
            " the",
            " an",
            "aph",
            "oric",
            " form",
            ".",
            " '",
            "L",
            "atter",
            "-Day",
            " Beat",
            "'",
            " Bob",
            " Dylan",
            " is",
            " known",
            " for",
            " using",
            " an",
            "aph",
            "ora",
            ",",
            " as",
            " in",
            " '",
            "T",
            "angled",
            " Up"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.461,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 8,
          "is_repeated_datapoint": false,
          "tokens": [
            " Battle",
            "world",
            ".",
            " Battle",
            "world",
            " was",
            " divided",
            " into",
            " sections",
            " with",
            " most",
            " of",
            " them",
            " being",
            " self",
            "-contained",
            " univers",
            "es",
            ".",
            " Marvel",
            " announced",
            " that",
            " several",
            " of",
            " these",
            " self",
            "-contained",
            " univers",
            "es",
            " would",
            " get",
            " their",
            " own",
            " tie",
            " in",
            " series",
            " and",
            " one",
            " of",
            " them",
            " was",
            " Amazing",
            " Spider",
            "-Man",
            ":",
            " Renew",
            " Your",
            " V",
            "ows",
            ",",
            " an",
            " alternate",
            " universe",
            " where",
            " Peter",
            " Parker",
            " and",
            " Mary",
            " Jane",
            " are",
            " still",
            " married",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.461,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " vary",
            " among",
            " the",
            " different",
            " sections",
            " or",
            " zones",
            " of",
            " the",
            " mountains",
            ".",
            " The",
            " lowest",
            " zone",
            " is",
            " the",
            " coll",
            "ine",
            " zone",
            ",",
            " which",
            " exists",
            " between",
            " ,",
            " depending",
            " on",
            " the",
            " location",
            ".",
            " The",
            " mont",
            "ane",
            " zone",
            " extends",
            " from",
            " ,",
            " followed",
            " by",
            " the",
            " sub",
            "-Al",
            "pine",
            " zone",
            " from",
            " .",
            " The",
            " Alpine",
            " zone",
            ",",
            " extending",
            " from",
            " tree",
            " line",
            " to",
            " the",
            " snow",
            " line",
            ",",
            " is",
            " followed",
            " by",
            " the",
            " gl"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.459,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 16,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " country",
            " by",
            " the",
            " turn",
            " of",
            " the",
            " century",
            " and",
            " the",
            " city",
            " marketed",
            " itself",
            " as",
            " the",
            " \"",
            "Capital",
            " of",
            " J",
            "ut",
            "land",
            "\".",
            " The",
            " population",
            " increased",
            " from",
            " ",
            "15",
            ",",
            "000",
            " in",
            " ",
            "187",
            "0",
            " to",
            " ",
            "52",
            ",",
            "000",
            " in",
            " ",
            "190",
            "1",
            " and",
            ",",
            " in",
            " response",
            ",",
            " the",
            " city",
            " annex",
            "ed",
            " large",
            " land",
            " areas",
            " to",
            " develop",
            " new",
            " residential",
            " quarters",
            " such",
            " as",
            " Tr"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            0.459,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " designed",
            " splendid",
            " merchants",
            "'",
            " houses",
            " throughout",
            " the",
            " city",
            ".",
            " A",
            " famous",
            " building",
            " in",
            " bar",
            "oque",
            " style",
            " in",
            " Amsterdam",
            " is",
            " the",
            " Royal",
            " Palace",
            " on",
            " Dam",
            " Square",
            ".",
            " Throughout",
            " the",
            " ",
            "18",
            "th",
            " century",
            ",",
            " Amsterdam",
            " was",
            " heavily",
            " influenced",
            " by",
            " French",
            " culture",
            ".",
            " This",
            " is",
            " reflected",
            " in",
            " the",
            " architecture",
            " of",
            " that",
            " period",
            ".",
            " Around",
            " ",
            "181",
            "5",
            ",",
            " architects",
            " broke",
            " with",
            " the",
            " bar",
            "oque",
            " style"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.459,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            "iss",
            "am",
            "ph",
            "ibia",
            " may",
            " possibly",
            " fall",
            " within",
            " extinct",
            " groups",
            ",",
            " like",
            " the",
            " Tem",
            "nos",
            "pond",
            "y",
            "li",
            " (",
            "trad",
            "itionally",
            " placed",
            " in",
            " the",
            " subclass",
            " L",
            "abyrinth",
            "odont",
            "ia",
            ")",
            " or",
            " the",
            " Lep",
            "os",
            "pond",
            "y",
            "li",
            ",",
            " and",
            " in",
            " some",
            " analyses",
            " even",
            " in",
            " the",
            " am",
            "ni",
            "otes",
            ".",
            " This",
            " means",
            " that",
            " advocates",
            " of",
            " phy",
            "logen",
            "etic",
            " n",
            "omencl",
            "ature",
            " have",
            " removed",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.459,
            -0.0,
            -0.0
          ],
          "train_token_ind": 60,
          "is_repeated_datapoint": false,
          "tokens": [
            " by",
            " the",
            " By",
            "r",
            "ds",
            " on",
            " the",
            " ",
            "196",
            "9",
            " album",
            " Ball",
            "ad",
            " of",
            " Easy",
            " Rider",
            " and",
            " \"",
            "Co",
            "on",
            " on",
            " the",
            " Moon",
            "\"",
            " by",
            " How",
            "lin",
            "'",
            " Wolf",
            " on",
            " the",
            " ",
            "197",
            "3",
            " album",
            " The",
            " Back",
            " Door",
            " Wolf",
            ".",
            "Space",
            "craft",
            " ",
            "The",
            " command",
            " module",
            " Columbia",
            " went",
            " on",
            " a",
            " tour",
            " of",
            " the",
            " United",
            " States",
            ",",
            " visiting",
            " ",
            "49",
            " state",
            " capitals",
            ",",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.457,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " arguments",
            ";",
            " episodes",
            " –",
            " sections",
            " of",
            " dialogue",
            " in",
            " i",
            "amb",
            "ic",
            " trim",
            "eter",
            ",",
            " often",
            " in",
            " a",
            " succession",
            " of",
            " scenes",
            " featuring",
            " minor",
            " characters",
            " towards",
            " the",
            " end",
            " of",
            " a",
            " play",
            ";",
            " songs",
            " ('",
            "st",
            "roph",
            "es",
            "'",
            "/'",
            "ant",
            "istro",
            "ph",
            "es",
            "'",
            " or",
            " '",
            "odes",
            "'",
            "/'",
            "ant",
            "odes",
            "')",
            " –",
            " often",
            " in",
            " sym",
            "metrical",
            " pairs",
            " where",
            " each",
            " half",
            " has",
            " the",
            " same",
            " meter"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.346,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.124,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.455,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 53,
          "is_repeated_datapoint": false,
          "tokens": [
            " displaying",
            " Ionic",
            " influences",
            " can",
            " be",
            " seen",
            " as",
            " far",
            " as",
            " Pat",
            "na",
            ",",
            " especially",
            " with",
            " the",
            " P",
            "atal",
            "ip",
            "utra",
            " capital",
            ",",
            " dated",
            " to",
            " the",
            " ",
            "3",
            "rd",
            " century",
            " BC",
            ".",
            " The",
            " Corinth",
            "ian",
            " order",
            " is",
            " also",
            " heavily",
            " represented",
            " in",
            " the",
            " art",
            " of",
            " Gand",
            "h",
            "ara",
            ",",
            " especially",
            " through",
            " Indo",
            "-C",
            "or",
            "inth",
            "ian",
            " capitals",
            ".",
            "In",
            "fluence",
            " on",
            " Rome",
            "Alexander",
            " and",
            " his"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.451,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "In",
            " music",
            ",",
            " pieces",
            " or",
            " sections",
            " which",
            " conf",
            "ound",
            " expectations",
            " and",
            " may",
            " be",
            " or",
            " are",
            " interpreted",
            " simultaneously",
            " in",
            " different",
            " ways",
            " are",
            " ambiguous",
            ",",
            " such",
            " as",
            " some",
            " poly",
            "ton",
            "ality",
            ",",
            " polym",
            "eter",
            ",",
            " other",
            " ambiguous",
            " meters",
            " or",
            " rhythms",
            ",",
            " and",
            " ambiguous",
            " ph",
            "rasing",
            ",",
            " or",
            " (",
            "Ste",
            "in",
            " ",
            "200",
            "5",
            ",",
            " p",
            ".",
            "Âł",
            "79",
            ")",
            " any",
            " aspect",
            " of",
            " music",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.449,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            "ai",
            "us",
            " S",
            "os",
            "ius",
            ",",
            " probably",
            " in",
            " ",
            "34",
            " BC",
            ".",
            " Only",
            " three",
            " columns",
            " with",
            " Corinth",
            "ian",
            " capitals",
            " exist",
            " today",
            ".",
            " It",
            " seems",
            " that",
            " the",
            " cult",
            " of",
            " Apollo",
            " had",
            " existed",
            " in",
            " this",
            " area",
            " since",
            " at",
            " least",
            " to",
            " the",
            " mid",
            "-",
            "5",
            "th",
            " century",
            " BC",
            ".",
            "R",
            "ome",
            ":",
            " The",
            " temple",
            " of",
            " Apollo",
            " Pal",
            "atin",
            "us",
            " was",
            " located",
            " on",
            " the",
            " Pal",
            "at",
            "ine"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.449,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            "ai",
            "us",
            " S",
            "os",
            "ius",
            ",",
            " probably",
            " in",
            " ",
            "34",
            " BC",
            ".",
            " Only",
            " three",
            " columns",
            " with",
            " Corinth",
            "ian",
            " capitals",
            " exist",
            " today",
            ".",
            " It",
            " seems",
            " that",
            " the",
            " cult",
            " of",
            " Apollo",
            " had",
            " existed",
            " in",
            " this",
            " area",
            " since",
            " at",
            " least",
            " to",
            " the",
            " mid",
            "-",
            "5",
            "th",
            " century",
            " BC",
            ".",
            "R",
            "ome",
            ":",
            " The",
            " temple",
            " of",
            " Apollo",
            " Pal",
            "atin",
            "us",
            " was",
            " located",
            " on",
            " the",
            " Pal",
            "at",
            "ine"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.447,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            " were",
            " published",
            " in",
            " ",
            "191",
            "2",
            "–",
            "14",
            ".",
            " Three",
            " more",
            ",",
            " to",
            " contain",
            " the",
            " Ch",
            "or",
            "ale",
            " Prel",
            "udes",
            " with",
            " Schwe",
            "itzer",
            "'s",
            " analyses",
            ",",
            " were",
            " to",
            " be",
            " worked",
            " on",
            " in",
            " Africa",
            ",",
            " but",
            " these",
            " were",
            " never",
            " completed",
            ",",
            " perhaps",
            " because",
            " for",
            " him",
            " they",
            " were",
            " inse",
            "parable",
            " from",
            " his",
            " evolving",
            " theological",
            " thought",
            ".",
            "On",
            " departure",
            " for",
            " Lam",
            "bar",
            "Ã©nÃ©",
            " in",
            " ",
            "191"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.445,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.014,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 11,
          "is_repeated_datapoint": false,
          "tokens": [
            " XX",
            "I",
            " and",
            " Type",
            " XX",
            "III",
            ",",
            " as",
            " pref",
            "abric",
            "ated",
            " sections",
            " at",
            " different",
            " facilities",
            " rather",
            " than",
            " at",
            " single",
            " dock",
            "yards",
            " contributed",
            " to",
            " the",
            " failure",
            " of",
            " this",
            " strategically",
            " important",
            " program",
            ".",
            " The",
            " designs",
            " were",
            " rushed",
            " into",
            " production",
            ",",
            " and",
            " the",
            " completed",
            " submarines",
            " were",
            " crippled",
            " by",
            " flaws",
            " which",
            " resulted",
            " from",
            " the",
            " way",
            " they",
            " had",
            " been",
            " constructed",
            ".",
            " While",
            " dozens",
            " of",
            " submarines",
            " were",
            " built",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.445,
            -0.0,
            -0.0,
            -0.0,
            0.438
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            " Manchester",
            ",",
            " United",
            " Kingdom",
            ",",
            " ",
            "200",
            "7",
            " ",
            " Zap",
            "op",
            "an",
            ",",
            " Jal",
            "isco",
            ",",
            " Mexico",
            ",",
            " ",
            "201",
            "1",
            "See",
            " also",
            "List",
            " of",
            " populated",
            " places",
            " in",
            " the",
            " Netherlands",
            "List",
            " of",
            " cities",
            ",",
            " towns",
            " and",
            " villages",
            " in",
            " North",
            " Holland",
            "List",
            " of",
            " cities",
            " in",
            " the",
            " Netherlands",
            " by",
            " province",
            "List",
            " of",
            " national",
            " capitals",
            "List",
            " of",
            " national",
            " capitals"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.445,
            -0.0,
            -0.0,
            -0.0,
            0.436,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.016,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " an",
            " inverted",
            " pyramid",
            ",",
            " with",
            " larger",
            " sections",
            " leading",
            " to",
            " smaller",
            " sections",
            ".",
            " In",
            " America",
            ",",
            " he",
            " also",
            " experimented",
            " with",
            " a",
            " mix",
            " of",
            " longer",
            " and",
            " shorter",
            " lines",
            ".",
            "G",
            "ins",
            "berg",
            "'s",
            " mature",
            " style",
            " made",
            " use",
            " of",
            " many",
            " specific",
            ",",
            " highly",
            " developed",
            " techniques",
            ",",
            " which",
            " he",
            " expressed",
            " in",
            " the",
            " \"",
            "po",
            "etic",
            " slogans",
            "\"",
            " he",
            " used",
            " in",
            " his",
            " Nar",
            "opa",
            " teaching",
            ".",
            " Prom",
            "inent"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.445,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " Nashville",
            ",",
            " the",
            " capital",
            " of",
            " Tennessee",
            " and",
            " an",
            " increasingly",
            " important",
            " Confederate",
            " industrial",
            " center",
            ",",
            " beginning",
            " on",
            " February",
            " ",
            "11",
            ",",
            " ",
            "186",
            "2",
            ".",
            "John",
            "ston",
            " also",
            " reinforced",
            " Fort",
            " Don",
            "elson",
            " with",
            " ",
            "12",
            ",",
            "000",
            " more",
            " men",
            ",",
            " including",
            " those",
            " under",
            " Floyd",
            " and",
            " Pillow",
            ",",
            " a",
            " curious",
            " decision",
            " given",
            " his",
            " thought",
            " that",
            " the",
            " U",
            ".S",
            ".",
            " gun",
            "boats",
            " alone",
            " could",
            " take",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.445,
            -0.0,
            -0.0,
            -0.0,
            0.438
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            " Manchester",
            ",",
            " United",
            " Kingdom",
            ",",
            " ",
            "200",
            "7",
            " ",
            " Zap",
            "op",
            "an",
            ",",
            " Jal",
            "isco",
            ",",
            " Mexico",
            ",",
            " ",
            "201",
            "1",
            "See",
            " also",
            "List",
            " of",
            " populated",
            " places",
            " in",
            " the",
            " Netherlands",
            "List",
            " of",
            " cities",
            ",",
            " towns",
            " and",
            " villages",
            " in",
            " North",
            " Holland",
            "List",
            " of",
            " cities",
            " in",
            " the",
            " Netherlands",
            " by",
            " province",
            "List",
            " of",
            " national",
            " capitals",
            "List",
            " of",
            " national",
            " capitals"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.434,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.391,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            " five",
            " presidents",
            " to",
            " do",
            " so",
            ".",
            "He",
            " has",
            " been",
            " memorial",
            "ized",
            " in",
            " many",
            " town",
            ",",
            " city",
            ",",
            " and",
            " county",
            " names",
            ",",
            " including",
            " the",
            " capital",
            " of",
            " Nebraska",
            ".",
            " The",
            " United",
            " States",
            " Navy",
            "  ",
            " is",
            " named",
            " after",
            " Lincoln",
            ",",
            " the",
            " second",
            " Navy",
            " ship",
            " to",
            " bear",
            " his",
            " name",
            ".",
            " The",
            " Lincoln",
            " Memorial",
            " is",
            " one",
            " of",
            " the",
            " most",
            " visited",
            " monuments",
            " in",
            " the",
            " nation",
            "'s",
            " capital",
            " and",
            " is"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.406,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 15,
          "is_repeated_datapoint": false,
          "tokens": [
            "9",
            ")",
            " was",
            " the",
            " American",
            " space",
            "flight",
            " that",
            " first",
            " landed",
            " humans",
            " on",
            " the",
            " Moon",
            ".",
            " Commander",
            " Neil",
            " Armstrong",
            " and",
            " Lunar",
            " Module",
            " Pilot",
            " Buzz",
            " Ald",
            "rin",
            " landed",
            " the",
            " Apollo",
            " Lunar",
            " Module",
            " Eagle",
            " on",
            " July",
            " ",
            "20",
            ",",
            " ",
            "196",
            "9",
            ",",
            " at",
            " ",
            "20",
            ":",
            "17",
            " UTC",
            ",",
            " and",
            " Armstrong",
            " became",
            " the",
            " first",
            " person",
            " to",
            " step",
            " onto",
            " the",
            " Moon",
            "'s",
            " surface",
            " six",
            " hours",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.402,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "-capital",
            "ist",
            " society",
            ",",
            " the",
            " system",
            " of",
            " private",
            " property",
            " would",
            " still",
            " exist",
            " and",
            " be",
            " enforced",
            " by",
            " private",
            " defense",
            " agencies",
            " and",
            "/or",
            " insurance",
            " companies",
            " selected",
            " by",
            " customers",
            ",",
            " which",
            " would",
            " operate",
            " competit",
            "ively",
            " in",
            " a",
            " market",
            " and",
            " fulfill",
            " the",
            " roles",
            " of",
            " courts",
            " and",
            " the",
            " police",
            ".",
            "According",
            " to",
            " its",
            " proponents",
            ",",
            " various",
            " historical",
            " theorists",
            " have",
            " esp",
            "oused",
            " philosoph",
            "ies",
            " similar",
            " to",
            " an",
            "ar",
            "cho"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.381,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            " Ankara",
            " has",
            " experienced",
            " a",
            " phenomenal",
            " growth",
            " since",
            " it",
            " was",
            " made",
            " Turkey",
            "'s",
            " capital",
            " in",
            " ",
            "192",
            "3",
            ",",
            " when",
            " it",
            " was",
            " \"",
            "a",
            " small",
            " town",
            " of",
            " no",
            " importance",
            "\".",
            " In",
            " ",
            "192",
            "4",
            ",",
            " the",
            " year",
            " after",
            " the",
            " government",
            " had",
            " moved",
            " there",
            ",",
            " Ankara",
            " had",
            " about",
            " ",
            "35",
            ",",
            "000",
            " residents",
            ".",
            " By",
            " ",
            "192",
            "7",
            " there",
            " were",
            " ",
            "44",
            ",",
            "553",
            " residents"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.34,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " which",
            " they",
            " were",
            " stored",
            ".",
            " He",
            " had",
            " them",
            " copied",
            " out",
            " into",
            " new",
            " manuscripts",
            ",",
            " and",
            " used",
            " his",
            " best",
            " guess",
            "work",
            " to",
            " fill",
            " in",
            " the",
            " gaps",
            " where",
            " the",
            " originals",
            " were",
            " unread",
            "able",
            ".",
            "When",
            " S",
            "ulla",
            " seized",
            " Athens",
            " in",
            " ,",
            " he",
            " seized",
            " the",
            " library",
            " and",
            " transferred",
            " it",
            " to",
            " Rome",
            ".",
            " There",
            ",",
            " And",
            "ronic",
            "us",
            " of",
            " Rhodes",
            " organized",
            " the",
            " texts",
            " into",
            " the",
            " first"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.324,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.316,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.338,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            " states",
            " that",
            " the",
            " an",
            "ar",
            "cho",
            "-capital",
            "ist",
            " definition",
            " of",
            " freedom",
            " is",
            " entirely",
            " negative",
            " and",
            " that",
            " it",
            " cannot",
            " guarantee",
            " the",
            " positive",
            " freedom",
            " of",
            " individual",
            " autonomy",
            " and",
            " independence",
            ".",
            "About",
            " an",
            "ar",
            "cho",
            "-capital",
            "ism",
            ",",
            " an",
            "ar",
            "cho",
            "-s",
            "y",
            "nd",
            "ical",
            "ist",
            " and",
            " anti",
            "-capital",
            "ist",
            " intellectual",
            " No",
            "am",
            " Ch",
            "om",
            "sky",
            " says",
            ":",
            "E",
            "conomics",
            " and",
            " property",
            " ",
            "Social",
            " anarchists",
            " argue"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.041,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.334,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.039,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 32,
          "is_repeated_datapoint": false,
          "tokens": [
            "-long",
            " war",
            ",",
            " and",
            " does",
            " not",
            " narr",
            "ate",
            " Achilles",
            "'",
            " death",
            ".",
            " It",
            " begins",
            " with",
            " Achilles",
            "'",
            " withdrawal",
            " from",
            " battle",
            " after",
            " being",
            " dish",
            "on",
            "oured",
            " by",
            " Ag",
            "am",
            "em",
            "non",
            ",",
            " the",
            " commander",
            " of",
            " the",
            " A",
            "cha",
            "ean",
            " forces",
            ".",
            " Ag",
            "am",
            "em",
            "non",
            " has",
            " taken",
            " a",
            " woman",
            " named",
            " Ch",
            "ry",
            "se",
            "is",
            " as",
            " his",
            " slave",
            ".",
            " Her",
            " father",
            " Ch",
            "ry",
            "ses",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.316,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.318,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.318
          ],
          "train_token_ind": 39,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " the",
            " extent",
            " possible",
            ".",
            " Ret",
            "rib",
            "utive",
            " justice",
            " is",
            " often",
            " a",
            " component",
            " of",
            " the",
            " contracts",
            " imagined",
            " for",
            " an",
            " an",
            "ar",
            "cho",
            "-capital",
            "ist",
            " society",
            ".",
            " According",
            " to",
            " Matthew",
            " O",
            "'",
            "Ke",
            "ef",
            "ee",
            ",",
            " some",
            " an",
            "ar",
            "cho",
            "-capital",
            "ists",
            " believe",
            " prisons",
            " or",
            " indent",
            "ured",
            " serv",
            "itude",
            " would",
            " be",
            " just",
            "ifiable",
            " institutions",
            " to",
            " deal",
            " with",
            " those",
            " who",
            " violate",
            " an",
            "ar",
            "cho",
            "-capital"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.266,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 17,
          "is_repeated_datapoint": false,
          "tokens": [
            " free",
            " elections",
            ",",
            " which",
            " were",
            " open",
            " at",
            " the",
            " time",
            " to",
            " the",
            " majority",
            " of",
            " white",
            " men",
            ".",
            " In",
            " analysis",
            " of",
            " the",
            " Revolution",
            ",",
            " historians",
            " in",
            " recent",
            " decades",
            " have",
            " often",
            " cited",
            " three",
            " motivations",
            " behind",
            " it",
            ":",
            " The",
            " Atlantic",
            " history",
            " view",
            " places",
            " the",
            " American",
            " story",
            " in",
            " a",
            " broader",
            " context",
            ",",
            " including",
            " subsequent",
            " revolutions",
            " in",
            " France",
            " and",
            " Haiti",
            ".",
            " It",
            " tends",
            " to",
            " reint",
            "egrate",
            " the",
            " histor",
            "i"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.254,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 15,
          "is_repeated_datapoint": false,
          "tokens": [
            "9",
            ",",
            " Bout",
            "ef",
            "li",
            "ka",
            " resigned",
            " from",
            " the",
            " presidency",
            " after",
            " mass",
            " protests",
            " against",
            " his",
            " candidacy",
            " for",
            " a",
            " fifth",
            " term",
            " in",
            " office",
            ".",
            "In",
            " December",
            " ",
            "201",
            "9",
            ",",
            " Abdel",
            "mad",
            "jid",
            " Te",
            "bb",
            "ou",
            "ne",
            " became",
            " Algeria",
            "'s",
            " president",
            ",",
            " after",
            " winning",
            " the",
            " first",
            " round",
            " of",
            " the",
            " presidential",
            " election",
            " with",
            " a",
            " record",
            " abst",
            "ention",
            " rate",
            " –",
            " the",
            " highest",
            " of",
            " all",
            " presidential",
            " elections"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.249,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            " circulation",
            " by",
            " War",
            "hol",
            " and",
            " the",
            " people",
            " around",
            " him",
            " who",
            " ran",
            " his",
            " business",
            ".",
            " After",
            " War",
            "hol",
            "'s",
            " death",
            ",",
            " the",
            " films",
            " were",
            " slowly",
            " restored",
            " by",
            " the",
            " Whitney",
            " Museum",
            " and",
            " are",
            " occasionally",
            " projected",
            " at",
            " museums",
            " and",
            " film",
            " festivals",
            ".",
            " Few",
            " of",
            " the",
            " War",
            "hol",
            "-directed",
            " films",
            " are",
            " available",
            " on",
            " video",
            " or",
            " DVD",
            ".",
            "Music",
            "In",
            " the",
            " mid",
            "-",
            "196",
            "0",
            "s",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.213,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 53,
          "is_repeated_datapoint": false,
          "tokens": [
            " conflict",
            " in",
            " the",
            " history",
            " of",
            " philosophy",
            ".",
            "Rand",
            "'s",
            " relationship",
            " with",
            " contemporary",
            " philosophers",
            " was",
            " mostly",
            " antagon",
            "istic",
            ".",
            " She",
            " was",
            " not",
            " an",
            " academic",
            " and",
            " did",
            " not",
            " participate",
            " in",
            " academic",
            " discourse",
            ".",
            " She",
            " was",
            " dismiss",
            "ive",
            " of",
            " critics",
            " and",
            " wrote",
            " about",
            " ideas",
            " she",
            " disagreed",
            " with",
            " in",
            " a",
            " pole",
            "m",
            "ical",
            " manner",
            " without",
            " in",
            "-depth",
            " analysis",
            ".",
            " She",
            " was",
            " in",
            " turn",
            " viewed",
            " very",
            " negatively",
            " by"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.134,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " illumination",
            " comes",
            " from",
            " directly",
            " behind",
            " the",
            " observer",
            ")",
            " and",
            " the",
            " Bond",
            " al",
            "bedo",
            " (",
            "me",
            "asuring",
            " total",
            " proportion",
            " of",
            " electromagnetic",
            " energy",
            " reflected",
            ").",
            " Their",
            " values",
            " can",
            " differ",
            " significantly",
            ",",
            " which",
            " is",
            " a",
            " common",
            " source",
            " of",
            " confusion",
            ".",
            "In",
            " detailed",
            " studies",
            ",",
            " the",
            " directional",
            " reflect",
            "ance",
            " properties",
            " of",
            " astronomical",
            " bodies",
            " are",
            " often",
            " expressed",
            " in",
            " terms",
            " of",
            " the",
            " five",
            " H",
            "ap",
            "ke",
            " parameters",
            " which",
            " semi"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.005,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.01,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.017,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            "in",
            "organic",
            " acids",
            ")",
            " Hydro",
            "gen",
            " hal",
            "ides",
            " and",
            " their",
            " solutions",
            ":",
            " hydro",
            "flu",
            "oric",
            " acid",
            " (",
            "HF",
            "),",
            " hydro",
            "chlor",
            "ic",
            " acid",
            " (",
            "H",
            "Cl",
            "),",
            " hydro",
            "b",
            "rom",
            "ic",
            " acid",
            " (",
            "H",
            "Br",
            "),",
            " hydro",
            "iod",
            "ic",
            " acid",
            " (",
            "HI",
            ")",
            " Hal",
            "ogen",
            " ox",
            "o",
            "ac",
            "ids",
            ":",
            " hyp",
            "och",
            "lor",
            "ous",
            " acid",
            " (",
            "H",
            "Cl",
            "O",
            "),",
            " chlor",
            "ous",
            " acid"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.015,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            " (",
            "201",
            "2",
            " estimates",
            "),",
            " the",
            " ",
            "11",
            "th",
            " highest",
            " in",
            " the",
            " world",
            ".",
            "Languages",
            " ",
            "The",
            " languages",
            " in",
            " Angola",
            " are",
            " those",
            " originally",
            " spoken",
            " by",
            " the",
            " different",
            " ethnic",
            " groups",
            " and",
            " Portuguese",
            ",",
            " introduced",
            " during",
            " the",
            " Portuguese",
            " colonial",
            " era",
            ".",
            " The",
            " most",
            " widely",
            " spoken",
            " indigenous",
            " languages",
            " are",
            " Umb",
            "und",
            "u",
            ",",
            " Kim",
            "b",
            "und",
            "u",
            " and",
            " K",
            "ik",
            "ongo",
            ",",
            " in",
            " that",
            " order",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " proposed",
            " that",
            " it",
            " may",
            " be",
            " a",
            " separate",
            " branch",
            " of",
            " Afro",
            "asi",
            "atic",
            ".",
            "Further",
            " subdivisions",
            " ",
            "There",
            " is",
            " no",
            " agreement",
            " on",
            " the",
            " relationships",
            " between",
            " and",
            " subgroup",
            "ing",
            " of",
            " the",
            " different",
            " Afro",
            "asi",
            "atic",
            " branches",
            ".",
            " Whereas",
            " Marcel",
            " Cohen",
            " (",
            "194",
            "7",
            ")",
            " claimed",
            " he",
            " saw",
            " no",
            " evidence",
            " for",
            " internal",
            " subgroup",
            "ings",
            ",",
            " numerous",
            " other",
            " scholars",
            " have",
            " made",
            " proposals",
            ",",
            " with",
            " Car",
            "sten",
            " Pe"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "many",
            " from",
            " the",
            " US",
            ",",
            " Canada",
            ",",
            " and",
            " the",
            " UK",
            ")",
            " who",
            " supported",
            " a",
            " re",
            "definition",
            " of",
            " Anglic",
            "an",
            " doctrine",
            ".",
            " Seen",
            " in",
            " this",
            " light",
            " ",
            "199",
            "8",
            " is",
            " a",
            " date",
            " that",
            " marked",
            " the",
            " shift",
            " from",
            " a",
            " West",
            "-dominated",
            " Christianity",
            " to",
            " one",
            " wherein",
            " the",
            " growing",
            " churches",
            " of",
            " the",
            " two",
            "-thirds",
            " world",
            " are",
            " predominant",
            ".",
            "Cont",
            "rovers",
            "ies",
            "One",
            " effect",
            " of",
            " the",
            " Anglic"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " Norwegian",
            " alph",
            "ab",
            "ets",
            " end",
            " with",
            " Ã¦",
            "—",
            "Ã¸",
            "—",
            "Ã¥",
            ",",
            " whereas",
            " the",
            " Swedish",
            " convention",
            "ally",
            " put",
            " Ã¥",
            "—",
            "Ã¤",
            "—",
            "Ã¶",
            " at",
            " the",
            " end",
            ".",
            " However",
            ",",
            " Ã¦",
            " phon",
            "etically",
            " corresponds",
            " with",
            " Ã¤",
            ",",
            " as",
            " does",
            " Ã¸",
            " and",
            " Ã¶",
            ".",
            "Early",
            " alph",
            "ab",
            "ets",
            " ",
            "It",
            " is",
            " unknown",
            " whether",
            " the",
            " earliest",
            " alph",
            "ab",
            "ets",
            " had",
            " a",
            " defined",
            " sequence",
            ".",
            " Some",
            " alph"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "_INITIALIZER",
    " nháºŃt",
    "CallCheck",
    "ographies",
    "ÃŃg"
  ],
  "bottom_logits": [
    "ather",
    "actus",
    "ieten",
    "CEE",
    "Ø§"
  ],
  "act_min": -0.0,
  "act_max": 0.664
}
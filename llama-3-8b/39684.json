{
  "index": 39684,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            0.656,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.406,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " Dallas",
            ",",
            " Texas",
            ",",
            " was",
            " renamed",
            " Cedar",
            " Crest",
            " Elementary",
            ".",
            " Johnston",
            " Middle",
            " School",
            " in",
            " Houston",
            ",",
            " Texas",
            ",",
            " was",
            " also",
            " renamed",
            " Meyer",
            "land",
            " Middle",
            " School",
            ".",
            " Three",
            " other",
            " elementary",
            " schools",
            " named",
            " for",
            " Confederate",
            " veterans",
            " were",
            " renamed",
            " simultaneously",
            ".",
            "See",
            " also",
            " Albert",
            " Sidney",
            " Johnston",
            " High",
            " School",
            ",",
            " a",
            " def",
            "unct",
            " public",
            " high",
            " school",
            " in",
            " Austin",
            ",",
            " Texas",
            " Statue",
            " of",
            " Albert",
            " Sidney"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.656,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " include",
            " Dallas",
            ",",
            " Low",
            "nd",
            "es",
            ",",
            " Mare",
            "ngo",
            " and",
            " Perry",
            ".\"",
            "In",
            " ",
            "197",
            "2",
            ",",
            " for",
            " the",
            " first",
            " time",
            " since",
            " ",
            "190",
            "1",
            ",",
            " the",
            " legislature",
            " completed",
            " the",
            " congressional",
            " red",
            "istrict",
            "ing",
            " based",
            " on",
            " the",
            " dec",
            "ennial",
            " census",
            ".",
            " This",
            " benefited",
            " the",
            " urban",
            " areas",
            " that",
            " had",
            " developed",
            ",",
            " as",
            " well",
            " as",
            " all",
            " in",
            " the",
            " population",
            " who",
            " had",
            " been",
            " under",
            "represented",
            " for"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.656,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " Dallas",
            ",",
            " Texas",
            ".",
            "Music",
            " ",
            "War",
            "hol",
            " strongly",
            " influenced",
            " the",
            " new",
            " wave",
            "/p",
            "unk",
            " rock",
            " band",
            " De",
            "vo",
            ",",
            " as",
            " well",
            " as",
            " David",
            " Bowie",
            ".",
            " Bowie",
            " recorded",
            " a",
            " song",
            " called",
            " \"",
            "Andy",
            " War",
            "hol",
            "\"",
            " for",
            " his",
            " ",
            "197",
            "1",
            " album",
            " H",
            "unky",
            " D",
            "ory",
            ".",
            " Lou",
            " Reed",
            " wrote",
            " the",
            " song",
            " \"",
            "Andy",
            "'s",
            " Chest",
            "\",",
            " about",
            " Valerie",
            " Sol",
            "anas",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.656,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.406,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " Dallas",
            ",",
            " Texas",
            ",",
            " was",
            " renamed",
            " Cedar",
            " Crest",
            " Elementary",
            ".",
            " Johnston",
            " Middle",
            " School",
            " in",
            " Houston",
            ",",
            " Texas",
            ",",
            " was",
            " also",
            " renamed",
            " Meyer",
            "land",
            " Middle",
            " School",
            ".",
            " Three",
            " other",
            " elementary",
            " schools",
            " named",
            " for",
            " Confederate",
            " veterans",
            " were",
            " renamed",
            " simultaneously",
            ".",
            "See",
            " also",
            " Albert",
            " Sidney",
            " Johnston",
            " High",
            " School",
            ",",
            " a",
            " def",
            "unct",
            " public",
            " high",
            " school",
            " in",
            " Austin",
            ",",
            " Texas",
            " Statue",
            " of",
            " Albert",
            " Sidney"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.629,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            "0",
            " T",
            "DI",
            ",",
            " Audi",
            " A",
            "3",
            " Sport",
            "back",
            " ",
            "2",
            ".",
            "0",
            " T",
            "DI",
            " with",
            " S",
            " tr",
            "onic",
            " transmission",
            ")",
            " travelling",
            " across",
            " the",
            " American",
            " continent",
            " from",
            " New",
            " York",
            " to",
            " Los",
            " Angeles",
            ",",
            " passing",
            " major",
            " cities",
            " like",
            " Chicago",
            ",",
            " Dallas",
            " and",
            " Las",
            " Vegas",
            " during",
            " the",
            " ",
            "13",
            " daily",
            " stages",
            ",",
            " as",
            " well",
            " as",
            " natural",
            " wonders",
            " including",
            " the",
            " Rocky",
            " Mountains",
            ",",
            " Death",
            " Valley"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.629,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            "0",
            " T",
            "DI",
            ",",
            " Audi",
            " A",
            "3",
            " Sport",
            "back",
            " ",
            "2",
            ".",
            "0",
            " T",
            "DI",
            " with",
            " S",
            " tr",
            "onic",
            " transmission",
            ")",
            " travelling",
            " across",
            " the",
            " American",
            " continent",
            " from",
            " New",
            " York",
            " to",
            " Los",
            " Angeles",
            ",",
            " passing",
            " major",
            " cities",
            " like",
            " Chicago",
            ",",
            " Dallas",
            " and",
            " Las",
            " Vegas",
            " during",
            " the",
            " ",
            "13",
            " daily",
            " stages",
            ",",
            " as",
            " well",
            " as",
            " natural",
            " wonders",
            " including",
            " the",
            " Rocky",
            " Mountains",
            ",",
            " Death",
            " Valley"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.625,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " Bran",
            "iff",
            "'s",
            " chairman",
            " and",
            " president",
            " Harding",
            " Lawrence",
            ",",
            " was",
            " representing",
            " the",
            " Dallas",
            "-based",
            " carrier",
            " at",
            " that",
            " time",
            ".",
            " Lois",
            " succeeded",
            " Wells",
            " Rich",
            " Greene",
            " Agency",
            " on",
            " December",
            " ",
            "1",
            ",",
            " ",
            "196",
            "8",
            ".",
            " The",
            " rights",
            " to",
            " War",
            "hol",
            "'s",
            " films",
            " for",
            " Bran",
            "iff",
            " and",
            " his",
            " signed",
            " contracts",
            " are",
            " owned",
            " by",
            " a",
            " private",
            " trust",
            " and",
            " are",
            " administered",
            " by",
            " Bran",
            "iff",
            " Airways",
            " Foundation"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.625,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " Bran",
            "iff",
            "'s",
            " chairman",
            " and",
            " president",
            " Harding",
            " Lawrence",
            ",",
            " was",
            " representing",
            " the",
            " Dallas",
            "-based",
            " carrier",
            " at",
            " that",
            " time",
            ".",
            " Lois",
            " succeeded",
            " Wells",
            " Rich",
            " Greene",
            " Agency",
            " on",
            " December",
            " ",
            "1",
            ",",
            " ",
            "196",
            "8",
            ".",
            " The",
            " rights",
            " to",
            " War",
            "hol",
            "'s",
            " films",
            " for",
            " Bran",
            "iff",
            " and",
            " his",
            " signed",
            " contracts",
            " are",
            " owned",
            " by",
            " a",
            " private",
            " trust",
            " and",
            " are",
            " administered",
            " by",
            " Bran",
            "iff",
            " Airways",
            " Foundation"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.034,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " World",
            " Cup",
            " last",
            " July",
            " at",
            " BC",
            " Place",
            " in",
            " Vancouver",
            ",",
            " British",
            " Columbia",
            ",",
            " Canada",
            " before",
            " an",
            " undis",
            "puted",
            " AT",
            "&T",
            " Stadium",
            " audience",
            " of",
            " ",
            "101",
            ",",
            "763",
            " to",
            " open",
            " Wrestle",
            "Man",
            "ia",
            " ",
            "32",
            " in",
            " Dallas",
            ",",
            " Texas",
            ".",
            "In",
            " ",
            "201",
            "7",
            ",",
            " Jackie",
            " Evan",
            "cho",
            " released",
            " Together",
            " We",
            " Stand",
            ",",
            " a",
            " disc",
            " containing",
            " three",
            " patriotic",
            " songs",
            " including",
            " \"",
            "America",
            " the",
            " Beautiful"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.014,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " moved",
            " to",
            " Cah",
            "aba",
            " in",
            " Dallas",
            " County",
            ".",
            "C",
            "ah",
            "aba",
            ",",
            " now",
            " a",
            " ghost",
            " town",
            ",",
            " was",
            " the",
            " first",
            " permanent",
            " state",
            " capital",
            " from",
            " ",
            "182",
            "0",
            " to",
            " ",
            "182",
            "5",
            ".",
            " The",
            " Alabama",
            " Fever",
            " land",
            " rush",
            " was",
            " underway",
            " when",
            " the",
            " state",
            " was",
            " admitted",
            " to",
            " the",
            " Union",
            ",",
            " with",
            " settlers",
            " and",
            " land",
            " spec",
            "ulators",
            " pouring",
            " into",
            " the",
            " state",
            " to",
            " take",
            " advantage",
            " of",
            " fertile"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.014,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " moved",
            " to",
            " Cah",
            "aba",
            " in",
            " Dallas",
            " County",
            ".",
            "C",
            "ah",
            "aba",
            ",",
            " now",
            " a",
            " ghost",
            " town",
            ",",
            " was",
            " the",
            " first",
            " permanent",
            " state",
            " capital",
            " from",
            " ",
            "182",
            "0",
            " to",
            " ",
            "182",
            "5",
            ".",
            " The",
            " Alabama",
            " Fever",
            " land",
            " rush",
            " was",
            " underway",
            " when",
            " the",
            " state",
            " was",
            " admitted",
            " to",
            " the",
            " Union",
            ",",
            " with",
            " settlers",
            " and",
            " land",
            " spec",
            "ulators",
            " pouring",
            " into",
            " the",
            " state",
            " to",
            " take",
            " advantage",
            " of",
            " fertile"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.539,
            0.012
          ],
          "train_token_ind": 61,
          "is_repeated_datapoint": false,
          "tokens": [
            " With",
            " the",
            " exception",
            " of",
            " the",
            " aforementioned",
            " re",
            "locations",
            " since",
            " that",
            " time",
            ",",
            " the",
            " division",
            "al",
            " setup",
            " has",
            " remained",
            " static",
            " ever",
            " since",
            ".",
            "Between",
            " ",
            "199",
            "5",
            " and",
            " ",
            "202",
            "2",
            ",",
            " the",
            " AFC",
            " has",
            " sent",
            " only",
            " ",
            "9",
            " of",
            " its",
            " ",
            "16",
            " teams",
            " to",
            " the",
            " Super",
            " Bowl",
            ":",
            " New",
            " England",
            " Patriots",
            " (",
            "10",
            " times",
            "),",
            " Pittsburgh",
            " Steelers",
            " (",
            "4",
            " times",
            "),",
            " Denver",
            " Broncos"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.539,
            0.012
          ],
          "train_token_ind": 61,
          "is_repeated_datapoint": false,
          "tokens": [
            " With",
            " the",
            " exception",
            " of",
            " the",
            " aforementioned",
            " re",
            "locations",
            " since",
            " that",
            " time",
            ",",
            " the",
            " division",
            "al",
            " setup",
            " has",
            " remained",
            " static",
            " ever",
            " since",
            ".",
            "Between",
            " ",
            "199",
            "5",
            " and",
            " ",
            "202",
            "2",
            ",",
            " the",
            " AFC",
            " has",
            " sent",
            " only",
            " ",
            "9",
            " of",
            " its",
            " ",
            "16",
            " teams",
            " to",
            " the",
            " Super",
            " Bowl",
            ":",
            " New",
            " England",
            " Patriots",
            " (",
            "10",
            " times",
            "),",
            " Pittsburgh",
            " Steelers",
            " (",
            "4",
            " times",
            "),",
            " Denver",
            " Broncos"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.531,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 59,
          "is_repeated_datapoint": false,
          "tokens": [
            "\".",
            " The",
            " song",
            " chart",
            "ed",
            " at",
            " No",
            ".",
            " ",
            "4",
            " on",
            " Billboard",
            "'s",
            " Classical",
            " Digital",
            " Song",
            " sales",
            " chart",
            ".",
            "An",
            " abbreviated",
            " cover",
            " with",
            " the",
            " ",
            "191",
            "1",
            " lyrics",
            " was",
            " performed",
            " by",
            " Greg",
            " Jong",
            " for",
            " the",
            " soundtrack",
            " of",
            " the",
            " ",
            "202",
            "0",
            " video",
            " game",
            " W",
            "ast",
            "eland",
            " ",
            "3",
            ",",
            " and",
            " is",
            " played",
            " during",
            " the",
            " final",
            " hostile",
            " encounters",
            " in",
            " the",
            " Denver",
            " section",
            ".",
            "In"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.038,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " the",
            " granting",
            " of",
            " fishing",
            " rights",
            " in",
            " the",
            " Grand",
            " Banks",
            ",",
            " off",
            " the",
            " coast",
            " of",
            " Newfoundland",
            " and",
            " in",
            " the",
            " Gulf",
            " of",
            " Saint",
            " Lawrence",
            ";",
            " the",
            " United",
            " States",
            " and",
            " Great",
            " Britain",
            " were",
            " each",
            " given",
            " perpetual",
            " access",
            " to",
            " the",
            " Mississippi",
            " River",
            ".",
            "An",
            " Anglo",
            "-American",
            " Prel",
            "iminary",
            " Peace",
            " was",
            " formally",
            " entered",
            " into",
            " in",
            " November",
            " ",
            "178",
            "2",
            ",",
            " and",
            " Congress",
            " endorsed",
            " the",
            " settlement",
            " on",
            " April"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " Inside",
            " Passage",
            " off",
            " the",
            " coast",
            " of",
            " British",
            " Columbia",
            " and",
            " the",
            " Canadian",
            " Arctic",
            " Arch",
            "ipel",
            "ago",
            " are",
            " examples",
            ".",
            "Art",
            "ificial",
            " arch",
            "ipel",
            "agos",
            "Art",
            "ificial",
            " arch",
            "ipel",
            "agos",
            " have",
            " been",
            " created",
            " in",
            " various",
            " countries",
            " for",
            " different",
            " purposes",
            ".",
            " Palm",
            " Islands",
            " and",
            " The",
            " World",
            " Islands",
            " off",
            " Dubai",
            " were",
            " or",
            " are",
            " being",
            " created",
            " for",
            " leisure",
            " and",
            " tourism",
            " purposes",
            ".",
            " Marker",
            " W",
            "adden",
            " in",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.155,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            "000",
            "–",
            "5",
            ",",
            "500",
            " species",
            " of",
            " red",
            " algae",
            " worldwide",
            " \"",
            "some",
            " ",
            "1",
            ",",
            "300",
            " in",
            " Australian",
            " Seas",
            "\"",
            " ",
            "400",
            " seaw",
            "eed",
            " species",
            " for",
            " the",
            " western",
            " coastline",
            " of",
            " South",
            " Africa",
            ",",
            " and",
            " ",
            "212",
            " species",
            " from",
            " the",
            " coast",
            " of",
            " K",
            "wa",
            "Z",
            "ulu",
            "-N",
            "atal",
            ".",
            " Some",
            " of",
            " these",
            " are",
            " duplicates",
            ",",
            " as",
            " the",
            " range",
            " extends",
            " across",
            " both",
            " co"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            " mostly",
            " of",
            " its",
            " two",
            " names",
            "ake",
            " islands",
            ",",
            " Ant",
            "igua",
            ",",
            " and",
            " Barb",
            "uda",
            ".",
            " Other",
            " than",
            " that",
            ",",
            " Ant",
            "igua",
            " and",
            " Barb",
            "uda",
            "'s",
            " biggest",
            " islands",
            " are",
            " Gu",
            "iana",
            " Island",
            " and",
            " Long",
            " Island",
            " off",
            " the",
            " coast",
            " of",
            " Ant",
            "igua",
            ",",
            " and",
            " Red",
            "onda",
            " island",
            ",",
            " which",
            " is",
            " far",
            " from",
            " both",
            " of",
            " the",
            " main",
            " islands",
            ".",
            "Climate",
            " ",
            "Rain",
            "fall",
            " averages",
            " ",
            " per"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.155,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            "000",
            "–",
            "5",
            ",",
            "500",
            " species",
            " of",
            " red",
            " algae",
            " worldwide",
            " \"",
            "some",
            " ",
            "1",
            ",",
            "300",
            " in",
            " Australian",
            " Seas",
            "\"",
            " ",
            "400",
            " seaw",
            "eed",
            " species",
            " for",
            " the",
            " western",
            " coastline",
            " of",
            " South",
            " Africa",
            ",",
            " and",
            " ",
            "212",
            " species",
            " from",
            " the",
            " coast",
            " of",
            " K",
            "wa",
            "Z",
            "ulu",
            "-N",
            "atal",
            ".",
            " Some",
            " of",
            " these",
            " are",
            " duplicates",
            ",",
            " as",
            " the",
            " range",
            " extends",
            " across",
            " both",
            " co"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.498,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            " southern",
            " route",
            " to",
            " India",
            " and",
            " explored",
            " the",
            " Par",
            "ia",
            " Peninsula",
            " (",
            "Eastern",
            " Venezuela",
            ")",
            " and",
            " the",
            " Or",
            "in",
            "oco",
            " region",
            ",",
            " where",
            " he",
            " discovered",
            " the",
            " fresh",
            " river",
            " water",
            " of",
            " the",
            " Or",
            "in",
            "oco",
            " delta",
            ".",
            " The",
            " suspicion",
            " arose",
            " that",
            " he",
            " had",
            " not",
            " found",
            " islands",
            " off",
            " the",
            " coast",
            " of",
            " India",
            " but",
            " a",
            " much",
            " more",
            " extensive",
            " land",
            " mass",
            ";",
            " an",
            " extension",
            " of",
            " Asia",
            ".",
            " Columbus"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.498,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " western",
            " coast",
            " of",
            " Anat",
            "olia",
            " (",
            "Pre",
            "-S",
            "ocratic",
            " philosophy",
            ").",
            "Class",
            "ical",
            " Anat",
            "olia",
            "In",
            " Classical",
            " antiqu",
            "ity",
            ",",
            " Anat",
            "olia",
            " was",
            " described",
            " by",
            " the",
            " Ancient",
            " Greek",
            " historian",
            " Her",
            "od",
            "ot",
            "us",
            " and",
            " later",
            " historians",
            " as",
            " divided",
            " into",
            " regions",
            " that",
            " were",
            " diverse",
            " in",
            " culture",
            ",",
            " language",
            ",",
            " and",
            " religious",
            " practices",
            ".",
            " The",
            " northern",
            " regions",
            " included",
            " B",
            "ith",
            "yn",
            "ia",
            ",",
            " P"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.008,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.017,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.498,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " based",
            " in",
            " Angola",
            ",",
            " which",
            " extended",
            " north",
            "ward",
            " to",
            " what",
            " is",
            " now",
            " the",
            " Democratic",
            " Republic",
            " of",
            " the",
            " Congo",
            ",",
            " the",
            " Republic",
            " of",
            " the",
            " Congo",
            " and",
            " Gab",
            "on",
            ".",
            " It",
            " established",
            " trade",
            " routes",
            " with",
            " other",
            " city",
            "-states",
            " and",
            " civil",
            "isations",
            " up",
            " and",
            " down",
            " the",
            " coast",
            " of",
            " southwestern",
            " and",
            " western",
            " Africa",
            " and",
            " even",
            " with",
            " Great",
            " Zimbabwe",
            " and",
            " the",
            " Mut",
            "apa",
            " Empire",
            ",",
            " although",
            " it"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.498,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 17,
          "is_repeated_datapoint": false,
          "tokens": [
            " variables",
            ",",
            " or",
            " factors",
            " have",
            " statistically",
            " different",
            " means",
            " include",
            " the",
            " Tu",
            "key",
            "'s",
            " range",
            " test",
            ",",
            " and",
            " Duncan",
            "'s",
            " new",
            " multiple",
            " range",
            " test",
            ".",
            " ",
            " In",
            " turn",
            ",",
            " these",
            " tests",
            " are",
            " often",
            " followed",
            " with",
            " a",
            " Compact",
            " Letter",
            " Display",
            " (",
            "CL",
            "D",
            ")",
            " methodology",
            " in",
            " order",
            " to",
            " render",
            " the",
            " output",
            " of",
            " the",
            " mentioned",
            " tests",
            " more",
            " transparent",
            " to",
            " a",
            " non",
            "-stat",
            "istic",
            "ian",
            " audience",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.496,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            " with",
            " the",
            " exception",
            " of",
            " Cre",
            "te",
            ",",
            " which",
            " was",
            " a",
            " Ven",
            "et",
            "ian",
            " colony",
            " until",
            " ",
            "166",
            "9",
            ".",
            " The",
            " Greek",
            " War",
            " of",
            " Independence",
            " allowed",
            " a",
            " Greek",
            " state",
            " on",
            " the",
            " coast",
            " of",
            " the",
            " Ae",
            "ge",
            "an",
            " from",
            " ",
            "182",
            "9",
            " onwards",
            ".",
            " The",
            " Ottoman",
            " Empire",
            " held",
            " a",
            " presence",
            " over",
            " the",
            " sea",
            " for",
            " over",
            " ",
            "500",
            " years",
            ",",
            " until",
            " it",
            " was",
            " replaced",
            " by",
            " modern"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.496,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.48,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            " displacement",
            ".",
            " The",
            " Far",
            "allon",
            " Islands",
            " off",
            " the",
            " coast",
            " of",
            " California",
            " are",
            " an",
            " example",
            ".",
            "Contin",
            "ental",
            " arch",
            "ipel",
            "agos",
            "Sets",
            " of",
            " islands",
            " formed",
            " close",
            " to",
            " the",
            " coast",
            " of",
            " a",
            " continent",
            " are",
            " considered",
            " continental",
            " arch",
            "ipel",
            "agos",
            " when",
            " they",
            " form",
            " part",
            " of",
            " the",
            " same",
            " continental",
            " shelf",
            ",",
            " when",
            " those",
            " islands",
            " are",
            " above",
            "-water",
            " extensions",
            " of",
            " the",
            " shelf",
            ".",
            " The",
            " islands",
            " of",
            " the"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.496,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.041,
            -0.0
          ],
          "train_token_ind": 55,
          "is_repeated_datapoint": false,
          "tokens": [
            " carbonate",
            " deposits",
            " formed",
            " in",
            " warm",
            " shallow",
            " waters",
            " such",
            " as",
            " Florida",
            " and",
            " the",
            " Bahamas",
            ",",
            " while",
            " coarse",
            " river",
            " out",
            "wash",
            " sands",
            " and",
            " s",
            "ilt",
            " are",
            " common",
            " in",
            " shallow",
            " shelf",
            " areas",
            " like",
            " the",
            " Georges",
            " Bank",
            ".",
            " Co",
            "arse",
            " sand",
            ",",
            " b",
            "ould",
            "ers",
            ",",
            " and",
            " rocks",
            " were",
            " transported",
            " into",
            " some",
            " areas",
            ",",
            " such",
            " as",
            " off",
            " the",
            " coast",
            " of",
            " Nova",
            " Scotia",
            " or",
            " the",
            " Gulf",
            " of",
            " Maine"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.496,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            "useum",
            " Wol",
            "fs",
            "bug",
            ",",
            " ",
            "199",
            "9",
            ".",
            "  ",
            "  ",
            " Doyle",
            ",",
            " Jennifer",
            ",",
            " Jonathan",
            " Flat",
            "ley",
            ",",
            " and",
            " JosÃ©",
            " Est",
            "eb",
            "an",
            " Mu",
            "Ã±",
            "oz",
            ",",
            " eds",
            " (",
            "199",
            "6",
            ").",
            " Pop",
            " Out",
            ":",
            " Que",
            "er",
            " War",
            "hol",
            ".",
            " Durham",
            ":",
            " Duke",
            " University",
            " Press",
            ".",
            " Duncan",
            " F",
            "allow",
            "ell",
            ",",
            " ",
            "20",
            "th",
            " Century",
            " Characters",
            ",",
            " ch",
            ".",
            " Andy",
            " Lives",
            " ("
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.494,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 27,
          "is_repeated_datapoint": false,
          "tokens": [
            " pne",
            "uma",
            " of",
            " Apollo",
            ",",
            " said",
            " to",
            " come",
            " from",
            " a",
            " spring",
            " inside",
            " the",
            " Ad",
            "y",
            "ton",
            ".",
            " In",
            " Did",
            "ym",
            "a",
            ",",
            " an",
            " oracle",
            " on",
            " the",
            " coast",
            " of",
            " Anat",
            "olia",
            ",",
            " south",
            " west",
            " of",
            " Ly",
            "d",
            "ian",
            " (",
            "L",
            "uw",
            "ian",
            ")",
            " S",
            "ard",
            "is",
            ",",
            " in",
            " which",
            " priests",
            " from",
            " the",
            " lineage",
            " of",
            " the",
            " Branch",
            "idae",
            " received",
            " inspiration",
            " by",
            " drinking",
            " from",
            " a",
            " healing"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.494,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 49,
          "is_repeated_datapoint": false,
          "tokens": [
            " ice",
            " age",
            ".",
            " They",
            " are",
            " thought",
            " to",
            " have",
            " migrated",
            " from",
            " Siber",
            "ia",
            " to",
            " Alaska",
            " on",
            " a",
            " land",
            " bridge",
            " across",
            " the",
            " B",
            "ering",
            " Strait",
            " and",
            " then",
            " possibly",
            " moved",
            " down",
            " the",
            " east",
            " side",
            " of",
            " the",
            " Rocky",
            " Mountains",
            " through",
            " Alberta",
            " to",
            " settle",
            " the",
            " Americas",
            ".",
            " Others",
            " may",
            " have",
            " migrated",
            " down",
            " the",
            " coast",
            " of",
            " British",
            " Columbia",
            " and",
            " then",
            " moved",
            " inland",
            ".",
            " Over",
            " time",
            " they",
            " differentiated",
            " into",
            " various"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.494,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.03,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " and",
            " Montgomery",
            " Ad",
            "vertiser",
            ".",
            "Major",
            " television",
            " network",
            " affiliates",
            " in",
            " Alabama",
            " include",
            ":",
            " ABC",
            " WG",
            "WW",
            " ",
            "40",
            ".",
            "2",
            " ABC",
            ",",
            " Ann",
            "iston",
            " WB",
            "MA",
            " ",
            "58",
            "/W",
            "AB",
            "M",
            " ",
            "68",
            ".",
            "2",
            " ABC",
            ",",
            " Birmingham",
            " WD",
            "HN",
            " ",
            "18",
            " ABC",
            ",",
            " Do",
            "than",
            " WA",
            "AY",
            " ",
            "31",
            " ABC",
            ",",
            " Hunts",
            "ville",
            " WE",
            "AR",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.494,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.085,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            " assigned",
            " by",
            " a",
            " divine",
            " power",
            ".",
            " With",
            " the",
            " discovery",
            " of",
            " the",
            " Americas",
            " the",
            " myths",
            " of",
            " the",
            " Golden",
            " Age",
            ",",
            " Atlantis",
            ",",
            " and",
            " the",
            " earthly",
            " paradise",
            " moved",
            " from",
            " Asia",
            " to",
            " the",
            " New",
            " World",
            ".",
            " He",
            " died",
            " on",
            " May",
            " ",
            "20",
            ",",
            " ",
            "150",
            "6",
            ",",
            " believing",
            " that",
            " he",
            " had",
            " found",
            " new",
            " islands",
            " of",
            " the",
            " coast",
            " of",
            " or",
            " possibly",
            " a",
            " peninsula",
            " of",
            " India",
            "—",
            "pre"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.492,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 17,
          "is_repeated_datapoint": false,
          "tokens": [
            " with",
            " the",
            " city",
            " states",
            " of",
            " the",
            " eastern",
            " Mediterranean",
            ",",
            " especially",
            " By",
            "b",
            "los",
            " (",
            "on",
            " the",
            " coast",
            " of",
            " modern",
            "-day",
            " Lebanon",
            "),",
            " and",
            " in",
            " several",
            " exped",
            "itions",
            " down",
            " the",
            " Red",
            " Sea",
            " to",
            " the",
            " Land",
            " of",
            " P",
            "unt",
            ".",
            " In",
            " fact",
            " one",
            " of",
            " the",
            " earliest",
            " Egyptian",
            " words",
            " for",
            " a",
            " se",
            "ago",
            "ing",
            " ship",
            " is",
            " a",
            " \"",
            "By",
            "b",
            "los",
            " Ship",
            "\",",
            " which",
            " originally",
            " defined"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.492,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 29,
          "is_repeated_datapoint": false,
          "tokens": [
            " cloudy",
            ",",
            " and",
            " not",
            " severely",
            " cold",
            " in",
            " winter",
            ",",
            " like",
            " other",
            " locations",
            " at",
            " the",
            " same",
            " high",
            " latitude",
            ".",
            " The",
            " cold",
            " water",
            " currents",
            " contribute",
            " to",
            " heavy",
            " fog",
            " off",
            " the",
            " coast",
            " of",
            " eastern",
            " Canada",
            " (",
            "the",
            " Grand",
            " Banks",
            " of",
            " Newfoundland",
            " area",
            ")",
            " and",
            " Africa",
            "'s",
            " north",
            "-west",
            "ern",
            " coast",
            ".",
            " In",
            " general",
            ",",
            " winds",
            " transport",
            " moisture",
            " and",
            " air",
            " over",
            " land",
            " areas",
            ".",
            "Natural",
            " hazards",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.49,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 33,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " the",
            " Fo",
            "Ã§a",
            " Islands",
            ".",
            "The",
            " Ae",
            "ge",
            "an",
            " Sea",
            " has",
            " been",
            " historically",
            " important",
            ",",
            " especially",
            " in",
            " regards",
            " to",
            " the",
            " civilization",
            " of",
            " Ancient",
            " Greece",
            ",",
            " who",
            " inhabited",
            " the",
            " area",
            " around",
            " the",
            " coast",
            " of",
            " the",
            " Ae",
            "ge",
            "an",
            " and",
            " the",
            " Ae",
            "ge",
            "an",
            " islands",
            ".",
            " The",
            " Ae",
            "ge",
            "an",
            " islands",
            " facilitated",
            " contact",
            " between",
            " the",
            " people",
            " of",
            " the",
            " area",
            " and",
            " between",
            " Europe",
            " and",
            " Asia"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.488,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            "200",
            "1",
            ")",
            " ",
            " ",
            "191",
            "6",
            "  ",
            " –",
            " Robert",
            " Shaw",
            ",",
            " American",
            " conductor",
            " (",
            "d",
            ".",
            " ",
            "199",
            "9",
            ")",
            "191",
            "7",
            " –",
            " Bea",
            " W",
            "ain",
            ",",
            " American",
            " singer",
            " (",
            "d",
            ".",
            " ",
            "201",
            "7",
            ")",
            "192",
            "0",
            " –",
            " Duncan",
            " Hamilton",
            ",",
            " Irish",
            "-",
            "English",
            " race",
            " car",
            " driver",
            " and",
            " pilot",
            " (",
            "d",
            ".",
            " ",
            "199",
            "4",
            ")",
            " ",
            " ",
            "192",
            "0",
            "  "
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.486
          ],
          "train_token_ind": 62,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " over",
            " ",
            "20",
            " species",
            " such",
            " as",
            " nor",
            "i",
            " and",
            " a",
            "on",
            "ori",
            ";",
            " Ireland",
            ",",
            " d",
            "ulse",
            ";",
            " Chile",
            ",",
            " coch",
            "ay",
            "uyo",
            ".",
            " L",
            "aver",
            " is",
            " used",
            " to",
            " make",
            " l",
            "aver",
            "bread",
            " in",
            " Wales",
            ",",
            " where",
            " it",
            " is",
            " known",
            " as",
            " .",
            " In",
            " Korea",
            ",",
            " green",
            " l",
            "aver",
            " is",
            " used",
            " to",
            " make",
            " .",
            " It",
            " is",
            " also",
            " used",
            " along",
            " the",
            " west",
            " coast",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.473,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.451,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " Atlantic",
            " is",
            " up",
            " to",
            " ",
            "145",
            " million",
            " years",
            " and",
            " situated",
            " off",
            " the",
            " west",
            " coast",
            " of",
            " Africa",
            " and",
            " east",
            " coast",
            " of",
            " North",
            " America",
            ",",
            " or",
            " on",
            " either",
            " side",
            " of",
            " the",
            " South",
            " Atlantic",
            ".",
            "In",
            " many",
            " places",
            ",",
            " the",
            " continental",
            " shelf",
            " and",
            " continental",
            " slope",
            " are",
            " covered",
            " in",
            " thick",
            " sediment",
            "ary",
            " layers",
            ".",
            " For",
            " instance",
            ",",
            " on",
            " the",
            " North",
            " American",
            " side",
            " of",
            " the",
            " ocean",
            ",",
            " large"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.455,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 36,
          "is_repeated_datapoint": false,
          "tokens": [
            "ification",
            "Notes",
            "C",
            "itations",
            "General",
            " references",
            " ",
            " ",
            "  ",
            "Ant",
            "ise",
            "pt",
            "ics",
            "Functional",
            " groups",
            "<|begin_of_text|>",
            "A",
            "ch",
            "ill",
            " Island",
            " (;",
            " )",
            " is",
            " the",
            " largest",
            " of",
            " the",
            " Irish",
            " is",
            "les",
            " and",
            " lies",
            " off",
            " the",
            " west",
            " coast",
            " of",
            " Ireland",
            " in",
            " County",
            " Mayo",
            ".",
            " It",
            " has",
            " a",
            " population",
            " of",
            " ",
            "2",
            ",",
            "345",
            ".",
            " Its",
            " area",
            " is",
            " .",
            " Ach",
            "ill",
            " is"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.447,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 27,
          "is_repeated_datapoint": false,
          "tokens": [
            " On",
            " January",
            " ",
            "30",
            ",",
            " ",
            "184",
            "6",
            ",",
            " the",
            " Alabama",
            " legislature",
            " announced",
            " it",
            " had",
            " voted",
            " to",
            " move",
            " the",
            " capital",
            " city",
            " from",
            " Tus",
            "cal",
            "o",
            "osa",
            " to",
            " Montgomery",
            ".",
            " The",
            " first",
            " legislative",
            " session",
            " in",
            " the",
            " new",
            " capital",
            " met",
            " in",
            " December",
            " ",
            "184",
            "7",
            ".",
            " A",
            " new",
            " cap",
            "itol",
            " building",
            " was",
            " erected",
            " under",
            " the",
            " direction",
            " of",
            " Stephen",
            " Dec",
            "atur",
            " Button",
            " of",
            " Philadelphia",
            ".",
            " The"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.447,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " are",
            " likely",
            " to",
            " be",
            " their",
            " last",
            ".",
            "The",
            " announcement",
            " of",
            " the",
            " new",
            " album",
            " was",
            " accompanied",
            " by",
            " the",
            " release",
            " of",
            " the",
            " singles",
            " \"",
            "I",
            " Still",
            " Have",
            " Faith",
            " in",
            " You",
            "\"",
            " and",
            " \"",
            "Don",
            "'t",
            " Shut",
            " Me",
            " Down",
            "\".",
            " The",
            " music",
            " video",
            " for",
            " \"",
            "I",
            " Still",
            " Have",
            " Faith",
            " in",
            " You",
            "\",",
            " featuring",
            " footage",
            " of",
            " the",
            " band",
            " during",
            " their",
            " performing",
            " years",
            " and",
            " a",
            " first",
            " look",
            " at"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.357,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 36,
          "is_repeated_datapoint": false,
          "tokens": [
            " who",
            " remained",
            " his",
            " lifelong",
            " partner",
            ".",
            " Selection",
            "s",
            " from",
            " their",
            " correspondence",
            " have",
            " been",
            " published",
            ".",
            "Also",
            " in",
            " San",
            " Francisco",
            ",",
            " Gins",
            "berg",
            " met",
            " members",
            " of",
            " the",
            " San",
            " Francisco",
            " Renaissance",
            " (",
            "James",
            " B",
            "rought",
            "on",
            ",",
            " Robert",
            " Duncan",
            ",",
            " Mad",
            "eline",
            " Gle",
            "ason",
            " and",
            " Kenneth",
            " Rex",
            "ro",
            "th",
            ")",
            " and",
            " other",
            " poets",
            " who",
            " would",
            " later",
            " be",
            " associated",
            " with",
            " the",
            " Beat",
            " Generation",
            " in",
            " a",
            " broader"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.332,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            " human",
            "-created",
            " waste",
            " floating",
            " in",
            " a",
            " body",
            " of",
            " water",
            ".",
            " Ocean",
            "ic",
            " debris",
            " tends",
            " to",
            " accumulate",
            " at",
            " the",
            " center",
            " of",
            " gy",
            "res",
            " and",
            " coast",
            "lines",
            ",",
            " frequently",
            " washing",
            " ag",
            "round",
            " where",
            " it",
            " is",
            " known",
            " as",
            " beach",
            " litter",
            ".",
            " The",
            " North",
            " Atlantic",
            " garbage",
            " patch",
            " is",
            " estimated",
            " to",
            " be",
            " hundreds",
            " of",
            " kilometers",
            " across",
            " in",
            " size",
            ".",
            "Other",
            " pollution",
            " concerns",
            " include",
            " agricultural",
            " and",
            " municipal",
            " waste",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.046,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.314,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 49,
          "is_repeated_datapoint": false,
          "tokens": [
            "-time",
            " tennis",
            " career",
            ".",
            "Professional",
            " career",
            "198",
            "6",
            "–",
            "199",
            "3",
            ":",
            " Break",
            "through",
            " and",
            " the",
            " first",
            " major",
            " title",
            "Ag",
            "assi",
            " turned",
            " professional",
            " at",
            " the",
            " age",
            " of",
            " ",
            "16",
            " and",
            " competed",
            " in",
            " his",
            " first",
            " tournament",
            " at",
            " La",
            " Quint",
            "a",
            ",",
            " California",
            ".",
            " He",
            " won",
            " his",
            " first",
            " match",
            " against",
            " John",
            " Austin",
            ",",
            " but",
            " then",
            " lost",
            " his",
            " second",
            " match",
            " to",
            " Mats",
            " Wil",
            "ander"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.283,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 17,
          "is_repeated_datapoint": false,
          "tokens": [
            " national",
            " policy",
            ",",
            " aims",
            " to",
            " be",
            " -",
            "neutral",
            " and",
            " independent",
            " of",
            " fossil",
            " fuels",
            " for",
            " heating",
            " by",
            " ",
            "203",
            "0",
            ".",
            " The",
            " municipal",
            " power",
            " plants",
            " were",
            " adapted",
            " for",
            " this",
            " purpose",
            " in",
            " the",
            " ",
            "201",
            "0",
            "s",
            ".",
            " In",
            " ",
            "201",
            "5",
            ",",
            " the",
            " municipality",
            " took",
            " over",
            " three",
            " private",
            " straw",
            "-fired",
            " heating",
            " plants",
            " and",
            " the",
            " year",
            " after",
            ",",
            " a",
            " new",
            " ",
            "77",
            " MW",
            " combined",
            " heat"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.266,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 16,
          "is_repeated_datapoint": false,
          "tokens": [
            "194",
            "8",
            ",",
            " with",
            " the",
            " help",
            " of",
            " several",
            " other",
            " drivers",
            " of",
            " the",
            " time",
            ".",
            " The",
            " first",
            " NASCAR",
            " \"",
            "Strict",
            "ly",
            " Stock",
            "\"",
            " race",
            " ever",
            " was",
            " held",
            " on",
            " June",
            " ",
            "19",
            ",",
            " ",
            "194",
            "9",
            ",",
            " at",
            " Daytona",
            " Beach",
            ",",
            " Florida",
            ",",
            " U",
            ".S",
            "..",
            "From",
            " ",
            "196",
            "2",
            ",",
            " sports",
            " cars",
            " temporarily",
            " took",
            " a",
            " back",
            " seat",
            " to",
            " GT",
            " cars",
            ",",
            " with",
            " the",
            " "
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.186,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " American",
            " culture",
            ".",
            " Numerous",
            " books",
            " that",
            " discussed",
            " sex",
            " were",
            " banned",
            " at",
            " the",
            " time",
            ",",
            " including",
            " Lady",
            " Ch",
            "atter",
            "ley",
            "'s",
            " Lover",
            ".",
            " The",
            " sex",
            " that",
            " Gins",
            "berg",
            " described",
            " did",
            " not",
            " portray",
            " the",
            " sex",
            " between",
            " heterosexual",
            " married",
            " couples",
            ",",
            " or",
            " even",
            " longtime",
            " lovers",
            ".",
            " Instead",
            ",",
            " Gins",
            "berg",
            " portrayed",
            " casual",
            " sex",
            ".",
            " For",
            " example",
            ",",
            " in",
            " How",
            "l",
            ",",
            " Gins",
            "berg",
            " praises",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.171,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            " used",
            " in",
            " fireworks",
            " in",
            " China",
            " by",
            " the",
            " ",
            "10",
            "th",
            " century",
            ",",
            " it",
            " was",
            " used",
            " in",
            " cannons",
            " by",
            " ",
            "129",
            "0",
            ".",
            " From",
            " China",
            ",",
            " the",
            " use",
            " of",
            " gun",
            "pow",
            "der",
            " spread",
            " to",
            " Japan",
            ",",
            " the",
            " Mong",
            "ols",
            ",",
            " the",
            " Muslim",
            " world",
            ",",
            " and",
            " Europe",
            ".",
            " Gun",
            "pow",
            "der",
            " was",
            " used",
            " by",
            " the",
            " Mong",
            "ols",
            " against",
            " the",
            " Hung",
            "arians",
            " in",
            " ",
            "124",
            "1"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.164,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            "ise",
            " de",
            " Maint",
            "en",
            "on",
            ",",
            " French",
            " wife",
            " of",
            " Louis",
            " XIV",
            " of",
            " France",
            " (",
            "b",
            ".",
            " ",
            "163",
            "5",
            ")",
            "175",
            "4",
            " –",
            " Jac",
            "opo",
            " Ric",
            "cat",
            "i",
            ",",
            " Italian",
            " mathematic",
            "ian",
            " and",
            " academic",
            " (",
            "b",
            ".",
            " ",
            "167",
            "6",
            ")",
            "175",
            "7",
            " –",
            " Ros",
            "al",
            "ba",
            " Car",
            "ri",
            "era",
            ",",
            " Italian",
            " painter",
            " (",
            "b",
            ".",
            " ",
            "167",
            "3",
            ")",
            "176",
            "1",
            " –"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.157,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            " aluminium",
            ".",
            " A",
            " cell",
            " is",
            " usually",
            " terminated",
            " after",
            " ",
            "2",
            "–",
            "6",
            " years",
            " following",
            " a",
            " failure",
            " of",
            " the",
            " cath",
            "ode",
            ".",
            "The",
            " Hall",
            "–",
            "Her",
            "ou",
            "lt",
            " process",
            " produces",
            " aluminium",
            " with",
            " a",
            " purity",
            " of",
            " above",
            " ",
            "99",
            "%.",
            " Further",
            " purification",
            " can",
            " be",
            " done",
            " by",
            " the",
            " Ho",
            "opes",
            " process",
            ".",
            " This",
            " process",
            " involves",
            " the",
            " electroly",
            "sis",
            " of",
            " mol",
            "ten",
            " aluminium",
            " with",
            " a",
            " sodium",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.131,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            " subsequent",
            " missions",
            ",",
            " extra",
            " anti",
            "-s",
            "lo",
            "sh",
            " baff",
            "les",
            " were",
            " added",
            " to",
            " the",
            " tanks",
            " to",
            " prevent",
            " this",
            ".",
            "Arm",
            "strong",
            " acknowledged",
            " Ald",
            "rin",
            "'s",
            " completion",
            " of",
            " the",
            " post",
            "-",
            "landing",
            " checklist",
            " with",
            " \"",
            "Engine",
            " arm",
            " is",
            " off",
            "\",",
            " before",
            " responding",
            " to",
            " the",
            " CAP",
            "COM",
            ",",
            " Charles",
            " Duke",
            ",",
            " with",
            " the",
            " words",
            ",",
            " \"",
            "Houston",
            ",",
            " Tran",
            "qu",
            "ility",
            " Base",
            " here",
            ".",
            " The"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.012,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            " becoming",
            " an",
            " EU",
            " member",
            " state",
            ".",
            "Al",
            "ban",
            "ia",
            " and",
            " Kosovo",
            " maintain",
            " a",
            " frat",
            "ernal",
            " relationship",
            " strengthened",
            " by",
            " their",
            " substantial",
            " cultural",
            ",",
            " ethn",
            "ical",
            " and",
            " historical",
            " ties",
            ".",
            " Both",
            " countries",
            " foster",
            " enduring",
            " diplomatic",
            " ties",
            ",",
            " with",
            " Albania",
            " actively",
            " supporting",
            " Kosovo",
            "'s",
            " development",
            " and",
            " international",
            " integration",
            " efforts",
            ".",
            " Its",
            " fundamental",
            " contribution",
            " to",
            " Kosovo",
            "'s",
            " path",
            " to",
            " independence",
            " is",
            " underscore",
            "d",
            " by",
            " its",
            " early",
            " recognition"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " dragon",
            " sl",
            "ayer",
            " (",
            "probably",
            " the",
            " son",
            " of",
            " Tri",
            "op",
            "as",
            ")",
            "Children",
            "Apollo",
            " s",
            "ired",
            " many",
            " children",
            ",",
            " from",
            " mortal",
            " women",
            " and",
            " nymph",
            "s",
            " as",
            " well",
            " as",
            " the",
            " goddess",
            "es",
            ".",
            " His",
            " children",
            " grew",
            " up",
            " to",
            " be",
            " physicians",
            ",",
            " musicians",
            ",",
            " poets",
            ",",
            " se",
            "ers",
            " or",
            " arch",
            "ers",
            ".",
            " Many",
            " of",
            " his",
            " sons",
            " founded",
            " new",
            " cities",
            " and",
            " became",
            " kings",
            ".",
            "As"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " as",
            " the",
            " automobile",
            " became",
            " available",
            " to",
            " most",
            " people",
            ".",
            " A",
            " metro",
            " started",
            " operating",
            " in",
            " ",
            "197",
            "7",
            " between",
            " the",
            " new",
            " suburb",
            " of",
            " Bij",
            "l",
            "mer",
            "meer",
            " in",
            " the",
            " city",
            "'s",
            " Z",
            "uido",
            "ost",
            " (",
            "sou",
            "theast",
            ")",
            " ex",
            "clave",
            " and",
            " the",
            " centre",
            " of",
            " Amsterdam",
            ".",
            " Further",
            " plans",
            " were",
            " to",
            " build",
            " a",
            " new",
            " highway",
            " above",
            " the",
            " metro",
            " to",
            " connect",
            " Amsterdam",
            " Cent",
            "ra",
            "al"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " sent",
            " another",
            " story",
            ",",
            " entitled",
            " \"",
            "Black",
            " Destroy",
            "er",
            "\",",
            " which",
            " was",
            " accepted",
            ".",
            " It",
            " featured",
            " a",
            " fierce",
            ",",
            " carniv",
            "orous",
            " alien",
            " stalking",
            " the",
            " crew",
            " of",
            " a",
            " spaceship",
            ",",
            " and",
            " served",
            " as",
            " the",
            " inspiration",
            " for",
            " multiple",
            " science",
            " fiction",
            " movies",
            ",",
            " including",
            " Alien",
            " (",
            "197",
            "9",
            ").",
            " A",
            " revised",
            " version",
            " of",
            " \"",
            "Vault",
            " of",
            " the",
            " Beast",
            "\"",
            " was",
            " published",
            " in",
            " ",
            "194",
            "0",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " was",
            " founded",
            " in",
            " ",
            "193",
            "0",
            ".",
            " Under",
            " the",
            " patron",
            "age",
            " of",
            " His",
            " Royal",
            " High",
            "ness",
            " Crown",
            " Prince",
            " Freder",
            "ik",
            ",",
            " it",
            " offers",
            " graduate",
            " level",
            " studies",
            " in",
            " areas",
            " such",
            " as",
            " music",
            " teaching",
            ",",
            " and",
            " solo",
            " and",
            " professional",
            " musicians",
            "hip",
            ".",
            " VIA",
            " University",
            " College",
            " was",
            " established",
            " in",
            " January",
            " ",
            "200",
            "8",
            " and",
            " is",
            " one",
            " of",
            " eight",
            " new",
            " regional",
            " organisations",
            " offering",
            " bachelor",
            " courses",
            " of",
            " all"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "ycastle",
    ".mybatisplus",
    "onders",
    "inch",
    "ibo"
  ],
  "bottom_logits": [
    "egr",
    "idot",
    "kers",
    " crystall",
    " cause"
  ],
  "act_min": -0.0,
  "act_max": 0.656
}
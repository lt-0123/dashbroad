{
  "index": 45878,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.941,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " currently",
            " in",
            " a",
            " state",
            " of",
            " flux",
            ",",
            " with",
            " many",
            " of",
            " the",
            " groups",
            " being",
            " found",
            " to",
            " be",
            " gross",
            "ly",
            " paraph",
            "yle",
            "tic",
            " or",
            " poly",
            "ph",
            "yle",
            "tic",
            ".",
            "Classification",
            " and",
            " phy",
            "log",
            "eny",
            "Prior",
            " to",
            " molecular",
            " phy",
            "logen",
            "etic",
            " studies",
            ",",
            " the",
            " family",
            " was",
            " subdiv",
            "ided",
            " primarily",
            " based",
            " on",
            " fruit",
            " characteristics",
            ".",
            " Molecular",
            " phy",
            "logen",
            "etic",
            " analyses",
            " from",
            " the",
            " mid",
            "-",
            "199",
            "0"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.941,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " currently",
            " in",
            " a",
            " state",
            " of",
            " flux",
            ",",
            " with",
            " many",
            " of",
            " the",
            " groups",
            " being",
            " found",
            " to",
            " be",
            " gross",
            "ly",
            " paraph",
            "yle",
            "tic",
            " or",
            " poly",
            "ph",
            "yle",
            "tic",
            ".",
            "Classification",
            " and",
            " phy",
            "log",
            "eny",
            "Prior",
            " to",
            " molecular",
            " phy",
            "logen",
            "etic",
            " studies",
            ",",
            " the",
            " family",
            " was",
            " subdiv",
            "ided",
            " primarily",
            " based",
            " on",
            " fruit",
            " characteristics",
            ".",
            " Molecular",
            " phy",
            "logen",
            "etic",
            " analyses",
            " from",
            " the",
            " mid",
            "-",
            "199",
            "0"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.934,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 39,
          "is_repeated_datapoint": false,
          "tokens": [
            " initials",
            " and",
            " allow",
            " players",
            " to",
            " enter",
            " their",
            " initials",
            " for",
            " appearing",
            " in",
            " the",
            " top",
            " ",
            "10",
            " high",
            " scores",
            ",",
            " and",
            " commented",
            ",",
            " \"",
            "the",
            " vector",
            " graphics",
            " fit",
            " the",
            " futuristic",
            " outer",
            " space",
            " theme",
            " very",
            " well",
            "\".",
            " In",
            " ",
            "199",
            "5",
            ",",
            " Flux",
            " magazine",
            " ranked",
            " the",
            " arcade",
            " version",
            " ",
            "11",
            "th",
            " on",
            " their",
            " \"",
            "Top",
            " ",
            "100",
            " Video",
            " Games",
            ".\"",
            " In",
            " ",
            "199",
            "6",
            ",",
            " Next"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.934,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 39,
          "is_repeated_datapoint": false,
          "tokens": [
            " initials",
            " and",
            " allow",
            " players",
            " to",
            " enter",
            " their",
            " initials",
            " for",
            " appearing",
            " in",
            " the",
            " top",
            " ",
            "10",
            " high",
            " scores",
            ",",
            " and",
            " commented",
            ",",
            " \"",
            "the",
            " vector",
            " graphics",
            " fit",
            " the",
            " futuristic",
            " outer",
            " space",
            " theme",
            " very",
            " well",
            "\".",
            " In",
            " ",
            "199",
            "5",
            ",",
            " Flux",
            " magazine",
            " ranked",
            " the",
            " arcade",
            " version",
            " ",
            "11",
            "th",
            " on",
            " their",
            " \"",
            "Top",
            " ",
            "100",
            " Video",
            " Games",
            ".\"",
            " In",
            " ",
            "199",
            "6",
            ",",
            " Next"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.926,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 20,
          "is_repeated_datapoint": false,
          "tokens": [
            " over",
            " all",
            " solar",
            " angles",
            " in",
            " a",
            " given",
            " period",
            ".",
            " The",
            " temporal",
            " resolution",
            " may",
            " range",
            " from",
            " seconds",
            " (",
            "as",
            " obtained",
            " from",
            " flux",
            " measurements",
            ")",
            " to",
            " daily",
            ",",
            " monthly",
            ",",
            " or",
            " annual",
            " averages",
            ".",
            "Unless",
            " given",
            " for",
            " a",
            " specific",
            " wavelength",
            " (",
            "spect",
            "ral",
            " al",
            "bedo",
            "),",
            " al",
            "bedo",
            " refers",
            " to",
            " the",
            " entire",
            " spectrum",
            " of",
            " solar",
            " radiation",
            ".",
            " Due",
            " to",
            " measurement",
            " constraints",
            ",",
            " it",
            " is",
            " often"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.898,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            " its",
            " nuclear",
            " is",
            "omer",
            " ",
            "242",
            "m",
            "Am",
            ":",
            "Americ",
            "ium",
            "-",
            "242",
            " has",
            " a",
            " half",
            "-life",
            " of",
            " only",
            " ",
            "16",
            " hours",
            ",",
            " which",
            " makes",
            " its",
            " further",
            " conversion",
            " to",
            " ",
            "243",
            "Am",
            " extremely",
            " inefficient",
            ".",
            " The",
            " latter",
            " is",
            "otope",
            " is",
            " produced",
            " instead",
            " in",
            " a",
            " process",
            " where",
            " ",
            "239",
            "Pu",
            " captures",
            " four",
            " neut",
            "rons",
            " under",
            " high",
            " neutron",
            " flux",
            ":",
            " ^{",
            "239",
            "}_{",
            "94",
            "}"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.898,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            " its",
            " nuclear",
            " is",
            "omer",
            " ",
            "242",
            "m",
            "Am",
            ":",
            "Americ",
            "ium",
            "-",
            "242",
            " has",
            " a",
            " half",
            "-life",
            " of",
            " only",
            " ",
            "16",
            " hours",
            ",",
            " which",
            " makes",
            " its",
            " further",
            " conversion",
            " to",
            " ",
            "243",
            "Am",
            " extremely",
            " inefficient",
            ".",
            " The",
            " latter",
            " is",
            "otope",
            " is",
            " produced",
            " instead",
            " in",
            " a",
            " process",
            " where",
            " ",
            "239",
            "Pu",
            " captures",
            " four",
            " neut",
            "rons",
            " under",
            " high",
            " neutron",
            " flux",
            ":",
            " ^{",
            "239",
            "}_{",
            "94",
            "}"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.852,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.006,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 29,
          "is_repeated_datapoint": false,
          "tokens": [
            "ing",
            " to",
            " a",
            " body",
            " that",
            " reflects",
            " all",
            " incident",
            " radiation",
            ").",
            "Surface",
            " al",
            "bedo",
            " is",
            " defined",
            " as",
            " the",
            " ratio",
            " of",
            " radi",
            "osity",
            " Je",
            " to",
            " the",
            " irradi",
            "ance",
            " E",
            "e",
            " (",
            "flux",
            " per",
            " unit",
            " area",
            ")",
            " received",
            " by",
            " a",
            " surface",
            ".",
            " The",
            " proportion",
            " reflected",
            " is",
            " not",
            " only",
            " determined",
            " by",
            " properties",
            " of",
            " the",
            " surface",
            " itself",
            ",",
            " but",
            " also",
            " by",
            " the",
            " spectral",
            " and",
            " angular",
            " distribution",
            " of",
            " solar"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.852,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.006,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 29,
          "is_repeated_datapoint": false,
          "tokens": [
            "ing",
            " to",
            " a",
            " body",
            " that",
            " reflects",
            " all",
            " incident",
            " radiation",
            ").",
            "Surface",
            " al",
            "bedo",
            " is",
            " defined",
            " as",
            " the",
            " ratio",
            " of",
            " radi",
            "osity",
            " Je",
            " to",
            " the",
            " irradi",
            "ance",
            " E",
            "e",
            " (",
            "flux",
            " per",
            " unit",
            " area",
            ")",
            " received",
            " by",
            " a",
            " surface",
            ".",
            " The",
            " proportion",
            " reflected",
            " is",
            " not",
            " only",
            " determined",
            " by",
            " properties",
            " of",
            " the",
            " surface",
            " itself",
            ",",
            " but",
            " also",
            " by",
            " the",
            " spectral",
            " and",
            " angular",
            " distribution",
            " of",
            " solar"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.789,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " Security",
            " Council",
            " to",
            " impose",
            " and",
            " carry",
            " out",
            " sanctions",
            " on",
            " UNIT",
            "A",
            ".",
            " More",
            " recently",
            ",",
            " it",
            " has",
            " extended",
            " those",
            " efforts",
            " to",
            " controls",
            " on",
            " conflict",
            " diamonds",
            ",",
            " the",
            " primary",
            " source",
            " of",
            " revenue",
            " for",
            " UNIT",
            "A",
            " during",
            " the",
            " Civil",
            " War",
            " that",
            " ended",
            " in",
            " ",
            "200",
            "2",
            ".",
            " At",
            " the",
            " same",
            " time",
            ",",
            " Angola",
            " has",
            " promoted",
            " the",
            " revival",
            " of",
            " the",
            " Community",
            " of",
            " Portuguese",
            "-S",
            "pe",
            "aking"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            0.789,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " Security",
            " Studies",
            ".",
            " Global",
            " Witness",
            " (",
            "199",
            "9",
            ").",
            " A",
            " Cr",
            "ude",
            " Awakening",
            ",",
            " The",
            " Role",
            " of",
            " Oil",
            " and",
            " Banking",
            " Industries",
            " in",
            " Angola",
            "'s",
            " Civil",
            " War",
            " and",
            " the",
            " Pl",
            "under",
            "ing",
            " of",
            " State",
            " Assets",
            ".",
            " London",
            ",",
            " UK",
            ",",
            " Global",
            " Witness",
            ".",
            " A",
            " Cr",
            "ude",
            " Awakening",
            " Hod",
            "ges",
            ",",
            " Tony",
            " (",
            "200",
            "1",
            ").",
            " Angola",
            " from",
            " Afro",
            "-St",
            "alin",
            "ism",
            " to",
            " Petro"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.789,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " Security",
            " Studies",
            ".",
            " Global",
            " Witness",
            " (",
            "199",
            "9",
            ").",
            " A",
            " Cr",
            "ude",
            " Awakening",
            ",",
            " The",
            " Role",
            " of",
            " Oil",
            " and",
            " Banking",
            " Industries",
            " in",
            " Angola",
            "'s",
            " Civil",
            " War",
            " and",
            " the",
            " Pl",
            "under",
            "ing",
            " of",
            " State",
            " Assets",
            ".",
            " London",
            ",",
            " UK",
            ",",
            " Global",
            " Witness",
            ".",
            " A",
            " Cr",
            "ude",
            " Awakening",
            " Hod",
            "ges",
            ",",
            " Tony",
            " (",
            "200",
            "1",
            ").",
            " Angola",
            " from",
            " Afro",
            "-St",
            "alin",
            "ism",
            " to",
            " Petro"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.723,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            " Me",
            "asuring",
            " the",
            " heat",
            " flux",
            " of",
            " an",
            " asteroid",
            " at",
            " a",
            " single",
            " wavelength",
            " gives",
            " an",
            " estimate",
            " of",
            " the",
            " dimensions",
            " of",
            " the",
            " object",
            ";",
            " these",
            " measurements",
            " have",
            " lower",
            " uncertainty",
            " than",
            " measurements",
            " of",
            " the",
            " reflected",
            " sunlight",
            " in",
            " the",
            " visible",
            "-light",
            " spectral",
            " region",
            ".",
            " If",
            " the",
            " two",
            " measurements",
            " can",
            " be",
            " combined",
            ",",
            " both",
            " the",
            " effective",
            " diameter",
            " and",
            " the",
            " geometric",
            " al",
            "bedo",
            "â€”the",
            " latter",
            " being",
            " a",
            " measure"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.703,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 33,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            " In",
            " June",
            " ",
            "201",
            "2",
            ",",
            " the",
            " President",
            " approved",
            " the",
            " new",
            " Regulation",
            ",",
            " which",
            " granted",
            " additional",
            " powers",
            " to",
            " Local",
            " Executive",
            " Authorities",
            ",",
            " strengthening",
            " their",
            " dominant",
            " position",
            " in",
            " Azerbaijan",
            "'s",
            " local",
            " affairs",
            " The",
            " Security",
            " Council",
            " is",
            " the",
            " deliber",
            "ative",
            " body",
            " under",
            " the",
            " president",
            ",",
            " and",
            " he",
            " organ",
            "izes",
            " it",
            " according",
            " to",
            " the",
            " Constitution",
            ".",
            " It",
            " was",
            " established",
            " on",
            " ",
            "10",
            " April",
            " ",
            "199"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.699,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " highest",
            " perfection",
            ",",
            " and",
            " the",
            " distinction",
            " of",
            " Families",
            ",",
            " with",
            " the",
            " Security",
            " of",
            " the",
            " Marriage",
            " Bed",
            ",",
            " as",
            " necessary",
            " there",
            "unto",
            "\".",
            " (",
            "First",
            " Treat",
            "ise",
            ",",
            " sec",
            ".",
            " ",
            "59",
            ").",
            "E",
            "conomic",
            " themes",
            "Robert",
            " Ph",
            "idd",
            "ian",
            "'s",
            " article",
            " \"",
            "Have",
            " you",
            " eaten",
            " yet",
            "?",
            " The",
            " Reader",
            " in",
            " A",
            " Mod",
            "est",
            " Proposal",
            "\"",
            " focuses",
            " on",
            " two",
            " aspects",
            " of",
            " A"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.699,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " highest",
            " perfection",
            ",",
            " and",
            " the",
            " distinction",
            " of",
            " Families",
            ",",
            " with",
            " the",
            " Security",
            " of",
            " the",
            " Marriage",
            " Bed",
            ",",
            " as",
            " necessary",
            " there",
            "unto",
            "\".",
            " (",
            "First",
            " Treat",
            "ise",
            ",",
            " sec",
            ".",
            " ",
            "59",
            ").",
            "E",
            "conomic",
            " themes",
            "Robert",
            " Ph",
            "idd",
            "ian",
            "'s",
            " article",
            " \"",
            "Have",
            " you",
            " eaten",
            " yet",
            "?",
            " The",
            " Reader",
            " in",
            " A",
            " Mod",
            "est",
            " Proposal",
            "\"",
            " focuses",
            " on",
            " two",
            " aspects",
            " of",
            " A"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.691,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            "200",
            "6",
            " Azerbaijan",
            " was",
            " elected",
            " to",
            " membership",
            " in",
            " the",
            " newly",
            " established",
            " Human",
            " Rights",
            " Council",
            " by",
            " the",
            " United",
            " Nations",
            " General",
            " Assembly",
            ".",
            " The",
            " term",
            " of",
            " office",
            " began",
            " on",
            " ",
            "19",
            " June",
            " ",
            "200",
            "6",
            ".",
            " Azerbaijan",
            " was",
            " first",
            " elected",
            " as",
            " a",
            " non",
            "-per",
            "manent",
            " member",
            " of",
            " the",
            " UN",
            " Security",
            " Council",
            " in",
            " ",
            "201",
            "1",
            " with",
            " the",
            " support",
            " of",
            " ",
            "155",
            " countries",
            ".",
            "Foreign",
            " policy"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.691,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " able",
            "-bodied",
            " man",
            " of",
            " a",
            " house",
            ")",
            " should",
            ",",
            " by",
            " law",
            ",",
            " keep",
            " a",
            " rifle",
            ",",
            " even",
            " though",
            " the",
            " law",
            " also",
            " states",
            " that",
            " the",
            " police",
            " will",
            " offer",
            " a",
            " firearm",
            " in",
            " case",
            " of",
            " need",
            ".",
            " And",
            "orra",
            " is",
            " a",
            " full",
            " member",
            " of",
            " the",
            " United",
            " Nations",
            " (",
            "UN",
            "),",
            " the",
            " Organization",
            " for",
            " Security",
            " and",
            " Co",
            "-operation",
            " in",
            " Europe",
            " (",
            "OS",
            "CE",
            "),",
            " and",
            " has",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.633,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.555,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "im",
            " Administration",
            " under",
            " Ham",
            "id",
            " Kar",
            "z",
            "ai",
            " was",
            " formed",
            ".",
            " The",
            " International",
            " Security",
            " Assistance",
            " Force",
            " (",
            "IS",
            "AF",
            ")",
            " was",
            " established",
            " by",
            " the",
            " UN",
            " Security",
            " Council",
            " to",
            " help",
            " assist",
            " the",
            " Kar",
            "z",
            "ai",
            " administration",
            " and",
            " provide",
            " basic",
            " security",
            ".",
            " By",
            " this",
            " time",
            ",",
            " after",
            " two",
            " decades",
            " of",
            " war",
            " as",
            " well",
            " as",
            " an",
            " acute",
            " famine",
            " at",
            " the",
            " time",
            ",",
            " Afghanistan",
            " had",
            " one",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.633,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.555,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "im",
            " Administration",
            " under",
            " Ham",
            "id",
            " Kar",
            "z",
            "ai",
            " was",
            " formed",
            ".",
            " The",
            " International",
            " Security",
            " Assistance",
            " Force",
            " (",
            "IS",
            "AF",
            ")",
            " was",
            " established",
            " by",
            " the",
            " UN",
            " Security",
            " Council",
            " to",
            " help",
            " assist",
            " the",
            " Kar",
            "z",
            "ai",
            " administration",
            " and",
            " provide",
            " basic",
            " security",
            ".",
            " By",
            " this",
            " time",
            ",",
            " after",
            " two",
            " decades",
            " of",
            " war",
            " as",
            " well",
            " as",
            " an",
            " acute",
            " famine",
            " at",
            " the",
            " time",
            ",",
            " Afghanistan",
            " had",
            " one",
            " of"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.633,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.555,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "im",
            " Administration",
            " under",
            " Ham",
            "id",
            " Kar",
            "z",
            "ai",
            " was",
            " formed",
            ".",
            " The",
            " International",
            " Security",
            " Assistance",
            " Force",
            " (",
            "IS",
            "AF",
            ")",
            " was",
            " established",
            " by",
            " the",
            " UN",
            " Security",
            " Council",
            " to",
            " help",
            " assist",
            " the",
            " Kar",
            "z",
            "ai",
            " administration",
            " and",
            " provide",
            " basic",
            " security",
            ".",
            " By",
            " this",
            " time",
            ",",
            " after",
            " two",
            " decades",
            " of",
            " war",
            " as",
            " well",
            " as",
            " an",
            " acute",
            " famine",
            " at",
            " the",
            " time",
            ",",
            " Afghanistan",
            " had",
            " one",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.684,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            " program",
            ";",
            " in",
            " addition",
            ",",
            " HT",
            "S",
            " teams",
            " are",
            " working",
            " with",
            " the",
            " US",
            " military",
            " in",
            " Iraq",
            ".",
            " In",
            " ",
            "200",
            "9",
            ",",
            " the",
            " American",
            " Anthrop",
            "ological",
            " Association",
            "'s",
            " Commission",
            " on",
            " the",
            " Engagement",
            " of",
            " Anthrop",
            "ology",
            " with",
            " the",
            " US",
            " Security",
            " and",
            " Intelligence",
            " Communities",
            " (",
            "CE",
            "AU",
            "SS",
            "IC",
            ")",
            " released",
            " its",
            " final",
            " report",
            " concluding",
            ",",
            " in",
            " part",
            ",",
            " that",
            ",",
            "Post",
            "-",
            "World",
            " War"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.475,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " security",
            ",",
            " and",
            " how",
            " changes",
            " in",
            " the",
            " former",
            " affect",
            " the",
            " latter",
            ".",
            " If",
            " economic",
            " and",
            " environmental",
            " changes",
            " in",
            " a",
            " community",
            " affect",
            " access",
            " to",
            " food",
            ",",
            " food",
            " security",
            ",",
            " and",
            " dietary",
            " health",
            ",",
            " then",
            " this",
            " inter",
            "play",
            " between",
            " culture",
            " and",
            " biology",
            " is",
            " in",
            " turn",
            " connected",
            " to",
            " broader",
            " historical",
            " and",
            " economic",
            " trends",
            " associated",
            " with",
            " globalization",
            ".",
            " Nut",
            "ritional",
            " status",
            " affects",
            " overall",
            " health",
            " status",
            ",",
            " work"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 44,
          "is_repeated_datapoint": false,
          "tokens": [
            " pog",
            "rom",
            ".",
            " Furthermore",
            ",",
            " an",
            " estimated",
            " ",
            "30",
            ",",
            "000",
            " people",
            " have",
            " been",
            " killed",
            " and",
            " more",
            " than",
            " a",
            " million",
            " people",
            " have",
            " been",
            " displaced",
            ",",
            " more",
            " than",
            " ",
            "800",
            ",",
            "000",
            " Azerbaijan",
            "is",
            " and",
            " ",
            "300",
            ",",
            "000",
            " Armen",
            "ians",
            ".",
            " Four",
            " United",
            " Nations",
            " Security",
            " Council",
            " Res",
            "olutions",
            " (",
            "822",
            ",",
            " ",
            "853",
            ",",
            " ",
            "874",
            ",",
            " and",
            " ",
            "884",
            ")",
            " demand",
            " for"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 11,
          "is_repeated_datapoint": false,
          "tokens": [
            " that",
            " \"",
            "the",
            " ",
            "184",
            "9",
            " article",
            " '",
            "The",
            " Production",
            " of",
            " Security",
            "'",
            " is",
            " probably",
            " the",
            " single",
            " most",
            " important",
            " contribution",
            " to",
            " the",
            " modern",
            " theory",
            " of",
            " an",
            "ar",
            "cho",
            "-capital",
            "ism",
            "\".",
            " According",
            " to",
            " Hans",
            "-H",
            "ermann",
            " Hop",
            "pe",
            ",",
            " one",
            " of",
            " the",
            " ",
            "19",
            "th",
            " century",
            " prec",
            "ursors",
            " of",
            " an",
            "ar",
            "cho",
            "-capital",
            "ism",
            " were",
            " philosopher",
            " Herbert",
            " Spencer",
            ",",
            " classical",
            " liberal",
            " Aub",
            "eron"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " ",
            "197",
            "7",
            " English",
            " translation",
            " by",
            " Murray",
            " Roth",
            "bard",
            " called",
            " The",
            " Production",
            " of",
            " Security",
            " the",
            " \"",
            "first",
            " presentation",
            " anywhere",
            " in",
            " human",
            " history",
            " of",
            " what",
            " is",
            " now",
            " called",
            " an",
            "ar",
            "cho",
            "-capital",
            "ism",
            "\",",
            " although",
            " admitting",
            " that",
            " \"",
            "M",
            "olin",
            "ari",
            " did",
            " not",
            " use",
            " the",
            " terminology",
            ",",
            " and",
            " probably",
            " would",
            " have",
            " balk",
            "ed",
            " at",
            " the",
            " name",
            "\".",
            " Hans",
            "-H",
            "ermann",
            " Hop",
            "pe",
            " said"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.672,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 42,
          "is_repeated_datapoint": false,
          "tokens": [
            "ed",
            " off",
            " the",
            " New",
            " South",
            " Wales",
            " coast",
            " dumps",
            " a",
            " record",
            " ",
            "328",
            " mill",
            "imeters",
            " (",
            "13",
            "Ã‚Å‚in",
            "ches",
            ")",
            " of",
            " rain",
            " in",
            " a",
            " day",
            " on",
            " Sydney",
            ",",
            " New",
            " South",
            " Wales",
            ",",
            " Australia",
            ".",
            "199",
            "0",
            " â€“",
            " Gulf",
            " War",
            ":",
            " The",
            " United",
            " Nations",
            " Security",
            " Council",
            " orders",
            " a",
            " global",
            " trade",
            " embargo",
            " against",
            " Iraq",
            " in",
            " response",
            " to",
            " Iraq",
            "'s",
            " invasion",
            " of",
            " Kuwait",
            ".",
            "199",
            "1",
            " â€“"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.668,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 15,
          "is_repeated_datapoint": false,
          "tokens": [
            " was",
            " elected",
            " for",
            " the",
            " second",
            " time",
            " a",
            " non",
            "-per",
            "manent",
            " member",
            " of",
            " the",
            " United",
            " Nations",
            " Security",
            " Council",
            ",",
            " with",
            " ",
            "190",
            " favorable",
            " votes",
            " out",
            " of",
            " a",
            " total",
            " of",
            " ",
            "193",
            ".",
            " The",
            " term",
            " of",
            " office",
            " began",
            " on",
            " ",
            "1",
            " January",
            " ",
            "201",
            "5",
            " and",
            " expired",
            " on",
            " ",
            "31",
            " December",
            " ",
            "201",
            "6",
            ".",
            "Since",
            " January",
            " ",
            "201",
            "4",
            ",",
            " the",
            " Republic",
            " of",
            " Angola"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.668,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            " World",
            " Trade",
            " Organization",
            " and",
            " the",
            " Eastern",
            " Caribbean",
            "'s",
            " Regional",
            " Security",
            " System",
            ".",
            "Ant",
            "igua",
            " and",
            " Barb",
            "uda",
            " is",
            " also",
            " a",
            " member",
            " of",
            " the",
            " International",
            " Criminal",
            " Court",
            " (",
            "with",
            " a",
            " Bil",
            "ateral",
            " Imm",
            "unity",
            " Agreement",
            " of",
            " Protection",
            " for",
            " the",
            " US",
            " military",
            " as",
            " covered",
            " under",
            " Article",
            " ",
            "98",
            " of",
            " the",
            " Rome",
            " Stat",
            "ute",
            ").",
            "In",
            " ",
            "201",
            "3",
            ",",
            " Ant",
            "igua",
            " and",
            " Barb",
            "uda",
            " called"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.664,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            "ere",
            "'s",
            " Response",
            "\",",
            " pp",
            ".",
            "Ã‚Å‚",
            "324",
            "â€“",
            "346",
            ",",
            " .",
            " Pearce",
            ",",
            " Justin",
            " (",
            "200",
            "4",
            ").",
            " \"",
            "War",
            ",",
            " Peace",
            " and",
            " Diamonds",
            " in",
            " Angola",
            ":",
            " Popular",
            " perceptions",
            " of",
            " the",
            " diamond",
            " industry",
            " in",
            " the",
            " Lund",
            "as",
            "\".",
            " African",
            " Security",
            " Review",
            " ",
            "13",
            " (",
            "2",
            "),",
            " pp",
            " ",
            "51",
            "â€“",
            "64",
            ".",
            " Wayback",
            " Machine",
            " Porto",
            ",",
            " Jo",
            "ÃƒÂ£o",
            " G",
            "omes",
            " ("
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.66
          ],
          "train_token_ind": 62,
          "is_repeated_datapoint": false,
          "tokens": [
            " Supreme",
            " Military",
            " Court",
            " are",
            " appointed",
            " by",
            " the",
            " President",
            " of",
            " the",
            " Republic",
            ".",
            " The",
            " composition",
            ",",
            " organization",
            ",",
            " powers",
            " and",
            " functioning",
            " of",
            " the",
            " Supreme",
            " Military",
            " Court",
            " are",
            " established",
            " by",
            " law",
            ".",
            "Military",
            " Bands",
            " ",
            "The",
            " FAA",
            " maintains",
            " Portuguese",
            "-style",
            " military",
            " bands",
            " in",
            " all",
            " three",
            " branches",
            " and",
            " in",
            " individual",
            " units",
            ".",
            " The",
            " primary",
            " band",
            " is",
            " the",
            " ",
            "100",
            "-member",
            " Music",
            " Band",
            " of",
            " the",
            " Presidential",
            " Security"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.652
          ],
          "train_token_ind": 62,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " are",
            " relatively",
            " high",
            " â€“",
            " ",
            "57",
            ".",
            "6",
            " to",
            " ",
            "75",
            ".",
            "6",
            "Ã‚Å‚",
            "kg",
            " for",
            " ",
            "241",
            "Am",
            " and",
            " ",
            "209",
            "Ã‚Å‚",
            "kg",
            " for",
            " ",
            "243",
            "Am",
            ".",
            " Sc",
            "arc",
            "ity",
            " and",
            " high",
            " price",
            " yet",
            " hinder",
            " application",
            " of",
            " americ",
            "ium",
            " as",
            " a",
            " nuclear",
            " fuel",
            " in",
            " nuclear",
            " reactors",
            ".",
            "There",
            " are",
            " proposals",
            " of",
            " very",
            " compact",
            " ",
            "10",
            "-k",
            "W",
            " high",
            "-fl",
            "ux"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.648,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            " recognise",
            " Te",
            "bb",
            "ou",
            "ne",
            " as",
            " president",
            ",",
            " citing",
            " demands",
            " for",
            " comprehensive",
            " reform",
            " of",
            " the",
            " political",
            " system",
            ".",
            " Algeria",
            " has",
            " universal",
            " suff",
            "rage",
            " at",
            " ",
            "18",
            " years",
            " of",
            " age",
            ".",
            " The",
            " President",
            " is",
            " the",
            " head",
            " of",
            " the",
            " army",
            ",",
            " the",
            " Council",
            " of",
            " Ministers",
            " and",
            " the",
            " High",
            " Security",
            " Council",
            ".",
            " He",
            " appoint",
            "s",
            " the",
            " Prime",
            " Minister",
            " who",
            " is",
            " also",
            " the",
            " head",
            " of",
            " government",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.648,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            " K",
            "ev",
            "li",
            "han",
            " (",
            "200",
            "4",
            ").",
            " \"",
            "International",
            " Human",
            " Rights",
            " Protection",
            " in",
            " Sit",
            "uations",
            " of",
            " Conflict",
            " and",
            " Post",
            "-",
            "Conflict",
            ",",
            " A",
            " Case",
            " Study",
            " of",
            " Angola",
            "\".",
            " African",
            " Security",
            " Review",
            " ",
            "13",
            "(",
            "4",
            "):",
            " ",
            "29",
            "â€“",
            "41",
            ".",
            " Le",
            " Bill",
            "on",
            ",",
            " Philippe",
            " (",
            "200",
            "5",
            ")",
            " Aid",
            " in",
            " the",
            " Mid",
            "st",
            " of",
            " Plenty",
            ":",
            " Oil",
            " Wealth",
            ",",
            " Mis"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.644,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 52,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " ",
            "200",
            "1",
            "-",
            "2",
            "\".",
            " Irish",
            " Studies",
            " in",
            " International",
            " Affairs",
            " ",
            "14",
            ":",
            " ",
            "95",
            "â€“",
            "106",
            ".",
            " L",
            "ari",
            ",",
            " A",
            ".",
            " (",
            "200",
            "4",
            ").",
            " Returning",
            " home",
            " to",
            " a",
            " normal",
            " life",
            "?",
            " The",
            " plight",
            " of",
            " displaced",
            " Ang",
            "ol",
            "ans",
            ".",
            " Pret",
            "oria",
            ",",
            " South",
            " Africa",
            ",",
            " Institute",
            " for",
            " Security",
            " Studies",
            ".",
            " L",
            "ari",
            ",",
            " A",
            ".",
            " and",
            " R",
            "."
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.641,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            "200",
            "3",
            ").",
            " Cab",
            "inda",
            ":",
            " Notes",
            " on",
            " a",
            " soon",
            " to",
            " be",
            " forgotten",
            " war",
            ".",
            " Pret",
            "oria",
            ",",
            " South",
            " Africa",
            ",",
            " Institute",
            " for",
            " Security",
            " Studies",
            ".",
            " T",
            "ved",
            "ten",
            ",",
            " In",
            "ge",
            " (",
            "199",
            "7",
            ").",
            " Angola",
            ",",
            " Str",
            "uggle",
            " for",
            " Peace",
            " and",
            " Reconstruction",
            ".",
            " Boulder",
            ",",
            " Colorado",
            ",",
            " West",
            "view",
            " Press",
            ".",
            " V",
            "ines",
            ",",
            " Alex",
            " (",
            "199",
            "9",
            ").",
            " Angola",
            " Un"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.633,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            "196",
            "1",
            " the",
            " Portuguese",
            " colonial",
            " authorities",
            " expelled",
            " a",
            " series",
            " of",
            " Protestant",
            " missionaries",
            " and",
            " closed",
            " mission",
            " stations",
            " based",
            " on",
            " the",
            " belief",
            " that",
            " the",
            " missionaries",
            " were",
            " inc",
            "iting",
            " pro",
            "-in",
            "dependence",
            " sentiments",
            ".",
            " Mission",
            "aries",
            " have",
            " been",
            " able",
            " to",
            " return",
            " to",
            " the",
            " country",
            " since",
            " the",
            " early",
            " ",
            "199",
            "0",
            "s",
            ",",
            " although",
            " security",
            " conditions",
            " due",
            " to",
            " the",
            " civil",
            " war",
            " have",
            " prevented",
            " them",
            " until",
            " ",
            "200"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.602,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " Blue",
            "bell",
            ",",
            " the",
            " puppies",
            " were",
            " taken",
            " away",
            " at",
            " birth",
            " by",
            " Napoleon",
            " and",
            " raised",
            " by",
            " him",
            " to",
            " serve",
            " as",
            " his",
            " powerful",
            " security",
            " force",
            ".",
            " Moses",
            "Ã‚Å‚",
            "â€“",
            " The",
            " Raven",
            ",",
            " \"",
            "Mr",
            ".",
            " Jones",
            "'s",
            " especial",
            " pet",
            ",",
            " was",
            " a",
            " spy",
            " and",
            " a",
            " tale",
            "-b",
            "earer",
            ",",
            " but",
            " he",
            " was",
            " also",
            " a",
            " clever",
            " talk",
            "er",
            "\".",
            " Initially",
            " following",
            " Mrs",
            ".",
            " Jones",
            " into"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.602,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            " hom",
            "olog",
            "ous",
            ");",
            " The",
            " Governors",
            " of",
            " the",
            " provinces",
            ";",
            " The",
            " members",
            " of",
            " the",
            " Republic",
            " Council",
            ";",
            " The",
            " members",
            " of",
            " the",
            " National",
            " Security",
            " Council",
            ";",
            " The",
            " members",
            " of",
            " the",
            " Superior",
            " Mag",
            "istrates",
            " Council",
            "s",
            ";",
            " The",
            " General",
            " Chief",
            " of",
            " the",
            " Armed",
            " Forces",
            " and",
            " his",
            " deputy",
            ";",
            " All",
            " other",
            " command",
            " posts",
            " in",
            " the",
            " military",
            ";",
            " The",
            " Police",
            " General",
            " Commander",
            ",",
            " and",
            " the",
            " ",
            "2"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.582,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " role",
            " in",
            " internal",
            " security",
            " was",
            " largely",
            " taken",
            " over",
            " by",
            " the",
            " formation",
            " of",
            " the",
            " Police",
            " Corps",
            " of",
            " And",
            "orra",
            " in",
            " ",
            "193",
            "1",
            ".",
            " Brief",
            " civil",
            " disorder",
            " associated",
            " with",
            " the",
            " elections",
            " of",
            " ",
            "193",
            "3",
            " led",
            " to",
            " assistance",
            " being",
            " sought",
            " from",
            " the",
            " French",
            " National",
            " G",
            "endar",
            "mer",
            "ie",
            ",",
            " with",
            " a",
            " detachment",
            " resident",
            " in",
            " And",
            "orra",
            " for",
            " two",
            " months",
            " under",
            " the",
            " command",
            " of",
            " Ren"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.473,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " the",
            " novel",
            ".",
            " ",
            "9",
            " April",
            " ",
            "200",
            "9",
            ".",
            " (",
            "Audio",
            ",",
            " ",
            "45",
            " minutes",
            ")",
            " BBC",
            " In",
            " their",
            " own",
            " words",
            " series",
            ".",
            " ",
            "12",
            " October",
            " ",
            "195",
            "8",
            " (",
            "video",
            ",",
            " ",
            "12",
            " mins",
            ")",
            " \"",
            "The",
            " Ultimate",
            " Revolution",
            "\"",
            " (",
            "talk",
            " at",
            " UC",
            " Berkeley",
            ",",
            " ",
            "20",
            " March",
            " ",
            "196",
            "2",
            ")",
            " H",
            "ux",
            "ley",
            " interviewed",
            " on",
            " The",
            " Mike"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.422,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.461,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " for",
            " \"",
            "O",
            "gre",
            "\".",
            " He",
            " was",
            " described",
            " by",
            " his",
            " brother",
            ",",
            " Julian",
            ",",
            " as",
            " someone",
            " who",
            " frequently",
            " [",
            "cont",
            "empl",
            "ated",
            "]",
            " the",
            " strang",
            "eness",
            " of",
            " things",
            "\".",
            " According",
            " to",
            " his",
            " cousin",
            " and",
            " contemporary",
            " G",
            "ervas",
            " H",
            "ux",
            "ley",
            ",",
            " he",
            " had",
            " an",
            " early",
            " interest",
            " in",
            " drawing",
            ".",
            "H",
            "ux",
            "ley",
            "'s",
            " education",
            " began",
            " in",
            " his",
            " father",
            "'s",
            " well",
            "-equipped",
            " botanical",
            " laboratory"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.457,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            " non",
            "-fiction",
            " works",
            ",",
            " as",
            " well",
            " as",
            " essays",
            ",",
            " narratives",
            ",",
            " and",
            " poems",
            ".",
            "Born",
            " into",
            " the",
            " prominent",
            " H",
            "ux",
            "ley",
            " family",
            ",",
            " he",
            " graduated",
            " from",
            " Ball",
            "iol",
            " College",
            ",",
            " Oxford",
            ",",
            " with",
            " an",
            " undergraduate",
            " degree",
            " in",
            " English",
            " literature",
            ".",
            " Early",
            " in",
            " his",
            " career",
            ",",
            " he",
            " published",
            " short",
            " stories",
            " and",
            " poetry",
            " and",
            " edited",
            " the",
            " literary",
            " magazine",
            " Oxford",
            " Poetry",
            ",",
            " before",
            " going",
            " on",
            " to"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.449,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.443,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " Department",
            " of",
            " Humanities",
            ",",
            " H",
            "ux",
            "ley",
            " presented",
            " a",
            " series",
            " of",
            " lectures",
            " titled",
            ",",
            " \"",
            "What",
            " a",
            " Piece",
            " of",
            " Work",
            " is",
            " a",
            " Man",
            "\"",
            " which",
            " concerned",
            " history",
            ",",
            " language",
            ",",
            " and",
            " art",
            ".",
            "Robert",
            " S",
            ".",
            " de",
            " R",
            "opp",
            " (",
            "scient",
            "ist",
            ",",
            " humanitarian",
            ",",
            " and",
            " author",
            "),",
            " who",
            " had",
            " spent",
            " time",
            " with",
            " H",
            "ux",
            "ley",
            " in",
            " England",
            " in",
            " the",
            " ",
            "193",
            "0"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.404,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            " God",
            "al",
            "ming",
            ",",
            " Surrey",
            ",",
            " England",
            ",",
            " in",
            " ",
            "189",
            "4",
            ".",
            " He",
            " was",
            " the",
            " third",
            " son",
            " of",
            " the",
            " writer",
            " and",
            " school",
            "master",
            " Leonard",
            " H",
            "ux",
            "ley",
            ",",
            " who",
            " edited",
            " The",
            " Corn",
            "hill",
            " Magazine",
            ",",
            " and",
            " his",
            " first",
            " wife",
            ",",
            " Julia",
            " Arnold",
            ",",
            " who",
            " founded",
            " Prior",
            "'s",
            " Field",
            " School",
            ".",
            " Julia",
            " was",
            " the",
            " niece",
            " of",
            " poet",
            " and",
            " critic",
            " Matthew",
            " Arnold",
            " and",
            " the"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.342,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.35,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " United",
            " States",
            ")",
            " Apple",
            "seed",
            " Ex",
            " Mach",
            "ina",
            " (",
            "200",
            "7",
            ",",
            " Japan",
            "),",
            " The",
            " Legend",
            " of",
            " Zelda",
            ":",
            " The",
            " Wind",
            " W",
            "aker",
            " (",
            "200",
            "2",
            ",",
            " Japan",
            "),",
            " The",
            " Legend",
            " of",
            " Zelda",
            ":",
            " Breath",
            " of",
            " the",
            " Wild",
            " (",
            "201",
            "7",
            ",",
            " Japan",
            ")",
            " Mach",
            "in",
            "ima",
            " â€“",
            " Films",
            " created",
            " by",
            " screen",
            " capturing",
            " in",
            " video",
            " games",
            " and",
            " virtual",
            " worlds",
            ".",
            " The",
            " term"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.324,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " restaurant",
            " (",
            "Mer",
            "ke",
            "z",
            " Lok",
            "antas",
            "Ã„Â±",
            ",",
            " Central",
            " Restaurant",
            "),",
            " caf",
            "ÃƒÂ©s",
            " and",
            " other",
            " establishments",
            " scattered",
            " around",
            " the",
            " farm",
            ".",
            "Education",
            "Univers",
            "ities",
            "An",
            "kara",
            " is",
            " noted",
            ",",
            " within",
            " Turkey",
            ",",
            " for",
            " the",
            " multitude",
            " of",
            " universities",
            " it",
            " is",
            " home",
            " to",
            ".",
            " These",
            " include",
            " the",
            " following",
            ",",
            " several",
            " of",
            " them",
            " being",
            " among",
            " the",
            " most",
            " reputable",
            " in",
            " the",
            " country",
            ":",
            "An"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.32,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 41,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " local",
            " shops",
            " are",
            " making",
            " way",
            " for",
            " tourist",
            "-oriented",
            " ones",
            ",",
            " making",
            " the",
            " centre",
            " un",
            "aff",
            "ordable",
            " for",
            " the",
            " city",
            "'s",
            " inhabitants",
            ".",
            " These",
            " developments",
            " have",
            " ev",
            "oked",
            " comparisons",
            " with",
            " Venice",
            ",",
            " a",
            " city",
            " thought",
            " to",
            " be",
            " overwhelmed",
            " by",
            " the",
            " tourist",
            " influx",
            ".",
            "Construction",
            " of",
            " a",
            " new",
            " metro",
            " line",
            " connecting",
            " the",
            " part",
            " of",
            " the",
            " city",
            " north",
            " of",
            " the",
            " I",
            "J",
            " to",
            " its",
            " southern"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.316,
            -0.0
          ],
          "train_token_ind": 61,
          "is_repeated_datapoint": false,
          "tokens": [
            " Yen",
            " sign",
            ",",
            " in",
            " Japan",
            ")",
            " or",
            " Ã¢Ä¤",
            "Â©",
            " (",
            "a",
            " Won",
            " sign",
            ",",
            " in",
            " Korea",
            ").",
            " This",
            " means",
            " that",
            ",",
            " for",
            " example",
            ",",
            " the",
            " file",
            " path",
            " C",
            ":\\",
            "Users",
            "\\",
            "Smith",
            " is",
            " shown",
            " as",
            " C",
            ":",
            "Ã‚Â¥",
            "Users",
            "Ã‚Â¥",
            "Smith",
            " (",
            "in",
            " Japan",
            ")",
            " or",
            " C",
            ":",
            "Ã¢Ä¤",
            "Â©",
            "Users",
            "Ã¢Ä¤",
            "Â©",
            "Smith",
            " (",
            "in",
            " Korea",
            ").",
            "In",
            " Europe",
            ",",
            " te",
            "let"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.312,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            " ruled",
            " out",
            " despite",
            " this",
            " more",
            " recent",
            " sub",
            "-Saharan",
            " African",
            " influx",
            ",",
            " while",
            " continuity",
            " with",
            " modern",
            " Ethi",
            "op",
            "ians",
            " is",
            " not",
            " supported",
            "\".",
            "G",
            "ourd",
            "ine",
            ",",
            " An",
            "sel",
            "in",
            " and",
            " Ke",
            "ita",
            " criticised",
            " the",
            " methodology",
            " of",
            " the",
            " Sche",
            "un",
            "emann",
            " et",
            " al",
            " study",
            " and",
            " argued",
            " that",
            " the",
            " Sub",
            "-Saharan",
            " \"",
            "gen",
            "etic",
            " aff",
            "in",
            "ities",
            "\"",
            " may",
            " be",
            " attributed",
            " to",
            " \"",
            "early",
            " settlers"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.012,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 20,
          "is_repeated_datapoint": false,
          "tokens": [
            " as",
            " the",
            " negative",
            " logarith",
            "m",
            " of",
            " the",
            " concentration",
            " of",
            " hy",
            "d",
            "ron",
            "ium",
            " ions",
            ",",
            " acidic",
            " solutions",
            " thus",
            " have",
            " a",
            " pH",
            " of",
            " less",
            " than",
            " ",
            "7",
            ".",
            "Br",
            "ÃƒÂ¸",
            "n",
            "sted",
            "â€“",
            "Low",
            "ry",
            " acids",
            "While",
            " the",
            " Arr",
            "hen",
            "ius",
            " concept",
            " is",
            " useful",
            " for",
            " describing",
            " many",
            " reactions",
            ",",
            " it",
            " is",
            " also",
            " quite",
            " limited",
            " in",
            " its",
            " scope",
            ".",
            " In",
            " ",
            "192",
            "3",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " about",
            " to",
            " become",
            " social",
            " classes",
            ".",
            " However",
            ",",
            " almost",
            " half",
            " the",
            " population",
            " has",
            " to",
            " be",
            " considered",
            " poor",
            ",",
            " with",
            " dramatic",
            " differences",
            " between",
            " the",
            " countryside",
            " and",
            " the",
            " cities",
            ",",
            " where",
            " slightly",
            " more",
            " than",
            " ",
            "50",
            "%",
            " of",
            " the",
            " people",
            " reside",
            ".",
            "A",
            " study",
            " carried",
            " out",
            " in",
            " ",
            "200",
            "8",
            " by",
            " the",
            " Ang",
            "olan",
            " Instituto",
            " Nacional",
            " de",
            " Est",
            "at",
            "ÃƒÅƒstica",
            " found",
            " that",
            " in",
            " rural",
            " areas"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " and",
            " several",
            " guarded",
            " bike",
            " storage",
            " gar",
            "ages",
            " (",
            "fi",
            "ets",
            "en",
            "st",
            "alling",
            ")",
            " which",
            " can",
            " be",
            " used",
            ".",
            "According",
            " to",
            " the",
            " most",
            " recent",
            " figures",
            " published",
            " by",
            " Central",
            " Bureau",
            " of",
            " Statistics",
            " (",
            "CBS",
            "),",
            " in",
            " ",
            "201",
            "5",
            " the",
            " ",
            "442",
            ".",
            "693",
            " households",
            " (",
            "850",
            ".",
            "000",
            " residents",
            ")",
            " in",
            " Amsterdam",
            " together",
            " owned",
            " ",
            "847",
            ".",
            "000",
            " bicycles",
            " â€“",
            " ",
            "1"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "z",
            "antine",
            " history",
            "The",
            " city",
            " is",
            " well",
            " known",
            " during",
            " the",
            " ",
            "4",
            "th",
            " century",
            " as",
            " a",
            " center",
            " of",
            " Christian",
            " activity",
            " (",
            "see",
            " also",
            " below",
            "),",
            " due",
            " to",
            " frequent",
            " imperial",
            " visits",
            ",",
            " and",
            " through",
            " the",
            " letters",
            " of",
            " the",
            " pagan",
            " scholar",
            " Lib",
            "ani",
            "us",
            ".",
            " Bishop",
            " Mar",
            "cell",
            "us",
            " of",
            " A",
            "ncy",
            "ra",
            " and",
            " Basil",
            " of",
            " A",
            "ncy",
            "ra",
            " were",
            " active",
            " in",
            " the",
            " theological"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " premise",
            " uses",
            " the",
            " phrase",
            " \"",
            "is",
            " not",
            "\",",
            " a",
            " form",
            " of",
            " \"",
            "to",
            " be",
            "\";",
            " this",
            " and",
            " many",
            " other",
            " examples",
            " show",
            " that",
            " he",
            " did",
            " not",
            " intend",
            " to",
            " abandon",
            " \"",
            "to",
            " be",
            "\"",
            " as",
            " such",
            ".",
            " In",
            " fact",
            ",",
            " he",
            " said",
            " explicitly",
            " that",
            " there",
            " were",
            " no",
            " structural",
            " problems",
            " with",
            " the",
            " verb",
            " \"",
            "to",
            " be",
            "\"",
            " when",
            " used",
            " as",
            " an",
            " auxiliary",
            " verb",
            " or",
            " when",
            " used"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "nze",
    "contri",
    "atori",
    "ÃƒÄ¹\n\n",
    "_PB"
  ],
  "bottom_logits": [
    " Ã‚Â«",
    " bel",
    "arch",
    "_hint",
    " diagn"
  ],
  "act_min": -0.0,
  "act_max": 0.941
}
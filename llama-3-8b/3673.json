{
  "index": 3673,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.543,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.715,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            " stored",
            " in",
            " a",
            " different",
            " database",
            " (",
            "and",
            " thus",
            " managed",
            " by",
            " a",
            " different",
            " Persistence",
            "Manager",
            ").",
            " The",
            " database",
            " with",
            " the",
            " object",
            " A",
            " doesn",
            "’t",
            " in",
            " fact",
            " in",
            " this",
            " case",
            " contain",
            " an",
            " object",
            " B",
            ",",
            " but",
            " a",
            " Dynamic",
            "Proxy",
            " object",
            ".",
            " The",
            " object",
            " B",
            " can",
            " be",
            " transparent",
            "ly",
            " retrieved",
            " using",
            " three",
            " co",
            "-oper",
            "ating",
            " components",
            " (",
            "as",
            " shown",
            " on",
            " Fig",
            "Âł",
            "\\[",
            "References",
            "\\",
            "])",
            ":\n\n",
            "-",
            "  ",
            " When",
            " reference",
            " from",
            " an",
            " object",
            " A",
            " to",
            " an",
            " object",
            " B",
            " is",
            " requested",
            ",",
            " J",
            "DO",
            " delivers",
            " Dynamic",
            "Proxy",
            " instead",
            ".\n\n",
            "-",
            "  ",
            " The",
            " Dynamic",
            "Proxy",
            " asks",
            " Persistence",
            "Manager",
            "Factory",
            " for",
            " a",
            " Persistence",
            "Manager",
            " which",
            " handles",
            " the",
            " object",
            " B",
            ".",
            " It",
            " then",
            " uses",
            " that",
            " Persistence",
            "Manager",
            " to",
            " get",
            " the",
            " object",
            " B",
            " and",
            " casts",
            " itself",
            " into",
            " it",
            ".\n\n",
            "-",
            "  ",
            " Persistence",
            "Manager",
            "Factory"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.691,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 122,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " the",
            " documentation",
            " for",
            " high",
            "charts",
            ".",
            " I",
            " even",
            " setup",
            " a",
            " really",
            " quick",
            " demo",
            " on",
            " js",
            "f",
            "iddle",
            " here",
            ",",
            " http",
            "://",
            "js",
            "f",
            "iddle",
            ".net",
            "/",
            "7",
            "c",
            "bs",
            "V",
            "/\n",
            "can",
            " anyone",
            " please",
            " help",
            " me",
            ".",
            " It",
            " is",
            " kind",
            " of",
            " important",
            ".",
            " Thank",
            " you",
            " in",
            " advance",
            " for",
            " the",
            " help",
            ".\n\n",
            "A",
            ":\n\n",
            "How",
            " about",
            " using",
            " simple",
            " chart",
            ".setSize",
            "(w",
            ",h",
            ")?",
            " See",
            " docs",
            ".\n",
            "$(\"#",
            "container",
            "\").",
            "high",
            "charts",
            "().",
            "setSize",
            "(",
            "800",
            ",",
            " height",
            ");\n\n",
            "<|begin_of_text|>",
            "R",
            "at",
            "no",
            " Dol",
            "ne",
            "\n\n",
            "R",
            "at",
            "no",
            " Dol",
            "ne",
            " ",
            " ()",
            " is",
            " a",
            " village",
            " in",
            " the",
            " administrative",
            " district",
            " of",
            " G",
            "mina",
            " Rad",
            "kÃ³w",
            ",",
            " within",
            " K",
            "ÅĤ",
            "od",
            "z",
            "ko",
            " County",
            ",",
            " Lower",
            " S",
            "iles",
            "ian",
            " Vo",
            "iv",
            "odes",
            "hip",
            ",",
            " in",
            " south",
            "-west",
            "ern",
            " Poland"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.691,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " the",
            " documentation",
            " for",
            " high",
            "charts",
            ".",
            " I",
            " even",
            " setup",
            " a",
            " really",
            " quick",
            " demo",
            " on",
            " js",
            "f",
            "iddle",
            " here",
            ",",
            " http",
            "://",
            "js",
            "f",
            "iddle",
            ".net",
            "/",
            "7",
            "c",
            "bs",
            "V",
            "/\n",
            "can",
            " anyone",
            " please",
            " help",
            " me",
            ".",
            " It",
            " is",
            " kind",
            " of",
            " important",
            ".",
            " Thank",
            " you",
            " in",
            " advance",
            " for",
            " the",
            " help",
            ".\n\n",
            "A",
            ":\n\n",
            "How",
            " about",
            " using",
            " simple",
            " chart",
            ".setSize",
            "(w",
            ",h",
            ")?",
            " See",
            " docs",
            ".\n",
            "$(\"#",
            "container",
            "\").",
            "high",
            "charts",
            "().",
            "setSize",
            "(",
            "800",
            ",",
            " height",
            ");\n\n",
            "<|begin_of_text|>",
            "R",
            "at",
            "no",
            " Dol",
            "ne",
            "\n\n",
            "R",
            "at",
            "no",
            " Dol",
            "ne",
            " ",
            " ()",
            " is",
            " a",
            " village",
            " in",
            " the",
            " administrative",
            " district",
            " of",
            " G",
            "mina",
            " Rad",
            "kÃ³w",
            ",",
            " within",
            " K",
            "ÅĤ",
            "od",
            "z",
            "ko",
            " County",
            ",",
            " Lower",
            " S",
            "iles",
            "ian",
            " Vo",
            "iv",
            "odes",
            "hip",
            ",",
            " in",
            " south",
            "-west",
            "ern",
            " Poland"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.68,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " {\n",
            "   ",
            " return",
            " this",
            ".input",
            "Value",
            ";\n",
            " ",
            " }\n\n",
            " ",
            " return",
            " this",
            ";\n",
            "});\n\n",
            "Example",
            " on",
            " Pl",
            "unk",
            "r",
            "\n",
            "Read",
            ":",
            " Angular",
            "JS",
            " Docs",
            " on",
            " services",
            "\n",
            "or",
            " check",
            " this",
            " Egg",
            "head",
            ".io",
            " video",
            "\n\n",
            "<|begin_of_text|>",
            "R",
            "etro",
            "active",
            " effects",
            " of",
            " irrelevant",
            " speech",
            " on",
            " serial",
            " recall",
            " from",
            " short",
            "-term",
            " memory",
            ".\n",
            "The",
            " authors",
            " report",
            " ",
            "5",
            " serial",
            "-rec",
            "all",
            " experiments",
            ".",
            " In",
            " ",
            "4",
            " of",
            " the",
            " ",
            "5",
            " experiments",
            ",",
            " they",
            " show",
            " that",
            " irrelevant",
            " sound",
            " (",
            "IS",
            ")",
            " has",
            " a",
            " retro",
            "active",
            " effect",
            " on",
            " material",
            " already",
            " in",
            " memory",
            ".",
            " In",
            " Experiment",
            " ",
            "1",
            ",",
            " IS",
            " presented",
            " during",
            " a",
            " filled",
            " retention",
            " interval",
            " had",
            " a",
            " reliable",
            " effect",
            " on",
            " list",
            " recall",
            ".",
            " Four",
            " further",
            " experiments",
            ",",
            " ",
            "3",
            " of",
            " which",
            " used",
            " retro",
            "active",
            " IS",
            ",",
            " showed",
            " that",
            " IS",
            " continued"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.668,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " nu",
            "clide",
            " $",
            "^{",
            "19",
            "}$",
            "F",
            " is",
            " also",
            " an",
            " advantage",
            " since",
            " it",
            " conf",
            "ers",
            " sensitivity",
            " to",
            " purely",
            " spin",
            "-c",
            "ou",
            "pled",
            " W",
            "IM",
            "Ps",
            "Âł",
            "[@",
            "Ell",
            "is",
            "199",
            "1",
            "],",
            " allowing",
            " smaller",
            " active",
            " mass",
            " experiments",
            " to",
            " be",
            " competitive",
            ".",
            " Another",
            " attractive",
            " feature",
            " of",
            " CF",
            "$_",
            "4",
            "$",
            " is",
            " that",
            " its",
            " Townsend",
            " aval",
            "anches",
            " cop",
            "iously",
            " emit",
            " visible",
            " and",
            " near",
            " infrared",
            " light",
            "Âł",
            "[@",
            "P",
            "ans",
            "ky",
            "199",
            "5",
            ";",
            " @",
            "K",
            "ab",
            "oth",
            "200",
            "8",
            ";",
            " @",
            "F",
            "rag",
            "a",
            "200",
            "3",
            "],",
            " allowing",
            " optical",
            " read",
            "out",
            " as",
            " in",
            " the",
            " DM",
            "TP",
            "C",
            " detector",
            " discussed",
            " in",
            " section",
            "Âł",
            "\\[",
            "DM",
            "TP",
            "C",
            "\\",
            "].",
            " The",
            " ultr",
            "aviolet",
            " part",
            " of",
            " the",
            " spectrum",
            " may",
            " also",
            " be",
            " seen",
            " by",
            " making",
            " use",
            " of",
            " a",
            " wavelength",
            " sh",
            "ifter",
            ".",
            " Finally"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.68,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " {\n",
            "   ",
            " return",
            " this",
            ".input",
            "Value",
            ";\n",
            " ",
            " }\n\n",
            " ",
            " return",
            " this",
            ";\n",
            "});\n\n",
            "Example",
            " on",
            " Pl",
            "unk",
            "r",
            "\n",
            "Read",
            ":",
            " Angular",
            "JS",
            " Docs",
            " on",
            " services",
            "\n",
            "or",
            " check",
            " this",
            " Egg",
            "head",
            ".io",
            " video",
            "\n\n",
            "<|begin_of_text|>",
            "R",
            "etro",
            "active",
            " effects",
            " of",
            " irrelevant",
            " speech",
            " on",
            " serial",
            " recall",
            " from",
            " short",
            "-term",
            " memory",
            ".\n",
            "The",
            " authors",
            " report",
            " ",
            "5",
            " serial",
            "-rec",
            "all",
            " experiments",
            ".",
            " In",
            " ",
            "4",
            " of",
            " the",
            " ",
            "5",
            " experiments",
            ",",
            " they",
            " show",
            " that",
            " irrelevant",
            " sound",
            " (",
            "IS",
            ")",
            " has",
            " a",
            " retro",
            "active",
            " effect",
            " on",
            " material",
            " already",
            " in",
            " memory",
            ".",
            " In",
            " Experiment",
            " ",
            "1",
            ",",
            " IS",
            " presented",
            " during",
            " a",
            " filled",
            " retention",
            " interval",
            " had",
            " a",
            " reliable",
            " effect",
            " on",
            " list",
            " recall",
            ".",
            " Four",
            " further",
            " experiments",
            ",",
            " ",
            "3",
            " of",
            " which",
            " used",
            " retro",
            "active",
            " IS",
            ",",
            " showed",
            " that",
            " IS",
            " continued"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.668,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " nu",
            "clide",
            " $",
            "^{",
            "19",
            "}$",
            "F",
            " is",
            " also",
            " an",
            " advantage",
            " since",
            " it",
            " conf",
            "ers",
            " sensitivity",
            " to",
            " purely",
            " spin",
            "-c",
            "ou",
            "pled",
            " W",
            "IM",
            "Ps",
            "Âł",
            "[@",
            "Ell",
            "is",
            "199",
            "1",
            "],",
            " allowing",
            " smaller",
            " active",
            " mass",
            " experiments",
            " to",
            " be",
            " competitive",
            ".",
            " Another",
            " attractive",
            " feature",
            " of",
            " CF",
            "$_",
            "4",
            "$",
            " is",
            " that",
            " its",
            " Townsend",
            " aval",
            "anches",
            " cop",
            "iously",
            " emit",
            " visible",
            " and",
            " near",
            " infrared",
            " light",
            "Âł",
            "[@",
            "P",
            "ans",
            "ky",
            "199",
            "5",
            ";",
            " @",
            "K",
            "ab",
            "oth",
            "200",
            "8",
            ";",
            " @",
            "F",
            "rag",
            "a",
            "200",
            "3",
            "],",
            " allowing",
            " optical",
            " read",
            "out",
            " as",
            " in",
            " the",
            " DM",
            "TP",
            "C",
            " detector",
            " discussed",
            " in",
            " section",
            "Âł",
            "\\[",
            "DM",
            "TP",
            "C",
            "\\",
            "].",
            " The",
            " ultr",
            "aviolet",
            " part",
            " of",
            " the",
            " spectrum",
            " may",
            " also",
            " be",
            " seen",
            " by",
            " making",
            " use",
            " of",
            " a",
            " wavelength",
            " sh",
            "ifter",
            ".",
            " Finally"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.684,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "*,",
            " to",
            " allow",
            " comparison",
            " with",
            " $\\",
            "document",
            "class",
            "[",
            "12",
            "pt",
            "]{",
            "minimal",
            "}\n",
            "               ",
            " \\",
            "use",
            "package",
            "{",
            "am",
            "sm",
            "ath",
            "}\n",
            "               ",
            " \\",
            "use",
            "package",
            "{",
            "was",
            "ys",
            "ym",
            "}",
            " \n",
            "               ",
            " \\",
            "use",
            "package",
            "{",
            "ams",
            "fonts",
            "}",
            " \n",
            "               ",
            " \\",
            "use",
            "package",
            "{",
            "am",
            "ss",
            "ymb",
            "}",
            " \n",
            "               ",
            " \\",
            "use",
            "package",
            "{",
            "ams",
            "bs",
            "y",
            "}\n",
            "               ",
            " \\",
            "use",
            "package",
            "{",
            "math",
            "rs",
            "fs",
            "}\n",
            "               ",
            " \\",
            "use",
            "package",
            "{",
            "up",
            "g",
            "reek",
            "}\n",
            "               ",
            " \\",
            "set",
            "length",
            "{\\",
            "od",
            "ds",
            "id",
            "em",
            "argin",
            "}{",
            "-",
            "69",
            "pt",
            "}\n",
            "               ",
            " \\",
            "begin",
            "{",
            "document",
            "}",
            "$$",
            " {\\",
            "over",
            "line",
            "{",
            "Q",
            "}}",
            "_",
            "I",
            " $$",
            "\\",
            "end",
            "{",
            "document",
            "}$",
            ",",
            " the",
            " mean",
            " calculated",
            " from",
            " *",
            "I",
            "*",
            " for",
            " the",
            " same",
            " quantity"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.66,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.684,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "B",
            "-->\n",
            "\t\t",
            "\t",
            "<",
            "param",
            " name",
            "=\"",
            "number",
            "_m",
            "cs",
            "\"",
            " value",
            "=\"",
            "4",
            "\"/>\n",
            "\t\t",
            "\t",
            "<!--",
            " current",
            " Mc",
            "PAT",
            " only",
            " supports",
            " homogeneous",
            " memory",
            " controllers",
            " -->\n",
            "\t\t",
            "\t",
            "<",
            "param",
            " name",
            "=\"",
            "memory",
            "_channels",
            "_per",
            "_mc",
            "\"",
            " value",
            "=\"",
            "1",
            "\"/>\n",
            "\t\t",
            "\t",
            "<",
            "param",
            " name",
            "=\"",
            "number",
            "_r",
            "anks",
            "\"",
            " value",
            "=\"",
            "2",
            "\"/>\n",
            "\t\t",
            "\t",
            "<!--",
            " #",
            " of",
            " ranks",
            " of",
            " each",
            " channel",
            "-->\n",
            "\t\t",
            "\t",
            "<",
            "param",
            " name",
            "=\"",
            "req",
            "_window",
            "_size",
            "_per",
            "_channel",
            "\"",
            " value",
            "=\"",
            "32",
            "\"/>\n",
            "\t\t",
            "\t",
            "<",
            "param",
            " name",
            "=\"",
            "IO",
            "_buffer",
            "_size",
            "_per",
            "_channel",
            "\"",
            " value",
            "=\"",
            "32",
            "\"/>\n",
            "\t\t",
            "\t",
            "<",
            "param",
            " name",
            "=\"",
            "d",
            "atab",
            "us",
            "_width",
            "\"",
            " value",
            "=\"",
            "128",
            "\"/>\n",
            "\t\t",
            "\t",
            "<",
            "param",
            " name",
            "=\"",
            "address",
            "bus",
            "_width",
            "\"",
            " value",
            "=\"",
            "51"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.66,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.684,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "B",
            "-->\n",
            "\t\t",
            "\t",
            "<",
            "param",
            " name",
            "=\"",
            "number",
            "_m",
            "cs",
            "\"",
            " value",
            "=\"",
            "4",
            "\"/>\n",
            "\t\t",
            "\t",
            "<!--",
            " current",
            " Mc",
            "PAT",
            " only",
            " supports",
            " homogeneous",
            " memory",
            " controllers",
            " -->\n",
            "\t\t",
            "\t",
            "<",
            "param",
            " name",
            "=\"",
            "memory",
            "_channels",
            "_per",
            "_mc",
            "\"",
            " value",
            "=\"",
            "1",
            "\"/>\n",
            "\t\t",
            "\t",
            "<",
            "param",
            " name",
            "=\"",
            "number",
            "_r",
            "anks",
            "\"",
            " value",
            "=\"",
            "2",
            "\"/>\n",
            "\t\t",
            "\t",
            "<!--",
            " #",
            " of",
            " ranks",
            " of",
            " each",
            " channel",
            "-->\n",
            "\t\t",
            "\t",
            "<",
            "param",
            " name",
            "=\"",
            "req",
            "_window",
            "_size",
            "_per",
            "_channel",
            "\"",
            " value",
            "=\"",
            "32",
            "\"/>\n",
            "\t\t",
            "\t",
            "<",
            "param",
            " name",
            "=\"",
            "IO",
            "_buffer",
            "_size",
            "_per",
            "_channel",
            "\"",
            " value",
            "=\"",
            "32",
            "\"/>\n",
            "\t\t",
            "\t",
            "<",
            "param",
            " name",
            "=\"",
            "d",
            "atab",
            "us",
            "_width",
            "\"",
            " value",
            "=\"",
            "128",
            "\"/>\n",
            "\t\t",
            "\t",
            "<",
            "param",
            " name",
            "=\"",
            "address",
            "bus",
            "_width",
            "\"",
            " value",
            "=\"",
            "51"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.68,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.027,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " kinase",
            " exceeded",
            " the",
            " ",
            "99",
            "^",
            "th",
            "^",
            " percentile",
            " upper",
            " reference",
            " limit",
            "),",
            " documented",
            " findings",
            " of",
            " a",
            " new",
            " ST",
            " segment",
            " elevation",
            "/de",
            "pression",
            " or",
            " a",
            " new",
            " T",
            " wave",
            " inversion",
            " on",
            " electro",
            "card",
            "i",
            "ography",
            ",",
            " and",
            "/or",
            " with",
            " evidence",
            " of",
            " obstruct",
            "ive",
            " coronary",
            " artery",
            " on",
            " angi",
            "ography",
            ".",
            " Un",
            "stable",
            " ang",
            "ina",
            " was",
            " confirmed",
            " by",
            " chest",
            " pain",
            ",",
            " ST",
            " segment",
            " depression",
            " or",
            " T",
            " wave",
            " changes",
            " with",
            " evidence",
            " of",
            " obstruct",
            "ive",
            " coronary",
            " artery",
            " on",
            " angi",
            "ography",
            ",",
            " but",
            " without",
            " the",
            " elevation",
            " of",
            " cardiac",
            " enzymes",
            ".\n\n",
            "Stat",
            "istical",
            " analysis",
            " {",
            "#",
            "sec",
            "2",
            ".",
            "3",
            "}\n",
            "----------------",
            "----\n\n",
            "Continuous",
            " variables",
            " are",
            " presented",
            " as",
            " mean",
            " Â±",
            " SD",
            " or",
            " median",
            " and",
            " inter",
            "qu",
            "art",
            "ile",
            " range",
            " according",
            " to",
            " whether",
            " they",
            " follow",
            " Gaussian",
            " distributions",
            ".",
            " C",
            "ategorical",
            " data",
            " are",
            " presented",
            " as",
            " numbers"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.664,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.177,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "3",
            ",",
            " ech",
            "oc",
            "ardi",
            "ographic",
            " optimization",
            " was",
            " only",
            " undertaken",
            " in",
            " sympt",
            "omatic",
            " non",
            "respond",
            "ers",
            ".\n\n",
            "End",
            " Points",
            " {",
            "#",
            "jah",
            "325",
            "87",
            "-",
            "sec",
            "-",
            "001",
            "2",
            "}\n",
            "----------\n\n",
            "The",
            " primary",
            " end",
            " point",
            " was",
            " total",
            " mortality",
            ",",
            " which",
            " included",
            " cardiac",
            " transplantation",
            ".",
            " Secondary",
            " end",
            " points",
            " included",
            " cardiac",
            " mortality",
            " and",
            " unpl",
            "anned",
            " HF",
            " hospital",
            "ization",
            ".",
            " The",
            " first",
            " event",
            " was",
            " included",
            " in",
            " the",
            " analysis",
            ".",
            " With",
            " respect",
            " to",
            " mode",
            " of",
            " death",
            ",",
            " sudden",
            " cardiac",
            " death",
            " was",
            " defined",
            " as",
            " a",
            " \"",
            "natural",
            ",",
            " unexpected",
            " death",
            " due",
            " to",
            " cardiac",
            " causes",
            ",",
            " herald",
            "ed",
            " by",
            " an",
            " abrupt",
            " loss",
            " of",
            " consciousness",
            " within",
            " ",
            "1",
            "Âł",
            "hour",
            " of",
            " the",
            " onset",
            " of",
            " acute",
            " symptoms",
            ",\"",
            "[",
            "16",
            "](",
            "#",
            "jah",
            "325",
            "87",
            "-b",
            "ib",
            "-",
            "001",
            "6",
            "){",
            "ref",
            "-type",
            "=\"",
            "ref"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " treatment",
            " programs",
            " view",
            " ab",
            "stinence",
            " as",
            " the",
            " ultimate",
            " goal",
            " \\",
            "[",
            "[@",
            "CR",
            "8",
            "]\\",
            "],",
            " whereas",
            " ab",
            "stinence",
            " is",
            " not",
            " required",
            " with",
            " all",
            " medications",
            " and",
            " reduced",
            " drinking",
            " can",
            " be",
            " a",
            " goal",
            " of",
            " medication",
            " treatment",
            " \\",
            "[",
            "[@",
            "CR",
            "9",
            "]\\",
            "].",
            " Finally",
            ",",
            " AUD",
            " medications",
            " can",
            " be",
            " offered",
            " across",
            " healthcare",
            " settings",
            ",",
            " including",
            " primary",
            " care",
            ",",
            " which",
            " has",
            " been",
            " highlighted",
            " as",
            " an",
            " optimal",
            " setting",
            " for",
            " expansion",
            " of",
            " care",
            " for",
            " AUD",
            " \\",
            "[",
            "[@",
            "CR",
            "8",
            "],",
            " [@",
            "CR",
            "13",
            "],",
            " [@",
            "CR",
            "14",
            "]\\",
            "].\n\n",
            "Despite",
            " the",
            " promise",
            " of",
            " medication",
            " treatment",
            " for",
            " addressing",
            " several",
            " known",
            " barriers",
            " to",
            " AUD",
            " treatment",
            " and",
            " national",
            " recommendations",
            " encouraging",
            " medications",
            " be",
            " made",
            " available",
            " to",
            " all",
            " patients",
            " with",
            " AUD",
            " \\",
            "[",
            "[@",
            "CR",
            "15",
            "],",
            " [@",
            "CR",
            "16",
            "]\\",
            "],",
            " rates",
            " of",
            " pharmac"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.668,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " make",
            " NAS",
            "M",
            " assemble",
            " your",
            " assembly",
            " source",
            " file",
            " into",
            " visual",
            " studio",
            " compatible",
            " object",
            " file",
            ".\n",
            "We",
            " are",
            " not",
            " done",
            " yet",
            " though",
            ",",
            " you",
            " need",
            " to",
            " make",
            " some",
            " changes",
            " to",
            " the",
            " assembly",
            " file",
            " before",
            " you",
            " can",
            " link",
            " it",
            " using",
            " MS",
            "VC",
            "'s",
            " linker",
            ".\n",
            "1",
            ")",
            " MS",
            "VC",
            "'s",
            " linker",
            " requires",
            " your",
            " functions",
            " to",
            " start",
            " with",
            " an",
            " underscore",
            " so",
            " main",
            " becomes",
            " _",
            "main",
            ".\n",
            "2",
            ")",
            " The",
            " naming",
            " convention",
            " when",
            " declaring",
            " imported",
            " APIs",
            " is",
            " different",
            " too",
            ".",
            " So",
            " extern",
            " printf",
            " becomes",
            " extern",
            " __",
            "imp",
            "__",
            "printf",
            "\n",
            "3",
            ")",
            " Call",
            " instructions",
            " to",
            " imported",
            " APIs",
            " are",
            " different",
            " too",
            ".",
            " call",
            " printf",
            " becomes",
            " call",
            " [",
            "__",
            "imp",
            "__",
            "printf",
            "].",
            " The",
            " address",
            " of",
            " printf",
            " will",
            " be",
            " stored",
            " in",
            " an",
            " import",
            " table",
            " entry",
            " and",
            " our",
            " instruction",
            " dere",
            "ferences",
            " it",
            " to",
            " find"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " for",
            " the",
            " presumption",
            " of",
            " correctness",
            " to",
            " attach",
            " in",
            " an",
            " un",
            "reported",
            " income",
            "\n\n",
            "case",
            " such",
            " as",
            " this",
            ",",
            " the",
            " Commissioner",
            " must",
            " base",
            " his",
            " deficiency",
            " determination",
            " on",
            "\n\n",
            "some",
            " substantive",
            " evidence",
            " that",
            " the",
            " taxpayer",
            " received",
            " un",
            "reported",
            " income",
            ".",
            " Hardy",
            " v",
            ".\n\n",
            "Commission",
            "er",
            ",",
            " ",
            "181",
            " F",
            ".",
            "3",
            "d",
            " ",
            "100",
            "2",
            ",",
            " ",
            "100",
            "4",
            " (",
            "9",
            "th",
            " Cir",
            ".",
            " ",
            "199",
            "9",
            "),",
            " aff",
            "’",
            "g",
            " T",
            ".C",
            ".",
            " Memo",
            ".",
            " ",
            "199",
            "7",
            "-",
            "97",
            ".\n",
            "Č",
            "                                       ",
            " -",
            "7",
            "-\n\n",
            "[*",
            "7",
            "]",
            " There",
            " is",
            " no",
            " dispute",
            " in",
            " this",
            " case",
            " that",
            " petitioner",
            " had",
            " debt",
            " that",
            " was",
            " forgiven",
            ".\n\n",
            "Section",
            " ",
            "749",
            "1",
            "(a",
            ")",
            " shifts",
            " the",
            " burden",
            " of",
            " proof",
            " to",
            " the",
            " Commissioner",
            " where",
            " the",
            " taxpayer",
            "\n\n",
            "has",
            " presented",
            " credible",
            " evidence",
            " with",
            " respect"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.668,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " make",
            " NAS",
            "M",
            " assemble",
            " your",
            " assembly",
            " source",
            " file",
            " into",
            " visual",
            " studio",
            " compatible",
            " object",
            " file",
            ".\n",
            "We",
            " are",
            " not",
            " done",
            " yet",
            " though",
            ",",
            " you",
            " need",
            " to",
            " make",
            " some",
            " changes",
            " to",
            " the",
            " assembly",
            " file",
            " before",
            " you",
            " can",
            " link",
            " it",
            " using",
            " MS",
            "VC",
            "'s",
            " linker",
            ".\n",
            "1",
            ")",
            " MS",
            "VC",
            "'s",
            " linker",
            " requires",
            " your",
            " functions",
            " to",
            " start",
            " with",
            " an",
            " underscore",
            " so",
            " main",
            " becomes",
            " _",
            "main",
            ".\n",
            "2",
            ")",
            " The",
            " naming",
            " convention",
            " when",
            " declaring",
            " imported",
            " APIs",
            " is",
            " different",
            " too",
            ".",
            " So",
            " extern",
            " printf",
            " becomes",
            " extern",
            " __",
            "imp",
            "__",
            "printf",
            "\n",
            "3",
            ")",
            " Call",
            " instructions",
            " to",
            " imported",
            " APIs",
            " are",
            " different",
            " too",
            ".",
            " call",
            " printf",
            " becomes",
            " call",
            " [",
            "__",
            "imp",
            "__",
            "printf",
            "].",
            " The",
            " address",
            " of",
            " printf",
            " will",
            " be",
            " stored",
            " in",
            " an",
            " import",
            " table",
            " entry",
            " and",
            " our",
            " instruction",
            " dere",
            "ferences",
            " it",
            " to",
            " find"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.664,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.177,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "3",
            ",",
            " ech",
            "oc",
            "ardi",
            "ographic",
            " optimization",
            " was",
            " only",
            " undertaken",
            " in",
            " sympt",
            "omatic",
            " non",
            "respond",
            "ers",
            ".\n\n",
            "End",
            " Points",
            " {",
            "#",
            "jah",
            "325",
            "87",
            "-",
            "sec",
            "-",
            "001",
            "2",
            "}\n",
            "----------\n\n",
            "The",
            " primary",
            " end",
            " point",
            " was",
            " total",
            " mortality",
            ",",
            " which",
            " included",
            " cardiac",
            " transplantation",
            ".",
            " Secondary",
            " end",
            " points",
            " included",
            " cardiac",
            " mortality",
            " and",
            " unpl",
            "anned",
            " HF",
            " hospital",
            "ization",
            ".",
            " The",
            " first",
            " event",
            " was",
            " included",
            " in",
            " the",
            " analysis",
            ".",
            " With",
            " respect",
            " to",
            " mode",
            " of",
            " death",
            ",",
            " sudden",
            " cardiac",
            " death",
            " was",
            " defined",
            " as",
            " a",
            " \"",
            "natural",
            ",",
            " unexpected",
            " death",
            " due",
            " to",
            " cardiac",
            " causes",
            ",",
            " herald",
            "ed",
            " by",
            " an",
            " abrupt",
            " loss",
            " of",
            " consciousness",
            " within",
            " ",
            "1",
            "Âł",
            "hour",
            " of",
            " the",
            " onset",
            " of",
            " acute",
            " symptoms",
            ",\"",
            "[",
            "16",
            "](",
            "#",
            "jah",
            "325",
            "87",
            "-b",
            "ib",
            "-",
            "001",
            "6",
            "){",
            "ref",
            "-type",
            "=\"",
            "ref"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.668,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " make",
            " NAS",
            "M",
            " assemble",
            " your",
            " assembly",
            " source",
            " file",
            " into",
            " visual",
            " studio",
            " compatible",
            " object",
            " file",
            ".\n",
            "We",
            " are",
            " not",
            " done",
            " yet",
            " though",
            ",",
            " you",
            " need",
            " to",
            " make",
            " some",
            " changes",
            " to",
            " the",
            " assembly",
            " file",
            " before",
            " you",
            " can",
            " link",
            " it",
            " using",
            " MS",
            "VC",
            "'s",
            " linker",
            ".\n",
            "1",
            ")",
            " MS",
            "VC",
            "'s",
            " linker",
            " requires",
            " your",
            " functions",
            " to",
            " start",
            " with",
            " an",
            " underscore",
            " so",
            " main",
            " becomes",
            " _",
            "main",
            ".\n",
            "2",
            ")",
            " The",
            " naming",
            " convention",
            " when",
            " declaring",
            " imported",
            " APIs",
            " is",
            " different",
            " too",
            ".",
            " So",
            " extern",
            " printf",
            " becomes",
            " extern",
            " __",
            "imp",
            "__",
            "printf",
            "\n",
            "3",
            ")",
            " Call",
            " instructions",
            " to",
            " imported",
            " APIs",
            " are",
            " different",
            " too",
            ".",
            " call",
            " printf",
            " becomes",
            " call",
            " [",
            "__",
            "imp",
            "__",
            "printf",
            "].",
            " The",
            " address",
            " of",
            " printf",
            " will",
            " be",
            " stored",
            " in",
            " an",
            " import",
            " table",
            " entry",
            " and",
            " our",
            " instruction",
            " dere",
            "ferences",
            " it",
            " to",
            " find"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " for",
            " the",
            " presumption",
            " of",
            " correctness",
            " to",
            " attach",
            " in",
            " an",
            " un",
            "reported",
            " income",
            "\n\n",
            "case",
            " such",
            " as",
            " this",
            ",",
            " the",
            " Commissioner",
            " must",
            " base",
            " his",
            " deficiency",
            " determination",
            " on",
            "\n\n",
            "some",
            " substantive",
            " evidence",
            " that",
            " the",
            " taxpayer",
            " received",
            " un",
            "reported",
            " income",
            ".",
            " Hardy",
            " v",
            ".\n\n",
            "Commission",
            "er",
            ",",
            " ",
            "181",
            " F",
            ".",
            "3",
            "d",
            " ",
            "100",
            "2",
            ",",
            " ",
            "100",
            "4",
            " (",
            "9",
            "th",
            " Cir",
            ".",
            " ",
            "199",
            "9",
            "),",
            " aff",
            "’",
            "g",
            " T",
            ".C",
            ".",
            " Memo",
            ".",
            " ",
            "199",
            "7",
            "-",
            "97",
            ".\n",
            "Č",
            "                                       ",
            " -",
            "7",
            "-\n\n",
            "[*",
            "7",
            "]",
            " There",
            " is",
            " no",
            " dispute",
            " in",
            " this",
            " case",
            " that",
            " petitioner",
            " had",
            " debt",
            " that",
            " was",
            " forgiven",
            ".\n\n",
            "Section",
            " ",
            "749",
            "1",
            "(a",
            ")",
            " shifts",
            " the",
            " burden",
            " of",
            " proof",
            " to",
            " the",
            " Commissioner",
            " where",
            " the",
            " taxpayer",
            "\n\n",
            "has",
            " presented",
            " credible",
            " evidence",
            " with",
            " respect"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.672,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "\"",
            " [",
            "crime",
            "]",
            " of",
            " being",
            " white",
            ".\n\n",
            "There",
            " is",
            " no",
            " evidence",
            " whatever",
            " that",
            " race",
            " played",
            " a",
            " part",
            " in",
            " Zimmerman",
            "'s",
            " execution",
            " of",
            " his",
            " duties",
            " as",
            " the",
            " on",
            "-duty",
            " Neighborhood",
            " Watch",
            " Volunteer",
            ".\n\n",
            "It",
            " is",
            " said",
            " with",
            " great",
            " der",
            "ision",
            " that",
            " Zimmerman",
            " is",
            " or",
            " was",
            " \"",
            "a",
            " wann",
            "abe",
            " cop",
            ".\"",
            " These",
            " critics",
            " appear",
            " to",
            " live",
            " in",
            " safe",
            " neighborhoods",
            ",",
            " no",
            "?",
            " There",
            "'s",
            " nothing",
            " wrong",
            " with",
            " the",
            " aspiration",
            " to",
            " be",
            " a",
            " cop",
            " unless",
            " one",
            " intends",
            " to",
            " indict",
            " all",
            " cops",
            " for",
            " wanting",
            " to",
            " be",
            " cops",
            " ---",
            " and",
            " letting",
            " a",
            " p",
            "uddy",
            " like",
            " Chris",
            " Matthews",
            " be",
            " the",
            " nighttime",
            " Neighborhood",
            " Watch",
            " volunteer",
            " strikes",
            " me",
            " as",
            " ineffective",
            ",",
            " to",
            " say",
            " the",
            " least",
            " ---",
            " although",
            " a",
            " pretty",
            " good",
            " way",
            " to",
            " get",
            " rid",
            " of",
            " Chris",
            " Matthews",
            ",",
            " come",
            " to",
            " think",
            " of",
            " it"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.633,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.344,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.336,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            " Gaussian",
            " approximation",
            ":",
            " $\\",
            "math",
            "cal",
            " M",
            "(n",
            ";",
            "(\\",
            "gamma",
            "_",
            "1",
            ",\\",
            "dots",
            "\\",
            "gamma",
            "_m",
            "))",
            " \\",
            "overs",
            "et",
            "{\\",
            "Delta",
            "}",
            " \\",
            "Long",
            "leftrightarrow",
            " \\",
            "big",
            "ot",
            "imes",
            "_{",
            "j",
            "=",
            "2",
            "}",
            "^",
            "m",
            " {\\",
            "ensure",
            "math",
            " {\\",
            "math",
            "scr",
            "{",
            "N",
            "n",
            "}}",
            "}(",
            "2",
            "\\",
            "sqrt",
            "{T",
            "_n",
            "\\n",
            "u",
            "(J",
            "_j",
            ")},",
            "1",
            ")$",
            ";\n\n",
            "-",
            "  ",
            " Step",
            " ",
            "4",
            ".",
            " $\\",
            "big",
            "ot",
            "imes",
            "_{",
            "j",
            "=",
            "2",
            "}",
            "^",
            "m",
            " {\\",
            "ensure",
            "math",
            " {\\",
            "math",
            "scr",
            "{",
            "N",
            "n",
            "}}",
            "}(",
            "2",
            "\\",
            "sqrt",
            "{T",
            "_n",
            "\\n",
            "u",
            "(J",
            "_j",
            ")},",
            "1",
            ")\\",
            "overs",
            "et",
            "{\\",
            "Delta",
            "}",
            " \\",
            "Long",
            "leftrightarrow",
            " (",
            "y",
            "_t",
            ")",
            "_{",
            "t",
            "\\",
            "in",
            " I",
            "}$",
            ".\n\n",
            "\\[",
            "lemma",
            ":",
            "ch"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.629,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.344,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.038,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.264,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "RF",
            " and",
            " in",
            " that",
            " way",
            " explore",
            " the",
            " clinical",
            " relevance",
            " of",
            " the",
            " technique",
            ".\n\n",
            "In",
            " conclusion",
            ",",
            " the",
            " high",
            " unders",
            "ampling",
            " factors",
            " used",
            " for",
            " this",
            " Cartesian",
            ",",
            " non",
            "parallel",
            " imaging",
            "âĢĲ",
            "based",
            " approach",
            " shorten",
            " scan",
            " time",
            " and",
            " in",
            " this",
            " way",
            " reduce",
            " the",
            " risk",
            " of",
            " motion",
            " artifacts",
            ",",
            " which",
            " is",
            " most",
            " relevant",
            " for",
            " elderly",
            " patients",
            ",",
            " who",
            " typically",
            " experience",
            " difficulties",
            " focusing",
            " on",
            " a",
            " fixation",
            " target",
            ".\n\n",
            "Support",
            "ing",
            " information",
            "\n",
            "================",
            "======",
            "\n\n",
            "######",
            " \n\n",
            "**",
            "FIG",
            "URE",
            " S",
            "1",
            "**",
            " The",
            " effect",
            " of",
            " the",
            " unders",
            "ampling",
            " factor",
            " on",
            " the",
            " performance",
            " of",
            " different",
            " reconstruction",
            " methods",
            ".",
            " Und",
            "ers",
            "ampled",
            " data",
            " sets",
            " were",
            " obtained",
            " by",
            " subs",
            "ampling",
            " a",
            " fully",
            " sampled",
            " data",
            " set",
            ",",
            " while",
            " fixing",
            " the",
            " number",
            " of",
            " central",
            " k",
            "âĢĲ",
            "space",
            " lines",
            " to",
            " six",
            " for",
            " all",
            " unders",
            "ampling",
            " factors"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.629,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.344,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.038,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.264,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "RF",
            " and",
            " in",
            " that",
            " way",
            " explore",
            " the",
            " clinical",
            " relevance",
            " of",
            " the",
            " technique",
            ".\n\n",
            "In",
            " conclusion",
            ",",
            " the",
            " high",
            " unders",
            "ampling",
            " factors",
            " used",
            " for",
            " this",
            " Cartesian",
            ",",
            " non",
            "parallel",
            " imaging",
            "âĢĲ",
            "based",
            " approach",
            " shorten",
            " scan",
            " time",
            " and",
            " in",
            " this",
            " way",
            " reduce",
            " the",
            " risk",
            " of",
            " motion",
            " artifacts",
            ",",
            " which",
            " is",
            " most",
            " relevant",
            " for",
            " elderly",
            " patients",
            ",",
            " who",
            " typically",
            " experience",
            " difficulties",
            " focusing",
            " on",
            " a",
            " fixation",
            " target",
            ".\n\n",
            "Support",
            "ing",
            " information",
            "\n",
            "================",
            "======",
            "\n\n",
            "######",
            " \n\n",
            "**",
            "FIG",
            "URE",
            " S",
            "1",
            "**",
            " The",
            " effect",
            " of",
            " the",
            " unders",
            "ampling",
            " factor",
            " on",
            " the",
            " performance",
            " of",
            " different",
            " reconstruction",
            " methods",
            ".",
            " Und",
            "ers",
            "ampled",
            " data",
            " sets",
            " were",
            " obtained",
            " by",
            " subs",
            "ampling",
            " a",
            " fully",
            " sampled",
            " data",
            " set",
            ",",
            " while",
            " fixing",
            " the",
            " number",
            " of",
            " central",
            " k",
            "âĢĲ",
            "space",
            " lines",
            " to",
            " six",
            " for",
            " all",
            " unders",
            "ampling",
            " factors"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.34,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.179,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " should",
            " see",
            " a",
            " black",
            " screen",
            " prompting",
            " you",
            " to",
            " define",
            " the",
            " keys",
            " on",
            " your",
            "\n",
            "remote",
            ".",
            " After",
            " finishing",
            " the",
            " wizard",
            ",",
            " you",
            "'re",
            " ready",
            " to",
            " watch",
            " TV",
            ",",
            " record",
            "\n",
            "shows",
            " and",
            " remove",
            " commercials",
            ".",
            " You",
            " can",
            " listen",
            " to",
            " your",
            " MP",
            "3",
            "s",
            " and",
            " watch",
            "\n",
            "videos",
            ".",
            " There",
            "'s",
            " a",
            " manual",
            " in",
            " V",
            "DR",
            "'s",
            " root",
            " that",
            " explains",
            "\n",
            "how",
            " to",
            " record",
            " and",
            " edit",
            " TV",
            " events",
            ",",
            " using",
            " the",
            " time",
            "-shift",
            " feature",
            ".\n\n",
            "Back",
            " It",
            " Up",
            "\n\n",
            "In",
            " case",
            " you",
            "'re",
            " disappointed",
            " that",
            " the",
            " end",
            " of",
            " the",
            " article",
            " is",
            " within",
            " reach",
            ",\n",
            "don",
            "'t",
            " worry",
            ";",
            " there",
            " still",
            " are",
            " some",
            " optional",
            " things",
            " you",
            " can",
            " do",
            ".",
            " The",
            " automatic",
            "\n",
            "backup",
            " feature",
            " has",
            " some",
            " limitations",
            ".",
            " Although",
            " the",
            " (",
            "S",
            ")V",
            "CD",
            " backup",
            " works",
            "\n",
            "fl",
            "aw"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.348,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.184,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "/",
            "2",
            "}\\",
            "{\\",
            "int",
            "[\\",
            "hat",
            "{\\",
            "gamma",
            "}_{",
            "\\",
            "ell",
            "}(",
            "w",
            ")-",
            "\\",
            "gamma",
            "_{",
            "0",
            "}(",
            "w",
            ")]",
            "^{",
            "2",
            "}",
            "F",
            "_{",
            "0",
            "}(",
            "dw",
            ")\\",
            "}",
            "^{",
            "1",
            "/",
            "2",
            "}",
            ".\\",
            "end",
            "{",
            "aligned",
            "}",
            "$$",
            " Then",
            " the",
            " first",
            " rate",
            " condition",
            " of",
            " Ass",
            "umption",
            " ",
            "5",
            " holds",
            " under",
            " the",
            " first",
            " rate",
            " condition",
            " of",
            " The",
            "orem",
            " ",
            "13",
            " while",
            " the",
            " second",
            " condition",
            " of",
            " Ass",
            "umption",
            " ",
            "5",
            " holds",
            " under",
            " the",
            " last",
            " hypothesis",
            " of",
            " The",
            "orem",
            " ",
            "13",
            ".",
            " Then",
            " eq",
            ".",
            " (\\",
            "[",
            "no",
            " eff",
            "ec",
            "\\",
            "])",
            " holds",
            " by",
            " Lemma",
            " ",
            "12",
            ",",
            " and",
            " the",
            " conclusion",
            " by",
            " rearr",
            "anging",
            " the",
            " terms",
            " in",
            " eq",
            ".",
            " (\\",
            "[",
            "no",
            " eff",
            "ec",
            "\\",
            "]).",
            " *",
            "Q",
            ".E",
            ".D",
            ".*\n\n",
            "**",
            "Proof",
            " of",
            " Lemma"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.609,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "\"\n",
            "       ",
            " android",
            ":",
            "layout",
            "_below",
            "=\"@",
            "id",
            "/b",
            "tn",
            "_cr",
            "ash",
            "_restart",
            "\"\n",
            "       ",
            " />\n",
            "    \n\n",
            "</",
            "RelativeLayout",
            ">",
            "<|begin_of_text|>",
            "Q",
            ":\n\n",
            "Node",
            " JS",
            " Express",
            " Boiler",
            "plate",
            " and",
            " rendering",
            "\n\n",
            "I",
            " am",
            " trying",
            " out",
            " node",
            " and",
            " it",
            "'s",
            " Express",
            " framework",
            " via",
            " the",
            " Express",
            " boiler",
            "plate",
            " installation",
            ".",
            " It",
            " took",
            " me",
            " a",
            " while",
            " to",
            " figure",
            " out",
            " I",
            " need",
            " Redis",
            " installed",
            " (",
            "bt",
            "w",
            ",",
            " if",
            " you",
            "'re",
            " making",
            " a",
            " boiler",
            "plate",
            " either",
            " include",
            " all",
            " required",
            " software",
            " with",
            " it",
            " or",
            " warn",
            " about",
            " the",
            " requirement",
            " for",
            " certain",
            " software",
            " -",
            " Redis",
            " was",
            " never",
            " mentioned",
            " as",
            " required",
            ")",
            " and",
            " to",
            " get",
            " my",
            " way",
            " around",
            " the",
            " server",
            ".js",
            " file",
            ".\n",
            "Right",
            " now",
            " I",
            "'m",
            " still",
            " a",
            " stranger",
            " to",
            " how",
            " I",
            " could",
            " build",
            " a",
            " site",
            " in",
            " this",
            "..\n",
            "There",
            " is",
            " one",
            " problem",
            " that"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.551,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.297,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.594,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "100",
            "7",
            "/s",
            "101",
            "15",
            "-",
            "017",
            "-",
            "114",
            "5",
            "-y",
            ").",
            " <",
            "http",
            "://",
            "link",
            ".spring",
            "er",
            ".com",
            "/",
            "10",
            ".",
            "100",
            "7",
            "/s",
            "101",
            "15",
            "-",
            "017",
            "-",
            "114",
            "5",
            "-y",
            ">\n\n",
            "H",
            ".",
            "ÂłP",
            "eng",
            ",",
            " F",
            ".",
            "Âł",
            "Long",
            ",",
            " C",
            ".",
            "ÂłD",
            "ing",
            ",",
            " [[",
            "Feature",
            " selection",
            " based",
            " on",
            " mutual",
            " information",
            ":",
            " criteria",
            " of",
            " max",
            "-depend",
            "ency",
            ",",
            " max",
            "-re",
            "levance",
            ",",
            " and",
            " min",
            "-re",
            "du",
            "nd",
            "ancy",
            ".]",
            "{}",
            "]{",
            "},",
            " IEEE",
            " transactions",
            " on",
            " pattern",
            " analysis",
            " and",
            " machine",
            " intelligence",
            " ",
            "27",
            "Âł",
            "(",
            "8",
            ")",
            " (",
            "200",
            "5",
            ")",
            " ",
            "122",
            "6",
            "–",
            "38",
            ".",
            " [](",
            "http",
            "://",
            "dx",
            ".d",
            "oi",
            ".org",
            "/",
            "10",
            ".",
            "110",
            "9",
            "/",
            "TP",
            "AMI",
            ".",
            "200",
            "5",
            ".",
            "159",
            ").",
            " <",
            "http",
            "://",
            "www",
            ".ncbi"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.582,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " NA",
            "                                                                      ",
            " glucose",
            ",",
            " mann",
            "ose",
            ",",
            " gal",
            "act",
            "ose",
            ",",
            " rib",
            "ose",
            "                                                                ",
            "                            ",
            " \\",
            "[",
            "[@",
            "B",
            "25",
            "],",
            "[@",
            "B",
            "117",
            "],",
            "[@",
            "B",
            "118",
            "]\\",
            "]\n\n",
            "                                                                                                                                ",
            "                                                                                                                                ",
            "                                                                                                                                ",
            "                                                                                                                                ",
            "                                                                ",
            "                                                  ",
            "\n\n",
            " ",
            " *",
            "Ag",
            "ar",
            "icus",
            " sub",
            "r",
            "uf",
            "esc",
            "ens",
            "*(",
            "my",
            "cel",
            "ia",
            ")",
            "                                                                ",
            "                                                                               ",
            " Extract",
            " (",
            "ATOM",
            ")",
            "                           ",
            " Î²",
            "-",
            "1",
            ",",
            "6",
            "-D",
            "-gl",
            "uc",
            "an",
            ",",
            " protein",
            " complex",
            ",",
            " ",
            "5",
            "%",
            " protein",
            "                                                                                                                                ",
            "                                 ",
            " ",
            "100",
            ",",
            "000",
            "-",
            "1",
            ",",
            "000",
            ",",
            "000",
            "                                                       ",
            " glucose",
            ",",
            " mann",
            "ose",
            ",",
            " gal",
            "act",
            "ose",
            ",",
            " rib",
            "ose",
            "                                                                ",
            "                            ",
            " \\",
            "[",
            "[@",
            "B",
            "93",
            "]\\",
            "]\n\n",
            "                                                                                                                                ",
            "                                                                                                                                ",
            "                                                                                                                                ",
            "                                                                                                                                ",
            "                                                                ",
            "                                                  ",
            "\n\n",
            " ",
            " *",
            "A",
            "loe",
            " bar",
            "bad",
            "ensis",
            "*(",
            "leaf",
            " gel",
            ")"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.011,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.166,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.578,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " }\n\n",
            "   ",
            " .",
            "hl",
            "js",
            "-selector",
            "-id",
            " {\n",
            "     ",
            " color",
            ":",
            " #",
            "8",
            "b",
            "98",
            "ab",
            ";\n",
            "   ",
            " }\n\n",
            "   ",
            " .",
            "hl",
            "js",
            "-em",
            "phasis",
            " {\n",
            "     ",
            " font",
            "-style",
            ":",
            " italic",
            ";\n",
            "   ",
            " }\n\n",
            "   ",
            " .",
            "hl",
            "js",
            "-strong",
            " {\n",
            "     ",
            " font",
            "-weight",
            ":",
            " bold",
            ";\n",
            "   ",
            " }\n\n",
            "   ",
            " .",
            "hl",
            "js",
            "-link",
            " {\n",
            "     ",
            " text",
            "-decoration",
            ":",
            " underline",
            ";\n",
            "   ",
            " }\n",
            "}",
            "<|begin_of_text|>",
            "\n",
            "58",
            " Cal",
            ".App",
            ".",
            "3",
            "d",
            " ",
            "439",
            " (",
            "197",
            "6",
            ")\n",
            "129",
            " Cal",
            ".",
            " R",
            "ptr",
            ".",
            " ",
            "797",
            "\n",
            "L",
            ".",
            " G",
            "ENE",
            " ALL",
            "ARD",
            ",",
            " Plaintiff",
            ",",
            " Cross",
            "-def",
            "endant",
            " and",
            " Respond",
            "ent",
            ",\n",
            "v",
            ".\n",
            "CH",
            "UR",
            "CH",
            " OF",
            " SC",
            "IENT",
            "O",
            "LOGY",
            " OF",
            " CAL",
            "IF",
            "ORN",
            "IA",
            ",",
            " Defendant",
            ",",
            " Cross",
            "-com",
            "plain",
            "ant",
            " and",
            " App",
            "ellant"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.566,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.578,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " payment",
            " and",
            "/or",
            " incentives",
            " or",
            " changes",
            " in",
            " laws",
            " and",
            "/or",
            " credential",
            "ing",
            " and",
            " licensing",
            ".Table",
            "Âł",
            "1",
            "Implementation",
            " strategies",
            " identified",
            " in",
            " published",
            " evaluations",
            " of",
            " care",
            " delivery",
            " and",
            " implementation",
            " interventions",
            " that",
            " have",
            " aimed",
            " to",
            " increase",
            " medication",
            " treatment",
            " for",
            " patients",
            " with",
            " alcohol",
            " use",
            " disorder",
            "Strategy",
            "S",
            "ait",
            "z",
            " A",
            "HEAD",
            " C",
            "CM",
            " \\",
            "[",
            "[@",
            "CR",
            "32",
            "]\\",
            "]",
            "O",
            "sl",
            "in",
            "\\\n",
            "Al",
            "cohol",
            " Care",
            " Management",
            " \\",
            "[",
            "[@",
            "CR",
            "31",
            "]\\",
            "]",
            "Wat",
            "kins",
            "\\\n",
            "SUM",
            "MIT",
            " \\",
            "[",
            "[@",
            "CR",
            "35",
            "]",
            "--",
            "[@",
            "CR",
            "38",
            "]\\",
            "]",
            "Brad",
            "ley",
            " CHO",
            "ICE",
            " \\",
            "[",
            "[@",
            "CR",
            "33",
            "],",
            " [@",
            "CR",
            "34",
            "]\\",
            "]",
            "Rob",
            "inson",
            " Group",
            " Manage",
            " \\",
            "[",
            "[@",
            "CR",
            "44",
            "]\\",
            "]",
            "H",
            "arris",
            "\\\n",
            "VA",
            " Academic",
            " Detail",
            "ing",
            " Program",
            " \\",
            "[",
            "[@",
            "CR"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.574,
            -0.0,
            -0.0,
            0.492,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " dogs",
            ".",
            " My",
            " name",
            "’s",
            " Rick",
            " and",
            " Henry",
            "’s",
            " my",
            " dog",
            ".”",
            " I",
            " introduced",
            " myself",
            " and",
            " Spike",
            ",",
            " who",
            " decided",
            " since",
            " I",
            " was",
            " talking",
            " nicely",
            " with",
            " the",
            " fine",
            " fellow",
            " that",
            " it",
            " would",
            " be",
            " ok",
            " to",
            " start",
            " sniff",
            "ing",
            " HIM",
            ".",
            " He",
            "’d",
            " just",
            " began",
            " at",
            " the",
            " man",
            "’s",
            " shoe",
            " and",
            " I",
            " hastily",
            " t",
            "ugged",
            " on",
            " the",
            " leash",
            " again",
            " in",
            " fear",
            " that",
            " he",
            "’d",
            " complete",
            " the",
            " “",
            "tr",
            "ick",
            "”",
            " that",
            " I",
            "’d",
            " taught",
            " him",
            ".\n\n",
            "“No",
            ",",
            " Spike",
            ",",
            " no",
            "!”",
            " Again",
            ",",
            " he",
            " gave",
            " me",
            " that",
            " hurt",
            " look",
            " and",
            " came",
            " back",
            " to",
            " ‘",
            "h",
            "mp",
            "f",
            "’",
            " at",
            " my",
            " feet",
            ",",
            " watching",
            " both",
            " Henry",
            " and",
            " Rick",
            " carefully",
            " just",
            " in",
            " case",
            " I",
            " changed",
            " my",
            " mind",
            ".",
            " Indeed",
            ",",
            " I",
            " would",
            " have",
            " been",
            " quite",
            " pleased",
            " to",
            " have",
            " Spike"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.574,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "}}",
            "=\n",
            "\\",
            "frac",
            "{",
            "g",
            "^",
            "2",
            "}{",
            "2",
            "\\",
            "k",
            "appa",
            "_{",
            "\\",
            "mathrm",
            "{",
            "in",
            "}}",
            " \\",
            "gamma",
            " },\n",
            "\\",
            "label",
            "{",
            "eq",
            "-C",
            "in",
            "}\\",
            "end",
            "{",
            "aligned",
            "}",
            "$$",
            " as",
            " the",
            " cooper",
            "ativity",
            " parameter",
            " with",
            " respect",
            " to",
            " $\\",
            "k",
            "appa",
            "_{",
            "\\",
            "mathrm",
            "{",
            "in",
            "}}",
            "$",
            " instead",
            " of",
            " $\\",
            "k",
            "appa",
            "$",
            " for",
            " the",
            " standard",
            " definition",
            ",",
            " $",
            "C",
            "=g",
            "^",
            "2",
            "/(",
            "2",
            "\\",
            "k",
            "appa",
            " \\",
            "gamma",
            " )",
            "$",
            " [@",
            "Rem",
            "pe",
            "201",
            "5",
            "a",
            "].",
            " The",
            " approximation",
            " in",
            " Eq",
            ".",
            "Âł",
            "(\\",
            "[",
            "eq",
            "-P",
            "F",
            "\\",
            "])",
            " holds",
            " when",
            " $",
            "C",
            "_{",
            "\\",
            "mathrm",
            "{",
            "in",
            "}}",
            " \\",
            "gg",
            " ",
            "1",
            "$",
            ".\n\n",
            "The",
            " lower",
            " bound",
            " on",
            " $",
            "P",
            "_F",
            "$",
            " in",
            " Eq",
            ".",
            "Âł",
            "(\\",
            "["
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.574,
            -0.0,
            -0.0,
            0.492,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " dogs",
            ".",
            " My",
            " name",
            "’s",
            " Rick",
            " and",
            " Henry",
            "’s",
            " my",
            " dog",
            ".”",
            " I",
            " introduced",
            " myself",
            " and",
            " Spike",
            ",",
            " who",
            " decided",
            " since",
            " I",
            " was",
            " talking",
            " nicely",
            " with",
            " the",
            " fine",
            " fellow",
            " that",
            " it",
            " would",
            " be",
            " ok",
            " to",
            " start",
            " sniff",
            "ing",
            " HIM",
            ".",
            " He",
            "’d",
            " just",
            " began",
            " at",
            " the",
            " man",
            "’s",
            " shoe",
            " and",
            " I",
            " hastily",
            " t",
            "ugged",
            " on",
            " the",
            " leash",
            " again",
            " in",
            " fear",
            " that",
            " he",
            "’d",
            " complete",
            " the",
            " “",
            "tr",
            "ick",
            "”",
            " that",
            " I",
            "’d",
            " taught",
            " him",
            ".\n\n",
            "“No",
            ",",
            " Spike",
            ",",
            " no",
            "!”",
            " Again",
            ",",
            " he",
            " gave",
            " me",
            " that",
            " hurt",
            " look",
            " and",
            " came",
            " back",
            " to",
            " ‘",
            "h",
            "mp",
            "f",
            "’",
            " at",
            " my",
            " feet",
            ",",
            " watching",
            " both",
            " Henry",
            " and",
            " Rick",
            " carefully",
            " just",
            " in",
            " case",
            " I",
            " changed",
            " my",
            " mind",
            ".",
            " Indeed",
            ",",
            " I",
            " would",
            " have",
            " been",
            " quite",
            " pleased",
            " to",
            " have",
            " Spike"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.574,
            -0.0,
            -0.0,
            0.492,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " dogs",
            ".",
            " My",
            " name",
            "’s",
            " Rick",
            " and",
            " Henry",
            "’s",
            " my",
            " dog",
            ".”",
            " I",
            " introduced",
            " myself",
            " and",
            " Spike",
            ",",
            " who",
            " decided",
            " since",
            " I",
            " was",
            " talking",
            " nicely",
            " with",
            " the",
            " fine",
            " fellow",
            " that",
            " it",
            " would",
            " be",
            " ok",
            " to",
            " start",
            " sniff",
            "ing",
            " HIM",
            ".",
            " He",
            "’d",
            " just",
            " began",
            " at",
            " the",
            " man",
            "’s",
            " shoe",
            " and",
            " I",
            " hastily",
            " t",
            "ugged",
            " on",
            " the",
            " leash",
            " again",
            " in",
            " fear",
            " that",
            " he",
            "’d",
            " complete",
            " the",
            " “",
            "tr",
            "ick",
            "”",
            " that",
            " I",
            "’d",
            " taught",
            " him",
            ".\n\n",
            "“No",
            ",",
            " Spike",
            ",",
            " no",
            "!”",
            " Again",
            ",",
            " he",
            " gave",
            " me",
            " that",
            " hurt",
            " look",
            " and",
            " came",
            " back",
            " to",
            " ‘",
            "h",
            "mp",
            "f",
            "’",
            " at",
            " my",
            " feet",
            ",",
            " watching",
            " both",
            " Henry",
            " and",
            " Rick",
            " carefully",
            " just",
            " in",
            " case",
            " I",
            " changed",
            " my",
            " mind",
            ".",
            " Indeed",
            ",",
            " I",
            " would",
            " have",
            " been",
            " quite",
            " pleased",
            " to",
            " have",
            " Spike"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.57,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "?",
            " I",
            " actually",
            " prefer",
            " A",
            ",",
            " and",
            " if",
            " B",
            "'s",
            " offer",
            " were",
            " roughly",
            " the",
            " same",
            " size",
            ",",
            " I",
            " would",
            " be",
            " very",
            " happy",
            " to",
            " take",
            " A",
            ".",
            " However",
            ",",
            " I",
            " am",
            " wondering",
            " whether",
            " I",
            " am",
            " a",
            " w",
            "ussy",
            " if",
            " I",
            " play",
            " it",
            " safe",
            " now",
            ",",
            " and",
            " take",
            " no",
            " action",
            ",",
            " and",
            " should",
            " I",
            " instead",
            " try",
            " to",
            " get",
            " some",
            " competition",
            " between",
            " these",
            " two",
            ".",
            " There",
            "'s",
            " also",
            " a",
            " small",
            " chance",
            " that",
            " A",
            " is",
            " trying",
            " to",
            " low",
            "ball",
            " me",
            " with",
            " their",
            " offer",
            ",",
            " since",
            " I",
            " might",
            " be",
            " too",
            " humble",
            " analyzing",
            " my",
            " own",
            " value",
            ".",
            " All",
            " this",
            " leads",
            " me",
            " to",
            " think",
            " that",
            " I",
            " might",
            " just",
            " want",
            " to",
            " get",
            " the",
            " offer",
            " in",
            " writing",
            ",",
            " not",
            " caring",
            " what",
            " they",
            " think",
            " about",
            " it",
            ",",
            " but",
            " I",
            " am",
            " very",
            " very",
            " open",
            " to",
            " other",
            " ideas",
            ".<"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.064,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.4,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.328,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.328,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.324,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.57,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " value",
            "=\"",
            "800",
            "000",
            "\"/>\n",
            "\t\t",
            "\t",
            "<",
            "stat",
            " name",
            "=\"",
            "committed",
            "_int",
            "_instructions",
            "\"",
            " value",
            "=\"",
            "600",
            "000",
            "\"/>\n",
            "\t\t",
            "\t",
            "<",
            "stat",
            " name",
            "=\"",
            "committed",
            "_fp",
            "_instructions",
            "\"",
            " value",
            "=\"",
            "200",
            "00",
            "\"/>\n",
            "\t\t",
            "\t",
            "<",
            "stat",
            " name",
            "=\"",
            "pipeline",
            "_d",
            "uty",
            "_cycle",
            "\"",
            " value",
            "=\"",
            "0",
            ".",
            "6",
            "\"/",
            "><!--",
            "<=",
            "1",
            ",",
            " runtime",
            "_ipc",
            "/",
            "peak",
            "_ipc",
            ";",
            " averaged",
            " for",
            " all",
            " cores",
            " if",
            " hom",
            "ogenous",
            " -->\n",
            "\t\t",
            "\t",
            "<!--",
            " the",
            " following",
            " cycle",
            " stats",
            " are",
            " used",
            " for",
            " heter",
            "ogene",
            "ouse",
            " cores",
            " only",
            ",",
            " \n",
            "\t\t\t",
            "\t",
            "please",
            " ignore",
            " them",
            " if",
            " hom",
            "ogene",
            "ouse",
            " cores",
            " -->\n",
            "\t\t",
            "\t",
            "<",
            "stat",
            " name",
            "=\"",
            "total",
            "_cycles",
            "\"",
            " value",
            "=\"",
            "100",
            "000",
            "\"/>\n",
            "\t\t   ",
            " <",
            "stat",
            " name",
            "=\"",
            "idle",
            "_cycles",
            "\"",
            " value",
            "=\"",
            "0",
            "\"/>\n",
            "\t\t   ",
            " <",
            "stat"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.064,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.4,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.328,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.328,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.324,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.57,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " value",
            "=\"",
            "800",
            "000",
            "\"/>\n",
            "\t\t",
            "\t",
            "<",
            "stat",
            " name",
            "=\"",
            "committed",
            "_int",
            "_instructions",
            "\"",
            " value",
            "=\"",
            "600",
            "000",
            "\"/>\n",
            "\t\t",
            "\t",
            "<",
            "stat",
            " name",
            "=\"",
            "committed",
            "_fp",
            "_instructions",
            "\"",
            " value",
            "=\"",
            "200",
            "00",
            "\"/>\n",
            "\t\t",
            "\t",
            "<",
            "stat",
            " name",
            "=\"",
            "pipeline",
            "_d",
            "uty",
            "_cycle",
            "\"",
            " value",
            "=\"",
            "0",
            ".",
            "6",
            "\"/",
            "><!--",
            "<=",
            "1",
            ",",
            " runtime",
            "_ipc",
            "/",
            "peak",
            "_ipc",
            ";",
            " averaged",
            " for",
            " all",
            " cores",
            " if",
            " hom",
            "ogenous",
            " -->\n",
            "\t\t",
            "\t",
            "<!--",
            " the",
            " following",
            " cycle",
            " stats",
            " are",
            " used",
            " for",
            " heter",
            "ogene",
            "ouse",
            " cores",
            " only",
            ",",
            " \n",
            "\t\t\t",
            "\t",
            "please",
            " ignore",
            " them",
            " if",
            " hom",
            "ogene",
            "ouse",
            " cores",
            " -->\n",
            "\t\t",
            "\t",
            "<",
            "stat",
            " name",
            "=\"",
            "total",
            "_cycles",
            "\"",
            " value",
            "=\"",
            "100",
            "000",
            "\"/>\n",
            "\t\t   ",
            " <",
            "stat",
            " name",
            "=\"",
            "idle",
            "_cycles",
            "\"",
            " value",
            "=\"",
            "0",
            "\"/>\n",
            "\t\t   ",
            " <",
            "stat"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " status",
            " with",
            " no",
            " change",
            " for",
            " at",
            " least",
            "\n",
            "6",
            " months",
            ".",
            " Please",
            " provide",
            " the",
            " requested",
            " information",
            " as",
            " soon",
            " as",
            "\n",
            "possible",
            " and",
            " mark",
            " the",
            " bug",
            " as",
            " UN",
            "CONF",
            "IRM",
            "ED",
            ".",
            " Due",
            " to",
            " regular",
            " bug",
            "\n",
            "tracker",
            " maintenance",
            ",",
            " if",
            " the",
            " bug",
            " is",
            " still",
            " in",
            " NEED",
            "INFO",
            " status",
            " with",
            "\n",
            "no",
            " change",
            " in",
            " ",
            "30",
            " days",
            " the",
            " QA",
            " team",
            " will",
            " close",
            " the",
            " bug",
            " as",
            " INS",
            "UFF",
            "ICIENT",
            "DATA",
            "\n",
            "due",
            " to",
            " lack",
            " of",
            " needed",
            " information",
            ".\n",
            "For",
            " more",
            " information",
            " about",
            " our",
            " NEED",
            "INFO",
            " policy",
            " please",
            " read",
            " the",
            "\n",
            "wiki",
            " located",
            " here",
            ":\n",
            "https",
            "://",
            "wiki",
            ".document",
            "foundation",
            ".org",
            "/Q",
            "A",
            "/B",
            "ug",
            "zilla",
            "/",
            "Fields",
            "/",
            "Status",
            "/",
            "NE",
            "ED",
            "INFO",
            "\n",
            "If",
            " you",
            " have",
            " already",
            " provided",
            " the",
            " requested",
            " information",
            ",",
            " please",
            "\n",
            "mark",
            " the",
            " bug",
            " as"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.48,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " Tr",
            "uj",
            "illo",
            " asserts",
            " that",
            " the",
            " trial",
            " court",
            " er",
            "red",
            " in",
            " rejecting",
            " various",
            "\n\n",
            " jury",
            " instructions",
            " regarding",
            " his",
            " theory",
            " of",
            " the",
            " case",
            ".",
            " We",
            " disagree",
            ".\n\n",
            "                          ",
            " A",
            ".",
            " Additional",
            " Facts",
            "\n\n",
            "Â¶",
            "7",
            "   ",
            " Throughout",
            " trial",
            ",",
            " the",
            " defense",
            "’s",
            " theory",
            " of",
            " the",
            " case",
            " was",
            " that",
            "\n\n",
            " Tr",
            "uj",
            "illo",
            " lacked",
            " the",
            " requisite",
            " intent",
            " to",
            " commit",
            " the",
            " charged",
            " offenses",
            "\n\n",
            " because",
            " he",
            " believed",
            " that",
            " the",
            " property",
            " he",
            " removed",
            " from",
            " the",
            " house",
            "\n\n",
            " belonged",
            " to",
            " him",
            ".",
            " The",
            " defense",
            " tender",
            "ed",
            " five",
            " jury",
            " instructions",
            " related",
            "\n\n",
            " to",
            " this",
            " theory",
            " of",
            " the",
            " case",
            ".\n\n",
            "Â¶",
            "8",
            "   ",
            " Tr",
            "uj",
            "illo",
            "’s",
            " tender",
            "ed",
            " jury",
            " instructions",
            " detailed",
            " property",
            " law",
            "\n\n",
            " concepts",
            ".",
            " For",
            " example",
            ",",
            " the",
            " first",
            " tender",
            "ed",
            " instruction",
            " stated",
            " that",
            "\n\n",
            " “",
            "the",
            " person",
            " who",
            " has",
            " title"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.064,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.26,
            0.441,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            0.44,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.226,
            0.404,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.262,
            0.438,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " bool",
            "Value",
            "=true",
            ")\n",
            "@",
            "Provider",
            "\n",
            "@",
            "Consum",
            "es",
            "({",
            " //",
            "First",
            " the",
            " data",
            " types",
            " directly",
            " supported",
            " for",
            " parsing",
            " representations",
            "\n",
            "           ",
            " MediaType",
            ".APPLICATION",
            "_JSON",
            ",",
            " Supported",
            "Format",
            ".N",
            "3",
            ",",
            " Supported",
            "Format",
            ".N",
            "_TR",
            "IPLE",
            ",\n",
            "           ",
            " Supported",
            "Format",
            ".R",
            "DF",
            "_XML",
            ",",
            " Supported",
            "Format",
            ".T",
            "URT",
            "LE",
            ",",
            " Supported",
            "Format",
            ".X",
            "_T",
            "URT",
            "LE",
            ",\n",
            "           ",
            " Supported",
            "Format",
            ".R",
            "DF",
            "_JSON",
            ",\n",
            "           ",
            " //",
            "finally",
            " this",
            " also",
            " supports",
            " sending",
            " the",
            " data",
            " as",
            " form",
            " and",
            " mime",
            " multipart",
            "\n",
            "           ",
            " MediaType",
            ".APPLICATION",
            "_FORM",
            "_",
            "UR",
            "LE",
            "NC",
            "ODE",
            "D",
            ",",
            " \n",
            "           ",
            " MediaType",
            ".MULT",
            "IP",
            "ART",
            "_FORM",
            "_DATA",
            "})\n",
            "public",
            " class",
            " Representation",
            "Reader",
            " implements",
            " Message",
            "Body",
            "Reader",
            "<Map",
            "<String",
            ",",
            "Representation",
            ">>",
            " {\n",
            "    \n",
            "   ",
            " private",
            " static",
            " final",
            " Logger",
            " log",
            " =",
            " LoggerFactory",
            ".getLogger",
            "(",
            "Representation",
            "Reader"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.436,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " (",
            "a",
            ")",
            " The",
            " location",
            " of",
            " stimulating",
            " and",
            " recording",
            "\n",
            "elect",
            "ro",
            "des",
            " in",
            " acute",
            " slices",
            " containing",
            " the",
            " ent",
            "or",
            "h",
            "inal",
            " cortex",
            ".",
            " (",
            "b",
            ")",
            " and",
            " (",
            "c",
            ")",
            " Long",
            "-term",
            "\n",
            "de",
            "pression",
            " was",
            " induced",
            " by",
            " repetitive",
            " delivery",
            " of",
            " pairs",
            " of",
            " stimulation",
            " pulses",
            " at",
            " a",
            " rate",
            " of",
            " ",
            "1",
            " Hz",
            " for",
            " ",
            "15",
            " minutes",
            " (",
            "PP",
            "-L",
            "FS",
            ").",
            " The",
            " amplitude",
            "\n",
            "of",
            " synaptic",
            " responses",
            " remained",
            " stable",
            " in",
            " control",
            " cells",
            " that",
            " did",
            " not",
            " receive",
            " conditioning",
            "\n",
            "stim",
            "ulation",
            ".",
            " Tr",
            "aces",
            " in",
            " (",
            "b",
            ")",
            " compare",
            " responses",
            "\n",
            "record",
            "ed",
            " during",
            " the",
            " baseline",
            " period",
            " (",
            "1",
            ")",
            " and",
            " during",
            " the",
            " follow",
            "-up",
            " period",
            " (",
            "2",
            ")",
            " in",
            " a",
            "\n",
            "ne",
            "uron",
            " that",
            " received",
            " low",
            "-frequency",
            " stimulation",
            " (",
            "b",
            "1",
            ")",
            " and",
            " in",
            " a",
            " control"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.42,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " chance",
            " to",
            " have",
            " fun",
            " with",
            " me",
            " as",
            " well",
            "âĢ¦”",
            " I",
            " grinned",
            " and",
            " told",
            " Spike",
            " to",
            " stay",
            ",",
            " which",
            " he",
            " did",
            ",",
            " content",
            " (",
            "and",
            " full",
            " of",
            " man",
            " sp",
            "unk",
            ")",
            " to",
            " wait",
            " until",
            " I",
            " called",
            " again",
            ".",
            " The",
            " two",
            " of",
            " us",
            " headed",
            " into",
            " Rick",
            "’s",
            " bedroom",
            " and",
            ",",
            " after",
            " collecting",
            " a",
            " rubber",
            " and",
            " some",
            " l",
            "ube",
            " from",
            " a",
            " handy",
            " side",
            " table",
            " drawer",
            ",",
            " Rick",
            " was",
            " on",
            " his",
            " back",
            ",",
            " his",
            " ankles",
            " resting",
            " on",
            " my",
            " shoulders",
            " and",
            " my",
            " rubber",
            "ized",
            " cock",
            " ready",
            " to",
            " enter",
            " his",
            " puls",
            "ating",
            " hole",
            "!\n\n",
            "I",
            " slowly",
            " entered",
            " him",
            ",",
            " his",
            " mo",
            "ans",
            " deep",
            "ening",
            " to",
            " gro",
            "ans",
            " as",
            " I",
            " spread",
            " his",
            " legs",
            " wider",
            " to",
            " get",
            " better",
            " depth",
            " and",
            ",",
            " when",
            " I",
            " hit",
            " his",
            " joy",
            " button",
            ",",
            " his",
            " cock",
            " le",
            "apt",
            " up",
            " like",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.389,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " D",
            "-d",
            "imer",
            " level",
            " within",
            " ",
            "24",
            " h",
            " after",
            " symptom",
            " onset",
            " might",
            " be",
            " helpful",
            " for",
            " different",
            "iating",
            " patients",
            " with",
            " suspected",
            " A",
            "AD",
            " from",
            " other",
            " causes",
            " of",
            " chest",
            " pain",
            ".\n\n",
            "The",
            " first",
            " two",
            " authors",
            " contributed",
            " equally",
            " to",
            " this",
            " study",
            ".\n\n",
            "We",
            " wish",
            " to",
            " thank",
            " the",
            " patients",
            " for",
            " their",
            " particip",
            "ations",
            " in",
            " our",
            " study",
            ",",
            " and",
            " we",
            " are",
            " also",
            " grateful",
            " to",
            " other",
            " clinical",
            " doctors",
            " and",
            " nurses",
            " for",
            " their",
            " help",
            " in",
            " the",
            " study",
            ".",
            " This",
            " work",
            " was",
            " supported",
            " by",
            " a",
            " grant",
            " (",
            "811",
            "702",
            "86",
            ")",
            " from",
            " the",
            " National",
            " Natural",
            " Science",
            " Foundation",
            " of",
            " China",
            " to",
            " Dr",
            ".",
            " Fan",
            " Xia",
            "ohan",
            ".\n\n",
            "Conflict",
            " of",
            " interest",
            "\n",
            "================",
            "====",
            "\n\n",
            "The",
            " authors",
            " declare",
            " no",
            " conflict",
            " of",
            " interest",
            ".\n",
            "<|begin_of_text|>",
            "---\n",
            "abstract",
            ":",
            " '",
            "In",
            " state",
            " space",
            " models",
            ",",
            " smoothing",
            " refers",
            " to",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.044,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.057,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.03,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.017,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.373,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " \\",
            "theta",
            "}",
            "^{",
            "(",
            "u",
            ")},",
            " \\",
            ",",
            " u",
            "\\",
            "in",
            " \\",
            "T",
            "_",
            "1",
            ")$",
            " are",
            " independent",
            " of",
            " $(",
            "A",
            "(u",
            "),",
            " \\",
            ",",
            " u",
            "\\",
            "in",
            " \\",
            "T",
            "_",
            "1",
            ")$",
            " and",
            " are",
            " such",
            " that",
            " $\\",
            "e",
            "[\\",
            "Delta",
            "_{",
            "j",
            "-",
            "2",
            ",",
            " \\",
            "theta",
            "}",
            "^{",
            "(",
            "u",
            ")}",
            "]",
            " \\",
            "le",
            " c",
            "_{",
            "40",
            "}\\",
            ",",
            " (\\",
            "E",
            " Z",
            "_{",
            "j",
            "-",
            "2",
            ",",
            " \\",
            "theta",
            "})",
            "^",
            "{\\",
            "k",
            "appa",
            "-",
            "1",
            "-\\",
            "v",
            "are",
            "psilon",
            "}$",
            ".\n\n",
            "By",
            " induction",
            ",",
            " we",
            " arrive",
            " at",
            ":",
            " for",
            " $",
            "j",
            ">m",
            " \\",
            "ge",
            " ",
            "1",
            "$,",
            " $$",
            "Y",
            "_{",
            "j",
            ",",
            " \\",
            "theta",
            "}",
            " \\",
            ";",
            " {\\",
            "build",
            "rel",
            " st",
            ".",
            " \\",
            "over",
            " \\",
            "ge",
            "}\\",
            ";\n",
            "   ",
            " \\",
            "sum",
            "_{",
            "x"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.004,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.338,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " String",
            "\n",
            "   ",
            " let",
            " carbs",
            ":",
            " Int",
            "\n",
            "}\n\n",
            "struct",
            " Category",
            " {\n",
            "   ",
            " let",
            " name",
            ":",
            " String",
            "\n",
            "   ",
            " let",
            " items",
            ":",
            " [",
            "Item",
            "]\n",
            "}\n\n",
            "struct",
            " Restaurant",
            " {\n",
            "   ",
            " let",
            " name",
            ":",
            " String",
            "\n",
            "   ",
            " let",
            " categories",
            ":",
            " [",
            "Category",
            "]\n\n",
            "}\n\n",
            "A",
            ":\n\n",
            "In",
            " this",
            " line",
            "\n",
            "let",
            " menu",
            "Array",
            " =",
            " [",
            "a",
            "_w",
            "]\n\n",
            "you",
            " are",
            " creating",
            " a",
            " local",
            " variable",
            " menu",
            "Array",
            " which",
            " is",
            " different",
            " from",
            " the",
            " property",
            " with",
            " the",
            " same",
            " name",
            " representing",
            " the",
            " data",
            " source",
            " array",
            ".\n",
            "O",
            "mit",
            " let",
            "\n",
            "menu",
            "Array",
            " =",
            " [",
            "a",
            "_w",
            "]\n\n",
            "PS",
            ":",
            " Please",
            " use",
            " more",
            " descriptive",
            " variable",
            " names",
            " than",
            " a",
            "_w",
            ".\n\n",
            "<|begin_of_text|>",
            "Q",
            ":\n\n",
            "How",
            " to",
            " Compile",
            " and",
            " Debug",
            " C",
            "++",
            " in",
            " Not",
            "epad",
            "++",
            " using",
            " Turbo",
            " C",
            "++",
            " Compiler",
            "\n\n",
            "I",
            " have",
            " installed"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.262,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.283,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            " He",
            " progressed",
            " to",
            " becoming",
            " the",
            " organisations",
            " chairman",
            ",",
            " and",
            " then",
            " in",
            " ",
            "191",
            "1",
            " he",
            " joined",
            " the",
            " Council",
            " of",
            " the",
            " L",
            "TA",
            ".",
            " In",
            " ",
            "193",
            "3",
            " he",
            " became",
            " chairman",
            " of",
            " the",
            " L",
            "TA",
            " and",
            " the",
            " year",
            " later",
            " its",
            " vice",
            "-president",
            ".\n\n",
            "References",
            "\n\n",
            "B",
            "ibli",
            "ography",
            "\n \n",
            " \n\n",
            "Category",
            ":",
            "187",
            "1",
            " births",
            "\n",
            "Category",
            ":",
            "195",
            "4",
            " deaths",
            "\n",
            "Category",
            ":",
            "R",
            "ug",
            "by",
            " union",
            " forwards",
            "\n",
            "Category",
            ":",
            "English",
            " rugby",
            " union",
            " players",
            "\n",
            "Category",
            ":",
            "England",
            " international",
            " rugby",
            " union",
            " players",
            "\n",
            "Category",
            ":",
            "Bar",
            "bar",
            "ian",
            " F",
            ".C",
            ".",
            " players",
            "\n",
            "Category",
            ":",
            "Black",
            "he",
            "ath",
            " F",
            ".C",
            ".",
            " players",
            "\n",
            "Category",
            ":",
            "Sports",
            "people",
            " from",
            " Hart",
            "le",
            "pool",
            "\n",
            "Category",
            ":",
            "Officers",
            " of",
            " the",
            " Order",
            " of",
            " the",
            " British",
            " Empire",
            "\n",
            "Category",
            ":"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.12,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "x",
            "_{",
            "i",
            "})",
            "\\",
            "rho",
            "_{",
            "i",
            "}\\",
            "rho",
            "_{",
            "i",
            "}",
            "^",
            "{\\",
            "prime",
            "\n",
            "}\\",
            "lambda",
            "_{",
            "0",
            "}(",
            "x",
            "_{",
            "i",
            "})",
            "^",
            "{\\",
            "prime",
            "}]",
            "WM",
            "(M",
            "^",
            "{\\",
            "prime",
            "}",
            "WM",
            ")^",
            "{-",
            "1",
            "}",
            "=(",
            "E",
            "[m",
            "_{",
            "i",
            "}",
            "m",
            "_{",
            "i",
            "}",
            "^",
            "{\\",
            "ast",
            "\\",
            "prime",
            "\n",
            "}",
            "])",
            "^{-",
            "1",
            "}",
            "E",
            "[m",
            "_{",
            "i",
            "}",
            "m",
            "_{",
            "i",
            "}",
            "^",
            "{\\",
            "prime",
            "}",
            "](",
            "E",
            "[m",
            "_{",
            "i",
            "}",
            "m",
            "_{",
            "i",
            "}",
            "^",
            "{\\",
            "ast",
            "}",
            "])",
            "^{-",
            "1",
            "\\",
            "prime",
            "}",
            ".$$",
            " The",
            " fact",
            " that",
            " this",
            " matrix",
            " is",
            " minimized",
            " in",
            " the",
            " positive",
            " sem",
            "ide",
            "finite",
            " sense",
            " for",
            " $",
            "m",
            "_{",
            "i",
            "}=",
            "m",
            "_{",
            "i",
            "}",
            "^",
            "{\\",
            "ast",
            "}$",
            " is",
            " well",
            " known"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.18,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.247,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " Minneapolis",
            ",",
            " MN",
            "),",
            " and",
            " Ac",
            "uity",
            " X",
            "4",
            " (",
            "Boston",
            " Scientific",
            ",",
            " Marl",
            "borough",
            ",",
            " MA",
            ").",
            " The",
            " choice",
            " of",
            " vector",
            " was",
            " made",
            " at",
            " implant",
            "ation",
            " and",
            " was",
            " made",
            " on",
            " the",
            " basis",
            " of",
            " presence",
            " or",
            " absence",
            " of",
            " P",
            "NS",
            ".\n\n",
            "Follow",
            "âĢĲ",
            "Up",
            " {",
            "#",
            "jah",
            "325",
            "87",
            "-",
            "sec",
            "-",
            "001",
            "1",
            "}\n",
            "---------\n\n",
            "Patients",
            " were",
            " followed",
            " up",
            " in",
            " dedicated",
            " device",
            " therapy",
            " clinics",
            ".",
            " Before",
            " ",
            "201",
            "3",
            ",",
            " patients",
            " underwent",
            " systematic",
            " ech",
            "oc",
            "ardi",
            "ographic",
            " optimization",
            ".",
            " To",
            " this",
            " end",
            ",",
            " patients",
            " in",
            " sinus",
            " rhythm",
            " underwent",
            " transmit",
            "ral",
            " Dop",
            "pler",
            "âĢĲ",
            "direct",
            "ed",
            " optimization",
            " of",
            " atr",
            "io",
            "vent",
            "ricular",
            " delay",
            " using",
            " an",
            " iterative",
            " technique",
            " before",
            " discharge",
            " and",
            " at",
            " every",
            " scheduled",
            " visit",
            " thereafter",
            ".",
            " In",
            " patients",
            " with",
            " sinus",
            " rhythm",
            ",",
            " atr",
            "ial",
            " pacing",
            " was"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.245,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.231,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ":m",
            "}$",
            " requires",
            " two",
            " draws",
            " from",
            " $\\",
            "pi",
            "_",
            "0",
            "$,",
            " here",
            " taken",
            " as",
            " the",
            " distribution",
            " of",
            " a",
            " trajectory",
            " selected",
            " from",
            " a",
            " particle",
            " filter",
            " with",
            " $",
            "N",
            "$",
            " particles",
            ".",
            " Then",
            ",",
            " the",
            " estimator",
            " as",
            " described",
            " in",
            " Algorithm",
            " \\",
            "[",
            "alg",
            ":r",
            "he",
            "eg",
            "ly",
            "nn",
            "sm",
            "o",
            "other",
            "\\",
            "]",
            " requires",
            " a",
            " draw",
            " from",
            " the",
            " CPF",
            " kernel",
            ",",
            " $\\",
            "tau",
            "-",
            "1",
            "$",
            " draws",
            " from",
            " the",
            " C",
            "CPF",
            " kernel",
            ",",
            " and",
            " finally",
            " $",
            "m",
            "-\\",
            "tau",
            "$",
            " draws",
            " of",
            " the",
            " CPF",
            " kernel",
            " on",
            " the",
            " events",
            " $\\",
            "{",
            "m",
            ">\\",
            "tau",
            "\\",
            "}",
            "$.",
            " The",
            " cost",
            " of",
            " a",
            " particle",
            " filter",
            " and",
            " of",
            " an",
            " iteration",
            " of",
            " CPF",
            " is",
            " usually",
            " dominated",
            " by",
            " the",
            " propagation",
            " of",
            " $",
            "N",
            "$",
            " particles",
            " and",
            " the",
            " evaluation",
            " of",
            " their",
            " weights",
            ".",
            " The",
            " cost",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.216,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " ct",
            "os",
            ":",
            " ch",
            "acha",
            "20",
            "-p",
            "oly",
            "130",
            "5",
            "@",
            "opens",
            "sh",
            ".com",
            ",a",
            "es",
            "128",
            "-",
            "ctr",
            ",a",
            "es",
            "192",
            "-",
            "ctr",
            ",a",
            "es",
            "256",
            "-",
            "ctr",
            ",a",
            "es",
            "128",
            "-g",
            "cm",
            "@",
            "opens",
            "sh",
            ".com",
            ",a",
            "es",
            "256",
            "-g",
            "cm",
            "@",
            "opens",
            "sh",
            ".com",
            ",a",
            "es",
            "128",
            "-c",
            "bc",
            ",a",
            "es",
            "192",
            "-c",
            "bc",
            ",a",
            "es",
            "256",
            "-c",
            "bc",
            "\n",
            "debug",
            "2",
            ":",
            " c",
            "iphers",
            " st",
            "oc",
            ":",
            " ch",
            "acha",
            "20",
            "-p",
            "oly",
            "130",
            "5",
            "@",
            "opens",
            "sh",
            ".com",
            ",a",
            "es",
            "128",
            "-",
            "ctr",
            ",a",
            "es",
            "192",
            "-",
            "ctr",
            ",a",
            "es",
            "256",
            "-",
            "ctr",
            ",a",
            "es",
            "128",
            "-g",
            "cm",
            "@",
            "opens",
            "sh",
            ".com",
            ",a",
            "es",
            "256",
            "-g",
            "cm",
            "@",
            "opens",
            "sh",
            ".com",
            ",a",
            "es",
            "128",
            "-c",
            "bc",
            ",a",
            "es",
            "192",
            "-c",
            "bc",
            ",a",
            "es"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.165,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.159,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " attempted",
            " to",
            " pay",
            " tribute",
            " by",
            " singing",
            " the",
            " most",
            " devastating",
            " song",
            " in",
            " her",
            " god",
            "m",
            "um",
            "’s",
            " catalogue",
            " –",
            " “",
            "Love",
            " Is",
            " a",
            " Losing",
            " Game",
            "”",
            " –",
            " at",
            " The",
            " Big",
            " Chill",
            " on",
            " Saturday",
            " (",
            "August",
            " ",
            "6",
            "),",
            " well",
            ",",
            " she",
            " could",
            " barely",
            " sing",
            " for",
            " crying",
            ".",
            " And",
            " you",
            " can",
            " imagine",
            " what",
            " kind",
            " of",
            " effect",
            " that",
            " had",
            " on",
            " her",
            " audience",
            "âĢ¦",
            " (",
            "via",
            " Marie",
            " Claire",
            " UK",
            ")\n\n",
            "âĢ¢",
            " Ever",
            " the",
            " gentleman",
            ",",
            " Simon",
            " Cow",
            "ell",
            " is",
            " now",
            " attempting",
            " to",
            " fall",
            " on",
            " his",
            " sword",
            ",",
            " saying",
            " he",
            " probably",
            " shouldn",
            "’t",
            " have",
            " sacked",
            " Cheryl",
            " Cole",
            ",",
            " or",
            " try",
            " to",
            " move",
            " her",
            " back",
            " across",
            " to",
            " the",
            " UK",
            " version",
            " of",
            " The",
            " X",
            " Factor",
            ",",
            " but",
            " he",
            "’s",
            " sure",
            " their",
            " friendship",
            " will",
            " survive",
            ".",
            " (",
            "via",
            " Evening",
            " Echo",
            ")\n\n",
            "âĢ¢",
            " But",
            " should"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.102,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " a",
            " while",
            " ago",
            ",",
            " I",
            " tried",
            " to",
            " create",
            " a",
            " Flight",
            " Simulator",
            " X",
            " model",
            " for",
            " an",
            " aircraft",
            " that",
            " I",
            " wanted",
            " a",
            " model",
            " of",
            ",",
            " but",
            " was",
            " soon",
            " overwhelmed",
            " by",
            " having",
            " to",
            " guess",
            " so",
            " much",
            " of",
            " the",
            " flight",
            " dynamics",
            ".",
            " Is",
            " there",
            " somewhere",
            " where",
            " I",
            " could",
            " get",
            " detailed",
            " information",
            " about",
            " the",
            " flight",
            " dynamics",
            " of",
            " aircraft",
            " without",
            " contacting",
            " the",
            " manufacturer",
            ",",
            " a",
            " pilot",
            ",",
            " or",
            " having",
            " the",
            " plane",
            " itself",
            " to",
            " run",
            " tests",
            " on",
            "?",
            " I",
            " mean",
            " for",
            " things",
            " like",
            " drag",
            " at",
            " different",
            " mach",
            ",",
            " drag",
            " coefficient",
            " created",
            " by",
            " the",
            " landing",
            " gear",
            ",",
            " lift",
            " coefficient",
            " created",
            " by",
            " the",
            " fl",
            "aps",
            ",",
            " detailed",
            " stuff",
            " about",
            " the",
            " engines",
            ",",
            " etc",
            ".\n\n",
            "A",
            ":\n\n",
            "Unfortunately",
            " I",
            " have",
            " no",
            " experience",
            " with",
            " how",
            " FS",
            "X",
            " models",
            " aircraft",
            ",",
            " but",
            " at",
            " a",
            " guess",
            ",",
            " it",
            "'s"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "ated",
            " damages",
            " bears",
            " no",
            " reasonable",
            " relationship",
            " to",
            " the",
            " actual",
            " damage",
            " or",
            " is",
            " so",
            " gross",
            "ly",
            " excessive",
            " as",
            " to",
            " be",
            " entirely",
            " disproportionate",
            " to",
            " any",
            " possible",
            " loss",
            " that",
            " might",
            " have",
            " been",
            " contemplated",
            " that",
            " it",
            " shocks",
            " the",
            " conscience",
            ",",
            " the",
            " stip",
            "ulation",
            " will",
            " not",
            " be",
            " enforced",
            ".\n",
            "War",
            "ner",
            " v",
            ".",
            " R",
            "asm",
            "ussen",
            ",",
            " ",
            "704",
            " P",
            ".",
            "2",
            "d",
            " ",
            "559",
            ",",
            " ",
            "561",
            " (",
            "Ut",
            "ah",
            " ",
            "198",
            "5",
            ")",
            " (",
            "c",
            "itations",
            " omitted",
            ").\n",
            "In",
            " support",
            " of",
            " their",
            " contention",
            " that",
            " the",
            " liquid",
            "ated",
            " damages",
            " are",
            " not",
            " excessive",
            " compared",
            " to",
            " actual",
            " damages",
            ",",
            " the",
            " sellers",
            " assert",
            " that",
            " they",
            " offered",
            " evidence",
            " of",
            " actual",
            " damages",
            " in",
            " excess",
            " of",
            " $",
            "15",
            ",",
            "000",
            ".",
            " However",
            ",",
            " the",
            " trial",
            " court",
            " disagreed",
            " and",
            " found",
            " the",
            " amount",
            " of",
            " liquid",
            "ated",
            " damages",
            " excessive",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            "}(",
            "g",
            ")$",
            " and",
            " ${",
            "\\",
            "cal",
            " T",
            "}'",
            "_",
            "m",
            " {\\",
            "til",
            "de",
            " \\",
            "gamma",
            "}_{",
            "\\",
            "rm",
            " hop",
            "f",
            "}(",
            "g",
            ")$",
            " calculated",
            " according",
            " to",
            " Eq",
            ".",
            "Âł",
            "(\\",
            "[",
            "Ca",
            "Fi",
            "Trans",
            "\\",
            "]),",
            " i",
            ".e",
            ".",
            "Âł",
            "by",
            " the",
            " un",
            "modified",
            " conform",
            "al",
            " mapping",
            ",",
            " typically",
            " exhibit",
            " apparent",
            " convergence",
            " to",
            " ",
            "5",
            "–",
            "6",
            " significant",
            " figures",
            " in",
            " the",
            " transformation",
            " order",
            " $",
            "m",
            "=",
            "28",
            ",",
            "~",
            "29",
            ",",
            "~",
            "30",
            "$",
            " and",
            " at",
            " large",
            " coupling",
            " $",
            "g",
            " \\",
            "ge",
            "q",
            " ",
            "5",
            "$.",
            " Specifically",
            ",",
            " the",
            " numerical",
            " values",
            " for",
            " $",
            "g",
            "=",
            "5",
            ".",
            "0",
            "$",
            " are",
            " $$",
            "\\",
            "begin",
            "{",
            "aligned",
            "}\n",
            "{\\",
            "cal",
            " T",
            "}'",
            "_{",
            "28",
            "}",
            " \\",
            "gamma",
            "_{",
            "\\",
            "rm",
            " hop",
            "f",
            "}(",
            "g",
            " =",
            " ",
            "5",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": -1,
          "is_repeated_datapoint": false,
          "tokens": [
            " finish",
            ".",
            " I",
            " added",
            " m",
            "ott",
            "ling",
            " and",
            " small",
            " dots",
            " to",
            " some",
            " areas",
            " of",
            " the",
            " wings",
            " to",
            " add",
            " interest",
            ".\n\n",
            "The",
            " shoulder",
            " pads",
            " were",
            " from",
            " an",
            " unknown",
            " soft",
            " plastic",
            " kit",
            " (",
            "perhaps",
            " an",
            " action",
            " figure",
            "!",
            "?!",
            "),",
            " and",
            " their",
            " positioning",
            " did",
            " conflict",
            " with",
            " the",
            " wings",
            " a",
            " little",
            ".",
            " I",
            " used",
            " Citadel",
            " metallic",
            "s",
            " and",
            " wash",
            "es",
            ",",
            " then",
            " highlighted",
            " up",
            " so",
            " that",
            " the",
            " gold",
            "/",
            "br",
            "ass",
            " work",
            " really",
            " screams",
            ".\n\n",
            "More",
            " m",
            "ott",
            "ling",
            " was",
            " done",
            " on",
            " the",
            " back",
            ",",
            " around",
            " the",
            " sp",
            "ines",
            " and",
            " hair",
            ".\n\n",
            "This",
            " model",
            " also",
            " had",
            " a",
            " lot",
            " of",
            " skulls",
            "!",
            " This",
            " photo",
            " shows",
            " the",
            " skulls",
            " around",
            " the",
            " belt",
            " and",
            " groin",
            ".\n\n",
            "The",
            " sword",
            " was",
            " my",
            " client",
            "'s",
            " idea",
            ".",
            " I",
            " envis",
            "age",
            " that",
            " maybe",
            " it",
            " was",
            " once",
            " a",
            " noble"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "mini",
    "ethyst",
    "phalt",
    "sm",
    "ph"
  ],
  "bottom_logits": [
    "WithValue",
    "âĶĶ",
    "@s",
    "Ã¨o",
    " Ortiz"
  ],
  "act_min": -0.0,
  "act_max": 0.715
}

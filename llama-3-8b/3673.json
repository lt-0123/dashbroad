{
  "index": 3673,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.543,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.715,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 38,
          "is_repeated_datapoint": false,
          "tokens": [
            " at",
            " the",
            " Royal",
            " College",
            " of",
            " Physicians",
            ".\n\n",
            "Late",
            " modern",
            " \n\n",
            "In",
            " the",
            " United",
            " States",
            ",",
            " medical",
            " schools",
            " began",
            " to",
            " be",
            " set",
            " up",
            " towards",
            " the",
            " end",
            " of",
            " the",
            " ",
            "18",
            "th",
            " century",
            ".",
            " Classes",
            " in",
            " anatomy",
            " needed",
            " a",
            " continual",
            " stream",
            " of",
            " cad",
            "avers",
            " for",
            " dis",
            "section",
            " and",
            " these",
            " were",
            " difficult",
            " to",
            " obtain",
            ".",
            " Philadelphia",
            ",",
            " Baltimore",
            " and",
            " New",
            " York",
            " were",
            " all",
            " renowned",
            " for",
            " body",
            " sn",
            "atching",
            " activity",
            " as",
            " criminals",
            " raided",
            " grave",
            "yards",
            " at",
            " night",
            ",",
            " removing",
            " newly",
            " buried",
            " corpses",
            " from",
            " their",
            " coff",
            "ins",
            ".",
            " A",
            " similar",
            " problem",
            " existed",
            " in",
            " Britain",
            " where",
            " demand",
            " for",
            " bodies",
            " became",
            " so",
            " great",
            " that",
            " grave",
            "-ra",
            "iding",
            " and",
            " even",
            " anatomy",
            " murder",
            " were",
            " pract",
            "ised",
            " to",
            " obtain",
            " cad",
            "avers",
            ".",
            " Some",
            " grave",
            "yards",
            " were",
            " in",
            " consequence",
            " protected",
            " with",
            " watch",
            "t",
            "owers",
            ".",
            " The",
            " practice",
            " was"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.691,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 122,
          "is_repeated_datapoint": false,
          "tokens": [
            " a",
            " total",
            " death",
            " toll",
            " of",
            " ",
            "850",
            ",",
            "000",
            " soldiers",
            ".",
            " While",
            " Walker",
            "'s",
            " estimates",
            " were",
            " originally",
            " dismissed",
            " because",
            " of",
            " the",
            " ",
            "187",
            "0",
            " census",
            "'s",
            " under",
            "count",
            "ing",
            ",",
            " it",
            " was",
            " later",
            " found",
            " that",
            " the",
            " census",
            " was",
            " only",
            " off",
            " by",
            " ",
            "6",
            ".",
            "5",
            "%",
            " and",
            " that",
            " the",
            " data",
            " Walker",
            " used",
            " would",
            " be",
            " roughly",
            " accurate",
            ".\n\n",
            "Analy",
            "zing",
            " the",
            " number",
            " of",
            " dead",
            " by",
            " using",
            " census",
            " data",
            " to",
            " calculate",
            " the",
            " deviation",
            " of",
            " the",
            " death",
            " rate",
            " of",
            " men",
            " of",
            " fighting",
            " age",
            " from",
            " the",
            " norm",
            " suggests",
            " that",
            " at",
            " least",
            " ",
            "627",
            ",",
            "000",
            " and",
            " at",
            " most",
            " ",
            "888",
            ",",
            "000",
            ",",
            " but",
            " most",
            " likely",
            " ",
            "761",
            ",",
            "000",
            " soldiers",
            ",",
            " died",
            " in",
            " the",
            " war",
            ".",
            " This",
            " would",
            " break",
            " down",
            " to",
            " approximately",
            " ",
            "350",
            ",",
            "000",
            " Confederate",
            " and",
            " ",
            "411"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.691,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 122,
          "is_repeated_datapoint": false,
          "tokens": [
            " a",
            " total",
            " death",
            " toll",
            " of",
            " ",
            "850",
            ",",
            "000",
            " soldiers",
            ".",
            " While",
            " Walker",
            "'s",
            " estimates",
            " were",
            " originally",
            " dismissed",
            " because",
            " of",
            " the",
            " ",
            "187",
            "0",
            " census",
            "'s",
            " under",
            "count",
            "ing",
            ",",
            " it",
            " was",
            " later",
            " found",
            " that",
            " the",
            " census",
            " was",
            " only",
            " off",
            " by",
            " ",
            "6",
            ".",
            "5",
            "%",
            " and",
            " that",
            " the",
            " data",
            " Walker",
            " used",
            " would",
            " be",
            " roughly",
            " accurate",
            ".\n\n",
            "Analy",
            "zing",
            " the",
            " number",
            " of",
            " dead",
            " by",
            " using",
            " census",
            " data",
            " to",
            " calculate",
            " the",
            " deviation",
            " of",
            " the",
            " death",
            " rate",
            " of",
            " men",
            " of",
            " fighting",
            " age",
            " from",
            " the",
            " norm",
            " suggests",
            " that",
            " at",
            " least",
            " ",
            "627",
            ",",
            "000",
            " and",
            " at",
            " most",
            " ",
            "888",
            ",",
            "000",
            ",",
            " but",
            " most",
            " likely",
            " ",
            "761",
            ",",
            "000",
            " soldiers",
            ",",
            " died",
            " in",
            " the",
            " war",
            ".",
            " This",
            " would",
            " break",
            " down",
            " to",
            " approximately",
            " ",
            "350",
            ",",
            "000",
            " Confederate",
            " and",
            " ",
            "411"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.68,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0
          ],
          "train_token_ind": 125,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            " Voll",
            "mann",
            "\n\n",
            "Music",
            "\n\n",
            "Groups",
            "\n",
            " Atlas",
            " (",
            "band",
            "),",
            " a",
            " New",
            " Zealand",
            " rock",
            " band",
            "\n",
            " Atlas",
            " Sound",
            ",",
            " the",
            " solo",
            " musical",
            " project",
            " of",
            " Deer",
            "hunter",
            " lead",
            " singer",
            " and",
            " guitarist",
            " Bradford",
            " Cox",
            "\n\n",
            "Mus",
            "icians",
            "\n",
            " Black",
            " At",
            "lass",
            ",",
            " a",
            " Canadian",
            " musician",
            "\n\n",
            "Album",
            "s",
            "\n",
            " Atlas",
            " (",
            "K",
            "inky",
            " album",
            ")\n",
            " Atlas",
            " (",
            "La",
            "ure",
            "l",
            " Halo",
            " album",
            ")\n",
            " Atlas",
            " (",
            "Park",
            "way",
            " Drive",
            " album",
            ")\n",
            " Atlas",
            " (",
            "Real",
            " Estate",
            " album",
            ")\n",
            " Atlas",
            " (",
            "R",
            "Ãľ",
            "F",
            "Ãľ",
            "S",
            " album",
            ")\n",
            " Atlas",
            ",",
            " by",
            " The",
            " Score",
            ",",
            " ",
            "201",
            "7",
            "\n\n",
            "Oper",
            "as",
            "\n",
            " Atlas",
            " (",
            "op",
            "era",
            "),",
            " ",
            "199",
            "1",
            ",",
            " by",
            " Meredith",
            " Monk",
            "\n",
            "Atlas",
            ":",
            " An",
            " Opera",
            " in",
            " Three",
            " Parts",
            ",",
            " a",
            " ",
            "199",
            "3",
            " recording",
            " of",
            " Monk",
            "'s"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.668,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 91,
          "is_repeated_datapoint": false,
          "tokens": [
            " means",
            "\n",
            " Sample",
            " mean",
            " and",
            " covariance",
            "\n",
            " Standard",
            " deviation",
            "\n",
            " Standard",
            " error",
            " of",
            " the",
            " mean",
            "\n",
            " Summary",
            " statistics",
            "\n\n",
            "Notes",
            "\n\n",
            "References",
            "\n\n",
            "Further",
            " reading",
            "\n\n",
            "External",
            " links",
            "\n",
            "Calcul",
            "ations",
            " and",
            " comparisons",
            " between",
            " arithmetic",
            " mean",
            " and",
            " geometric",
            " mean",
            " of",
            " two",
            " numbers",
            "\n",
            "Calculate",
            " the",
            " arithmetic",
            " mean",
            " of",
            " a",
            " series",
            " of",
            " numbers",
            " on",
            " fx",
            "Solver",
            "\n\n",
            "Means",
            "<|begin_of_text|>",
            "The",
            " American",
            " Football",
            " Conference",
            " (",
            "A",
            "FC",
            ")",
            " is",
            " one",
            " of",
            " the",
            " two",
            " conferences",
            " of",
            " the",
            " National",
            " Football",
            " League",
            " (",
            "NFL",
            "),",
            " the",
            " highest",
            " professional",
            " level",
            " of",
            " American",
            " football",
            " in",
            " the",
            " United",
            " States",
            ".",
            " The",
            " AFC",
            " and",
            " its",
            " counterpart",
            ",",
            " the",
            " National",
            " Football",
            " Conference",
            " (",
            "N",
            "FC",
            "),",
            " each",
            " contain",
            " ",
            "16",
            " teams",
            " with",
            " ",
            "4",
            " divisions",
            ".",
            " Both",
            " conferences",
            " were",
            " created",
            " as",
            " part",
            " of",
            " the",
            " ",
            "197",
            "0"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.68,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0
          ],
          "train_token_ind": 125,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            " Voll",
            "mann",
            "\n\n",
            "Music",
            "\n\n",
            "Groups",
            "\n",
            " Atlas",
            " (",
            "band",
            "),",
            " a",
            " New",
            " Zealand",
            " rock",
            " band",
            "\n",
            " Atlas",
            " Sound",
            ",",
            " the",
            " solo",
            " musical",
            " project",
            " of",
            " Deer",
            "hunter",
            " lead",
            " singer",
            " and",
            " guitarist",
            " Bradford",
            " Cox",
            "\n\n",
            "Mus",
            "icians",
            "\n",
            " Black",
            " At",
            "lass",
            ",",
            " a",
            " Canadian",
            " musician",
            "\n\n",
            "Album",
            "s",
            "\n",
            " Atlas",
            " (",
            "K",
            "inky",
            " album",
            ")\n",
            " Atlas",
            " (",
            "La",
            "ure",
            "l",
            " Halo",
            " album",
            ")\n",
            " Atlas",
            " (",
            "Park",
            "way",
            " Drive",
            " album",
            ")\n",
            " Atlas",
            " (",
            "Real",
            " Estate",
            " album",
            ")\n",
            " Atlas",
            " (",
            "R",
            "Ãľ",
            "F",
            "Ãľ",
            "S",
            " album",
            ")\n",
            " Atlas",
            ",",
            " by",
            " The",
            " Score",
            ",",
            " ",
            "201",
            "7",
            "\n\n",
            "Oper",
            "as",
            "\n",
            " Atlas",
            " (",
            "op",
            "era",
            "),",
            " ",
            "199",
            "1",
            ",",
            " by",
            " Meredith",
            " Monk",
            "\n",
            "Atlas",
            ":",
            " An",
            " Opera",
            " in",
            " Three",
            " Parts",
            ",",
            " a",
            " ",
            "199",
            "3",
            " recording",
            " of",
            " Monk",
            "'s"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.668,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.688,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 91,
          "is_repeated_datapoint": false,
          "tokens": [
            " means",
            "\n",
            " Sample",
            " mean",
            " and",
            " covariance",
            "\n",
            " Standard",
            " deviation",
            "\n",
            " Standard",
            " error",
            " of",
            " the",
            " mean",
            "\n",
            " Summary",
            " statistics",
            "\n\n",
            "Notes",
            "\n\n",
            "References",
            "\n\n",
            "Further",
            " reading",
            "\n\n",
            "External",
            " links",
            "\n",
            "Calcul",
            "ations",
            " and",
            " comparisons",
            " between",
            " arithmetic",
            " mean",
            " and",
            " geometric",
            " mean",
            " of",
            " two",
            " numbers",
            "\n",
            "Calculate",
            " the",
            " arithmetic",
            " mean",
            " of",
            " a",
            " series",
            " of",
            " numbers",
            " on",
            " fx",
            "Solver",
            "\n\n",
            "Means",
            "<|begin_of_text|>",
            "The",
            " American",
            " Football",
            " Conference",
            " (",
            "A",
            "FC",
            ")",
            " is",
            " one",
            " of",
            " the",
            " two",
            " conferences",
            " of",
            " the",
            " National",
            " Football",
            " League",
            " (",
            "NFL",
            "),",
            " the",
            " highest",
            " professional",
            " level",
            " of",
            " American",
            " football",
            " in",
            " the",
            " United",
            " States",
            ".",
            " The",
            " AFC",
            " and",
            " its",
            " counterpart",
            ",",
            " the",
            " National",
            " Football",
            " Conference",
            " (",
            "N",
            "FC",
            "),",
            " each",
            " contain",
            " ",
            "16",
            " teams",
            " with",
            " ",
            "4",
            " divisions",
            ".",
            " Both",
            " conferences",
            " were",
            " created",
            " as",
            " part",
            " of",
            " the",
            " ",
            "197",
            "0"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.684,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 49,
          "is_repeated_datapoint": false,
          "tokens": [
            " opposition",
            " groups",
            " which",
            " were",
            " won",
            " by",
            " President",
            " Abdel",
            "az",
            "iz",
            " Bout",
            "ef",
            "li",
            "ka",
            ".",
            " He",
            " worked",
            " to",
            " restore",
            " political",
            " stability",
            " to",
            " the",
            " country",
            " and",
            " announced",
            " a",
            " \"",
            "Civil",
            " Concord",
            "\"",
            " initiative",
            ",",
            " approved",
            " in",
            " a",
            " referendum",
            ",",
            " under",
            " which",
            " many",
            " political",
            " prisoners",
            " were",
            " pard",
            "oned",
            ",",
            " and",
            " several",
            " thousand",
            " members",
            " of",
            " armed",
            " groups",
            " were",
            " granted",
            " exemption",
            " from",
            " prosecution",
            " under",
            " a",
            " limited",
            " amnesty",
            ",",
            " in",
            " force",
            " until",
            " ",
            "13",
            " January",
            " ",
            "200",
            "0",
            ".",
            " The",
            " AIS",
            " disb",
            "anded",
            " and",
            " levels",
            " of",
            " insurg",
            "ent",
            " violence",
            " fell",
            " rapidly",
            ".",
            " The",
            " G",
            "roupe",
            " Sal",
            "af",
            "iste",
            " pour",
            " la",
            " Pr",
            "Ã©d",
            "ication",
            " et",
            " le",
            " Combat",
            " (",
            "G",
            "SP",
            "C",
            "),",
            " a",
            " spl",
            "inter",
            " group",
            " of",
            " the",
            " Armed",
            " Islamic",
            " Group",
            ",",
            " continued",
            " a",
            " terrorist",
            " campaign",
            " against",
            " the",
            " Government",
            ".\n\n",
            "B",
            "out",
            "ef"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.66,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.684,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 60,
          "is_repeated_datapoint": false,
          "tokens": [
            ":",
            " systematically",
            " gathering",
            " data",
            ",",
            " discovering",
            " patterns",
            " common",
            " to",
            " whole",
            " groups",
            " of",
            " animals",
            ",",
            " and",
            " inf",
            "erring",
            " possible",
            " causal",
            " explanations",
            " from",
            " these",
            ".",
            " This",
            " style",
            " is",
            " common",
            " in",
            " modern",
            " biology",
            " when",
            " large",
            " amounts",
            " of",
            " data",
            " become",
            " available",
            " in",
            " a",
            " new",
            " field",
            ",",
            " such",
            " as",
            " gen",
            "omics",
            ".",
            " It",
            " does",
            " not",
            " result",
            " in",
            " the",
            " same",
            " certainty",
            " as",
            " experimental",
            " science",
            ",",
            " but",
            " it",
            " sets",
            " out",
            " test",
            "able",
            " hypotheses",
            " and",
            " constructs",
            " a",
            " narrative",
            " explanation",
            " of",
            " what",
            " is",
            " observed",
            ".",
            " In",
            " this",
            " sense",
            ",",
            " Aristotle",
            "'s",
            " biology",
            " is",
            " scientific",
            ".\n\n",
            "From",
            " the",
            " data",
            " he",
            " collected",
            " and",
            " documented",
            ",",
            " Aristotle",
            " inferred",
            " quite",
            " a",
            " number",
            " of",
            " rules",
            " relating",
            " the",
            " life",
            "-history",
            " features",
            " of",
            " the",
            " live",
            "-bearing",
            " tet",
            "rap",
            "ods",
            " (",
            "ter",
            "restrial",
            " plac",
            "ental",
            " mammals",
            ")",
            " that",
            " he",
            " studied",
            ".",
            " Among",
            " these",
            " correct"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.66,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.684,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 60,
          "is_repeated_datapoint": false,
          "tokens": [
            ":",
            " systematically",
            " gathering",
            " data",
            ",",
            " discovering",
            " patterns",
            " common",
            " to",
            " whole",
            " groups",
            " of",
            " animals",
            ",",
            " and",
            " inf",
            "erring",
            " possible",
            " causal",
            " explanations",
            " from",
            " these",
            ".",
            " This",
            " style",
            " is",
            " common",
            " in",
            " modern",
            " biology",
            " when",
            " large",
            " amounts",
            " of",
            " data",
            " become",
            " available",
            " in",
            " a",
            " new",
            " field",
            ",",
            " such",
            " as",
            " gen",
            "omics",
            ".",
            " It",
            " does",
            " not",
            " result",
            " in",
            " the",
            " same",
            " certainty",
            " as",
            " experimental",
            " science",
            ",",
            " but",
            " it",
            " sets",
            " out",
            " test",
            "able",
            " hypotheses",
            " and",
            " constructs",
            " a",
            " narrative",
            " explanation",
            " of",
            " what",
            " is",
            " observed",
            ".",
            " In",
            " this",
            " sense",
            ",",
            " Aristotle",
            "'s",
            " biology",
            " is",
            " scientific",
            ".\n\n",
            "From",
            " the",
            " data",
            " he",
            " collected",
            " and",
            " documented",
            ",",
            " Aristotle",
            " inferred",
            " quite",
            " a",
            " number",
            " of",
            " rules",
            " relating",
            " the",
            " life",
            "-history",
            " features",
            " of",
            " the",
            " live",
            "-bearing",
            " tet",
            "rap",
            "ods",
            " (",
            "ter",
            "restrial",
            " plac",
            "ental",
            " mammals",
            ")",
            " that",
            " he",
            " studied",
            ".",
            " Among",
            " these",
            " correct"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.68,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.027,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            "When",
            " the",
            " commissioners",
            " returned",
            " to",
            " London",
            " in",
            " November",
            " ",
            "177",
            "8",
            ",",
            " they",
            " recommended",
            " a",
            " change",
            " in",
            " policy",
            ".",
            " Sir",
            " Henry",
            " Clinton",
            ",",
            " the",
            " new",
            " British",
            " Commander",
            "-in",
            "-Ch",
            "ief",
            " in",
            " America",
            ",",
            " was",
            " ordered",
            " to",
            " stop",
            " treating",
            " the",
            " rebels",
            " as",
            " enemies",
            ",",
            " rather",
            " than",
            " subjects",
            " whose",
            " loyalty",
            " might",
            " be",
            " regained",
            ".",
            " Those",
            " standing",
            " orders",
            " would",
            " be",
            " in",
            " effect",
            " for",
            " three",
            " years",
            " until",
            " Clinton",
            " was",
            " relieved",
            ".\n\n",
            "North",
            " initially",
            " backed",
            " the",
            " Southern",
            " strategy",
            " attempting",
            " to",
            " exploit",
            " divisions",
            " between",
            " the",
            " merc",
            "ant",
            "ile",
            " north",
            " and",
            " slave",
            "-",
            "own",
            "ing",
            " south",
            ",",
            " but",
            " after",
            " the",
            " defeat",
            " of",
            " York",
            "town",
            ",",
            " he",
            " was",
            " forced",
            " to",
            " accept",
            " the",
            " fact",
            " that",
            " this",
            " policy",
            " had",
            " failed",
            ".",
            " It",
            " was",
            " clear",
            " the",
            " war",
            " was",
            " lost",
            ",",
            " although",
            " the",
            " Royal",
            " Navy",
            " forced",
            " the",
            " French",
            " to"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.664,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.177,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 27,
          "is_repeated_datapoint": false,
          "tokens": [
            "19",
            " foreign",
            "-born",
            " free",
            " black",
            " individuals",
            " in",
            " Ar",
            "uba",
            ".",
            " By",
            " ",
            "184",
            "0",
            ",",
            " Ar",
            "uba",
            " had",
            " ",
            "497",
            " slaves",
            ",",
            " with",
            " ",
            "269",
            " being",
            " indigenous",
            " people",
            " and",
            " ",
            "228",
            " of",
            " African",
            " descent",
            ".",
            " In",
            " the",
            " same",
            " year",
            ",",
            " there",
            " were",
            " ",
            "77",
            " free",
            "-born",
            " black",
            " individuals",
            " and",
            " ",
            "225",
            " foreign",
            "-born",
            " free",
            " black",
            " individuals",
            " in",
            " Ar",
            "uba",
            ".",
            " Rough",
            "ly",
            " half",
            " of",
            " the",
            " slaves",
            " in",
            " Ar",
            "uba",
            " were",
            " of",
            " indigenous",
            " origin",
            ",",
            " while",
            " the",
            " other",
            " half",
            " were",
            " of",
            " African",
            " descent",
            ".",
            " Although",
            " Dutch",
            " government",
            " law",
            " did",
            " not",
            " permit",
            " the",
            " ensl",
            "av",
            "ement",
            " of",
            " indigenous",
            " people",
            ",",
            " the",
            " practice",
            " varied",
            ".\n\n",
            "It",
            " wasn",
            "'t",
            " until",
            " after",
            " the",
            " year",
            " ",
            "177",
            "5",
            " that",
            " the",
            " names",
            " of",
            " African",
            " slaves",
            " began",
            " to",
            " appear",
            " in",
            " our",
            " records",
            ".",
            " Some",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 42,
          "is_repeated_datapoint": false,
          "tokens": [
            "¥",
            " ",
            "È",
            "¦",
            " ",
            "È",
            "§",
            " ",
            "Ç",
            "ł",
            " ",
            "Ç",
            "¡",
            " áº",
            "ł",
            " ",
            "áº¡",
            " ÃĦ",
            " Ã¤",
            " ",
            "Ç",
            "ŀ",
            " ",
            "Ç",
            "Ł",
            " ÃĢ",
            " Ãł",
            " ",
            "È",
            "Ģ",
            " ",
            "È",
            "ģ",
            " Ãģ",
            " Ã¡",
            " Ä",
            "Ģ",
            " Ä",
            "ģ",
            " Ä",
            "Ģ",
            "ÌĢ",
            " Ä",
            "ģ",
            "ÌĢ",
            " Ãĥ",
            " Ã",
            "£",
            " Ä",
            "Ħ",
            " ",
            "Äħ",
            " Ä",
            "Ħ",
            "Ìģ",
            " ",
            "Äħ",
            "Ìģ",
            " Ä",
            "Ħ",
            "Ìĥ",
            " ",
            "Äħ",
            "Ìĥ",
            " A",
            "Ì",
            "²",
            " a",
            "Ì",
            "²",
            " á",
            "¶",
            "ı",
            "\n",
            "Ph",
            "on",
            "etic",
            " alphabet",
            " symbols",
            " related",
            " to",
            " A",
            " (",
            "the",
            " International",
            " Phonetic",
            " Alphabet",
            " only",
            " uses",
            " lowercase",
            ",",
            " but",
            " uppercase",
            " forms",
            " are",
            " used",
            " in",
            " some",
            " other",
            " writing",
            " systems",
            "):",
            " \n",
            "â",
            "±",
            "Ń",
            " ",
            "É",
            "ĳ",
            " :",
            " Latin",
            " letter",
            " alpha",
            " /",
            " script",
            " A",
            ",",
            " which",
            " represents",
            " an",
            " open",
            " back",
            " un",
            "rounded",
            " vowel",
            " in",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.668,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " are",
            " restored",
            " to",
            " their",
            " rightful",
            " place",
            " in",
            " society",
            ",",
            " they",
            " have",
            " enough",
            " capital",
            " to",
            " rebuild",
            " the",
            " world",
            ".",
            " Ke",
            "pt",
            " in",
            " the",
            " background",
            " for",
            " much",
            " of",
            " the",
            " book",
            ",",
            " D",
            "annes",
            "kj",
            "Ã¶",
            "ld",
            " makes",
            " a",
            " personal",
            " appearance",
            " to",
            " encourage",
            " Re",
            "arden",
            " to",
            " perse",
            "vere",
            " in",
            " his",
            " increasingly",
            " difficult",
            " situation",
            ",",
            " and",
            " gives",
            " him",
            " a",
            " bar",
            " of",
            " gold",
            " as",
            " compensation",
            " for",
            " the",
            " income",
            " taxes",
            " he",
            " has",
            " paid",
            " over",
            " the",
            " last",
            " several",
            " years",
            ".",
            " D",
            "annes",
            "kj",
            "Ã¶",
            "ld",
            " is",
            " married",
            " to",
            " the",
            " actress",
            " Kay",
            " Lud",
            "low",
            ";",
            " their",
            " relationship",
            " is",
            " kept",
            " hidden",
            " from",
            " the",
            " outside",
            " world",
            ",",
            " which",
            " only",
            " knows",
            " of",
            " Lud",
            "low",
            " as",
            " a",
            " retired",
            " film",
            " star",
            ".",
            " Consider",
            "ed",
            " a",
            " mis",
            "fit",
            " by",
            " G",
            "alt",
            "'s",
            " other",
            " adher",
            "ents",
            ",",
            " he",
            " views",
            " his",
            " actions",
            " as"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 74,
          "is_repeated_datapoint": false,
          "tokens": [
            " with",
            " Apollo",
            ".\n",
            " Apollo",
            " Map",
            "onus",
            ".",
            " A",
            " god",
            " known",
            " from",
            " ins",
            "criptions",
            " in",
            " Britain",
            ".",
            " This",
            " may",
            " be",
            " a",
            " local",
            " fusion",
            " of",
            " Apollo",
            " and",
            " Map",
            "onus",
            ".\n",
            " Apollo",
            " Mor",
            "itas",
            "g",
            "us",
            " (\"",
            "mass",
            "es",
            " of",
            " sea",
            " water",
            "\").",
            " An",
            " epith",
            "et",
            " for",
            " Apollo",
            " at",
            " A",
            "lesia",
            ",",
            " where",
            " he",
            " was",
            " worsh",
            "ipped",
            " as",
            " the",
            " god",
            " of",
            " healing",
            " and",
            ",",
            " possibly",
            ",",
            " of",
            " physicians",
            ".\n",
            " Apollo",
            " V",
            "ind",
            "onn",
            "us",
            " (\"",
            "clear",
            " light",
            "\").",
            " Apollo",
            " V",
            "ind",
            "onn",
            "us",
            " had",
            " a",
            " temple",
            " at",
            " Ess",
            "aro",
            "is",
            ",",
            " near",
            " Ch",
            "Ã¢t",
            "illon",
            "-sur",
            "-Se",
            "ine",
            " in",
            " present",
            "-day",
            " Burg",
            "undy",
            ".",
            " He",
            " was",
            " a",
            " god",
            " of",
            " healing",
            ",",
            " especially",
            " of",
            " the",
            " eyes",
            ".\n",
            " Apollo",
            " Vi",
            "rot",
            "ut",
            "is",
            " (\"",
            "benef",
            "actor",
            " of",
            " mankind",
            "\").",
            " Apollo",
            " Vi",
            "rot"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.668,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " are",
            " restored",
            " to",
            " their",
            " rightful",
            " place",
            " in",
            " society",
            ",",
            " they",
            " have",
            " enough",
            " capital",
            " to",
            " rebuild",
            " the",
            " world",
            ".",
            " Ke",
            "pt",
            " in",
            " the",
            " background",
            " for",
            " much",
            " of",
            " the",
            " book",
            ",",
            " D",
            "annes",
            "kj",
            "Ã¶",
            "ld",
            " makes",
            " a",
            " personal",
            " appearance",
            " to",
            " encourage",
            " Re",
            "arden",
            " to",
            " perse",
            "vere",
            " in",
            " his",
            " increasingly",
            " difficult",
            " situation",
            ",",
            " and",
            " gives",
            " him",
            " a",
            " bar",
            " of",
            " gold",
            " as",
            " compensation",
            " for",
            " the",
            " income",
            " taxes",
            " he",
            " has",
            " paid",
            " over",
            " the",
            " last",
            " several",
            " years",
            ".",
            " D",
            "annes",
            "kj",
            "Ã¶",
            "ld",
            " is",
            " married",
            " to",
            " the",
            " actress",
            " Kay",
            " Lud",
            "low",
            ";",
            " their",
            " relationship",
            " is",
            " kept",
            " hidden",
            " from",
            " the",
            " outside",
            " world",
            ",",
            " which",
            " only",
            " knows",
            " of",
            " Lud",
            "low",
            " as",
            " a",
            " retired",
            " film",
            " star",
            ".",
            " Consider",
            "ed",
            " a",
            " mis",
            "fit",
            " by",
            " G",
            "alt",
            "'s",
            " other",
            " adher",
            "ents",
            ",",
            " he",
            " views",
            " his",
            " actions",
            " as"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.664,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.177,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 27,
          "is_repeated_datapoint": false,
          "tokens": [
            "19",
            " foreign",
            "-born",
            " free",
            " black",
            " individuals",
            " in",
            " Ar",
            "uba",
            ".",
            " By",
            " ",
            "184",
            "0",
            ",",
            " Ar",
            "uba",
            " had",
            " ",
            "497",
            " slaves",
            ",",
            " with",
            " ",
            "269",
            " being",
            " indigenous",
            " people",
            " and",
            " ",
            "228",
            " of",
            " African",
            " descent",
            ".",
            " In",
            " the",
            " same",
            " year",
            ",",
            " there",
            " were",
            " ",
            "77",
            " free",
            "-born",
            " black",
            " individuals",
            " and",
            " ",
            "225",
            " foreign",
            "-born",
            " free",
            " black",
            " individuals",
            " in",
            " Ar",
            "uba",
            ".",
            " Rough",
            "ly",
            " half",
            " of",
            " the",
            " slaves",
            " in",
            " Ar",
            "uba",
            " were",
            " of",
            " indigenous",
            " origin",
            ",",
            " while",
            " the",
            " other",
            " half",
            " were",
            " of",
            " African",
            " descent",
            ".",
            " Although",
            " Dutch",
            " government",
            " law",
            " did",
            " not",
            " permit",
            " the",
            " ensl",
            "av",
            "ement",
            " of",
            " indigenous",
            " people",
            ",",
            " the",
            " practice",
            " varied",
            ".\n\n",
            "It",
            " wasn",
            "'t",
            " until",
            " after",
            " the",
            " year",
            " ",
            "177",
            "5",
            " that",
            " the",
            " names",
            " of",
            " African",
            " slaves",
            " began",
            " to",
            " appear",
            " in",
            " our",
            " records",
            ".",
            " Some",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.668,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " are",
            " restored",
            " to",
            " their",
            " rightful",
            " place",
            " in",
            " society",
            ",",
            " they",
            " have",
            " enough",
            " capital",
            " to",
            " rebuild",
            " the",
            " world",
            ".",
            " Ke",
            "pt",
            " in",
            " the",
            " background",
            " for",
            " much",
            " of",
            " the",
            " book",
            ",",
            " D",
            "annes",
            "kj",
            "Ã¶",
            "ld",
            " makes",
            " a",
            " personal",
            " appearance",
            " to",
            " encourage",
            " Re",
            "arden",
            " to",
            " perse",
            "vere",
            " in",
            " his",
            " increasingly",
            " difficult",
            " situation",
            ",",
            " and",
            " gives",
            " him",
            " a",
            " bar",
            " of",
            " gold",
            " as",
            " compensation",
            " for",
            " the",
            " income",
            " taxes",
            " he",
            " has",
            " paid",
            " over",
            " the",
            " last",
            " several",
            " years",
            ".",
            " D",
            "annes",
            "kj",
            "Ã¶",
            "ld",
            " is",
            " married",
            " to",
            " the",
            " actress",
            " Kay",
            " Lud",
            "low",
            ";",
            " their",
            " relationship",
            " is",
            " kept",
            " hidden",
            " from",
            " the",
            " outside",
            " world",
            ",",
            " which",
            " only",
            " knows",
            " of",
            " Lud",
            "low",
            " as",
            " a",
            " retired",
            " film",
            " star",
            ".",
            " Consider",
            "ed",
            " a",
            " mis",
            "fit",
            " by",
            " G",
            "alt",
            "'s",
            " other",
            " adher",
            "ents",
            ",",
            " he",
            " views",
            " his",
            " actions",
            " as"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 74,
          "is_repeated_datapoint": false,
          "tokens": [
            " with",
            " Apollo",
            ".\n",
            " Apollo",
            " Map",
            "onus",
            ".",
            " A",
            " god",
            " known",
            " from",
            " ins",
            "criptions",
            " in",
            " Britain",
            ".",
            " This",
            " may",
            " be",
            " a",
            " local",
            " fusion",
            " of",
            " Apollo",
            " and",
            " Map",
            "onus",
            ".\n",
            " Apollo",
            " Mor",
            "itas",
            "g",
            "us",
            " (\"",
            "mass",
            "es",
            " of",
            " sea",
            " water",
            "\").",
            " An",
            " epith",
            "et",
            " for",
            " Apollo",
            " at",
            " A",
            "lesia",
            ",",
            " where",
            " he",
            " was",
            " worsh",
            "ipped",
            " as",
            " the",
            " god",
            " of",
            " healing",
            " and",
            ",",
            " possibly",
            ",",
            " of",
            " physicians",
            ".\n",
            " Apollo",
            " V",
            "ind",
            "onn",
            "us",
            " (\"",
            "clear",
            " light",
            "\").",
            " Apollo",
            " V",
            "ind",
            "onn",
            "us",
            " had",
            " a",
            " temple",
            " at",
            " Ess",
            "aro",
            "is",
            ",",
            " near",
            " Ch",
            "Ã¢t",
            "illon",
            "-sur",
            "-Se",
            "ine",
            " in",
            " present",
            "-day",
            " Burg",
            "undy",
            ".",
            " He",
            " was",
            " a",
            " god",
            " of",
            " healing",
            ",",
            " especially",
            " of",
            " the",
            " eyes",
            ".\n",
            " Apollo",
            " Vi",
            "rot",
            "ut",
            "is",
            " (\"",
            "benef",
            "actor",
            " of",
            " mankind",
            "\").",
            " Apollo",
            " Vi",
            "rot"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.672,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " ad",
            "verb",
            "ial",
            " accus",
            "ative",
            " formations",
            ",",
            " e",
            ".g",
            ".,",
            " ",
            " Øª",
            "ÙİÙĤ",
            "ÙĴØ±",
            "ÙĲÙĬ",
            "Ø¨",
            "ÙĭØ§",
            " '",
            "almost",
            ",",
            " approximately",
            "',",
            " ",
            " Ø¹",
            "Ùİ",
            "Ø§Ø¯",
            "ÙİØ©",
            "Ùĭ",
            " '",
            "usually",
            "'.\n",
            " The",
            " t",
            "Äģ",
            "Ê",
            "¾",
            " mar",
            "b",
            "Å«",
            "á¹",
            "Ń",
            "ah",
            " ending",
            " Ø",
            "©",
            " is",
            " un",
            "pron",
            "ounced",
            ",",
            " except",
            " in",
            " construct",
            " state",
            " nouns",
            ",",
            " where",
            " it",
            " sounds",
            " as",
            " t",
            " and",
            " in",
            " ad",
            "verb",
            "ial",
            " accus",
            "ative",
            " constructions",
            ",",
            " e",
            ".g",
            ".,",
            " ",
            " Ø¹",
            "Ùİ",
            "Ø§Ø¯",
            "ÙİØ©",
            "Ùĭ",
            " '",
            "usually",
            "',",
            " where",
            " the",
            " entire",
            " -",
            "tan",
            " is",
            " pronounced",
            ".\n",
            " The",
            " masculine",
            " singular",
            " n",
            "is",
            "bah",
            " ending",
            " ",
            " is",
            " pronounced",
            " ",
            " and",
            " is",
            " unst",
            "ressed",
            ",",
            " but",
            " plural",
            " and",
            " feminine",
            " singular",
            " forms",
            ",",
            " i",
            ".e",
            ".",
            " when",
            " followed",
            " by",
            " a",
            " suffix",
            ",",
            " still",
            " sound",
            " as",
            " .\n"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.633,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.344,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.336,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 33,
          "is_repeated_datapoint": false,
          "tokens": [
            "is",
            " and",
            " Ar",
            "iste",
            "as",
            " were",
            " also",
            " the",
            " followers",
            " of",
            " Apollo",
            ",",
            " who",
            " hailed",
            " from",
            " Hyper",
            "b",
            "orea",
            ".\n\n",
            "In",
            " myths",
            ",",
            " the",
            " tears",
            " of",
            " amber",
            " Apollo",
            " shed",
            " when",
            " his",
            " son",
            " As",
            "cle",
            "pi",
            "us",
            " died",
            " mixed",
            " with",
            " the",
            " waters",
            " of",
            " the",
            " river",
            " E",
            "rid",
            "anos",
            ",",
            " which",
            " surrounded",
            " Hyper",
            "b",
            "orea",
            ".",
            " Apollo",
            " also",
            " buried",
            " in",
            " Hyper",
            "b",
            "orea",
            " the",
            " arrow",
            " which",
            " he",
            " had",
            " used",
            " to",
            " kill",
            " the",
            " Cyc",
            "lo",
            "pes",
            ".",
            " He",
            " later",
            " gave",
            " this",
            " arrow",
            " to",
            " A",
            "bar",
            "is",
            ".\n\n",
            "Child",
            "hood",
            " and",
            " youth",
            "\n\n",
            "Growing",
            " up",
            ",",
            " Apollo",
            " was",
            " nurs",
            "ed",
            " by",
            " the",
            " nymph",
            "s",
            " K",
            "ory",
            "th",
            "alia",
            " and",
            " Ale",
            "the",
            "ia",
            ",",
            " the",
            " person",
            "ification",
            " of",
            " truth",
            ".",
            " As",
            " a",
            " child",
            ",",
            " Apollo",
            " is",
            " said",
            " to",
            " have",
            " built",
            " a",
            " foundation",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.629,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.344,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.038,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.264,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " great",
            " poetic",
            " art",
            ",",
            " and",
            " laughter",
            " as",
            " well",
            ".",
            " In",
            " Ion",
            ",",
            " S",
            "ocrates",
            " gives",
            " no",
            " hint",
            " of",
            " the",
            " dis",
            "approval",
            " of",
            " Homer",
            " that",
            " he",
            " expresses",
            " in",
            " the",
            " Republic",
            ".",
            " The",
            " dialogue",
            " Ion",
            " suggests",
            " that",
            " Homer",
            "'s",
            " I",
            "li",
            "ad",
            " function",
            "ed",
            " in",
            " the",
            " ancient",
            " Greek",
            " world",
            " as",
            " the",
            " Bible",
            " does",
            " today",
            " in",
            " the",
            " modern",
            " Christian",
            " world",
            ":",
            " as",
            " div",
            "inely",
            " inspired",
            " literary",
            " art",
            " that",
            " can",
            " provide",
            " moral",
            " guidance",
            ",",
            " if",
            " only",
            " it",
            " can",
            " be",
            " properly",
            " interpreted",
            ".\n\n",
            "With",
            " regards",
            " to",
            " the",
            " literary",
            " art",
            " and",
            " the",
            " musical",
            " arts",
            ",",
            " Aristotle",
            " considered",
            " epic",
            " poetry",
            ",",
            " tragedy",
            ",",
            " comedy",
            ",",
            " D",
            "ith",
            "y",
            "ram",
            "bic",
            " poetry",
            " and",
            " music",
            " to",
            " be",
            " mim",
            "etic",
            " or",
            " im",
            "itative",
            " art",
            ",",
            " each",
            " varying",
            " in",
            " imitation",
            " by",
            " medium",
            ",",
            " object",
            ",",
            " and",
            " manner",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.629,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.344,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.038,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.264,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " great",
            " poetic",
            " art",
            ",",
            " and",
            " laughter",
            " as",
            " well",
            ".",
            " In",
            " Ion",
            ",",
            " S",
            "ocrates",
            " gives",
            " no",
            " hint",
            " of",
            " the",
            " dis",
            "approval",
            " of",
            " Homer",
            " that",
            " he",
            " expresses",
            " in",
            " the",
            " Republic",
            ".",
            " The",
            " dialogue",
            " Ion",
            " suggests",
            " that",
            " Homer",
            "'s",
            " I",
            "li",
            "ad",
            " function",
            "ed",
            " in",
            " the",
            " ancient",
            " Greek",
            " world",
            " as",
            " the",
            " Bible",
            " does",
            " today",
            " in",
            " the",
            " modern",
            " Christian",
            " world",
            ":",
            " as",
            " div",
            "inely",
            " inspired",
            " literary",
            " art",
            " that",
            " can",
            " provide",
            " moral",
            " guidance",
            ",",
            " if",
            " only",
            " it",
            " can",
            " be",
            " properly",
            " interpreted",
            ".\n\n",
            "With",
            " regards",
            " to",
            " the",
            " literary",
            " art",
            " and",
            " the",
            " musical",
            " arts",
            ",",
            " Aristotle",
            " considered",
            " epic",
            " poetry",
            ",",
            " tragedy",
            ",",
            " comedy",
            ",",
            " D",
            "ith",
            "y",
            "ram",
            "bic",
            " poetry",
            " and",
            " music",
            " to",
            " be",
            " mim",
            "etic",
            " or",
            " im",
            "itative",
            " art",
            ",",
            " each",
            " varying",
            " in",
            " imitation",
            " by",
            " medium",
            ",",
            " object",
            ",",
            " and",
            " manner",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.34,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.179,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " he",
            " wrote",
            " Owens",
            " a",
            " letter",
            " saying",
            " he",
            " would",
            " not",
            " blame",
            " her",
            " if",
            " she",
            " ended",
            " the",
            " relationship",
            ",",
            " and",
            " she",
            " never",
            " replied",
            ".\n\n",
            "In",
            " ",
            "183",
            "9",
            ",",
            " Lincoln",
            " met",
            " Mary",
            " Todd",
            " in",
            " Springfield",
            ",",
            " Illinois",
            ",",
            " and",
            " the",
            " following",
            " year",
            " they",
            " became",
            " engaged",
            ".",
            " She",
            " was",
            " the",
            " daughter",
            " of",
            " Robert",
            " Smith",
            " Todd",
            ",",
            " a",
            " wealthy",
            " lawyer",
            " and",
            " businessman",
            " in",
            " Lexington",
            ",",
            " Kentucky",
            ".",
            " A",
            " wedding",
            " set",
            " for",
            " January",
            " ",
            "1",
            ",",
            " ",
            "184",
            "1",
            ",",
            " was",
            " canceled",
            " at",
            " Lincoln",
            "'s",
            " request",
            ",",
            " but",
            " they",
            " reconc",
            "iled",
            " and",
            " married",
            " on",
            " November",
            " ",
            "4",
            ",",
            " ",
            "184",
            "2",
            ",",
            " in",
            " the",
            " Springfield",
            " mansion",
            " of",
            " Mary",
            "'s",
            " sister",
            ".",
            " While",
            " anx",
            "iously",
            " preparing",
            " for",
            " the",
            " n",
            "upt",
            "ials",
            ",",
            " he",
            " was",
            " asked",
            " where",
            " he",
            " was",
            " going",
            " and",
            " replied",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.348,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.184,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 27,
          "is_repeated_datapoint": false,
          "tokens": [
            "ake",
            " in",
            " this",
            " medium",
            " of",
            " communication",
            ".",
            " There",
            " are",
            " also",
            " options",
            " to",
            " adjust",
            " the",
            " frequency",
            " and",
            " tone",
            " of",
            " a",
            " call",
            " to",
            " suit",
            " their",
            " individual",
            " hearing",
            " needs",
            ".",
            " Additionally",
            ",",
            " there",
            " is",
            " a",
            " wide",
            " variety",
            " of",
            " amplified",
            " tele",
            "phones",
            " to",
            " choose",
            " from",
            ",",
            " with",
            " different",
            " degrees",
            " of",
            " ampl",
            "ification",
            ".",
            " For",
            " example",
            ",",
            " a",
            " phone",
            " with",
            " ",
            "26",
            " to",
            " ",
            "40",
            " dec",
            "ibel",
            " is",
            " generally",
            " sufficient",
            " for",
            " mild",
            " hearing",
            " loss",
            ",",
            " while",
            " a",
            " phone",
            " with",
            " ",
            "71",
            " to",
            " ",
            "90",
            " dec",
            "ibel",
            " is",
            " better",
            " for",
            " more",
            " severe",
            " hearing",
            " loss",
            ".\n\n",
            "Aug",
            "ment",
            "ative",
            " and",
            " alternative",
            " communication",
            "\n\n",
            "Aug",
            "ment",
            "ative",
            " and",
            " alternative",
            " communication",
            " (",
            "AAC",
            ")",
            " is",
            " an",
            " umbrella",
            " term",
            " that",
            " encompasses",
            " methods",
            " of",
            " communication",
            " for",
            " those",
            " with",
            " impair",
            "ments",
            " or",
            " restrictions",
            " on",
            " the",
            " production",
            " or",
            " comprehension",
            " of"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.609,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            " co",
            "att",
            "ails",
            ".",
            " This",
            " led",
            " to",
            " them",
            " being",
            " greeted",
            " with",
            " \"",
            "Yellow",
            "hammer",
            "\",",
            " and",
            " the",
            " name",
            " later",
            " was",
            " applied",
            " to",
            " all",
            " Alabama",
            " troops",
            " in",
            " the",
            " Confederate",
            " Army",
            ".\n\n",
            "Alabama",
            "'s",
            " slaves",
            " were",
            " freed",
            " by",
            " the",
            " ",
            "13",
            "th",
            " Amendment",
            " in",
            " ",
            "186",
            "5",
            ".",
            " Alabama",
            " was",
            " under",
            " military",
            " rule",
            " from",
            " the",
            " end",
            " of",
            " the",
            " war",
            " in",
            " May",
            " ",
            "186",
            "5",
            " until",
            " its",
            " official",
            " restoration",
            " to",
            " the",
            " Union",
            " in",
            " ",
            "186",
            "8",
            ".",
            " From",
            " ",
            "186",
            "7",
            " to",
            " ",
            "187",
            "4",
            ",",
            " with",
            " most",
            " white",
            " citizens",
            " barred",
            " temporarily",
            " from",
            " voting",
            " and",
            " freed",
            "men",
            " en",
            "fr",
            "anch",
            "ised",
            ",",
            " many",
            " African",
            " Americans",
            " emerged",
            " as",
            " political",
            " leaders",
            " in",
            " the",
            " state",
            ".",
            " Alabama",
            " was",
            " represented",
            " in",
            " Congress",
            " during",
            " this",
            " period",
            " by",
            " three",
            " African",
            "-American",
            " congress",
            "men",
            ":",
            " Jeremiah",
            " Har"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.551,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.297,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.594,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 84,
          "is_repeated_datapoint": false,
          "tokens": [
            "14",
            ".",
            "7",
            "%.",
            " Foreign",
            " direct",
            " investment",
            " has",
            " increased",
            " significantly",
            " in",
            " recent",
            " years",
            " as",
            " the",
            " government",
            " has",
            " embarked",
            " on",
            " an",
            " ambitious",
            " programme",
            " to",
            " improve",
            " the",
            " business",
            " climate",
            " through",
            " fiscal",
            " and",
            " legislative",
            " reforms",
            ".\n\n",
            "Primary",
            " sector",
            " \n\n",
            "A",
            "gricult",
            "ure",
            " in",
            " the",
            " country",
            " is",
            " based",
            " on",
            " small",
            " to",
            " medium",
            "-sized",
            " family",
            "-owned",
            " dispersed",
            " units",
            ".",
            " It",
            " remains",
            " a",
            " significant",
            " sector",
            " of",
            " the",
            " economy",
            " of",
            " Albania",
            ".",
            " It",
            " employs",
            " ",
            "41",
            "%",
            " of",
            " the",
            " population",
            ",",
            " and",
            " about",
            " ",
            "24",
            ".",
            "31",
            "%",
            " of",
            " the",
            " land",
            " is",
            " used",
            " for",
            " agricultural",
            " purposes",
            ".",
            " One",
            " of",
            " the",
            " earliest",
            " farming",
            " sites",
            " in",
            " Europe",
            " has",
            " been",
            " found",
            " in",
            " the",
            " southeast",
            " of",
            " the",
            " country",
            ".",
            " As",
            " part",
            " of",
            " the",
            " pre",
            "-access",
            "ion",
            " process",
            " of",
            " Albania",
            " to",
            " the",
            " European",
            " Union",
            ",",
            " farmers",
            " are",
            " being",
            " aided"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.582,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " ,",
            " and",
            " an",
            " airborne",
            " endurance",
            " of",
            " two",
            " weeks",
            " with",
            " a",
            " payload",
            " of",
            " up",
            " to",
            " .\n\n",
            "The",
            " largest",
            " aircraft",
            " by",
            " weight",
            " and",
            " largest",
            " regular",
            " fixed",
            "-wing",
            " aircraft",
            " ever",
            " built",
            ",",
            " ,",
            " was",
            " the",
            " Anton",
            "ov",
            " An",
            "-",
            "225",
            " M",
            "ri",
            "ya",
            ".",
            " That",
            " Soviet",
            "-built",
            " (",
            "U",
            "kr",
            "ain",
            "ian",
            " SSR",
            ")",
            " six",
            "-engine",
            " transport",
            " of",
            " the",
            " ",
            "198",
            "0",
            "s",
            " was",
            " ",
            " long",
            ",",
            " with",
            " an",
            " ",
            " wings",
            "pan",
            ".",
            " It",
            " holds",
            " the",
            " world",
            " payload",
            " record",
            ",",
            " after",
            " transporting",
            " ",
            " of",
            " goods",
            ",",
            " and",
            " has",
            " flown",
            " ",
            " loads",
            " commercially",
            ".",
            " With",
            " a",
            " maximum",
            " loaded",
            " weight",
            " of",
            " ,",
            " it",
            " was",
            " also",
            " the",
            " he",
            "aviest",
            " aircraft",
            " built",
            " to",
            " date",
            ".",
            " It",
            " could",
            " cruise",
            " at",
            " .",
            " The",
            " aircraft",
            " was",
            " destroyed",
            " during",
            " the",
            " Russo",
            "-U",
            "kr",
            "ain",
            "ian",
            " War",
            ".\n\n"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.001,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.011,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.166,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.578,
            -0.0,
            -0.0
          ],
          "train_token_ind": 124,
          "is_repeated_datapoint": false,
          "tokens": [
            " land",
            " title",
            " difficulties",
            ".\n\n",
            "In",
            " Kentucky",
            " and",
            " Indiana",
            ",",
            " Thomas",
            " worked",
            " as",
            " a",
            " farmer",
            ",",
            " cabinet",
            "maker",
            ",",
            " and",
            " carp",
            "enter",
            ".",
            " At",
            " various",
            " times",
            ",",
            " he",
            " owned",
            " farms",
            ",",
            " livestock",
            ",",
            " and",
            " town",
            " lots",
            ",",
            " paid",
            " taxes",
            ",",
            " sat",
            " on",
            " j",
            "uries",
            ",",
            " app",
            "raised",
            " estates",
            ",",
            " and",
            " served",
            " on",
            " county",
            " patrols",
            ".",
            " Thomas",
            " and",
            " Nancy",
            " were",
            " members",
            " of",
            " a",
            " Separate",
            " Bapt",
            "ists",
            " church",
            ",",
            " which",
            " forb",
            "ade",
            " alcohol",
            ",",
            " dancing",
            ",",
            " and",
            " slavery",
            ".\n\n",
            "Over",
            "coming",
            " financial",
            " challenges",
            ",",
            " Thomas",
            " in",
            " ",
            "182",
            "7",
            " obtained",
            " clear",
            " title",
            " to",
            " ",
            " in",
            " Indiana",
            ",",
            " an",
            " area",
            " which",
            " became",
            " the",
            " Little",
            " P",
            "ige",
            "on",
            " Creek",
            " Community",
            ".\n\n",
            "Mother",
            "'s",
            " death",
            "\n",
            "On",
            " October",
            " ",
            "5",
            ",",
            " ",
            "181",
            "8",
            ",",
            " Nancy",
            " Lincoln",
            " died",
            " from",
            " milk",
            " sickness",
            ",",
            " leaving"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.566,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.578,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            " there",
            " has",
            " only",
            " been",
            " a",
            " general",
            " emergency",
            " call",
            " to",
            " the",
            " popular",
            " army",
            " of",
            " S",
            "omet",
            "ent",
            " during",
            " the",
            " floods",
            " of",
            " ",
            "198",
            "2",
            " in",
            " the",
            " Catalan",
            " Py",
            "rene",
            "es",
            ",",
            " where",
            " ",
            "12",
            " citizens",
            " per",
            "ished",
            " in",
            " And",
            "orra",
            ",",
            " to",
            " help",
            " the",
            " population",
            " and",
            " establish",
            " a",
            " public",
            " order",
            " along",
            " with",
            " the",
            " Local",
            " Police",
            " units",
            ".\n\n",
            "Police",
            " Corps",
            "\n\n",
            "And",
            "orra",
            " maintains",
            " a",
            " small",
            " but",
            " modern",
            " and",
            " well",
            "-equipped",
            " internal",
            " police",
            " force",
            ",",
            " with",
            " around",
            " ",
            "240",
            " police",
            " officers",
            " supported",
            " by",
            " civilian",
            " assistants",
            ".",
            " The",
            " principal",
            " services",
            " supplied",
            " by",
            " the",
            " corps",
            " are",
            " uniform",
            "ed",
            " community",
            " policing",
            ",",
            " criminal",
            " detection",
            ",",
            " border",
            " control",
            ",",
            " and",
            " traffic",
            " policing",
            ".",
            " There",
            " are",
            " also",
            " small",
            " specialist",
            " units",
            " including",
            " police",
            " dogs",
            ",",
            " mountain",
            " rescue",
            ",",
            " and",
            " a",
            " bomb",
            " disposal",
            " team",
            ".\n\n",
            "G"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.574,
            -0.0,
            -0.0,
            0.492,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 108,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "100",
            "%",
            " of",
            " the",
            " proceeds",
            " from",
            " the",
            " applications",
            " participating",
            " in",
            " the",
            " App",
            " Store",
            " via",
            " both",
            " the",
            " purchases",
            " of",
            " any",
            " paid",
            " apps",
            " and",
            " the",
            " In",
            "-",
            "App",
            " Purch",
            "ases",
            ".",
            " Apple",
            " and",
            " WW",
            "F",
            "'s",
            " Apps",
            " for",
            " Earth",
            " campaign",
            " raised",
            " more",
            " than",
            " $",
            "8",
            "Âł",
            "million",
            " in",
            " total",
            " proceeds",
            " to",
            " support",
            " WW",
            "F",
            "'s",
            " conservation",
            " work",
            ".",
            " WW",
            "F",
            " announced",
            " the",
            " results",
            " at",
            " WW",
            "DC",
            " ",
            "201",
            "6",
            " in",
            " San",
            " Francisco",
            ".\n\n",
            "During",
            " the",
            " COVID",
            "-",
            "19",
            " pandemic",
            ",",
            " Apple",
            "'s",
            " CEO",
            " Cook",
            " announced",
            " that",
            " the",
            " company",
            " will",
            " be",
            " donating",
            " \"",
            "mill",
            "ions",
            "\"",
            " of",
            " masks",
            " to",
            " health",
            " workers",
            " in",
            " the",
            " United",
            " States",
            " and",
            " Europe",
            ".\n\n",
            "On",
            " January",
            " ",
            "13",
            ",",
            " ",
            "202",
            "1",
            ",",
            " Apple",
            " announced",
            " a",
            " $",
            "100",
            " million",
            " \"",
            "R",
            "acial",
            " Equity",
            " and",
            " Justice"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.574,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "22",
            " seconds",
            " after",
            " launch",
            " he",
            " radio",
            "ed",
            ",",
            " \"",
            "Apollo",
            "8",
            ".",
            " You",
            " are",
            " Go",
            " for",
            " T",
            "LI",
            ".\"",
            " This",
            " communication",
            " meant",
            " that",
            " Mission",
            " Control",
            " had",
            " given",
            " official",
            " permission",
            " for",
            " Apollo",
            "8",
            " to",
            " go",
            " to",
            " the",
            " Moon",
            ".",
            " The",
            " S",
            "-",
            "IV",
            "B",
            " engine",
            " ignited",
            " on",
            " time",
            " and",
            " performed",
            " the",
            " T",
            "LI",
            " burn",
            " perfectly",
            ".",
            " Over",
            " the",
            " next",
            " five",
            " minutes",
            ",",
            " the",
            " spacecraft",
            "'s",
            " speed",
            " increased",
            " from",
            " .\n\n",
            "After",
            " the",
            " S",
            "-",
            "IV",
            "B",
            " had",
            " placed",
            " the",
            " mission",
            " on",
            " course",
            " for",
            " the",
            " Moon",
            ",",
            " the",
            " command",
            " and",
            " service",
            " modules",
            " (",
            "CS",
            "M",
            "),",
            " the",
            " remaining",
            " Apollo",
            "8",
            " spacecraft",
            ",",
            " separated",
            " from",
            " it",
            ".",
            " The",
            " crew",
            " then",
            " rotated",
            " the",
            " spacecraft",
            " to",
            " take",
            " photographs",
            " of",
            " the",
            " spent",
            " stage",
            " and",
            " then",
            " practiced",
            " flying",
            " in",
            " formation",
            " with",
            " it",
            ".",
            " As",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.574,
            -0.0,
            -0.0,
            0.492,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 108,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "100",
            "%",
            " of",
            " the",
            " proceeds",
            " from",
            " the",
            " applications",
            " participating",
            " in",
            " the",
            " App",
            " Store",
            " via",
            " both",
            " the",
            " purchases",
            " of",
            " any",
            " paid",
            " apps",
            " and",
            " the",
            " In",
            "-",
            "App",
            " Purch",
            "ases",
            ".",
            " Apple",
            " and",
            " WW",
            "F",
            "'s",
            " Apps",
            " for",
            " Earth",
            " campaign",
            " raised",
            " more",
            " than",
            " $",
            "8",
            "Âł",
            "million",
            " in",
            " total",
            " proceeds",
            " to",
            " support",
            " WW",
            "F",
            "'s",
            " conservation",
            " work",
            ".",
            " WW",
            "F",
            " announced",
            " the",
            " results",
            " at",
            " WW",
            "DC",
            " ",
            "201",
            "6",
            " in",
            " San",
            " Francisco",
            ".\n\n",
            "During",
            " the",
            " COVID",
            "-",
            "19",
            " pandemic",
            ",",
            " Apple",
            "'s",
            " CEO",
            " Cook",
            " announced",
            " that",
            " the",
            " company",
            " will",
            " be",
            " donating",
            " \"",
            "mill",
            "ions",
            "\"",
            " of",
            " masks",
            " to",
            " health",
            " workers",
            " in",
            " the",
            " United",
            " States",
            " and",
            " Europe",
            ".\n\n",
            "On",
            " January",
            " ",
            "13",
            ",",
            " ",
            "202",
            "1",
            ",",
            " Apple",
            " announced",
            " a",
            " $",
            "100",
            " million",
            " \"",
            "R",
            "acial",
            " Equity",
            " and",
            " Justice"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.574,
            -0.0,
            -0.0,
            0.492,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 108,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "100",
            "%",
            " of",
            " the",
            " proceeds",
            " from",
            " the",
            " applications",
            " participating",
            " in",
            " the",
            " App",
            " Store",
            " via",
            " both",
            " the",
            " purchases",
            " of",
            " any",
            " paid",
            " apps",
            " and",
            " the",
            " In",
            "-",
            "App",
            " Purch",
            "ases",
            ".",
            " Apple",
            " and",
            " WW",
            "F",
            "'s",
            " Apps",
            " for",
            " Earth",
            " campaign",
            " raised",
            " more",
            " than",
            " $",
            "8",
            "Âł",
            "million",
            " in",
            " total",
            " proceeds",
            " to",
            " support",
            " WW",
            "F",
            "'s",
            " conservation",
            " work",
            ".",
            " WW",
            "F",
            " announced",
            " the",
            " results",
            " at",
            " WW",
            "DC",
            " ",
            "201",
            "6",
            " in",
            " San",
            " Francisco",
            ".\n\n",
            "During",
            " the",
            " COVID",
            "-",
            "19",
            " pandemic",
            ",",
            " Apple",
            "'s",
            " CEO",
            " Cook",
            " announced",
            " that",
            " the",
            " company",
            " will",
            " be",
            " donating",
            " \"",
            "mill",
            "ions",
            "\"",
            " of",
            " masks",
            " to",
            " health",
            " workers",
            " in",
            " the",
            " United",
            " States",
            " and",
            " Europe",
            ".\n\n",
            "On",
            " January",
            " ",
            "13",
            ",",
            " ",
            "202",
            "1",
            ",",
            " Apple",
            " announced",
            " a",
            " $",
            "100",
            " million",
            " \"",
            "R",
            "acial",
            " Equity",
            " and",
            " Justice"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.57,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " Sul",
            "ay",
            "man",
            "ids",
            ",",
            " A",
            "gh",
            "lab",
            "ids",
            ",",
            " Fat",
            "im",
            "ids",
            ",",
            " Z",
            "ir",
            "ids",
            ",",
            " H",
            "ammad",
            "ids",
            ",",
            " Al",
            "mor",
            "av",
            "ids",
            ",",
            " Al",
            "m",
            "oh",
            "ads",
            ",",
            " Marin",
            "ids",
            ",",
            " H",
            "afs",
            "ids",
            " and",
            " the",
            " Z",
            "ay",
            "yan",
            "ids",
            ".\n\n",
            "Cent",
            "uries",
            " of",
            " Arab",
            " migration",
            " to",
            " the",
            " Mag",
            "h",
            "reb",
            " since",
            " the",
            " ",
            "7",
            "th",
            " century",
            " shifted",
            " the",
            " demographic",
            " scope",
            " in",
            " Algeria",
            ".",
            " The",
            " Spanish",
            " expansion",
            "ism",
            " led",
            " to",
            " the",
            " establishment",
            " of",
            " the",
            " Reg",
            "ency",
            " of",
            " Alg",
            "iers",
            " in",
            " ",
            "151",
            "6",
            ",",
            " a",
            " state",
            " that",
            " attracted",
            " people",
            " from",
            " all",
            " over",
            " the",
            " Mediterranean",
            ",",
            " making",
            " its",
            " capital",
            " Alg",
            "iers",
            " one",
            " of",
            " the",
            " largest",
            ",",
            " wealthiest",
            ",",
            " and",
            " most",
            " cosm",
            "opolitan",
            " cities",
            " in",
            " the",
            " world",
            ".",
            " Its",
            " decline",
            " in",
            " the",
            " ",
            "19",
            "th"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.064,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.4,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.328,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.328,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.324,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.57,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 105,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " de",
            "ities",
            " and",
            " believed",
            " that",
            " Alexander",
            " meant",
            " to",
            " de",
            "ify",
            " himself",
            " by",
            " requiring",
            " it",
            ".",
            " This",
            " cost",
            " him",
            " the",
            " sympath",
            "ies",
            " of",
            " many",
            " of",
            " his",
            " country",
            "men",
            ",",
            " and",
            " he",
            " eventually",
            " abandoned",
            " it",
            ".\n\n",
            "During",
            " the",
            " long",
            " rule",
            " of",
            " the",
            " A",
            "cha",
            "emen",
            "ids",
            ",",
            " the",
            " elite",
            " positions",
            " in",
            " many",
            " segments",
            " of",
            " the",
            " empire",
            " including",
            " the",
            " central",
            " government",
            ",",
            " the",
            " army",
            ",",
            " and",
            " the",
            " many",
            " sat",
            "rap",
            "ies",
            " were",
            " specifically",
            " reserved",
            " for",
            " Iranians",
            " and",
            " to",
            " a",
            " major",
            " degree",
            " Persian",
            " nob",
            "lemen",
            ".",
            " The",
            " latter",
            " were",
            " in",
            " many",
            " cases",
            " additionally",
            " connected",
            " through",
            " marriage",
            " alliances",
            " with",
            " the",
            " royal",
            " A",
            "cha",
            "emen",
            "id",
            " family",
            ".",
            " This",
            " created",
            " a",
            " problem",
            " for",
            " Alexander",
            " as",
            " to",
            " whether",
            " he",
            " had",
            " to",
            " make",
            " use",
            " of",
            " the",
            " various",
            " segments",
            " and",
            " people",
            " that",
            " had",
            " given",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.064,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.4,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.328,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.328,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.324,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.57,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 105,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " de",
            "ities",
            " and",
            " believed",
            " that",
            " Alexander",
            " meant",
            " to",
            " de",
            "ify",
            " himself",
            " by",
            " requiring",
            " it",
            ".",
            " This",
            " cost",
            " him",
            " the",
            " sympath",
            "ies",
            " of",
            " many",
            " of",
            " his",
            " country",
            "men",
            ",",
            " and",
            " he",
            " eventually",
            " abandoned",
            " it",
            ".\n\n",
            "During",
            " the",
            " long",
            " rule",
            " of",
            " the",
            " A",
            "cha",
            "emen",
            "ids",
            ",",
            " the",
            " elite",
            " positions",
            " in",
            " many",
            " segments",
            " of",
            " the",
            " empire",
            " including",
            " the",
            " central",
            " government",
            ",",
            " the",
            " army",
            ",",
            " and",
            " the",
            " many",
            " sat",
            "rap",
            "ies",
            " were",
            " specifically",
            " reserved",
            " for",
            " Iranians",
            " and",
            " to",
            " a",
            " major",
            " degree",
            " Persian",
            " nob",
            "lemen",
            ".",
            " The",
            " latter",
            " were",
            " in",
            " many",
            " cases",
            " additionally",
            " connected",
            " through",
            " marriage",
            " alliances",
            " with",
            " the",
            " royal",
            " A",
            "cha",
            "emen",
            "id",
            " family",
            ".",
            " This",
            " created",
            " a",
            " problem",
            " for",
            " Alexander",
            " as",
            " to",
            " whether",
            " he",
            " had",
            " to",
            " make",
            " use",
            " of",
            " the",
            " various",
            " segments",
            " and",
            " people",
            " that",
            " had",
            " given",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            " screen",
            "writers",
            " to",
            " write",
            " screen",
            "plays",
            " (",
            "while",
            " also",
            " continuing",
            " to",
            " use",
            " story",
            " departments",
            ")",
            " and",
            " screen",
            "plays",
            " had",
            " become",
            " commonplace",
            " for",
            " animated",
            " films",
            " by",
            " the",
            " late",
            " ",
            "198",
            "0",
            "s",
            ".\n\n",
            "Techn",
            "iques",
            "\n\n",
            "Traditional",
            "\n\n",
            "Traditional",
            " animation",
            " (",
            "also",
            " called",
            " cel",
            " animation",
            " or",
            " hand",
            "-d",
            "rawn",
            " animation",
            ")",
            " was",
            " the",
            " process",
            " used",
            " for",
            " most",
            " animated",
            " films",
            " of",
            " the",
            " ",
            "20",
            "th",
            " century",
            ".",
            " The",
            " individual",
            " frames",
            " of",
            " a",
            " traditionally",
            " animated",
            " film",
            " are",
            " photographs",
            " of",
            " drawings",
            ",",
            " first",
            " drawn",
            " on",
            " paper",
            ".",
            " To",
            " create",
            " the",
            " illusion",
            " of",
            " movement",
            ",",
            " each",
            " drawing",
            " differs",
            " slightly",
            " from",
            " the",
            " one",
            " before",
            " it",
            ".",
            " The",
            " anim",
            "ators",
            "'",
            " drawings",
            " are",
            " traced",
            " or",
            " phot",
            "ocop",
            "ied",
            " onto",
            " transparent",
            " acet",
            "ate",
            " sheets",
            " called",
            " c",
            "els",
            ",",
            " which",
            " are",
            " filled",
            " in",
            " with",
            " paints",
            " in"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.48,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 16,
          "is_repeated_datapoint": false,
          "tokens": [
            "odynamic",
            " gas",
            "bag",
            " with",
            " stabil",
            "izing",
            " fins",
            " at",
            " the",
            " back",
            ".",
            " These",
            " soon",
            " became",
            " known",
            " as",
            " bl",
            "imps",
            ".",
            " During",
            " World",
            " War",
            " II",
            ",",
            " this",
            " shape",
            " was",
            " widely",
            " adopted",
            " for",
            " tether",
            "ed",
            " balloons",
            ";",
            " in",
            " windy",
            " weather",
            ",",
            " this",
            " both",
            " reduces",
            " the",
            " strain",
            " on",
            " the",
            " tether",
            " and",
            " stabil",
            "izes",
            " the",
            " balloon",
            ".",
            " The",
            " nickname",
            " bl",
            "imp",
            " was",
            " adopted",
            " along",
            " with",
            " the",
            " shape",
            ".",
            " In",
            " modern",
            " times",
            ",",
            " any",
            " small",
            " dirig",
            "ible",
            " or",
            " air",
            "ship",
            " is",
            " called",
            " a",
            " bl",
            "imp",
            ",",
            " though",
            " a",
            " bl",
            "imp",
            " may",
            " be",
            " un",
            "powered",
            " as",
            " well",
            " as",
            " powered",
            ".\n\n",
            "He",
            "avier",
            "-than",
            "-air",
            " –",
            " aer",
            "ody",
            "nes",
            " \n\n",
            "He",
            "avier",
            "-than",
            "-air",
            " aircraft",
            ",",
            " such",
            " as",
            " airplanes",
            ",",
            " must",
            " find",
            " some",
            " way",
            " to",
            " push",
            " air",
            " or",
            " gas",
            " downwards",
            " so",
            " that",
            " a",
            " reaction",
            " occurs"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.064,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.26,
            0.441,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            0.44,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.226,
            0.404,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.262,
            0.438,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            " frontier",
            " supervision",
            " officers",
            ",",
            " ",
            "182",
            " criminal",
            " investigators",
            " and",
            " ",
            "100",
            " financial",
            " crimes",
            " detectives",
            " and",
            " around",
            " ",
            "90",
            " economic",
            " activity",
            " inspectors",
            ".\n\n",
            "The",
            " National",
            " Police",
            " have",
            " implemented",
            " a",
            " modern",
            "isation",
            " and",
            " development",
            " plan",
            " to",
            " increase",
            " the",
            " capabilities",
            " and",
            " efficiency",
            " of",
            " the",
            " total",
            " force",
            ".",
            " In",
            " addition",
            " to",
            " administrative",
            " re",
            "organisation",
            ",",
            " modern",
            "isation",
            " projects",
            " include",
            " procurement",
            " of",
            " new",
            " vehicles",
            ",",
            " aircraft",
            " and",
            " equipment",
            ",",
            " construction",
            " of",
            " new",
            " police",
            " stations",
            " and",
            " forensic",
            " laboratories",
            ",",
            " re",
            "structured",
            " training",
            " programmes",
            " and",
            " the",
            " replacement",
            " of",
            " AK",
            "M",
            " rifles",
            " with",
            " ",
            "9",
            "Âł",
            "mm",
            " Uz",
            "is",
            " for",
            " officers",
            " in",
            " urban",
            " areas",
            ".\n\n",
            "Justice",
            "\n",
            "A",
            " Supreme",
            " Court",
            " serves",
            " as",
            " a",
            " court",
            " of",
            " appeal",
            ".",
            " The",
            " Constitutional",
            " Court",
            " is",
            " the",
            " supreme",
            " body",
            " of",
            " the",
            " constitutional",
            " jurisdiction",
            ",",
            " established",
            " with",
            " the",
            " approval",
            " of",
            " Law"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.436,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " M",
            "ino",
            "an",
            " civilization",
            " was",
            " a",
            " Bronze",
            " Age",
            " civilization",
            " on",
            " the",
            " island",
            " of",
            " Cre",
            "te",
            " and",
            " other",
            " Ae",
            "ge",
            "an",
            " islands",
            ",",
            " flourishing",
            " from",
            " around",
            " ",
            "300",
            "0",
            " to",
            " ",
            "145",
            "0",
            " BC",
            " before",
            " a",
            " period",
            " of",
            " decline",
            ",",
            " finally",
            " ending",
            " at",
            " around",
            " ",
            "110",
            "0",
            " BC",
            ".",
            " It",
            " represented",
            " the",
            " first",
            " advanced",
            " civilization",
            " in",
            " Europe",
            ",",
            " leaving",
            " behind",
            " massive",
            " building",
            " complexes",
            ",",
            " tools",
            ",",
            " stunning",
            " artwork",
            ",",
            " writing",
            " systems",
            ",",
            " and",
            " a",
            " massive",
            " network",
            " of",
            " trade",
            ".",
            " The",
            " M",
            "ino",
            "an",
            " period",
            " saw",
            " extensive",
            " trade",
            " between",
            " Cre",
            "te",
            ",",
            " Ae",
            "ge",
            "an",
            ",",
            " and",
            " Mediterranean",
            " settlements",
            ",",
            " particularly",
            " the",
            " Near",
            " East",
            ".",
            " The",
            " most",
            " notable",
            " M",
            "ino",
            "an",
            " palace",
            " is",
            " that",
            " of",
            " Kn",
            "oss",
            "os",
            ",",
            " followed",
            " by",
            " that",
            " of",
            " Ph",
            "a",
            "ist",
            "os",
            ".",
            " The"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.42,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 110,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " conventions",
            " aimed",
            " at",
            " stre",
            "ng",
            "thing",
            " its",
            " commitment",
            " to",
            " the",
            " preservation",
            " and",
            " sustainable",
            " management",
            " of",
            " biological",
            " diversity",
            ".",
            " Since",
            " ",
            "199",
            "4",
            ",",
            " the",
            " country",
            " is",
            " a",
            " party",
            " to",
            " the",
            " Convention",
            " on",
            " Biological",
            " Diversity",
            " (",
            "CBD",
            ")",
            " and",
            " its",
            " associated",
            " Cart",
            "ag",
            "ena",
            " and",
            " Nag",
            "oya",
            " Prot",
            "ocols",
            ".",
            " To",
            " uphold",
            " these",
            " commitments",
            ",",
            " it",
            " has",
            " developed",
            " and",
            " implemented",
            " a",
            " comprehensive",
            " National",
            " B",
            "iod",
            "iversity",
            " Strategy",
            " and",
            " Action",
            " Plan",
            " (",
            "N",
            "BS",
            "AP",
            ").",
            " Furthermore",
            ",",
            " Albania",
            " has",
            " established",
            " a",
            " partnership",
            " with",
            " the",
            " International",
            " Union",
            " for",
            " Conservation",
            " of",
            " Nature",
            " (",
            "I",
            "UC",
            "N",
            "),",
            " advancing",
            " its",
            " conservation",
            " efforts",
            " on",
            " both",
            " national",
            " and",
            " international",
            " scales",
            ".",
            " Guid",
            "ed",
            " by",
            " the",
            " I",
            "UC",
            "N",
            ",",
            " the",
            " country",
            " has",
            " made",
            " substantial",
            " progress",
            " in",
            " the",
            " foundation",
            " of",
            " protected",
            " areas",
            " within"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.389,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 93,
          "is_repeated_datapoint": false,
          "tokens": [
            "P",
            "ron",
            "aval",
            ").",
            " The",
            " military",
            " of",
            " Angola",
            " aims",
            " to",
            " modern",
            "ize",
            " its",
            " naval",
            " capability",
            ",",
            " presumably",
            " due",
            " to",
            " a",
            " rise",
            " in",
            " maritime",
            " piracy",
            " within",
            " the",
            " Gulf",
            " of",
            " Guinea",
            " which",
            " may",
            " have",
            " an",
            " adverse",
            " effect",
            " on",
            " the",
            " country",
            "'s",
            " economy",
            ".\n\n",
            "The",
            " navy",
            "'s",
            " current",
            " known",
            " inventory",
            " includes",
            " the",
            " following",
            ":\n\n",
            " Fast",
            " attack",
            " craft",
            "\n",
            " ",
            "4",
            " Mand",
            "ume",
            " class",
            " craft",
            " (",
            "B",
            "az",
            "an",
            " Corm",
            "oran",
            " type",
            ",",
            " refurbished",
            " in",
            " ",
            "200",
            "9",
            ")\n",
            " Patrol",
            " Bo",
            "ats",
            "\n",
            " ",
            "3",
            " ",
            "18",
            ".",
            "3",
            "m",
            " long",
            " Pat",
            "r",
            "ul",
            "heiro",
            " patrol",
            " boats",
            " (",
            "ref",
            "urb",
            "ished",
            " in",
            " ",
            "200",
            "2",
            ")\n",
            " ",
            "5",
            " A",
            "RES",
            "A",
            " PVC",
            "-",
            "170",
            "\n",
            " ",
            "2",
            " Nam",
            "ac",
            "ur",
            "ra",
            "-class",
            " harbour",
            " patrol",
            " boats",
            "\n",
            " Fisheries",
            " Patrol",
            " Bo",
            "ats",
            "\n"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.044,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.057,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.03,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.017,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.373,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 106,
          "is_repeated_datapoint": false,
          "tokens": [
            "-S",
            "enia",
            ".",
            " The",
            " University",
            " of",
            " Ab",
            "ou",
            " Bek",
            "r",
            " Bel",
            "ka",
            "Ã¯",
            "d",
            " in",
            " T",
            "lem",
            "cen",
            " and",
            " University",
            " of",
            " Bat",
            "na",
            " Had",
            "j",
            " Lak",
            "hd",
            "ar",
            " occupy",
            " the",
            " ",
            "26",
            "th",
            " and",
            " ",
            "45",
            "th",
            " row",
            " in",
            " Africa",
            ".",
            " Algeria",
            " was",
            " ranked",
            " ",
            "119",
            "th",
            " in",
            " the",
            " Global",
            " Innovation",
            " Index",
            " in",
            " ",
            "202",
            "3",
            ".\n\n",
            "L",
            "argest",
            " cities",
            "\n\n",
            "Culture",
            "\n\n",
            "Modern",
            " Alger",
            "ian",
            " literature",
            ",",
            " split",
            " between",
            " Arabic",
            ",",
            " Tam",
            "az",
            "ight",
            " and",
            " French",
            ",",
            " has",
            " been",
            " strongly",
            " influenced",
            " by",
            " the",
            " country",
            "'s",
            " recent",
            " history",
            ".",
            " Famous",
            " novel",
            "ists",
            " of",
            " the",
            " ",
            "20",
            "th",
            " century",
            " include",
            " Mohammed",
            " D",
            "ib",
            ",",
            " Albert",
            " Cam",
            "us",
            ",",
            " Kate",
            "b",
            " Y",
            "ac",
            "ine",
            " and",
            " Ah",
            "lam",
            " Most",
            "eg",
            "han",
            "emi",
            " while",
            " Ass",
            "ia",
            " D",
            "je",
            "bar",
            " is",
            " widely"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.004,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.338,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 90,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " U",
            ".S",
            ".",
            " was",
            " relatively",
            " undef",
            "ended",
            ",",
            " so",
            " Spanish",
            " policy",
            " developed",
            " a",
            " combination",
            " of",
            " initiatives",
            ".",
            " Spanish",
            " soft",
            " power",
            " diplom",
            "atically",
            " challenged",
            " the",
            " British",
            " territorial",
            " c",
            "ession",
            " west",
            " to",
            " the",
            " Mississippi",
            " River",
            " and",
            " the",
            " previous",
            " northern",
            " boundaries",
            " of",
            " Spanish",
            " Florida",
            ".",
            " It",
            " imposed",
            " a",
            " high",
            " tariff",
            " on",
            " American",
            " goods",
            ",",
            " then",
            " blocked",
            " American",
            " sett",
            "ler",
            " access",
            " to",
            " the",
            " port",
            " of",
            " New",
            " Orleans",
            ".",
            " Spanish",
            " hard",
            " power",
            " extended",
            " war",
            " alliances",
            " and",
            " arms",
            " to",
            " South",
            "western",
            " N",
            "atives",
            " to",
            " resist",
            " American",
            " settlement",
            ".",
            " A",
            " former",
            " Continental",
            " Army",
            " General",
            ",",
            " James",
            " Wilkinson",
            " settled",
            " in",
            " Kentucky",
            " County",
            ",",
            " Virginia",
            " in",
            " ",
            "178",
            "4",
            ",",
            " and",
            " there",
            " he",
            " foster",
            "ed",
            " sett",
            "ler",
            " se",
            "cession",
            " from",
            " Virginia",
            " during",
            " the",
            " Spanish",
            "-all",
            "ied",
            " Chick",
            "ama",
            "uga",
            " Cherokee",
            " war",
            ".",
            " Beginning",
            " in",
            " "
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.262,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.283,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 118,
          "is_repeated_datapoint": false,
          "tokens": [
            "20",
            "th",
            " century",
            ",",
            " owing",
            " to",
            " resistance",
            " by",
            " native",
            " groups",
            " such",
            " as",
            " the",
            " Cu",
            "am",
            "ato",
            ",",
            " the",
            " Kw",
            "any",
            "ama",
            " and",
            " the",
            " Mb",
            "unda",
            ".\n\n",
            "After",
            " a",
            " pro",
            "tracted",
            " anti",
            "-col",
            "on",
            "ial",
            " struggle",
            ",",
            " Angola",
            " achieved",
            " independence",
            " in",
            " ",
            "197",
            "5",
            " as",
            " a",
            " Marxist",
            "–",
            "Len",
            "in",
            "ist",
            " one",
            "-party",
            " Republic",
            ".",
            " The",
            " country",
            " descended",
            " into",
            " a",
            " devastating",
            " civil",
            " war",
            " the",
            " same",
            " year",
            ",",
            " between",
            " the",
            " ruling",
            " People",
            "'s",
            " Movement",
            " for",
            " the",
            " Liberation",
            " of",
            " Angola",
            " (",
            "M",
            "PL",
            "A",
            "),",
            " backed",
            " by",
            " the",
            " Soviet",
            " Union",
            " and",
            " Cuba",
            ",",
            " the",
            " insurg",
            "ent",
            " National",
            " Union",
            " for",
            " the",
            " Total",
            " Independence",
            " of",
            " Angola",
            ",",
            " an",
            " originally",
            " Mao",
            "ist",
            " and",
            " later",
            " anti",
            "-comm",
            "unist",
            " group",
            " supported",
            " by",
            " the",
            " United",
            " States",
            " and",
            " South",
            " Africa",
            ",",
            " and",
            " the",
            " militant",
            " organization",
            " National",
            " Liberation"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.12,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 100,
          "is_repeated_datapoint": false,
          "tokens": [
            "'s",
            " first",
            " album",
            ",",
            " War",
            "hol",
            " and",
            " band",
            " leader",
            " Lou",
            " Reed",
            " started",
            " to",
            " disagree",
            " more",
            " about",
            " the",
            " direction",
            " the",
            " band",
            " should",
            " take",
            ",",
            " and",
            " their",
            " artistic",
            " friendship",
            " ended",
            ".",
            " In",
            " ",
            "198",
            "9",
            ",",
            " after",
            " War",
            "hol",
            "'s",
            " death",
            ",",
            " Reed",
            " and",
            " John",
            " C",
            "ale",
            " re",
            "-un",
            "ited",
            " for",
            " the",
            " first",
            " time",
            " since",
            " ",
            "197",
            "2",
            " to",
            " write",
            ",",
            " perform",
            ",",
            " record",
            " and",
            " release",
            " the",
            " concept",
            " album",
            " Songs",
            " for",
            " D",
            "rella",
            ",",
            " a",
            " tribute",
            " to",
            " War",
            "hol",
            ".",
            " In",
            " October",
            " ",
            "201",
            "9",
            ",",
            " an",
            " audio",
            " tape",
            " of",
            " publicly",
            " unknown",
            " music",
            " by",
            " Reed",
            ",",
            " based",
            " on",
            " War",
            "h",
            "ols",
            "'",
            " ",
            "197",
            "5",
            " book",
            ",",
            " \"",
            "The",
            " Philosophy",
            " of",
            " Andy",
            " War",
            "hol",
            ":",
            " From",
            " A",
            " to",
            " B",
            " and",
            " Back",
            " Again",
            "\",",
            " was",
            " reported",
            " to",
            " have",
            " been",
            " discovered"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.18,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.247,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            " by",
            " an",
            " intervention",
            " of",
            " Athena",
            ".\n\n",
            "W",
            "or",
            "ship",
            " and",
            " heroic",
            " cult",
            " \n\n",
            "The",
            " tomb",
            " of",
            " Achilles",
            ",",
            " ext",
            "ant",
            " throughout",
            " antiqu",
            "ity",
            " in",
            " T",
            "road",
            ",",
            " was",
            " v",
            "enerated",
            " by",
            " Th",
            "ess",
            "al",
            "ians",
            ",",
            " but",
            " also",
            " by",
            " Persian",
            " expedition",
            "ary",
            " forces",
            ",",
            " as",
            " well",
            " as",
            " by",
            " Alexander",
            " the",
            " Great",
            " and",
            " the",
            " Roman",
            " emperor",
            " Car",
            "ac",
            "alla",
            ".",
            " Achilles",
            "'",
            " cult",
            " was",
            " also",
            " to",
            " be",
            " found",
            " at",
            " other",
            " places",
            ",",
            " e",
            ".",
            " g",
            ".",
            " on",
            " the",
            " island",
            " of",
            " Ast",
            "yp",
            "al",
            "aea",
            " in",
            " the",
            " Spor",
            "ades",
            ",",
            " in",
            " Sp",
            "arta",
            " which",
            " had",
            " a",
            " sanctuary",
            ",",
            " in",
            " Elis",
            " and",
            " in",
            " Achilles",
            "'",
            " homeland",
            " Th",
            "ess",
            "aly",
            ",",
            " as",
            " well",
            " as",
            " in",
            " the",
            " Magn",
            "a",
            " Gra",
            "ec",
            "ia",
            " cities",
            " of",
            " T",
            "arent",
            "um",
            ",",
            " Loc",
            "ri",
            " and",
            " Cro"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.245,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.231,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 20,
          "is_repeated_datapoint": false,
          "tokens": [
            " experiment",
            " in",
            " rented",
            " facilities",
            " at",
            " his",
            " boarding",
            " house",
            ".",
            " Keeping",
            " \"",
            "night",
            " owl",
            "\"",
            " hours",
            ",",
            " he",
            " worried",
            " that",
            " his",
            " work",
            " would",
            " be",
            " discovered",
            " and",
            " took",
            " great",
            " pains",
            " to",
            " lock",
            " up",
            " his",
            " notebooks",
            " and",
            " laboratory",
            " equipment",
            ".",
            " Bell",
            " had",
            " a",
            " specially",
            " made",
            " table",
            " where",
            " he",
            " could",
            " place",
            " his",
            " notes",
            " and",
            " equipment",
            " inside",
            " a",
            " locking",
            " cover",
            ".",
            " Worse",
            " still",
            ",",
            " his",
            " health",
            " deterior",
            "ated",
            " as",
            " he",
            " had",
            " severe",
            " headaches",
            ".",
            " Returning",
            " to",
            " Boston",
            " in",
            " fall",
            " ",
            "187",
            "3",
            ",",
            " Bell",
            " made",
            " a",
            " far",
            "-reaching",
            " decision",
            " to",
            " concentrate",
            " on",
            " his",
            " experiments",
            " in",
            " sound",
            ".\n\n",
            "Dec",
            "iding",
            " to",
            " give",
            " up",
            " his",
            " lucrative",
            " private",
            " Boston",
            " practice",
            ",",
            " Bell",
            " retained",
            " only",
            " two",
            " students",
            ",",
            " six",
            "-year",
            "-old",
            " \"",
            "Ge",
            "org",
            "ie",
            "\"",
            " Sanders",
            ",",
            " deaf",
            " from",
            " birth",
            ",",
            " and",
            " ",
            "15",
            "-year"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.216,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            " her",
            " cheeks",
            " p",
            "uffy",
            ".",
            " Athena",
            " had",
            " also",
            " placed",
            " a",
            " curse",
            " upon",
            " the",
            " instrument",
            ",",
            " that",
            " whoever",
            " would",
            " pick",
            " it",
            " up",
            " would",
            " be",
            " severely",
            " punished",
            ".",
            " When",
            " Mars",
            "yas",
            " played",
            " the",
            " flute",
            ",",
            " everyone",
            " became",
            " fren",
            "z",
            "ied",
            " with",
            " joy",
            ".",
            " This",
            " led",
            " Mars",
            "yas",
            " to",
            " think",
            " that",
            " he",
            " was",
            " better",
            " than",
            " Apollo",
            ",",
            " and",
            " he",
            " challenged",
            " the",
            " god",
            " to",
            " a",
            " musical",
            " contest",
            ".",
            " The",
            " contest",
            " was",
            " judged",
            " by",
            " the",
            " M",
            "uses",
            ",",
            " or",
            " the",
            " nymph",
            "s",
            " of",
            " N",
            "ysa",
            ".",
            " Athena",
            " was",
            " also",
            " present",
            " to",
            " witness",
            " the",
            " contest",
            ".\n\n",
            "M",
            "ars",
            "yas",
            " ta",
            "unted",
            " Apollo",
            " for",
            " \"",
            "w",
            "earing",
            " his",
            " hair",
            " long",
            ",",
            " for",
            " having",
            " a",
            " fair",
            " face",
            " and",
            " smooth",
            " body",
            ",",
            " for",
            " his",
            " skill",
            " in",
            " so",
            " many",
            " arts",
            "\".",
            " He",
            " also",
            " further",
            " said",
            ",\n\n",
            "The"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.165,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.159,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 32,
          "is_repeated_datapoint": false,
          "tokens": [
            " two",
            " models",
            " were",
            " the",
            " beginning",
            " of",
            " the",
            " mass",
            "-produced",
            " S",
            " series",
            " of",
            " performance",
            " cars",
            ".\n\n",
            "A",
            "udi",
            " ",
            "500",
            "0",
            " unintended",
            " acceleration",
            " allegations",
            "\n",
            "Sales",
            " in",
            " the",
            " United",
            " States",
            " fell",
            " after",
            " a",
            " series",
            " of",
            " recalls",
            " from",
            " ",
            "198",
            "2",
            " to",
            " ",
            "198",
            "7",
            " of",
            " Audi",
            " ",
            "500",
            "0",
            " models",
            " associated",
            " with",
            " reported",
            " incidents",
            " of",
            " sudden",
            " unintended",
            " acceleration",
            " linked",
            " to",
            " six",
            " deaths",
            " and",
            " ",
            "700",
            " accidents",
            ".",
            " ",
            " At",
            " the",
            " time",
            ",",
            " N",
            "HT",
            "SA",
            " was",
            " investigating",
            " ",
            "50",
            " car",
            " models",
            " from",
            " ",
            "20",
            " manufacturers",
            " for",
            " sudden",
            " sur",
            "ges",
            " of",
            " power",
            ".\n\n",
            "A",
            " ",
            "60",
            " Minutes",
            " report",
            " aired",
            " ",
            "23",
            " November",
            " ",
            "198",
            "6",
            ",",
            " featuring",
            " interviews",
            " with",
            " six",
            " people",
            " who",
            " had",
            " sued",
            " Audi",
            " after",
            " reporting",
            " unintended",
            " acceleration",
            ",",
            " showing",
            " an",
            " Audi",
            " ",
            "500",
            "0",
            " ostensibly",
            " suffering",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.102,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 58,
          "is_repeated_datapoint": false,
          "tokens": [
            "H",
            "3",
            "BO",
            "3",
            ")\n\n",
            "S",
            "ulf",
            "onic",
            " acids",
            "\n",
            "A",
            " sulf",
            "onic",
            " acid",
            " has",
            " the",
            " general",
            " formula",
            " RS",
            "(=",
            "O",
            ")",
            "2",
            "–",
            "OH",
            ",",
            " where",
            " R",
            " is",
            " an",
            " organic",
            " radical",
            ".\n",
            " Meth",
            "anes",
            "ulf",
            "onic",
            " acid",
            " (",
            "or",
            " mes",
            "y",
            "lic",
            " acid",
            ",",
            " CH",
            "3",
            "SO",
            "3",
            "H",
            ")\n",
            " Eth",
            "anes",
            "ulf",
            "onic",
            " acid",
            " (",
            "or",
            " es",
            "y",
            "lic",
            " acid",
            ",",
            " CH",
            "3",
            "CH",
            "2",
            "SO",
            "3",
            "H",
            ")\n",
            " Ben",
            "zen",
            "es",
            "ulf",
            "onic",
            " acid",
            " (",
            "or",
            " bes",
            "y",
            "lic",
            " acid",
            ",",
            " C",
            "6",
            "H",
            "5",
            "SO",
            "3",
            "H",
            ")\n",
            " p",
            "-T",
            "ol",
            "uen",
            "es",
            "ulf",
            "onic",
            " acid",
            " (",
            "or",
            " to",
            "sy",
            "lic",
            " acid",
            ",",
            " CH",
            "3",
            "C",
            "6",
            "H",
            "4",
            "SO",
            "3",
            "H",
            ")\n",
            " Tr",
            "if",
            "lu",
            "or",
            "om",
            "eth",
            "anes",
            "ulf",
            "onic",
            " acid"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "192",
            "2",
            ",",
            " the",
            " International",
            " Astr",
            "onom",
            "ical",
            " Union",
            " defined",
            " its",
            " recommended",
            " three",
            "-letter",
            " abbreviation",
            ",",
            " \"",
            "A",
            "ri",
            "\".",
            " The",
            " official",
            " boundaries",
            " of",
            " A",
            "ries",
            " were",
            " defined",
            " in",
            " ",
            "193",
            "0",
            " by",
            " Eug",
            "Ã¨ne",
            " Del",
            "porte",
            " as",
            " a",
            " polygon",
            " of",
            " ",
            "12",
            " segments",
            ".",
            " Its",
            " right",
            " asc",
            "ension",
            " is",
            " between",
            " ",
            "1",
            "h",
            " ",
            "46",
            ".",
            "4",
            "m",
            " and",
            " ",
            "3",
            "h",
            " ",
            "29",
            ".",
            "4",
            "m",
            " and",
            " its",
            " decl",
            "ination",
            " is",
            " between",
            " ",
            "10",
            ".",
            "36",
            "Â°",
            " and",
            " ",
            "31",
            ".",
            "22",
            "Â°",
            " in",
            " the",
            " equ",
            "atorial",
            " coordinate",
            " system",
            ".\n\n",
            "In",
            " non",
            "-West",
            "ern",
            " astronomy",
            " \n",
            "In",
            " traditional",
            " Chinese",
            " astronomy",
            ",",
            " stars",
            " from",
            " A",
            "ries",
            " were",
            " used",
            " in",
            " several",
            " const",
            "ell",
            "ations",
            ".",
            " The",
            " brightest",
            " stars",
            "—",
            "Alpha",
            ",",
            " Beta",
            ",",
            " and",
            " Gamma",
            " Ari"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " hundred",
            " years",
            ".",
            " Other",
            " common",
            "al",
            "ities",
            " shared",
            " between",
            " the",
            " two",
            " al",
            "chemical",
            " schools",
            " of",
            " thought",
            " include",
            " discrete",
            " naming",
            " for",
            " ingredients",
            " and",
            " heavy",
            " influence",
            " from",
            " the",
            " natural",
            " elements",
            ".",
            " The",
            " silk",
            " road",
            " provided",
            " a",
            " clear",
            " path",
            " for",
            " the",
            " exchange",
            " of",
            " goods",
            ",",
            " ideas",
            ",",
            " ingredients",
            ",",
            " religion",
            ",",
            " and",
            " many",
            " other",
            " aspects",
            " of",
            " life",
            " with",
            " which",
            " al",
            "chemy",
            " is",
            " intertwined",
            ".\n\n",
            "Where",
            "as",
            " European",
            " al",
            "chemy",
            " eventually",
            " centered",
            " on",
            " the",
            " trans",
            "mutation",
            " of",
            " base",
            " metals",
            " into",
            " noble",
            " metals",
            ",",
            " Chinese",
            " al",
            "chemy",
            " had",
            " a",
            " more",
            " obvious",
            " connection",
            " to",
            " medicine",
            ".",
            " The",
            " philosopher",
            "'s",
            " stone",
            " of",
            " European",
            " al",
            "chem",
            "ists",
            " can",
            " be",
            " compared",
            " to",
            " the",
            " Grand",
            " E",
            "lixir",
            " of",
            " Imm",
            "ortality",
            " sought",
            " by",
            " Chinese",
            " al",
            "chem",
            "ists",
            ".",
            " In",
            " the",
            " her",
            "metic",
            " view",
            ",",
            " these",
            " two",
            " goals",
            " were"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " it",
            " was",
            " almost",
            " ",
            "25",
            "%",
            " different",
            " from",
            " the",
            " atomic",
            " number",
            " of",
            " gold",
            " ,",
            " ),",
            " the",
            " single",
            " element",
            " from",
            " which",
            " R",
            "utherford",
            " made",
            " his",
            " guess",
            ").",
            " Nevertheless",
            ",",
            " in",
            " spite",
            " of",
            " R",
            "utherford",
            "'s",
            " estimation",
            " that",
            " gold",
            " had",
            " a",
            " central",
            " charge",
            " of",
            " about",
            " ",
            "100",
            " (",
            "but",
            " was",
            " element",
            " ",
            " on",
            " the",
            " periodic",
            " table",
            "),",
            " a",
            " month",
            " after",
            " R",
            "utherford",
            "'s",
            " paper",
            " appeared",
            ",",
            " Anton",
            "ius",
            " van",
            " den",
            " Bro",
            "ek",
            " first",
            " formally",
            " suggested",
            " that",
            " the",
            " central",
            " charge",
            " and",
            " number",
            " of",
            " electrons",
            " in",
            " an",
            " atom",
            " were",
            " exactly",
            " equal",
            " to",
            " its",
            " place",
            " in",
            " the",
            " periodic",
            " table",
            " (",
            "also",
            " known",
            " as",
            " element",
            " number",
            ",",
            " atomic",
            " number",
            ",",
            " and",
            " symbol",
            "ized",
            " Z",
            ").",
            " This",
            " eventually",
            " proved",
            " to",
            " be",
            " the",
            " case",
            ".\n\n",
            "M",
            "ose",
            "ley",
            "'s",
            " ",
            "191",
            "3",
            " experiment",
            " \n\n",
            "The"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "mini",
    "ethyst",
    "phalt",
    "sm",
    "ph"
  ],
  "bottom_logits": [
    "WithValue",
    "âĶĶ",
    "@s",
    "Ã¨o",
    " Ortiz"
  ],
  "act_min": -0.0,
  "act_max": 0.715
}

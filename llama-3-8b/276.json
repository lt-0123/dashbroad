{
  "index": 276,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.023,
            0.314,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 72,
          "is_repeated_datapoint": false,
          "tokens": [
            " have",
            " an",
            " ap",
            "ot",
            "ropa",
            "ic",
            " situation",
            ",",
            " where",
            " a",
            " god",
            " originally",
            " bringing",
            " the",
            " plague",
            " was",
            " invoked",
            " to",
            " end",
            " it",
            ".",
            " A",
            "pl",
            "u",
            ",",
            " meaning",
            " the",
            " son",
            " of",
            ",",
            " was",
            " a",
            " title",
            " given",
            " to",
            " the",
            " god",
            " N",
            "erg",
            "al",
            ",",
            " who",
            " was",
            " linked",
            " to",
            " the",
            " Babylon",
            "ian",
            " god",
            " of",
            " the",
            " sun",
            " Sham",
            "ash",
            ".",
            " Homer",
            " interpre",
            "ts",
            " Apollo",
            " as",
            " a",
            " terrible",
            " god",
            " ()",
            " who",
            " brings",
            " death",
            " and",
            " disease",
            " with",
            " his",
            " arrows",
            ",",
            " but",
            " who",
            " can",
            " also",
            " heal",
            ",",
            " possessing",
            " a",
            " magic",
            " art",
            " that",
            " separates",
            " him",
            " from",
            " the",
            " other",
            " Greek",
            " gods",
            ".",
            " In",
            " I",
            "li",
            "ad",
            ",",
            " his",
            " priest",
            " pr",
            "ays",
            " to",
            " Apollo",
            " S",
            "min",
            "the",
            "us",
            ",",
            " the",
            " mouse",
            " god",
            " who",
            " retains",
            " an",
            " older",
            " agricultural",
            " function",
            " as",
            " the",
            " protector",
            " from",
            " field",
            " rats",
            ".",
            " All",
            " these",
            " functions"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            1.023,
            0.314,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 72,
          "is_repeated_datapoint": false,
          "tokens": [
            " have",
            " an",
            " ap",
            "ot",
            "ropa",
            "ic",
            " situation",
            ",",
            " where",
            " a",
            " god",
            " originally",
            " bringing",
            " the",
            " plague",
            " was",
            " invoked",
            " to",
            " end",
            " it",
            ".",
            " A",
            "pl",
            "u",
            ",",
            " meaning",
            " the",
            " son",
            " of",
            ",",
            " was",
            " a",
            " title",
            " given",
            " to",
            " the",
            " god",
            " N",
            "erg",
            "al",
            ",",
            " who",
            " was",
            " linked",
            " to",
            " the",
            " Babylon",
            "ian",
            " god",
            " of",
            " the",
            " sun",
            " Sham",
            "ash",
            ".",
            " Homer",
            " interpre",
            "ts",
            " Apollo",
            " as",
            " a",
            " terrible",
            " god",
            " ()",
            " who",
            " brings",
            " death",
            " and",
            " disease",
            " with",
            " his",
            " arrows",
            ",",
            " but",
            " who",
            " can",
            " also",
            " heal",
            ",",
            " possessing",
            " a",
            " magic",
            " art",
            " that",
            " separates",
            " him",
            " from",
            " the",
            " other",
            " Greek",
            " gods",
            ".",
            " In",
            " I",
            "li",
            "ad",
            ",",
            " his",
            " priest",
            " pr",
            "ays",
            " to",
            " Apollo",
            " S",
            "min",
            "the",
            "us",
            ",",
            " the",
            " mouse",
            " god",
            " who",
            " retains",
            " an",
            " older",
            " agricultural",
            " function",
            " as",
            " the",
            " protector",
            " from",
            " field",
            " rats",
            ".",
            " All",
            " these",
            " functions"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.949,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.141,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 65,
          "is_repeated_datapoint": false,
          "tokens": [
            " well",
            " as",
            " into",
            " one",
            " of",
            " the",
            " following",
            ":\n\n",
            " Linear",
            " programming",
            "\n",
            " When",
            " searching",
            " for",
            " optimal",
            " solutions",
            " to",
            " a",
            " linear",
            " function",
            " bound",
            " to",
            " linear",
            " equality",
            " and",
            " inequality",
            " constraints",
            ",",
            " the",
            " constraints",
            " of",
            " the",
            " problem",
            " can",
            " be",
            " used",
            " directly",
            " in",
            " producing",
            " the",
            " optimal",
            " solutions",
            ".",
            " There",
            " are",
            " algorithms",
            " that",
            " can",
            " solve",
            " any",
            " problem",
            " in",
            " this",
            " category",
            ",",
            " such",
            " as",
            " the",
            " popular",
            " simplex",
            " algorithm",
            ".",
            " Problems",
            " that",
            " can",
            " be",
            " solved",
            " with",
            " linear",
            " programming",
            " include",
            " the",
            " maximum",
            " flow",
            " problem",
            " for",
            " directed",
            " graphs",
            ".",
            " If",
            " a",
            " problem",
            " additionally",
            " requires",
            " that",
            " one",
            " or",
            " more",
            " of",
            " the",
            " unknown",
            "s",
            " must",
            " be",
            " an",
            " integer",
            " then",
            " it",
            " is",
            " classified",
            " in",
            " integer",
            " programming",
            ".",
            " A",
            " linear",
            " programming",
            " algorithm",
            " can",
            " solve",
            " such",
            " a",
            " problem",
            " if",
            " it",
            " can",
            " be",
            " proved",
            " that",
            " all",
            " restrictions",
            " for",
            " integer",
            " values",
            " are",
            " superficial",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.949,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.141,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 65,
          "is_repeated_datapoint": false,
          "tokens": [
            " well",
            " as",
            " into",
            " one",
            " of",
            " the",
            " following",
            ":\n\n",
            " Linear",
            " programming",
            "\n",
            " When",
            " searching",
            " for",
            " optimal",
            " solutions",
            " to",
            " a",
            " linear",
            " function",
            " bound",
            " to",
            " linear",
            " equality",
            " and",
            " inequality",
            " constraints",
            ",",
            " the",
            " constraints",
            " of",
            " the",
            " problem",
            " can",
            " be",
            " used",
            " directly",
            " in",
            " producing",
            " the",
            " optimal",
            " solutions",
            ".",
            " There",
            " are",
            " algorithms",
            " that",
            " can",
            " solve",
            " any",
            " problem",
            " in",
            " this",
            " category",
            ",",
            " such",
            " as",
            " the",
            " popular",
            " simplex",
            " algorithm",
            ".",
            " Problems",
            " that",
            " can",
            " be",
            " solved",
            " with",
            " linear",
            " programming",
            " include",
            " the",
            " maximum",
            " flow",
            " problem",
            " for",
            " directed",
            " graphs",
            ".",
            " If",
            " a",
            " problem",
            " additionally",
            " requires",
            " that",
            " one",
            " or",
            " more",
            " of",
            " the",
            " unknown",
            "s",
            " must",
            " be",
            " an",
            " integer",
            " then",
            " it",
            " is",
            " classified",
            " in",
            " integer",
            " programming",
            ".",
            " A",
            " linear",
            " programming",
            " algorithm",
            " can",
            " solve",
            " such",
            " a",
            " problem",
            " if",
            " it",
            " can",
            " be",
            " proved",
            " that",
            " all",
            " restrictions",
            " for",
            " integer",
            " values",
            " are",
            " superficial",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.081,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.715,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.031,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " become",
            " the",
            " fastest",
            "-growing",
            " economy",
            " in",
            " Africa",
            " and",
            " one",
            " of",
            " the",
            " fastest",
            "-growing",
            " in",
            " the",
            " world",
            ",",
            " with",
            " an",
            " average",
            " GDP",
            " growth",
            " of",
            " ",
            "20",
            "%",
            " between",
            " ",
            "200",
            "5",
            " and",
            " ",
            "200",
            "7",
            ".",
            " In",
            " the",
            " period",
            " ",
            "200",
            "1",
            "–",
            "10",
            ",",
            " Angola",
            " had",
            " the",
            " world",
            "'s",
            " highest",
            " annual",
            " average",
            " GDP",
            " growth",
            ",",
            " at",
            " ",
            "11",
            ".",
            "1",
            "%.\n\n",
            "In",
            " ",
            "200",
            "4",
            ",",
            " the",
            " Ex",
            "im",
            " Bank",
            " of",
            " China",
            " approved",
            " a",
            " $",
            "2",
            "Âłb",
            "illion",
            " line",
            " of",
            " credit",
            " to",
            " Angola",
            ",",
            " to",
            " be",
            " used",
            " for",
            " rebuilding",
            " Angola",
            "'s",
            " infrastructure",
            ",",
            " and",
            " to",
            " limit",
            " the",
            " influence",
            " of",
            " the",
            " International",
            " Monetary",
            " Fund",
            " there",
            ".\n\n",
            "China",
            " is",
            " Angola",
            "'s",
            " biggest",
            " trade",
            " partner",
            " and",
            " export",
            " destination",
            " as",
            " well",
            " as",
            " the",
            " fourth",
            "-largest",
            " source",
            " of",
            " imports",
            ".",
            " Bil"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.081,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.715,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.031,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 22,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " become",
            " the",
            " fastest",
            "-growing",
            " economy",
            " in",
            " Africa",
            " and",
            " one",
            " of",
            " the",
            " fastest",
            "-growing",
            " in",
            " the",
            " world",
            ",",
            " with",
            " an",
            " average",
            " GDP",
            " growth",
            " of",
            " ",
            "20",
            "%",
            " between",
            " ",
            "200",
            "5",
            " and",
            " ",
            "200",
            "7",
            ".",
            " In",
            " the",
            " period",
            " ",
            "200",
            "1",
            "–",
            "10",
            ",",
            " Angola",
            " had",
            " the",
            " world",
            "'s",
            " highest",
            " annual",
            " average",
            " GDP",
            " growth",
            ",",
            " at",
            " ",
            "11",
            ".",
            "1",
            "%.\n\n",
            "In",
            " ",
            "200",
            "4",
            ",",
            " the",
            " Ex",
            "im",
            " Bank",
            " of",
            " China",
            " approved",
            " a",
            " $",
            "2",
            "Âłb",
            "illion",
            " line",
            " of",
            " credit",
            " to",
            " Angola",
            ",",
            " to",
            " be",
            " used",
            " for",
            " rebuilding",
            " Angola",
            "'s",
            " infrastructure",
            ",",
            " and",
            " to",
            " limit",
            " the",
            " influence",
            " of",
            " the",
            " International",
            " Monetary",
            " Fund",
            " there",
            ".\n\n",
            "China",
            " is",
            " Angola",
            "'s",
            " biggest",
            " trade",
            " partner",
            " and",
            " export",
            " destination",
            " as",
            " well",
            " as",
            " the",
            " fourth",
            "-largest",
            " source",
            " of",
            " imports",
            ".",
            " Bil"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.703,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            " central",
            " regions",
            " of",
            " Albania",
            ",",
            " whilst",
            " E",
            "pi",
            "ro",
            "tes",
            " inhabited",
            " the",
            " south",
            ".",
            " Several",
            " important",
            " ancient",
            " Greek",
            " colonies",
            " were",
            " also",
            " established",
            " on",
            " the",
            " coast",
            ".",
            " In",
            " the",
            " ",
            "2",
            "nd",
            " century",
            " BCE",
            ",",
            " the",
            " region",
            " was",
            " annex",
            "ed",
            " by",
            " the",
            " Roman",
            " Republic",
            ",",
            " and",
            " after",
            " the",
            " division",
            " of",
            " the",
            " Roman",
            " Empire",
            " it",
            " became",
            " part",
            " of",
            " Byz",
            "antium",
            ".",
            " The",
            " first",
            " known",
            " Alban",
            "ian",
            " autonomous",
            " princip",
            "ality",
            " –",
            " Ar",
            "ban",
            "on",
            " –",
            " was",
            " established",
            " in",
            " the",
            " ",
            "12",
            "th",
            " century",
            ".",
            " The",
            " Kingdom",
            " of",
            " Albania",
            ",",
            " Princip",
            "ality",
            " of",
            " Albania",
            " and",
            " Albania",
            " Ven",
            "eta",
            " were",
            " formed",
            " between",
            " the",
            " ",
            "13",
            "th",
            " and",
            " ",
            "15",
            "th",
            " centuries",
            " in",
            " different",
            " parts",
            " of",
            " the",
            " country",
            ",",
            " alongside",
            " other",
            " Alban",
            "ian",
            " principal",
            "ities",
            " and",
            " political",
            " entities",
            ".",
            " In",
            " the",
            " late",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.703,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            " central",
            " regions",
            " of",
            " Albania",
            ",",
            " whilst",
            " E",
            "pi",
            "ro",
            "tes",
            " inhabited",
            " the",
            " south",
            ".",
            " Several",
            " important",
            " ancient",
            " Greek",
            " colonies",
            " were",
            " also",
            " established",
            " on",
            " the",
            " coast",
            ".",
            " In",
            " the",
            " ",
            "2",
            "nd",
            " century",
            " BCE",
            ",",
            " the",
            " region",
            " was",
            " annex",
            "ed",
            " by",
            " the",
            " Roman",
            " Republic",
            ",",
            " and",
            " after",
            " the",
            " division",
            " of",
            " the",
            " Roman",
            " Empire",
            " it",
            " became",
            " part",
            " of",
            " Byz",
            "antium",
            ".",
            " The",
            " first",
            " known",
            " Alban",
            "ian",
            " autonomous",
            " princip",
            "ality",
            " –",
            " Ar",
            "ban",
            "on",
            " –",
            " was",
            " established",
            " in",
            " the",
            " ",
            "12",
            "th",
            " century",
            ".",
            " The",
            " Kingdom",
            " of",
            " Albania",
            ",",
            " Princip",
            "ality",
            " of",
            " Albania",
            " and",
            " Albania",
            " Ven",
            "eta",
            " were",
            " formed",
            " between",
            " the",
            " ",
            "13",
            "th",
            " and",
            " ",
            "15",
            "th",
            " centuries",
            " in",
            " different",
            " parts",
            " of",
            " the",
            " country",
            ",",
            " alongside",
            " other",
            " Alban",
            "ian",
            " principal",
            "ities",
            " and",
            " political",
            " entities",
            ".",
            " In",
            " the",
            " late",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.672,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.232,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.289,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.369,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.359,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            " (",
            "196",
            "1",
            " film",
            "),",
            " a",
            " ",
            "196",
            "1",
            " film",
            " by",
            " Daniel",
            " Mann",
            "\n",
            "Ada",
            " (",
            "201",
            "9",
            " film",
            "),",
            " a",
            " short",
            " bi",
            "opic",
            " about",
            " Ada",
            " Lov",
            "el",
            "ace",
            "\n",
            " Ada",
            "...",
            " A",
            " Way",
            " of",
            " Life",
            ",",
            " a",
            " ",
            "200",
            "8",
            " Bollywood",
            " musical",
            " by",
            " Tan",
            "vir",
            " Ahmed",
            "\n",
            " Ada",
            " (",
            "dog",
            " actor",
            "),",
            " a",
            " dog",
            " that",
            " played",
            " Colin",
            " on",
            " the",
            " sitcom",
            " Sp",
            "aced",
            "\n",
            " Ada",
            ",",
            " one",
            " of",
            " the",
            " main",
            " characters",
            " in",
            " ",
            "199",
            "1",
            " movie",
            " Armour",
            " of",
            " God",
            " II",
            ":",
            " Operation",
            " Cond",
            "or",
            "\n\n",
            "B",
            "iology",
            "\n",
            " Ada",
            " (",
            "plant",
            "),",
            " a",
            " genus",
            " of",
            " orch",
            "ids",
            "\n",
            " Ad",
            "enos",
            "ine",
            " de",
            "amin",
            "ase",
            ",",
            " an",
            " enzyme",
            " involved",
            " in",
            " pur",
            "ine",
            " metabolism",
            "\n",
            " Ada",
            " (",
            "protein",
            "),",
            " an",
            " enzyme",
            " induced",
            " by",
            " treatment",
            " of",
            " bacterial",
            " cells",
            "\n\n",
            "Computer"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.672,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.232,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.289,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.369,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.359,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            " (",
            "196",
            "1",
            " film",
            "),",
            " a",
            " ",
            "196",
            "1",
            " film",
            " by",
            " Daniel",
            " Mann",
            "\n",
            "Ada",
            " (",
            "201",
            "9",
            " film",
            "),",
            " a",
            " short",
            " bi",
            "opic",
            " about",
            " Ada",
            " Lov",
            "el",
            "ace",
            "\n",
            " Ada",
            "...",
            " A",
            " Way",
            " of",
            " Life",
            ",",
            " a",
            " ",
            "200",
            "8",
            " Bollywood",
            " musical",
            " by",
            " Tan",
            "vir",
            " Ahmed",
            "\n",
            " Ada",
            " (",
            "dog",
            " actor",
            "),",
            " a",
            " dog",
            " that",
            " played",
            " Colin",
            " on",
            " the",
            " sitcom",
            " Sp",
            "aced",
            "\n",
            " Ada",
            ",",
            " one",
            " of",
            " the",
            " main",
            " characters",
            " in",
            " ",
            "199",
            "1",
            " movie",
            " Armour",
            " of",
            " God",
            " II",
            ":",
            " Operation",
            " Cond",
            "or",
            "\n\n",
            "B",
            "iology",
            "\n",
            " Ada",
            " (",
            "plant",
            "),",
            " a",
            " genus",
            " of",
            " orch",
            "ids",
            "\n",
            " Ad",
            "enos",
            "ine",
            " de",
            "amin",
            "ase",
            ",",
            " an",
            " enzyme",
            " involved",
            " in",
            " pur",
            "ine",
            " metabolism",
            "\n",
            " Ada",
            " (",
            "protein",
            "),",
            " an",
            " enzyme",
            " induced",
            " by",
            " treatment",
            " of",
            " bacterial",
            " cells",
            "\n\n",
            "Computer"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.66,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            "imated",
            " by",
            " the",
            " approach",
            " using",
            " a",
            " normal",
            " linear",
            " model",
            ",",
            " most",
            " teachers",
            " emphasize",
            " the",
            " normal",
            " linear",
            " model",
            " approach",
            ".",
            " Few",
            " statist",
            "icians",
            " object",
            " to",
            " model",
            "-based",
            " analysis",
            " of",
            " balanced",
            " randomized",
            " experiments",
            ".\n\n",
            "Stat",
            "istical",
            " models",
            " for",
            " observational",
            " data",
            "\n",
            "However",
            ",",
            " when",
            " applied",
            " to",
            " data",
            " from",
            " non",
            "-random",
            "ized",
            " experiments",
            " or",
            " observational",
            " studies",
            ",",
            " model",
            "-based",
            " analysis",
            " lacks",
            " the",
            " warrant",
            " of",
            " random",
            "ization",
            ".",
            " For",
            " observational",
            " data",
            ",",
            " the",
            " derivation",
            " of",
            " confidence",
            " intervals",
            " must",
            " use",
            " subjective",
            " models",
            ",",
            " as",
            " emphasized",
            " by",
            " Ronald",
            " Fisher",
            " and",
            " his",
            " followers",
            ".",
            " In",
            " practice",
            ",",
            " the",
            " estimates",
            " of",
            " treatment",
            "-effects",
            " from",
            " observational",
            " studies",
            " generally",
            " are",
            " often",
            " inconsistent",
            ".",
            " In",
            " practice",
            ",",
            " \"",
            "stat",
            "istical",
            " models",
            "\"",
            " and",
            " observational",
            " data",
            " are",
            " useful",
            " for",
            " suggesting",
            " hypotheses",
            " that",
            " should",
            " be",
            " treated",
            " very",
            " cautiously",
            " by",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.01,
            -0.0,
            -0.0,
            0.126,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.186,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.141,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.66,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 78,
          "is_repeated_datapoint": false,
          "tokens": [
            " few",
            " who",
            " knew",
            " him",
            "\".",
            " Many",
            " of",
            " the",
            " animals",
            " who",
            " participated",
            " in",
            " the",
            " rebellion",
            " are",
            " dead",
            " or",
            " old",
            ".",
            " Mr",
            ".",
            " Jones",
            " is",
            " also",
            " now",
            " known",
            " to",
            " be",
            " dead",
            ",",
            " having",
            " \"",
            "d",
            "ied",
            " in",
            " an",
            " in",
            "eb",
            "ri",
            "ates",
            "'",
            " home",
            " in",
            " another",
            " part",
            " of",
            " the",
            " country",
            "\".",
            " The",
            " pigs",
            " start",
            " to",
            " resemble",
            " humans",
            ",",
            " as",
            " they",
            " walk",
            " upright",
            ",",
            " carry",
            " wh",
            "ips",
            ",",
            " drink",
            " alcohol",
            ",",
            " and",
            " wear",
            " clothes",
            ".",
            " The",
            " Seven",
            " Command",
            "ments",
            " are",
            " ab",
            "ridged",
            " to",
            " just",
            " one",
            " phrase",
            ":",
            " \"",
            "All",
            " animals",
            " are",
            " equal",
            ",",
            " but",
            " some",
            " animals",
            " are",
            " more",
            " equal",
            " than",
            " others",
            "\".",
            " The",
            " maxim",
            " \"",
            "Four",
            " legs",
            " good",
            ",",
            " two",
            " legs",
            " bad",
            "\"",
            " is",
            " similarly",
            " changed",
            " to",
            " \"",
            "Four",
            " legs",
            " good",
            ",",
            " two",
            " legs",
            " better",
            "\".",
            " Other",
            " changes",
            " include",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.66,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            "imated",
            " by",
            " the",
            " approach",
            " using",
            " a",
            " normal",
            " linear",
            " model",
            ",",
            " most",
            " teachers",
            " emphasize",
            " the",
            " normal",
            " linear",
            " model",
            " approach",
            ".",
            " Few",
            " statist",
            "icians",
            " object",
            " to",
            " model",
            "-based",
            " analysis",
            " of",
            " balanced",
            " randomized",
            " experiments",
            ".\n\n",
            "Stat",
            "istical",
            " models",
            " for",
            " observational",
            " data",
            "\n",
            "However",
            ",",
            " when",
            " applied",
            " to",
            " data",
            " from",
            " non",
            "-random",
            "ized",
            " experiments",
            " or",
            " observational",
            " studies",
            ",",
            " model",
            "-based",
            " analysis",
            " lacks",
            " the",
            " warrant",
            " of",
            " random",
            "ization",
            ".",
            " For",
            " observational",
            " data",
            ",",
            " the",
            " derivation",
            " of",
            " confidence",
            " intervals",
            " must",
            " use",
            " subjective",
            " models",
            ",",
            " as",
            " emphasized",
            " by",
            " Ronald",
            " Fisher",
            " and",
            " his",
            " followers",
            ".",
            " In",
            " practice",
            ",",
            " the",
            " estimates",
            " of",
            " treatment",
            "-effects",
            " from",
            " observational",
            " studies",
            " generally",
            " are",
            " often",
            " inconsistent",
            ".",
            " In",
            " practice",
            ",",
            " \"",
            "stat",
            "istical",
            " models",
            "\"",
            " and",
            " observational",
            " data",
            " are",
            " useful",
            " for",
            " suggesting",
            " hypotheses",
            " that",
            " should",
            " be",
            " treated",
            " very",
            " cautiously",
            " by",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.047,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.025,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.637,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.023,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " a",
            " theorem",
            " from",
            " Z",
            "FC",
            " than",
            " from",
            " Z",
            "F",
            ".\n\n",
            "The",
            " axiom",
            " of",
            " choice",
            " is",
            " not",
            " the",
            " only",
            " significant",
            " statement",
            " which",
            " is",
            " independent",
            " of",
            " Z",
            "F",
            ".",
            " ",
            " For",
            " example",
            ",",
            " the",
            " generalized",
            " continuum",
            " hypothesis",
            " (",
            "G",
            "CH",
            ")",
            " is",
            " not",
            " only",
            " independent",
            " of",
            " Z",
            "F",
            ",",
            " but",
            " also",
            " independent",
            " of",
            " Z",
            "FC",
            ".",
            " However",
            ",",
            " Z",
            "F",
            " plus",
            " G",
            "CH",
            " implies",
            " AC",
            ",",
            " making",
            " G",
            "CH",
            " a",
            " strictly",
            " stronger",
            " claim",
            " than",
            " AC",
            ",",
            " even",
            " though",
            " they",
            " are",
            " both",
            " independent",
            " of",
            " Z",
            "F",
            ".\n\n",
            "Strong",
            "er",
            " ax",
            "ioms",
            "\n",
            "The",
            " axiom",
            " of",
            " construct",
            "ibility",
            " and",
            " the",
            " generalized",
            " continuum",
            " hypothesis",
            " each",
            " imply",
            " the",
            " axiom",
            " of",
            " choice",
            " and",
            " so",
            " are",
            " strictly",
            " stronger",
            " than",
            " it",
            ".",
            " ",
            " In",
            " class",
            " theories",
            " such",
            " as",
            " Von",
            " Ne",
            "umann",
            "–",
            "Bern",
            "ays",
            "–"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.047,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.025,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.637,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.023,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " a",
            " theorem",
            " from",
            " Z",
            "FC",
            " than",
            " from",
            " Z",
            "F",
            ".\n\n",
            "The",
            " axiom",
            " of",
            " choice",
            " is",
            " not",
            " the",
            " only",
            " significant",
            " statement",
            " which",
            " is",
            " independent",
            " of",
            " Z",
            "F",
            ".",
            " ",
            " For",
            " example",
            ",",
            " the",
            " generalized",
            " continuum",
            " hypothesis",
            " (",
            "G",
            "CH",
            ")",
            " is",
            " not",
            " only",
            " independent",
            " of",
            " Z",
            "F",
            ",",
            " but",
            " also",
            " independent",
            " of",
            " Z",
            "FC",
            ".",
            " However",
            ",",
            " Z",
            "F",
            " plus",
            " G",
            "CH",
            " implies",
            " AC",
            ",",
            " making",
            " G",
            "CH",
            " a",
            " strictly",
            " stronger",
            " claim",
            " than",
            " AC",
            ",",
            " even",
            " though",
            " they",
            " are",
            " both",
            " independent",
            " of",
            " Z",
            "F",
            ".\n\n",
            "Strong",
            "er",
            " ax",
            "ioms",
            "\n",
            "The",
            " axiom",
            " of",
            " construct",
            "ibility",
            " and",
            " the",
            " generalized",
            " continuum",
            " hypothesis",
            " each",
            " imply",
            " the",
            " axiom",
            " of",
            " choice",
            " and",
            " so",
            " are",
            " strictly",
            " stronger",
            " than",
            " it",
            ".",
            " ",
            " In",
            " class",
            " theories",
            " such",
            " as",
            " Von",
            " Ne",
            "umann",
            "–",
            "Bern",
            "ays",
            "–"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.469,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.27,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.367,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " and",
            " the",
            " White",
            " League",
            ".\n\n",
            "Re",
            "construction",
            " in",
            " Alabama",
            " ended",
            " in",
            " ",
            "187",
            "4",
            ",",
            " when",
            " the",
            " Democrats",
            " regained",
            " control",
            " of",
            " the",
            " legislature",
            " and",
            " governor",
            "'s",
            " office",
            " through",
            " an",
            " election",
            " dominated",
            " by",
            " fraud",
            " and",
            " violence",
            ".",
            " They",
            " wrote",
            " another",
            " constitution",
            " in",
            " ",
            "187",
            "5",
            ",",
            " and",
            " the",
            " legislature",
            " passed",
            " the",
            " Bl",
            "aine",
            " Amendment",
            ",",
            " prohibiting",
            " public",
            " money",
            " from",
            " being",
            " used",
            " to",
            " finance",
            " religious",
            "-aff",
            "iliated",
            " schools",
            ".",
            " The",
            " same",
            " year",
            ",",
            " legislation",
            " was",
            " approved",
            " that",
            " called",
            " for",
            " racially",
            " segregated",
            " schools",
            ".",
            " Railroad",
            " passenger",
            " cars",
            " were",
            " segregated",
            " in",
            " ",
            "189",
            "1",
            ".\n\n",
            "20",
            "th",
            " century",
            " \n\n",
            "The",
            " new",
            " ",
            "190",
            "1",
            " Constitution",
            " of",
            " Alabama",
            " included",
            " provisions",
            " for",
            " voter",
            " registration",
            " that",
            " effectively",
            " disen",
            "fr",
            "anch",
            "ised",
            " large",
            " portions",
            " of",
            " the",
            " population",
            ",",
            " including",
            " nearly",
            " all",
            " African",
            " Americans",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 89,
          "is_repeated_datapoint": false,
          "tokens": [
            "ano",
            " Te",
            "ft",
            "a",
            " T",
            "ash",
            "ko",
            "-K",
            "o",
            "Ã§o",
            ".",
            " Several",
            " gram",
            "ophone",
            " compil",
            "ations",
            " were",
            " recorded",
            " at",
            " the",
            " time",
            " by",
            " the",
            " three",
            " artists",
            ",",
            " which",
            " eventually",
            " led",
            " to",
            " the",
            " recognition",
            " of",
            " Alban",
            "ian",
            " iso",
            "-p",
            "oly",
            "phony",
            " as",
            " a",
            " UNESCO",
            " Int",
            "angible",
            " Cultural",
            " Heritage",
            ".\n\n",
            " is",
            " a",
            " traditional",
            " Alban",
            "ian",
            " song",
            " contest",
            " organised",
            " by",
            " the",
            " national",
            " broadcaster",
            " Radio",
            " Te",
            "lev",
            "izioni",
            " Sh",
            "q",
            "ipt",
            "ar",
            " (",
            "RT",
            "SH",
            ").",
            " The",
            " festival",
            " is",
            " celebrated",
            " annually",
            " since",
            " its",
            " inauguration",
            " in",
            " ",
            "196",
            "2",
            " and",
            " has",
            " launched",
            " the",
            " careers",
            " of",
            " some",
            " of",
            " Albania",
            "'s",
            " most",
            " successful",
            " singers",
            " including",
            " Va",
            "Ã§e",
            " Z",
            "ela",
            " and",
            " Par",
            "ash",
            "q",
            "evi",
            " Sim",
            "aku",
            ".",
            " It",
            " is",
            " significantly",
            " a",
            " music",
            " competition",
            " among",
            " Alban",
            "ian",
            " performers",
            " presenting",
            " unre",
            "leased",
            " songs",
            " in",
            " premiere",
            ",",
            " composed"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.465,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.471,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "otle",
            " wrote",
            " his",
            " works",
            " on",
            " p",
            "apyrus",
            " scrolls",
            ",",
            " the",
            " common",
            " writing",
            " medium",
            " of",
            " that",
            " era",
            ".",
            " His",
            " writings",
            " are",
            " divisible",
            " into",
            " two",
            " groups",
            ":",
            " the",
            " \"",
            "ex",
            "oteric",
            "\",",
            " intended",
            " for",
            " the",
            " public",
            ",",
            " and",
            " the",
            " \"",
            "es",
            "oteric",
            "\",",
            " for",
            " use",
            " within",
            " the",
            " Ly",
            "ce",
            "um",
            " school",
            ".",
            " Aristotle",
            "'s",
            " \"",
            "lost",
            "\"",
            " works",
            " stray",
            " considerably",
            " in",
            " characterization",
            " from",
            " the",
            " surviving",
            " Arist",
            "otel",
            "ian",
            " corpus",
            ".",
            " Whereas",
            " the",
            " lost",
            " works",
            " appear",
            " to",
            " have",
            " been",
            " originally",
            " written",
            " with",
            " a",
            " view",
            " to",
            " subsequent",
            " publication",
            ",",
            " the",
            " surviving",
            " works",
            " mostly",
            " resemble",
            " lecture",
            " notes",
            " not",
            " intended",
            " for",
            " publication",
            ".",
            " Cic",
            "ero",
            "'s",
            " description",
            " of",
            " Aristotle",
            "'s",
            " literary",
            " style",
            " as",
            " \"",
            "a",
            " river",
            " of",
            " gold",
            "\"",
            " must",
            " have",
            " applied",
            " to",
            " the",
            " published",
            " works",
            ",",
            " not",
            " the",
            " surviving",
            " notes",
            ".",
            " A"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 89,
          "is_repeated_datapoint": false,
          "tokens": [
            "ano",
            " Te",
            "ft",
            "a",
            " T",
            "ash",
            "ko",
            "-K",
            "o",
            "Ã§o",
            ".",
            " Several",
            " gram",
            "ophone",
            " compil",
            "ations",
            " were",
            " recorded",
            " at",
            " the",
            " time",
            " by",
            " the",
            " three",
            " artists",
            ",",
            " which",
            " eventually",
            " led",
            " to",
            " the",
            " recognition",
            " of",
            " Alban",
            "ian",
            " iso",
            "-p",
            "oly",
            "phony",
            " as",
            " a",
            " UNESCO",
            " Int",
            "angible",
            " Cultural",
            " Heritage",
            ".\n\n",
            " is",
            " a",
            " traditional",
            " Alban",
            "ian",
            " song",
            " contest",
            " organised",
            " by",
            " the",
            " national",
            " broadcaster",
            " Radio",
            " Te",
            "lev",
            "izioni",
            " Sh",
            "q",
            "ipt",
            "ar",
            " (",
            "RT",
            "SH",
            ").",
            " The",
            " festival",
            " is",
            " celebrated",
            " annually",
            " since",
            " its",
            " inauguration",
            " in",
            " ",
            "196",
            "2",
            " and",
            " has",
            " launched",
            " the",
            " careers",
            " of",
            " some",
            " of",
            " Albania",
            "'s",
            " most",
            " successful",
            " singers",
            " including",
            " Va",
            "Ã§e",
            " Z",
            "ela",
            " and",
            " Par",
            "ash",
            "q",
            "evi",
            " Sim",
            "aku",
            ".",
            " It",
            " is",
            " significantly",
            " a",
            " music",
            " competition",
            " among",
            " Alban",
            "ian",
            " performers",
            " presenting",
            " unre",
            "leased",
            " songs",
            " in",
            " premiere",
            ",",
            " composed"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.469,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.27,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.367,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " and",
            " the",
            " White",
            " League",
            ".\n\n",
            "Re",
            "construction",
            " in",
            " Alabama",
            " ended",
            " in",
            " ",
            "187",
            "4",
            ",",
            " when",
            " the",
            " Democrats",
            " regained",
            " control",
            " of",
            " the",
            " legislature",
            " and",
            " governor",
            "'s",
            " office",
            " through",
            " an",
            " election",
            " dominated",
            " by",
            " fraud",
            " and",
            " violence",
            ".",
            " They",
            " wrote",
            " another",
            " constitution",
            " in",
            " ",
            "187",
            "5",
            ",",
            " and",
            " the",
            " legislature",
            " passed",
            " the",
            " Bl",
            "aine",
            " Amendment",
            ",",
            " prohibiting",
            " public",
            " money",
            " from",
            " being",
            " used",
            " to",
            " finance",
            " religious",
            "-aff",
            "iliated",
            " schools",
            ".",
            " The",
            " same",
            " year",
            ",",
            " legislation",
            " was",
            " approved",
            " that",
            " called",
            " for",
            " racially",
            " segregated",
            " schools",
            ".",
            " Railroad",
            " passenger",
            " cars",
            " were",
            " segregated",
            " in",
            " ",
            "189",
            "1",
            ".\n\n",
            "20",
            "th",
            " century",
            " \n\n",
            "The",
            " new",
            " ",
            "190",
            "1",
            " Constitution",
            " of",
            " Alabama",
            " included",
            " provisions",
            " for",
            " voter",
            " registration",
            " that",
            " effectively",
            " disen",
            "fr",
            "anch",
            "ised",
            " large",
            " portions",
            " of",
            " the",
            " population",
            ",",
            " including",
            " nearly",
            " all",
            " African",
            " Americans",
            " and"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.613,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.602,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            "\"",
            " lineage",
            " of",
            " the",
            " Koreans",
            " and",
            " Y",
            "ay",
            "oi",
            " people",
            ".\n\n",
            "A",
            " full",
            " genomic",
            " study",
            " by",
            " Lip",
            "son",
            " et",
            " al",
            ".",
            " (",
            "201",
            "8",
            ")",
            " identified",
            " a",
            " characteristic",
            " lineage",
            " that",
            " can",
            " be",
            " associated",
            " with",
            " the",
            " spread",
            " of",
            " Aust",
            "ro",
            "asi",
            "atic",
            " languages",
            " in",
            " Southeast",
            " Asia",
            " and",
            " which",
            " can",
            " be",
            " traced",
            " back",
            " to",
            " remains",
            " of",
            " Ne",
            "olithic",
            " farmers",
            " from",
            " M",
            "Ã¡n",
            " B",
            "áº¡c",
            " (",
            "ca",
            ".",
            " ",
            "200",
            "0",
            " BCE",
            ")",
            " in",
            " the",
            " Red",
            " River",
            " Delta",
            " in",
            " northern",
            " Vietnam",
            ",",
            " and",
            " to",
            " closely",
            " related",
            " Ban",
            " Ch",
            "iang",
            " and",
            " V",
            "at",
            " Kom",
            "nou",
            " remains",
            " in",
            " Thailand",
            " and",
            " Cambodia",
            " respectively",
            ".",
            " This",
            " Aust",
            "ro",
            "asi",
            "atic",
            " lineage",
            " can",
            " be",
            " modeled",
            " as",
            " a",
            " sister",
            " group",
            " of",
            " the",
            " Austr",
            "ones",
            "ian",
            " peoples",
            " with",
            " significant",
            " adm",
            "ixture",
            " (",
            "ca",
            ".",
            " ",
            "30",
            "%)"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.613,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.602,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            "\"",
            " lineage",
            " of",
            " the",
            " Koreans",
            " and",
            " Y",
            "ay",
            "oi",
            " people",
            ".\n\n",
            "A",
            " full",
            " genomic",
            " study",
            " by",
            " Lip",
            "son",
            " et",
            " al",
            ".",
            " (",
            "201",
            "8",
            ")",
            " identified",
            " a",
            " characteristic",
            " lineage",
            " that",
            " can",
            " be",
            " associated",
            " with",
            " the",
            " spread",
            " of",
            " Aust",
            "ro",
            "asi",
            "atic",
            " languages",
            " in",
            " Southeast",
            " Asia",
            " and",
            " which",
            " can",
            " be",
            " traced",
            " back",
            " to",
            " remains",
            " of",
            " Ne",
            "olithic",
            " farmers",
            " from",
            " M",
            "Ã¡n",
            " B",
            "áº¡c",
            " (",
            "ca",
            ".",
            " ",
            "200",
            "0",
            " BCE",
            ")",
            " in",
            " the",
            " Red",
            " River",
            " Delta",
            " in",
            " northern",
            " Vietnam",
            ",",
            " and",
            " to",
            " closely",
            " related",
            " Ban",
            " Ch",
            "iang",
            " and",
            " V",
            "at",
            " Kom",
            "nou",
            " remains",
            " in",
            " Thailand",
            " and",
            " Cambodia",
            " respectively",
            ".",
            " This",
            " Aust",
            "ro",
            "asi",
            "atic",
            " lineage",
            " can",
            " be",
            " modeled",
            " as",
            " a",
            " sister",
            " group",
            " of",
            " the",
            " Austr",
            "ones",
            "ian",
            " peoples",
            " with",
            " significant",
            " adm",
            "ixture",
            " (",
            "ca",
            ".",
            " ",
            "30",
            "%)"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.613,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.602,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            "\"",
            " lineage",
            " of",
            " the",
            " Koreans",
            " and",
            " Y",
            "ay",
            "oi",
            " people",
            ".\n\n",
            "A",
            " full",
            " genomic",
            " study",
            " by",
            " Lip",
            "son",
            " et",
            " al",
            ".",
            " (",
            "201",
            "8",
            ")",
            " identified",
            " a",
            " characteristic",
            " lineage",
            " that",
            " can",
            " be",
            " associated",
            " with",
            " the",
            " spread",
            " of",
            " Aust",
            "ro",
            "asi",
            "atic",
            " languages",
            " in",
            " Southeast",
            " Asia",
            " and",
            " which",
            " can",
            " be",
            " traced",
            " back",
            " to",
            " remains",
            " of",
            " Ne",
            "olithic",
            " farmers",
            " from",
            " M",
            "Ã¡n",
            " B",
            "áº¡c",
            " (",
            "ca",
            ".",
            " ",
            "200",
            "0",
            " BCE",
            ")",
            " in",
            " the",
            " Red",
            " River",
            " Delta",
            " in",
            " northern",
            " Vietnam",
            ",",
            " and",
            " to",
            " closely",
            " related",
            " Ban",
            " Ch",
            "iang",
            " and",
            " V",
            "at",
            " Kom",
            "nou",
            " remains",
            " in",
            " Thailand",
            " and",
            " Cambodia",
            " respectively",
            ".",
            " This",
            " Aust",
            "ro",
            "asi",
            "atic",
            " lineage",
            " can",
            " be",
            " modeled",
            " as",
            " a",
            " sister",
            " group",
            " of",
            " the",
            " Austr",
            "ones",
            "ian",
            " peoples",
            " with",
            " significant",
            " adm",
            "ixture",
            " (",
            "ca",
            ".",
            " ",
            "30",
            "%)"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.613,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.602,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            "\"",
            " lineage",
            " of",
            " the",
            " Koreans",
            " and",
            " Y",
            "ay",
            "oi",
            " people",
            ".\n\n",
            "A",
            " full",
            " genomic",
            " study",
            " by",
            " Lip",
            "son",
            " et",
            " al",
            ".",
            " (",
            "201",
            "8",
            ")",
            " identified",
            " a",
            " characteristic",
            " lineage",
            " that",
            " can",
            " be",
            " associated",
            " with",
            " the",
            " spread",
            " of",
            " Aust",
            "ro",
            "asi",
            "atic",
            " languages",
            " in",
            " Southeast",
            " Asia",
            " and",
            " which",
            " can",
            " be",
            " traced",
            " back",
            " to",
            " remains",
            " of",
            " Ne",
            "olithic",
            " farmers",
            " from",
            " M",
            "Ã¡n",
            " B",
            "áº¡c",
            " (",
            "ca",
            ".",
            " ",
            "200",
            "0",
            " BCE",
            ")",
            " in",
            " the",
            " Red",
            " River",
            " Delta",
            " in",
            " northern",
            " Vietnam",
            ",",
            " and",
            " to",
            " closely",
            " related",
            " Ban",
            " Ch",
            "iang",
            " and",
            " V",
            "at",
            " Kom",
            "nou",
            " remains",
            " in",
            " Thailand",
            " and",
            " Cambodia",
            " respectively",
            ".",
            " This",
            " Aust",
            "ro",
            "asi",
            "atic",
            " lineage",
            " can",
            " be",
            " modeled",
            " as",
            " a",
            " sister",
            " group",
            " of",
            " the",
            " Austr",
            "ones",
            "ian",
            " peoples",
            " with",
            " significant",
            " adm",
            "ixture",
            " (",
            "ca",
            ".",
            " ",
            "30",
            "%)"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.613,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.602,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            "\"",
            " lineage",
            " of",
            " the",
            " Koreans",
            " and",
            " Y",
            "ay",
            "oi",
            " people",
            ".\n\n",
            "A",
            " full",
            " genomic",
            " study",
            " by",
            " Lip",
            "son",
            " et",
            " al",
            ".",
            " (",
            "201",
            "8",
            ")",
            " identified",
            " a",
            " characteristic",
            " lineage",
            " that",
            " can",
            " be",
            " associated",
            " with",
            " the",
            " spread",
            " of",
            " Aust",
            "ro",
            "asi",
            "atic",
            " languages",
            " in",
            " Southeast",
            " Asia",
            " and",
            " which",
            " can",
            " be",
            " traced",
            " back",
            " to",
            " remains",
            " of",
            " Ne",
            "olithic",
            " farmers",
            " from",
            " M",
            "Ã¡n",
            " B",
            "áº¡c",
            " (",
            "ca",
            ".",
            " ",
            "200",
            "0",
            " BCE",
            ")",
            " in",
            " the",
            " Red",
            " River",
            " Delta",
            " in",
            " northern",
            " Vietnam",
            ",",
            " and",
            " to",
            " closely",
            " related",
            " Ban",
            " Ch",
            "iang",
            " and",
            " V",
            "at",
            " Kom",
            "nou",
            " remains",
            " in",
            " Thailand",
            " and",
            " Cambodia",
            " respectively",
            ".",
            " This",
            " Aust",
            "ro",
            "asi",
            "atic",
            " lineage",
            " can",
            " be",
            " modeled",
            " as",
            " a",
            " sister",
            " group",
            " of",
            " the",
            " Austr",
            "ones",
            "ian",
            " peoples",
            " with",
            " significant",
            " adm",
            "ixture",
            " (",
            "ca",
            ".",
            " ",
            "30",
            "%)"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.613,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.602,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            "\"",
            " lineage",
            " of",
            " the",
            " Koreans",
            " and",
            " Y",
            "ay",
            "oi",
            " people",
            ".\n\n",
            "A",
            " full",
            " genomic",
            " study",
            " by",
            " Lip",
            "son",
            " et",
            " al",
            ".",
            " (",
            "201",
            "8",
            ")",
            " identified",
            " a",
            " characteristic",
            " lineage",
            " that",
            " can",
            " be",
            " associated",
            " with",
            " the",
            " spread",
            " of",
            " Aust",
            "ro",
            "asi",
            "atic",
            " languages",
            " in",
            " Southeast",
            " Asia",
            " and",
            " which",
            " can",
            " be",
            " traced",
            " back",
            " to",
            " remains",
            " of",
            " Ne",
            "olithic",
            " farmers",
            " from",
            " M",
            "Ã¡n",
            " B",
            "áº¡c",
            " (",
            "ca",
            ".",
            " ",
            "200",
            "0",
            " BCE",
            ")",
            " in",
            " the",
            " Red",
            " River",
            " Delta",
            " in",
            " northern",
            " Vietnam",
            ",",
            " and",
            " to",
            " closely",
            " related",
            " Ban",
            " Ch",
            "iang",
            " and",
            " V",
            "at",
            " Kom",
            "nou",
            " remains",
            " in",
            " Thailand",
            " and",
            " Cambodia",
            " respectively",
            ".",
            " This",
            " Aust",
            "ro",
            "asi",
            "atic",
            " lineage",
            " can",
            " be",
            " modeled",
            " as",
            " a",
            " sister",
            " group",
            " of",
            " the",
            " Austr",
            "ones",
            "ian",
            " peoples",
            " with",
            " significant",
            " adm",
            "ixture",
            " (",
            "ca",
            ".",
            " ",
            "30",
            "%)"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.535,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.566,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.555,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.547,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.57,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 9,
          "is_repeated_datapoint": false,
          "tokens": [
            "ck",
            " plays",
            " am",
            "nes",
            "iac",
            " Dr",
            ".",
            " Anthony",
            " Edward",
            "es",
            " under",
            " the",
            " treatment",
            " of",
            " analyst",
            " Dr",
            ".",
            " Peterson",
            " (",
            "In",
            "grid",
            " Berg",
            "man",
            "),",
            " who",
            " falls",
            " in",
            " love",
            " with",
            " him",
            " while",
            " trying",
            " to",
            " unlock",
            " his",
            " re",
            "pressed",
            " past",
            ".",
            " Two",
            " point",
            "-of",
            "-view",
            " shots",
            " were",
            " achieved",
            " by",
            " building",
            " a",
            " large",
            " wooden",
            " hand",
            " (",
            "which",
            " would",
            " appear",
            " to",
            " belong",
            " to",
            " the",
            " character",
            " whose",
            " point",
            " of",
            " view",
            " the",
            " camera",
            " took",
            ")",
            " and",
            " out",
            "-sized",
            " props",
            " for",
            " it",
            " to",
            " hold",
            ":",
            " a",
            " bucket",
            "-sized",
            " glass",
            " of",
            " milk",
            " and",
            " a",
            " large",
            " wooden",
            " gun",
            ".",
            " For",
            " added",
            " novelty",
            " and",
            " impact",
            ",",
            " the",
            " clim",
            "actic",
            " gunshot",
            " was",
            " hand",
            "-col",
            "oured",
            " red",
            " on",
            " some",
            " copies",
            " of",
            " the",
            " black",
            "-and",
            "-white",
            " film",
            ".",
            " The",
            " original",
            " musical",
            " score",
            " by",
            " Mik",
            "l",
            "Ã³s",
            " R",
            "Ã³z",
            "sa",
            " makes"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0,
            -0.0,
            0.447,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.373,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.361,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.363,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 21,
          "is_repeated_datapoint": false,
          "tokens": [
            " close",
            " to",
            " the",
            " K",
            "–",
            "Pg",
            " boundary",
            "—the",
            " \"",
            "three",
            "-meter",
            " problem",
            "\"—",
            "s",
            "uggested",
            " a",
            " more",
            " gradual",
            " die",
            "-off",
            " of",
            " fossil",
            " species",
            ".\n\n",
            "There",
            " is",
            " broad",
            " consensus",
            " that",
            " the",
            " Chic",
            "x",
            "ul",
            "ub",
            " impact",
            "or",
            " was",
            " an",
            " asteroid",
            " with",
            " a",
            " carbon",
            "aceous",
            " ch",
            "ond",
            "rite",
            " composition",
            ",",
            " rather",
            " than",
            " a",
            " comet",
            ".",
            " The",
            " impact",
            "or",
            " was",
            " around",
            " ",
            " in",
            " diameter",
            "—",
            "large",
            " enough",
            " that",
            ",",
            " if",
            " set",
            " at",
            " sea",
            " level",
            ",",
            " it",
            " would",
            " have",
            " reached",
            " taller",
            " than",
            " Mount",
            " Everest",
            ".\n\n",
            "A",
            "ster",
            "oid",
            " def",
            "lection",
            " strategies",
            " \n\n",
            "Various",
            " collision",
            " avoidance",
            " techniques",
            " have",
            " different",
            " trade",
            "-offs",
            " with",
            " respect",
            " to",
            " metrics",
            " such",
            " as",
            " overall",
            " performance",
            ",",
            " cost",
            ",",
            " failure",
            " risks",
            ",",
            " operations",
            ",",
            " and",
            " technology",
            " readiness",
            ".",
            " There",
            " are",
            " various",
            " methods",
            " for",
            " changing",
            " the",
            " course",
            " of",
            " an",
            " asteroid"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.318,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.281,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.309,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.289,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.606,
            -0.0
          ],
          "train_token_ind": 125,
          "is_repeated_datapoint": false,
          "tokens": [
            " that",
            " have",
            " been",
            " investigated",
            ".\n\n",
            "Po",
            "ison",
            "ous",
            " species",
            " often",
            " use",
            " bright",
            " colour",
            "ing",
            " to",
            " warn",
            " potential",
            " predators",
            " of",
            " their",
            " toxicity",
            ".",
            " These",
            " warning",
            " colours",
            " tend",
            " to",
            " be",
            " red",
            " or",
            " yellow",
            " combined",
            " with",
            " black",
            ",",
            " with",
            " the",
            " fire",
            " sal",
            "am",
            "ander",
            " (",
            "S",
            "alam",
            "andra",
            " sal",
            "am",
            "andra",
            ")",
            " being",
            " an",
            " example",
            ".",
            " Once",
            " a",
            " predator",
            " has",
            " sampled",
            " one",
            " of",
            " these",
            ",",
            " it",
            " is",
            " likely",
            " to",
            " remember",
            " the",
            " colour",
            "ation",
            " next",
            " time",
            " it",
            " encounters",
            " a",
            " similar",
            " animal",
            ".",
            " In",
            " some",
            " species",
            ",",
            " such",
            " as",
            " the",
            " fire",
            "-b",
            "ell",
            "ied",
            " to",
            "ad",
            " (",
            "Bomb",
            "ina",
            " spp",
            ".),",
            " the",
            " warning",
            " colour",
            "ation",
            " is",
            " on",
            " the",
            " belly",
            " and",
            " these",
            " animals",
            " adopt",
            " a",
            " defensive",
            " pose",
            " when",
            " attacked",
            ",",
            " exhibiting",
            " their",
            " bright",
            " colours",
            " to",
            " the",
            " predator",
            ".",
            " The",
            " frog",
            " Al",
            "lob",
            "ates"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.359,
            -0.0,
            -0.0,
            -0.0,
            0.414,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.451,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.007,
            -0.0,
            -0.0,
            0.438,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.048,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " secondary",
            " thick",
            "ening",
            " which",
            " is",
            " otherwise",
            " only",
            " found",
            " in",
            " Dios",
            "core",
            "a",
            " (",
            "in",
            " the",
            " monoc",
            "ot",
            " order",
            " Dis",
            "os",
            "core",
            "ales",
            ").",
            " In",
            " a",
            " process",
            " called",
            " '",
            "an",
            "om",
            "alous",
            " secondary",
            " growth",
            "',",
            " they",
            " are",
            " able",
            " to",
            " create",
            " new",
            " vascular",
            " bundles",
            " around",
            " which",
            " thick",
            "ening",
            " growth",
            " occurs",
            ".",
            " Ag",
            "ave",
            ",",
            " Y",
            "ucc",
            "a",
            ",",
            " A",
            "loe",
            ",",
            " Dr",
            "aca",
            "ena",
            ",",
            " N",
            "olina",
            " and",
            " Cord",
            "y",
            "line",
            " can",
            " become",
            " massive",
            " trees",
            ",",
            " albeit",
            " not",
            " of",
            " the",
            " height",
            " of",
            " the",
            " tallest",
            " dic",
            "ots",
            ",",
            " and",
            " with",
            " less",
            " branching",
            ".",
            " Other",
            " genera",
            " in",
            " the",
            " order",
            ",",
            " such",
            " as",
            " L",
            "om",
            "andra",
            " and",
            " A",
            "phy",
            "ll",
            "an",
            "thes",
            ",",
            " have",
            " the",
            " same",
            " type",
            " of",
            " secondary",
            " growth",
            " but",
            " confined",
            " to",
            " their",
            " underground",
            " stems",
            ".\n",
            " Micro",
            "spor",
            "ogenesis",
            " ("
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " was",
            " committed",
            " permanently",
            " to",
            " Bur",
            "gh",
            "Ã¶l",
            "z",
            "li",
            ",",
            " the",
            " Psych",
            "iatric",
            " University",
            " Hospital",
            " in",
            " Z",
            "Ã¼r",
            "ich",
            ".\n\n",
            "190",
            "2",
            "–",
            "190",
            "9",
            ":",
            " Assistant",
            " at",
            " the",
            " Swiss",
            " Patent",
            " Office",
            " \n",
            "E",
            "instein",
            " graduated",
            " from",
            " the",
            " Federal",
            " poly",
            "techn",
            "ic",
            " school",
            " in",
            " ",
            "190",
            "0",
            ",",
            " duly",
            " certified",
            " as",
            " competent",
            " to",
            " teach",
            " mathematics",
            " and",
            " physics",
            ".",
            " His",
            " successful",
            " acquisition",
            " of",
            " Swiss",
            " citizenship",
            " in",
            " February",
            " ",
            "190",
            "1",
            " was",
            " not",
            " followed",
            " by",
            " the",
            " usual",
            " sequel",
            " of",
            " cons",
            "cription",
            ";",
            " the",
            " Swiss",
            " authorities",
            " deemed",
            " him",
            " medically",
            " unfit",
            " for",
            " military",
            " service",
            ".",
            " He",
            " found",
            " that",
            " Swiss",
            " schools",
            " too",
            " appeared",
            " to",
            " have",
            " no",
            " use",
            " for",
            " him",
            ",",
            " failing",
            " to",
            " offer",
            " him",
            " a",
            " teaching",
            " position",
            " despite",
            " the",
            " almost",
            " two",
            " years",
            " that",
            " he",
            " spent",
            " applying",
            " for",
            " one",
            ".",
            " Eventually",
            " it",
            " was"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.023,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            0.436,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 102,
          "is_repeated_datapoint": false,
          "tokens": [
            " is",
            " actually",
            " happening",
            ".\n\n",
            "He",
            " sought",
            " to",
            " train",
            " our",
            " awareness",
            " of",
            " abstract",
            "ing",
            ",",
            " using",
            " techniques",
            " he",
            " had",
            " derived",
            " from",
            " his",
            " study",
            " of",
            " mathematics",
            " and",
            " science",
            ".",
            " He",
            " called",
            " this",
            " awareness",
            ",",
            " this",
            " goal",
            " of",
            " his",
            " system",
            ",",
            " \"",
            "conscious",
            "ness",
            " of",
            " abstract",
            "ing",
            "\".",
            " His",
            " system",
            " included",
            " the",
            " promotion",
            " of",
            " attitudes",
            " such",
            " as",
            " \"",
            "I",
            " don",
            "'t",
            " know",
            ";",
            " let",
            "'s",
            " see",
            ",\"",
            " in",
            " order",
            " that",
            " we",
            " may",
            " better",
            " discover",
            " or",
            " reflect",
            " on",
            " its",
            " realities",
            " as",
            " revealed",
            " by",
            " modern",
            " science",
            ".",
            " Another",
            " technique",
            " involved",
            " becoming",
            " inward",
            "ly",
            " and",
            " outward",
            "ly",
            " quiet",
            ",",
            " an",
            " experience",
            " he",
            " termed",
            ",",
            " \"",
            "sil",
            "ence",
            " on",
            " the",
            " objective",
            " levels",
            "\".\n\n",
            "\"To",
            " be",
            "\"\n",
            "Many",
            " devote",
            "es",
            " and",
            " critics",
            " of",
            " Kor",
            "zy",
            "bs",
            "ki",
            " reduced",
            " his",
            " rather",
            " complex",
            " system",
            " to",
            " a",
            " simple"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            0.443,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 43,
          "is_repeated_datapoint": false,
          "tokens": [
            " black",
            ",",
            " red",
            ",",
            " green",
            ",",
            " or",
            " blue",
            ".\n\n",
            "The",
            " study",
            " of",
            " algae",
            " is",
            " most",
            " commonly",
            " called",
            " ph",
            "yc",
            "ology",
            " ();",
            " the",
            " term",
            " alg",
            "ology",
            " is",
            " falling",
            " out",
            " of",
            " use",
            ".\n\n",
            "Class",
            "ifications",
            "\n\n",
            "One",
            " definition",
            " of",
            " algae",
            " is",
            " that",
            " they",
            " \"",
            "have",
            " chlor",
            "oph",
            "yll",
            " as",
            " their",
            " primary",
            " photos",
            "yn",
            "thetic",
            " pigment",
            " and",
            " lack",
            " a",
            " sterile",
            " covering",
            " of",
            " cells",
            " around",
            " their",
            " reproductive",
            " cells",
            "\".",
            " On",
            " the",
            " other",
            " hand",
            ",",
            " the",
            " color",
            "less",
            " Proto",
            "th",
            "eca",
            " under",
            " Chlor",
            "ophy",
            "ta",
            " are",
            " all",
            " devoid",
            " of",
            " any",
            " chlor",
            "oph",
            "yll",
            ".",
            " Although",
            " cyan",
            "ob",
            "acteria",
            " are",
            " often",
            " referred",
            " to",
            " as",
            " \"",
            "blue",
            "-green",
            " algae",
            "\",",
            " most",
            " authorities",
            " exclude",
            " all",
            " pro",
            "k",
            "ary",
            "otes",
            ",",
            " including",
            " cyan",
            "ob",
            "acteria",
            ",",
            " from",
            " the",
            " definition",
            " of",
            " algae",
            ".\n\n",
            "The",
            " algae",
            " contain",
            " chlor"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.023,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.594,
            -0.0,
            -0.0,
            0.436,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 110,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " number",
            ")",
            " are",
            " used",
            ".",
            " The",
            " passive",
            " voice",
            " uses",
            " the",
            " same",
            " person",
            "/",
            "number",
            "/g",
            "ender",
            " aff",
            "ix",
            "es",
            " but",
            " changes",
            " the",
            " vowels",
            " of",
            " the",
            " stem",
            ".\n\n",
            "The",
            " following",
            " shows",
            " a",
            " paradigm",
            " of",
            " a",
            " regular",
            " Arabic",
            " verb",
            ",",
            "  ",
            " '",
            "to",
            " write",
            "'.",
            " In",
            " Modern",
            " Standard",
            ",",
            " the",
            " energetic",
            " mood",
            ",",
            " in",
            " either",
            " long",
            " or",
            " short",
            " form",
            ",",
            " which",
            " have",
            " the",
            " same",
            " meaning",
            ",",
            " is",
            " almost",
            " never",
            " used",
            ".\n\n",
            "Der",
            "ivation",
            "\n",
            "Like",
            " other",
            " Sem",
            "itic",
            " languages",
            ",",
            " and",
            " unlike",
            " most",
            " other",
            " languages",
            ",",
            " Arabic",
            " makes",
            " much",
            " more",
            " use",
            " of",
            " non",
            "concat",
            "en",
            "ative",
            " morphology",
            ",",
            " applying",
            " many",
            " templates",
            " applied",
            " roots",
            ",",
            " to",
            " derive",
            " words",
            " than",
            " adding",
            " prefixes",
            " or",
            " suffix",
            "es",
            " to",
            " words",
            ".\n\n",
            "For",
            " verbs",
            ",",
            " a",
            " given",
            " root",
            " can",
            " occur",
            " in",
            " many",
            " different",
            " derived"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.031,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 62,
          "is_repeated_datapoint": false,
          "tokens": [
            " neurons",
            " in",
            " the",
            " body",
            " wall",
            " cause",
            " a",
            " local",
            " reaction",
            " to",
            " a",
            " stimulus",
            ".",
            " In",
            " more",
            " complex",
            " animals",
            ",",
            " specialized",
            " receptor",
            " cells",
            " such",
            " as",
            " chem",
            "ore",
            "ceptors",
            " and",
            " phot",
            "ore",
            "ceptors",
            " are",
            " found",
            " in",
            " groups",
            " and",
            " send",
            " messages",
            " along",
            " neural",
            " networks",
            " to",
            " other",
            " parts",
            " of",
            " the",
            " organism",
            ".",
            " Ne",
            "urons",
            " can",
            " be",
            " connected",
            " together",
            " in",
            " gang",
            "lia",
            ".",
            " In",
            " higher",
            " animals",
            ",",
            " specialized",
            " receptors",
            " are",
            " the",
            " basis",
            " of",
            " sense",
            " organs",
            " and",
            " there",
            " is",
            " a",
            " central",
            " nervous",
            " system",
            " (",
            "brain",
            " and",
            " spinal",
            " cord",
            ")",
            " and",
            " a",
            " peripheral",
            " nervous",
            " system",
            ".",
            " The",
            " latter",
            " consists",
            " of",
            " sensory",
            " nerves",
            " that",
            " transmit",
            " information",
            " from",
            " sense",
            " organs",
            " and",
            " motor",
            " nerves",
            " that",
            " influence",
            " target",
            " organs",
            ".",
            " The",
            " peripheral",
            " nervous",
            " system",
            " is",
            " divided",
            " into",
            " the",
            " som",
            "atic",
            " nervous",
            " system",
            " which",
            " con",
            "veys",
            " sensation",
            " and",
            " controls",
            " voluntary"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.019,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.559,
            -0.0
          ],
          "train_token_ind": 119,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " highest",
            " rate",
            " of",
            " out",
            "migration",
            " relative",
            " to",
            " its",
            " population",
            " in",
            " the",
            " world",
            ".",
            " In",
            " ",
            "202",
            "2",
            " the",
            " birth",
            " rate",
            " was",
            " ",
            "20",
            "%",
            " lower",
            " than",
            " in",
            " ",
            "202",
            "1",
            ",",
            " largely",
            " due",
            " to",
            " em",
            "igration",
            " of",
            " people",
            " of",
            " child",
            "bearing",
            " age",
            ".\n\n",
            "About",
            " ",
            "53",
            ".",
            "4",
            "%",
            " of",
            " the",
            " country",
            "'s",
            " population",
            " lives",
            " in",
            " cities",
            ".",
            " The",
            " three",
            " largest",
            " counties",
            " by",
            " population",
            " account",
            " for",
            " half",
            " of",
            " the",
            " total",
            " population",
            ".",
            " Almost",
            " ",
            "30",
            "%",
            " of",
            " the",
            " total",
            " population",
            " is",
            " found",
            " in",
            " Tir",
            "ana",
            " County",
            " followed",
            " by",
            " F",
            "ier",
            " County",
            " with",
            " ",
            "11",
            "%",
            " and",
            " D",
            "urr",
            "Ã«",
            "s",
            " County",
            " with",
            " ",
            "10",
            "%.",
            " Over",
            " one",
            " million",
            " people",
            " are",
            " concentrated",
            " in",
            " Tir",
            "ana",
            " and",
            " D",
            "urr",
            "Ã«",
            "s",
            ",",
            " making",
            " it",
            " the",
            " largest",
            " urban",
            " area"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.015,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.582,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.02,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.018,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.042,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.018,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.012,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.004,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.57,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.033,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.015,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            " Last",
            " Gl",
            "acial",
            " Maximum",
            " (",
            "L",
            "GM",
            ")",
            " ",
            "20",
            ",",
            "000",
            " years",
            " ago",
            " humans",
            " had",
            " to",
            " abandon",
            " their",
            " initial",
            " settlements",
            " along",
            " the",
            " European",
            " North",
            " Atlantic",
            " coast",
            " and",
            " retreat",
            " to",
            " the",
            " Mediterranean",
            ".",
            " Following",
            " rapid",
            " climate",
            " changes",
            " at",
            " the",
            " end",
            " of",
            " the",
            " L",
            "GM",
            " this",
            " region",
            " was",
            " rep",
            "op",
            "ulated",
            " by",
            " Mag",
            "d",
            "alen",
            "ian",
            " culture",
            ".",
            " Other",
            " hunter",
            "-g",
            "ather",
            "ers",
            " followed",
            " in",
            " waves",
            " interrupted",
            " by",
            " large",
            "-scale",
            " hazards",
            " such",
            " as",
            " the",
            " La",
            "acher",
            " See",
            " volcanic",
            " eruption",
            ",",
            " the",
            " inund",
            "ation",
            " of",
            " Dog",
            "ger",
            "land",
            " (",
            "now",
            " the",
            " North",
            " Sea",
            "),",
            " and",
            " the",
            " formation",
            " of",
            " the",
            " Baltic",
            " Sea",
            ".",
            " The",
            " European",
            " co",
            "asts",
            " of",
            " the",
            " North",
            " Atlantic",
            " were",
            " permanently",
            " populated",
            " about",
            " ",
            "9",
            "–",
            "8",
            ".",
            "5",
            " thousand",
            " years",
            " ago",
            ".\n\n",
            "This",
            " human",
            " dispers",
            "al",
            " left"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.438,
            -0.0,
            -0.0,
            -0.0,
            0.578,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.438,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 31,
          "is_repeated_datapoint": false,
          "tokens": [
            " on",
            " October",
            " ",
            "28",
            " at",
            " the",
            " Battle",
            " of",
            " White",
            " Plains",
            ",",
            " and",
            " instead",
            " attacked",
            " a",
            " hill",
            " that",
            " was",
            " of",
            " no",
            " strategic",
            " value",
            ".\n\n",
            "Washington",
            "'s",
            " retreat",
            " isolated",
            " his",
            " remaining",
            " forces",
            " and",
            " the",
            " British",
            " captured",
            " Fort",
            " Washington",
            " on",
            " November",
            " ",
            "16",
            ".",
            " The",
            " British",
            " victory",
            " there",
            " amounted",
            " to",
            " Washington",
            "'s",
            " most",
            " disastrous",
            " defeat",
            " with",
            " the",
            " loss",
            " of",
            " ",
            "3",
            ",",
            "000",
            " prisoners",
            ".",
            " The",
            " remaining",
            " American",
            " reg",
            "iments",
            " on",
            " Long",
            " Island",
            " fell",
            " back",
            " four",
            " days",
            " later",
            ".",
            " General",
            " Henry",
            " Clinton",
            " wanted",
            " to",
            " pursue",
            " Washington",
            "'s",
            " dis",
            "organized",
            " army",
            ",",
            " but",
            " he",
            " was",
            " first",
            " required",
            " to",
            " commit",
            " ",
            "6",
            ",",
            "000",
            " troops",
            " to",
            " capture",
            " Newport",
            ",",
            " Rhode",
            " Island",
            " to",
            " secure",
            " the",
            " L",
            "oyal",
            "ist",
            " port",
            ".",
            " General",
            " Charles",
            " Cornwall",
            "is",
            " pursued",
            " Washington",
            ",",
            " but",
            " Howe",
            " ordered",
            " him",
            " to",
            " halt"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.016,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.562,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 120,
          "is_repeated_datapoint": false,
          "tokens": [
            " possible",
            " interpretations",
            " of",
            " the",
            " word",
            ".\n\n",
            " ()",
            " is",
            " mainly",
            " used",
            " in",
            " compounds",
            " to",
            " mean",
            " '",
            "combine",
            ",",
            " unite",
            ",",
            " join",
            " together",
            ",",
            " meet",
            "',",
            " examples",
            " being",
            " ",
            " (",
            "combined",
            "/un",
            "ited",
            "),",
            " ",
            " (",
            "composition",
            "),",
            " ",
            " (",
            "un",
            "ite",
            "/",
            "combine",
            "/j",
            "oin",
            " together",
            "),",
            " ",
            " (",
            "union",
            "/all",
            "iance",
            "/",
            "association",
            "),",
            " ",
            " (",
            "combine",
            "/un",
            "ify",
            "),",
            " and",
            " ",
            " (",
            "mut",
            "ual",
            " agreement",
            ").",
            " There",
            " is",
            " an",
            " idea",
            " of",
            " recipro",
            "city",
            ",",
            " ",
            " (",
            "to",
            " get",
            " to",
            " know",
            " one",
            " another",
            "),",
            " ",
            " (",
            "talk",
            "/disc",
            "ussion",
            "/n",
            "egot",
            "iation",
            "),",
            " and",
            " ",
            " (",
            "meet",
            " by",
            " appointment",
            ").\n\n",
            " ()",
            " is",
            " often",
            " used",
            " to",
            " describe",
            " a",
            " feeling",
            " or",
            " emot",
            "ive",
            " action",
            ",",
            " as",
            " in",
            " ",
            " ('",
            "I",
            " feel",
            " X",
            "',",
            " as",
            " in",
            " terms",
            " of",
            " thinking",
            " but"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.465,
            0.02,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 27,
          "is_repeated_datapoint": false,
          "tokens": [
            " obstacles",
            " that",
            " divide",
            " the",
            " country",
            ".",
            " Family",
            " is",
            " the",
            " main",
            "stay",
            " of",
            " Afghan",
            " society",
            " and",
            " families",
            " are",
            " often",
            " headed",
            " by",
            " a",
            " patriarch",
            ".",
            " In",
            " the",
            " southern",
            " and",
            " eastern",
            " region",
            ",",
            " the",
            " people",
            " live",
            " according",
            " to",
            " the",
            " Pas",
            "ht",
            "un",
            " culture",
            " by",
            " following",
            " Pas",
            "ht",
            "un",
            "w",
            "ali",
            " (",
            "the",
            " Pas",
            "ht",
            "un",
            " way",
            ").",
            " Key",
            " ten",
            "ets",
            " of",
            " Pas",
            "ht",
            "un",
            "w",
            "ali",
            " include",
            " hospitality",
            ",",
            " the",
            " provision",
            " of",
            " sanctuary",
            " to",
            " those",
            " seeking",
            " refuge",
            ",",
            " and",
            " revenge",
            " for",
            " the",
            " shedding",
            " of",
            " blood",
            ".",
            " The",
            " Pas",
            "ht",
            "uns",
            " are",
            " largely",
            " connected",
            " to",
            " the",
            " culture",
            " of",
            " Central",
            " Asia",
            " and",
            " the",
            " Iranian",
            " Plate",
            "au",
            ".",
            " The",
            " remaining",
            " Af",
            "gh",
            "ans",
            " are",
            " culturally",
            " Persian",
            " and",
            " Turk",
            "ic",
            ".",
            " Some",
            " non",
            "-P",
            "as",
            "ht",
            "uns",
            " who",
            " live",
            " in",
            " proximity",
            " with",
            " Pas",
            "ht"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.461,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.424,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.312,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.33,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.354,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.342,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 7,
          "is_repeated_datapoint": false,
          "tokens": [
            " that",
            " it",
            " was",
            " \"",
            "possibly",
            " used",
            " as",
            " kind",
            "ling",
            " wood",
            " by",
            " the",
            " Nazis",
            "\".\n\n",
            "193",
            "3",
            ":",
            " Em",
            "igration",
            " to",
            " the",
            " US",
            " \n\n",
            "In",
            " February",
            " ",
            "193",
            "3",
            ",",
            " while",
            " on",
            " a",
            " visit",
            " to",
            " the",
            " United",
            " States",
            ",",
            " Einstein",
            " knew",
            " he",
            " could",
            " not",
            " return",
            " to",
            " Germany",
            " with",
            " the",
            " rise",
            " to",
            " power",
            " of",
            " the",
            " Nazis",
            " under",
            " Germany",
            "'s",
            " new",
            " chancellor",
            ",",
            " Adolf",
            " Hitler",
            ".\n\n",
            "While",
            " at",
            " American",
            " universities",
            " in",
            " early",
            " ",
            "193",
            "3",
            ",",
            " he",
            " undert",
            "ook",
            " his",
            " third",
            " two",
            "-month",
            " visiting",
            " professor",
            "ship",
            " at",
            " the",
            " California",
            " Institute",
            " of",
            " Technology",
            " in",
            " Pasadena",
            ".",
            " In",
            " February",
            " and",
            " March",
            " ",
            "193",
            "3",
            ",",
            " the",
            " Gest",
            "apo",
            " repeatedly",
            " raided",
            " his",
            " family",
            "'s",
            " apartment",
            " in",
            " Berlin",
            ".",
            " He",
            " and",
            " his",
            " wife",
            " Elsa",
            " returned",
            " to",
            " Europe",
            " in",
            " March",
            ",",
            " and",
            " during",
            " the",
            " trip"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.455,
            0.012,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 102,
          "is_repeated_datapoint": false,
          "tokens": [
            " In",
            " ",
            "186",
            "1",
            ",",
            " the",
            " state",
            " se",
            "ced",
            "ed",
            " from",
            " the",
            " United",
            " States",
            " to",
            " become",
            " part",
            " of",
            " the",
            " Confederate",
            " States",
            " of",
            " America",
            ",",
            " with",
            " Montgomery",
            " acting",
            " as",
            " its",
            " first",
            " capital",
            ",",
            " and",
            " rejo",
            "ined",
            " the",
            " Union",
            " in",
            " ",
            "186",
            "8",
            ".",
            " Following",
            " the",
            " American",
            " Civil",
            " War",
            ",",
            " Alabama",
            " would",
            " suffer",
            " decades",
            " of",
            " economic",
            " hardship",
            ",",
            " in",
            " part",
            " due",
            " to",
            " agriculture",
            " and",
            " a",
            " few",
            " cash",
            " crops",
            " being",
            " the",
            " main",
            " driver",
            " of",
            " the",
            " state",
            "'s",
            " economy",
            ".",
            " Similar",
            " to",
            " other",
            " former",
            " slave",
            " states",
            ",",
            " Al",
            "ab",
            "am",
            "ian",
            " legislators",
            " employed",
            " Jim",
            " Crow",
            " laws",
            " from",
            " the",
            " late",
            " ",
            "19",
            "th",
            " century",
            " up",
            " until",
            " the",
            " ",
            "196",
            "0",
            "s",
            ".",
            " ",
            " High",
            "-profile",
            " events",
            " such",
            " as",
            " the",
            " Sel",
            "ma",
            " to",
            " Montgomery",
            " march",
            " made",
            " the",
            " state",
            " a",
            " major",
            " focal",
            " point",
            " of"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.436,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " The",
            " United",
            " Methodist",
            " Church",
            ",",
            " and",
            " non",
            "-den",
            "omin",
            "ational",
            " Evangel",
            "ical",
            " Protestant",
            ".\n\n",
            "In",
            " Alabama",
            ",",
            " the",
            " Southern",
            " Baptist",
            " Convention",
            " has",
            " the",
            " highest",
            " number",
            " of",
            " adher",
            "ents",
            " with",
            " ",
            "1",
            ",",
            "380",
            ",",
            "121",
            ";",
            " this",
            " is",
            " followed",
            " by",
            " the",
            " United",
            " Methodist",
            " Church",
            " with",
            " ",
            "327",
            ",",
            "734",
            " adher",
            "ents",
            ",",
            " non",
            "-den",
            "omin",
            "ational",
            " Evangel",
            "ical",
            " Protestant",
            " with",
            " ",
            "220",
            ",",
            "938",
            " adher",
            "ents",
            ",",
            " and",
            " the",
            " Catholic",
            " Church",
            " with",
            " ",
            "150",
            ",",
            "647",
            " adher",
            "ents",
            ".",
            " Many",
            " Baptist",
            " and",
            " Methodist",
            " congreg",
            "ations",
            " became",
            " established",
            " in",
            " the",
            " Great",
            " Awakening",
            " of",
            " the",
            " early",
            " ",
            "19",
            "th",
            " century",
            ",",
            " when",
            " pre",
            "achers",
            " pros",
            "ely",
            "t",
            "ized",
            " across",
            " the",
            " South",
            ".",
            " The",
            " As",
            "semblies",
            " of",
            " God",
            " had",
            " almost",
            " ",
            "60",
            ",",
            "000",
            " members",
            ",",
            " the",
            " Churches",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.316,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.338,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.002,
            -0.0,
            -0.0,
            0.428,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.023,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.402,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.43,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.02,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 55,
          "is_repeated_datapoint": false,
          "tokens": [
            " are",
            " att",
            "ested",
            " in",
            " writing",
            " as",
            " early",
            " as",
            " the",
            " fourth",
            " millennium",
            " BC",
            ",",
            " Ber",
            "ber",
            ",",
            " Cush",
            "itic",
            ",",
            " and",
            " Om",
            "otic",
            " languages",
            " were",
            " often",
            " not",
            " recorded",
            " until",
            " the",
            " ",
            "19",
            "th",
            " or",
            " ",
            "20",
            "th",
            " centuries",
            ".",
            " While",
            " systematic",
            " sound",
            " laws",
            " have",
            " not",
            " yet",
            " been",
            " established",
            " to",
            " explain",
            " the",
            " relationships",
            " between",
            " the",
            " various",
            " branches",
            " of",
            " Afro",
            "asi",
            "atic",
            ",",
            " the",
            " languages",
            " share",
            " a",
            " number",
            " of",
            " common",
            " features",
            ".",
            " One",
            " of",
            " the",
            " most",
            " important",
            " for",
            " establishing",
            " membership",
            " in",
            " the",
            " branch",
            " is",
            " a",
            " common",
            " set",
            " of",
            " pron",
            "ouns",
            ".",
            " Other",
            " widely",
            " shared",
            " features",
            " include",
            " a",
            " prefix",
            " m",
            "-",
            " which",
            " creates",
            " nouns",
            " from",
            " verbs",
            ",",
            " evidence",
            " for",
            " altern",
            "ations",
            " between",
            " the",
            " vowel",
            " \"",
            "a",
            "\"",
            " and",
            " a",
            " high",
            " vowel",
            " in",
            " the",
            " forms",
            " of",
            " the",
            " verb",
            ",",
            " similar",
            " methods",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.418,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 59,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " Hunts",
            "ville",
            "\n",
            " WE",
            "AR",
            " ",
            "3",
            " ABC",
            " Pens",
            "ac",
            "ola",
            ",",
            " Florida",
            "/M",
            "obile",
            "\n",
            " WN",
            "CF",
            " ",
            "32",
            " ABC",
            ",",
            " Montgomery",
            "\n",
            " W",
            "DB",
            "B",
            " ",
            "17",
            ".",
            "2",
            " ABC",
            ",",
            " Tus",
            "cal",
            "o",
            "osa",
            "\n",
            " CBS",
            "\n",
            " WI",
            "AT",
            " ",
            "42",
            " CBS",
            ",",
            " Birmingham",
            "\n",
            " W",
            "TV",
            "Y",
            " ",
            "4",
            " CBS",
            ",",
            " Do",
            "than",
            "\n",
            " WH",
            "NT",
            " ",
            "19",
            " CBS",
            ",",
            " Hunts",
            "ville",
            "\n",
            " WK",
            "RG",
            " ",
            "5",
            " CBS",
            ",",
            " Mobile",
            "\n",
            " W",
            "AK",
            "A",
            " ",
            "8",
            " CBS",
            ",",
            " Sel",
            "ma",
            "/M",
            "ont",
            "gomery",
            "\n",
            " Fox",
            "\n",
            " WB",
            "RC",
            " ",
            "6",
            " FOX",
            ",",
            " Birmingham",
            "\n",
            " W",
            "Z",
            "DX",
            " ",
            "54",
            " FOX",
            ",",
            " Hunts",
            "ville",
            "\n",
            " WAL",
            "A",
            " ",
            "10",
            " FOX",
            ",",
            " Mobile",
            "\n",
            " W",
            "CO",
            "V",
            " ",
            "20",
            " FOX",
            ",",
            " Montgomery",
            "\n",
            " W"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.402,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            " Associated",
            " offshore",
            " bas",
            "alt",
            "ic",
            " flows",
            " reach",
            " as",
            " far",
            " south",
            " as",
            " the",
            " Falk",
            "land",
            " Islands",
            " and",
            " South",
            " Africa",
            ".",
            " Tr",
            "aces",
            " of",
            " mag",
            "mat",
            "ism",
            " in",
            " both",
            " offshore",
            " and",
            " on",
            "shore",
            " bas",
            "ins",
            " in",
            " the",
            " central",
            " and",
            " southern",
            " segments",
            " have",
            " been",
            " dated",
            " to",
            " ",
            "147",
            "–",
            "49",
            "Âł",
            "Ma",
            " with",
            " two",
            " peaks",
            " between",
            " ",
            "143",
            " and",
            " ",
            "121",
            "Âł",
            "Ma",
            " and",
            " ",
            "90",
            "–",
            "60",
            "Âł",
            "Ma",
            ".\n\n",
            "In",
            " the",
            " Falk",
            "land",
            " segment",
            " r",
            "ifting",
            " began",
            " with",
            " d",
            "extr",
            "al",
            " movements",
            " between",
            " the",
            " Pat",
            "agon",
            "ia",
            " and",
            " Colorado",
            " sub",
            "-",
            "plates",
            " between",
            " the",
            " Early",
            " Jurassic",
            " (",
            "190",
            "Âł",
            "Ma",
            ")",
            " and",
            " the",
            " Early",
            " C",
            "ret",
            "aceous",
            " (",
            "126",
            ".",
            "7",
            "Âł",
            "Ma",
            ").",
            " Around",
            " ",
            "150",
            "Âł",
            "Ma",
            " sea",
            "-floor",
            " spreading",
            " propagated",
            " north",
            "ward",
            " into",
            " the",
            " southern"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.318,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.381,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 71,
          "is_repeated_datapoint": false,
          "tokens": [
            " spanning",
            " the",
            " Ar",
            "as",
            " River",
            ",",
            " and",
            " several",
            " ma",
            "us",
            "ole",
            "ums",
            ".",
            " In",
            " the",
            " ",
            "19",
            "th",
            " and",
            " early",
            " ",
            "20",
            "th",
            " centuries",
            ",",
            " little",
            " monumental",
            " architecture",
            " was",
            " created",
            ",",
            " but",
            " distinctive",
            " residences",
            " were",
            " built",
            " in",
            " B",
            "aku",
            " and",
            " elsewhere",
            ".",
            " Among",
            " the",
            " most",
            " recent",
            " architectural",
            " monuments",
            ",",
            " the",
            " B",
            "aku",
            " sub",
            "ways",
            " are",
            " noted",
            " for",
            " their",
            " lavish",
            " decor",
            ".\n\n",
            "The",
            " task",
            " for",
            " modern",
            " Azerbai",
            "j",
            "ani",
            " architecture",
            " is",
            " diverse",
            " application",
            " of",
            " modern",
            " aesthetics",
            ",",
            " the",
            " search",
            " for",
            " an",
            " architect",
            "'s",
            " own",
            " artistic",
            " style",
            " and",
            " inclusion",
            " of",
            " the",
            " existing",
            " histor",
            "ico",
            "-cultural",
            " environment",
            ".",
            " Major",
            " projects",
            " such",
            " as",
            " Hey",
            "dar",
            " Ali",
            "y",
            "ev",
            " Cultural",
            " Center",
            ",",
            " Flame",
            " Towers",
            ",",
            " B",
            "aku",
            " Crystal",
            " Hall",
            ",",
            " B",
            "aku",
            " White",
            " City",
            " and",
            " SO",
            "CAR",
            " Tower",
            " have",
            " transformed",
            " the",
            " country"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " progressed",
            " slowly",
            " until",
            " October",
            " ",
            "177",
            "7",
            ",",
            " when",
            " British",
            " defeat",
            " at",
            " Sar",
            "at",
            "oga",
            " and",
            " their",
            " apparent",
            " willingness",
            " to",
            " negotiate",
            " peace",
            " convinced",
            " Verg",
            "ennes",
            " only",
            " a",
            " permanent",
            " alliance",
            " could",
            " prevent",
            " the",
            " \"",
            "dis",
            "aster",
            "\"",
            " of",
            " Anglo",
            "-American",
            " r",
            "appro",
            "ch",
            "ement",
            ".",
            " Ass",
            "urances",
            " of",
            " formal",
            " French",
            " support",
            " allowed",
            " Congress",
            " to",
            " reject",
            " the",
            " Carl",
            "isle",
            " Peace",
            " Commission",
            " and",
            " insist",
            " on",
            " nothing",
            " short",
            " of",
            " complete",
            " independence",
            ".\n\n",
            "On",
            " February",
            " ",
            "6",
            ",",
            " ",
            "177",
            "8",
            ",",
            " France",
            " and",
            " the",
            " United",
            " States",
            " signed",
            " the",
            " Treaty",
            " of",
            " Am",
            "ity",
            " and",
            " Commerce",
            " regulating",
            " trade",
            " between",
            " the",
            " two",
            " countries",
            ",",
            " followed",
            " by",
            " a",
            " defensive",
            " military",
            " alliance",
            " against",
            " Britain",
            ",",
            " the",
            " Treaty",
            " of",
            " Alliance",
            ".",
            " In",
            " return",
            " for",
            " French",
            " guarantees",
            " of",
            " American",
            " independence",
            ",",
            " Congress",
            " undert",
            "ook",
            " to",
            " defend",
            " their",
            " interests"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " served",
            " on",
            " the",
            " advisory",
            " board",
            " of",
            " the",
            " First",
            " Human",
            "ist",
            " Society",
            " of",
            " New",
            " York",
            ",",
            " and",
            " was",
            " an",
            " honorary",
            " associate",
            " of",
            " the",
            " Rational",
            "ist",
            " Association",
            ",",
            " which",
            " publishes",
            " New",
            " Human",
            "ist",
            " in",
            " Britain",
            ".",
            " For",
            " the",
            " ",
            "75",
            "th",
            " anniversary",
            " of",
            " the",
            " New",
            " York",
            " Society",
            " for",
            " Eth",
            "ical",
            " Culture",
            ",",
            " he",
            " stated",
            " that",
            " the",
            " idea",
            " of",
            " Eth",
            "ical",
            " Culture",
            " embodied",
            " his",
            " personal",
            " conception",
            " of",
            " what",
            " is",
            " most",
            " valuable",
            " and",
            " enduring",
            " in",
            " religious",
            " ideal",
            "ism",
            ".",
            " He",
            " observed",
            ",",
            " \"",
            "Without",
            " '",
            "ethical",
            " culture",
            "'",
            " there",
            " is",
            " no",
            " salvation",
            " for",
            " humanity",
            ".\"\n\n",
            "In",
            " a",
            " German",
            "-language",
            " letter",
            " to",
            " philosopher",
            " Eric",
            " Gut",
            "kind",
            ",",
            " dated",
            " ",
            "3",
            " January",
            " ",
            "195",
            "4",
            ",",
            " Einstein",
            " wrote",
            ":The",
            " word",
            " God",
            " is",
            " for",
            " me",
            " nothing",
            " more",
            " than",
            " the",
            " expression",
            " and",
            " product",
            " of",
            " human"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " miniature",
            " style",
            ",",
            " with",
            " Kam",
            "ale",
            "dd",
            "in",
            " Beh",
            "z",
            "ad",
            " of",
            " Her",
            "at",
            " being",
            " one",
            " of",
            " the",
            " most",
            " notable",
            " miniature",
            " artists",
            " of",
            " the",
            " Tim",
            "ur",
            "id",
            " and",
            " early",
            " Saf",
            "avid",
            " periods",
            ".",
            " Since",
            " the",
            " ",
            "190",
            "0",
            "s",
            ",",
            " the",
            " nation",
            " began",
            " to",
            " use",
            " Western",
            " techniques",
            " in",
            " art",
            ".",
            " Abdul",
            " G",
            "ha",
            "fo",
            "or",
            " B",
            "resh",
            "na",
            " was",
            " a",
            " prominent",
            " Afghan",
            " painter",
            " and",
            " sketch",
            " artist",
            " from",
            " Kabul",
            " during",
            " the",
            " ",
            "20",
            "th",
            " century",
            ".\n\n",
            "Media",
            " and",
            " entertainment",
            " \n\n",
            "Af",
            "ghan",
            "istan",
            " has",
            " around",
            " ",
            "350",
            " radio",
            " stations",
            " and",
            " over",
            " ",
            "200",
            " television",
            " stations",
            ".",
            " Radio",
            " Television",
            " Afghanistan",
            ",",
            " originating",
            " from",
            " ",
            "192",
            "5",
            ",",
            " is",
            " the",
            " state",
            " public",
            " broadcaster",
            ".",
            " Television",
            " programs",
            " began",
            " airing",
            " in",
            " the",
            " ",
            "197",
            "0",
            "s",
            " and",
            " today",
            " there",
            " are",
            " many",
            " private"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " Norwegian",
            " Sea",
            " and",
            " B",
            "arent",
            "s",
            " Sea",
            ".",
            " To",
            " the",
            " east",
            ",",
            " the",
            " boundaries",
            " of",
            " the",
            " ocean",
            " proper",
            " are",
            " Europe",
            ":",
            " the",
            " Strait",
            " of",
            " Gibraltar",
            " (",
            "where",
            " it",
            " connects",
            " with",
            " the",
            " Mediterranean",
            " Sea",
            "one",
            " of",
            " its",
            " marginal",
            " seas",
            "and",
            ",",
            " in",
            " turn",
            ",",
            " the",
            " Black",
            " Sea",
            ",",
            " both",
            " of",
            " which",
            " also",
            " touch",
            " upon",
            " Asia",
            ")",
            " and",
            " Africa",
            ".\n\n",
            "In",
            " the",
            " southeast",
            ",",
            " the",
            " Atlantic",
            " merges",
            " into",
            " the",
            " Indian",
            " Ocean",
            ".",
            " The",
            " ",
            "20",
            "Â°",
            " East",
            " mer",
            "idian",
            ",",
            " running",
            " south",
            " from",
            " Cape",
            " Ag",
            "ul",
            "has",
            " to",
            " Antarctica",
            " defines",
            " its",
            " border",
            ".",
            " In",
            " the",
            " ",
            "195",
            "3",
            " definition",
            " it",
            " extends",
            " south",
            " to",
            " Antarctica",
            ",",
            " while",
            " in",
            " later",
            " maps",
            " it",
            " is",
            " bounded",
            " at",
            " the",
            " ",
            "60",
            "Â°",
            " parallel",
            " by",
            " the",
            " Southern",
            " Ocean",
            ".\n\n",
            "The",
            " Atlantic",
            " has",
            " irregular",
            " co",
            "asts"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "ak",
            "istani",
            " wars",
            " and",
            " conflicts",
            "\n",
            " The",
            " West",
            " Papua",
            " conflict",
            "\n",
            " The",
            " First",
            " Nag",
            "orno",
            "-K",
            "ar",
            "ab",
            "akh",
            " War",
            "\n",
            " The",
            " ",
            "198",
            "9",
            " Tian",
            "an",
            "men",
            " Square",
            " protests",
            "\n",
            " The",
            " Indonesian",
            " occupation",
            " of",
            " East",
            " Tim",
            "or",
            "\n",
            " The",
            " ",
            "199",
            "9",
            " Pakistani",
            " coup",
            " d",
            "'Ã©t",
            "at",
            "\n",
            " The",
            " War",
            " in",
            " Afghanistan",
            "\n",
            " The",
            " Iraq",
            " War",
            "\n",
            " The",
            " South",
            " Thailand",
            " insurgency",
            "\n",
            " The",
            " ",
            "200",
            "6",
            " Thai",
            " coup",
            " d",
            "'Ã©t",
            "at",
            "\n",
            " The",
            " Bur",
            "m",
            "ese",
            " Civil",
            " War",
            "\n",
            " The",
            " S",
            "aff",
            "ron",
            " Revolution",
            "\n",
            " The",
            " Kurdish",
            "–",
            "Tur",
            "kish",
            " conflict",
            "\n",
            " The",
            " Arab",
            " Spring",
            "\n",
            " The",
            " Israeli",
            "–",
            "Pale",
            "stinian",
            " conflict",
            "\n",
            " The",
            " Arab",
            "–",
            "Israeli",
            " conflict",
            "\n",
            " The",
            " Syrian",
            " Civil",
            " War",
            "\n",
            " The",
            " S",
            "ino",
            "-",
            "Indian",
            " War",
            "\n",
            " The",
            " ",
            "201",
            "4",
            " Thai"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "rani",
    "etas",
    "arella",
    "714",
    "ienza"
  ],
  "bottom_logits": [
    " another",
    " forecast",
    "à¸¸à¸Ķ",
    " Brow",
    "iram"
  ],
  "act_min": -0.0,
  "act_max": 1.023
}

{
  "index": 276,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.969,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 24,
          "is_repeated_datapoint": false,
          "tokens": [
            "ler",
            "'s",
            " Creek",
            " on",
            " April",
            " ",
            "6",
            ".",
            "End",
            " of",
            " the",
            " war",
            "Initially",
            ",",
            " Lee",
            " did",
            " not",
            " intend",
            " to",
            " surrender",
            " but",
            " planned",
            " to",
            " reg",
            "roup",
            " at",
            " App",
            "om",
            "atto",
            "x",
            " Station",
            ",",
            " where",
            " supplies",
            " were",
            " to",
            " be",
            " waiting",
            " and",
            " then",
            " continue",
            " the",
            " war",
            ".",
            " Grant",
            " chased",
            " Lee",
            " and",
            " got",
            " in",
            " front",
            " of",
            " him",
            " so",
            " that",
            " when",
            " Lee",
            "'s",
            " army",
            " reached",
            " the",
            " village"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.965,
            0.151,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 20,
          "is_repeated_datapoint": false,
          "tokens": [
            " Connecticut",
            ",",
            " the",
            " base",
            " for",
            " American",
            " naval",
            " operations",
            " during",
            " the",
            " Revolution",
            ".",
            "British",
            " New",
            " York",
            " counter",
            "-off",
            "ensive",
            "After",
            " reg",
            "roup",
            "ing",
            " at",
            " Halifax",
            " in",
            " Nova",
            " Scotia",
            ",",
            " Howe",
            " was",
            " determined",
            " to",
            " take",
            " the",
            " fight",
            " to",
            " the",
            " Americans",
            ".",
            " He",
            " set",
            " sail",
            " for",
            " New",
            " York",
            " in",
            " June",
            " ",
            "177",
            "6",
            " and",
            " began",
            " landing",
            " troops",
            " on",
            " Staten",
            " Island",
            " near",
            " the",
            " entrance",
            " to",
            " New"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.914,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.863,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.863
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            "log",
            "roup",
            " O",
            "1",
            "b",
            "1",
            ",",
            " which",
            " is",
            " common",
            " in",
            " Aust",
            "ro",
            "asi",
            "atic",
            " people",
            " and",
            " some",
            " other",
            " ethnic",
            " groups",
            " in",
            " southern",
            " China",
            ",",
            " and",
            " hap",
            "log",
            "roup",
            " O",
            "1",
            "b",
            "2",
            ",",
            " which",
            " is",
            " common",
            " in",
            " today",
            "'s",
            " Japanese",
            " and",
            " Koreans",
            ",",
            " are",
            " the",
            " carriers",
            " of",
            " early",
            " rice",
            " agriculture",
            " from",
            " southern",
            " China",
            ".",
            " Another",
            " study",
            " suggests",
            " that",
            " the",
            " hap",
            "log",
            "roup"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.914,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.863,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.863
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            "log",
            "roup",
            " O",
            "1",
            "b",
            "1",
            ",",
            " which",
            " is",
            " common",
            " in",
            " Aust",
            "ro",
            "asi",
            "atic",
            " people",
            " and",
            " some",
            " other",
            " ethnic",
            " groups",
            " in",
            " southern",
            " China",
            ",",
            " and",
            " hap",
            "log",
            "roup",
            " O",
            "1",
            "b",
            "2",
            ",",
            " which",
            " is",
            " common",
            " in",
            " today",
            "'s",
            " Japanese",
            " and",
            " Koreans",
            ",",
            " are",
            " the",
            " carriers",
            " of",
            " early",
            " rice",
            " agriculture",
            " from",
            " southern",
            " China",
            ".",
            " Another",
            " study",
            " suggests",
            " that",
            " the",
            " hap",
            "log",
            "roup"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.914,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.863,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.863
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            "log",
            "roup",
            " O",
            "1",
            "b",
            "1",
            ",",
            " which",
            " is",
            " common",
            " in",
            " Aust",
            "ro",
            "asi",
            "atic",
            " people",
            " and",
            " some",
            " other",
            " ethnic",
            " groups",
            " in",
            " southern",
            " China",
            ",",
            " and",
            " hap",
            "log",
            "roup",
            " O",
            "1",
            "b",
            "2",
            ",",
            " which",
            " is",
            " common",
            " in",
            " today",
            "'s",
            " Japanese",
            " and",
            " Koreans",
            ",",
            " are",
            " the",
            " carriers",
            " of",
            " early",
            " rice",
            " agriculture",
            " from",
            " southern",
            " China",
            ".",
            " Another",
            " study",
            " suggests",
            " that",
            " the",
            " hap",
            "log",
            "roup"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            0.914,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.863,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.863
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            "log",
            "roup",
            " O",
            "1",
            "b",
            "1",
            ",",
            " which",
            " is",
            " common",
            " in",
            " Aust",
            "ro",
            "asi",
            "atic",
            " people",
            " and",
            " some",
            " other",
            " ethnic",
            " groups",
            " in",
            " southern",
            " China",
            ",",
            " and",
            " hap",
            "log",
            "roup",
            " O",
            "1",
            "b",
            "2",
            ",",
            " which",
            " is",
            " common",
            " in",
            " today",
            "'s",
            " Japanese",
            " and",
            " Koreans",
            ",",
            " are",
            " the",
            " carriers",
            " of",
            " early",
            " rice",
            " agriculture",
            " from",
            " southern",
            " China",
            ".",
            " Another",
            " study",
            " suggests",
            " that",
            " the",
            " hap",
            "log",
            "roup"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.914,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.863,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.863
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            "log",
            "roup",
            " O",
            "1",
            "b",
            "1",
            ",",
            " which",
            " is",
            " common",
            " in",
            " Aust",
            "ro",
            "asi",
            "atic",
            " people",
            " and",
            " some",
            " other",
            " ethnic",
            " groups",
            " in",
            " southern",
            " China",
            ",",
            " and",
            " hap",
            "log",
            "roup",
            " O",
            "1",
            "b",
            "2",
            ",",
            " which",
            " is",
            " common",
            " in",
            " today",
            "'s",
            " Japanese",
            " and",
            " Koreans",
            ",",
            " are",
            " the",
            " carriers",
            " of",
            " early",
            " rice",
            " agriculture",
            " from",
            " southern",
            " China",
            ".",
            " Another",
            " study",
            " suggests",
            " that",
            " the",
            " hap",
            "log",
            "roup"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.914,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.272,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.863,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.863
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            "log",
            "roup",
            " O",
            "1",
            "b",
            "1",
            ",",
            " which",
            " is",
            " common",
            " in",
            " Aust",
            "ro",
            "asi",
            "atic",
            " people",
            " and",
            " some",
            " other",
            " ethnic",
            " groups",
            " in",
            " southern",
            " China",
            ",",
            " and",
            " hap",
            "log",
            "roup",
            " O",
            "1",
            "b",
            "2",
            ",",
            " which",
            " is",
            " common",
            " in",
            " today",
            "'s",
            " Japanese",
            " and",
            " Koreans",
            ",",
            " are",
            " the",
            " carriers",
            " of",
            " early",
            " rice",
            " agriculture",
            " from",
            " southern",
            " China",
            ".",
            " Another",
            " study",
            " suggests",
            " that",
            " the",
            " hap",
            "log",
            "roup"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.852,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.856,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.354,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.852,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 27,
          "is_repeated_datapoint": false,
          "tokens": [
            " therefore",
            ",",
            " also",
            " benefit",
            " the",
            " altru",
            "ist",
            ".",
            " Making",
            " ing",
            "roup",
            " membership",
            " more",
            " noticeable",
            " increases",
            " cooper",
            "at",
            "iveness",
            ".",
            " Extreme",
            " self",
            "-s",
            "acr",
            "ifice",
            " towards",
            " the",
            " ing",
            "roup",
            " may",
            " be",
            " adaptive",
            " if",
            " a",
            " hostile",
            " out",
            "group",
            " threatens",
            " the",
            " entire",
            " ing",
            "roup",
            ".",
            " Rec",
            "ipro",
            "cal",
            " altru",
            "ism",
            ".",
            " See",
            " also",
            " Rec",
            "ipro",
            "city",
            " (",
            "ev",
            "olution",
            ").",
            " Direct",
            " recipro",
            "city",
            ".",
            " Research",
            " shows"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.856,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.003,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " dissemination",
            " of",
            " hap",
            "log",
            "roup",
            " C",
            "2",
            " (",
            "M",
            "217",
            "):",
            " \"",
            "If",
            " the",
            " paternal",
            " lineage",
            " C",
            "2",
            " (",
            "M",
            "217",
            ")",
            " is",
            " correlated",
            " with",
            " Alta",
            "ic",
            " linguistic",
            " affinity",
            ",",
            " as",
            " appears",
            " to",
            " be",
            " the",
            " case",
            " for",
            " Turk",
            "ic",
            ",",
            " Mong",
            "olic",
            " and",
            " T",
            "ung",
            "usic",
            ",",
            " then",
            " Japanese",
            " is",
            " no",
            " Father",
            " Tong",
            "ue",
            ",",
            " and",
            " neither",
            " is",
            " Korean",
            ".",
            " This",
            " Y",
            "-ch"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.852,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.856,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.354,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.852,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 27,
          "is_repeated_datapoint": false,
          "tokens": [
            " therefore",
            ",",
            " also",
            " benefit",
            " the",
            " altru",
            "ist",
            ".",
            " Making",
            " ing",
            "roup",
            " membership",
            " more",
            " noticeable",
            " increases",
            " cooper",
            "at",
            "iveness",
            ".",
            " Extreme",
            " self",
            "-s",
            "acr",
            "ifice",
            " towards",
            " the",
            " ing",
            "roup",
            " may",
            " be",
            " adaptive",
            " if",
            " a",
            " hostile",
            " out",
            "group",
            " threatens",
            " the",
            " entire",
            " ing",
            "roup",
            ".",
            " Rec",
            "ipro",
            "cal",
            " altru",
            "ism",
            ".",
            " See",
            " also",
            " Rec",
            "ipro",
            "city",
            " (",
            "ev",
            "olution",
            ").",
            " Direct",
            " recipro",
            "city",
            ".",
            " Research",
            " shows"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.852,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.856,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.354,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.852,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 27,
          "is_repeated_datapoint": false,
          "tokens": [
            " therefore",
            ",",
            " also",
            " benefit",
            " the",
            " altru",
            "ist",
            ".",
            " Making",
            " ing",
            "roup",
            " membership",
            " more",
            " noticeable",
            " increases",
            " cooper",
            "at",
            "iveness",
            ".",
            " Extreme",
            " self",
            "-s",
            "acr",
            "ifice",
            " towards",
            " the",
            " ing",
            "roup",
            " may",
            " be",
            " adaptive",
            " if",
            " a",
            " hostile",
            " out",
            "group",
            " threatens",
            " the",
            " entire",
            " ing",
            "roup",
            ".",
            " Rec",
            "ipro",
            "cal",
            " altru",
            "ism",
            ".",
            " See",
            " also",
            " Rec",
            "ipro",
            "city",
            " (",
            "ev",
            "olution",
            ").",
            " Direct",
            " recipro",
            "city",
            ".",
            " Research",
            " shows"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.856,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.003,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " dissemination",
            " of",
            " hap",
            "log",
            "roup",
            " C",
            "2",
            " (",
            "M",
            "217",
            "):",
            " \"",
            "If",
            " the",
            " paternal",
            " lineage",
            " C",
            "2",
            " (",
            "M",
            "217",
            ")",
            " is",
            " correlated",
            " with",
            " Alta",
            "ic",
            " linguistic",
            " affinity",
            ",",
            " as",
            " appears",
            " to",
            " be",
            " the",
            " case",
            " for",
            " Turk",
            "ic",
            ",",
            " Mong",
            "olic",
            " and",
            " T",
            "ung",
            "usic",
            ",",
            " then",
            " Japanese",
            " is",
            " no",
            " Father",
            " Tong",
            "ue",
            ",",
            " and",
            " neither",
            " is",
            " Korean",
            ".",
            " This",
            " Y",
            "-ch"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.84,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            "rom",
            "osomal",
            " hap",
            "log",
            "roup",
            " accounts",
            " for",
            " ",
            "11",
            "%",
            " of",
            " Korean",
            " paternal",
            " line",
            "ages",
            ",",
            " and",
            " the",
            " frequency",
            " of",
            " the",
            " lineage",
            " is",
            " even",
            " more",
            " reduced",
            " in",
            " Japan",
            ".",
            " Yet",
            " this",
            " molecular",
            " marker",
            " may",
            " still",
            " be",
            " a",
            " tracer",
            " for",
            " the",
            " introduction",
            " of",
            " Alta",
            "ic",
            " language",
            " to",
            " the",
            " arch",
            "ipel",
            "ago",
            ",",
            " where",
            " the",
            " paternal",
            " lineage",
            " has",
            " persisted",
            ",",
            " albeit",
            " in",
            " a",
            " frequency",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.84,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            "rom",
            "osomal",
            " hap",
            "log",
            "roup",
            " accounts",
            " for",
            " ",
            "11",
            "%",
            " of",
            " Korean",
            " paternal",
            " line",
            "ages",
            ",",
            " and",
            " the",
            " frequency",
            " of",
            " the",
            " lineage",
            " is",
            " even",
            " more",
            " reduced",
            " in",
            " Japan",
            ".",
            " Yet",
            " this",
            " molecular",
            " marker",
            " may",
            " still",
            " be",
            " a",
            " tracer",
            " for",
            " the",
            " introduction",
            " of",
            " Alta",
            "ic",
            " language",
            " to",
            " the",
            " arch",
            "ipel",
            "ago",
            ",",
            " where",
            " the",
            " paternal",
            " lineage",
            " has",
            " persisted",
            ",",
            " albeit",
            " in",
            " a",
            " frequency",
            " of"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.451,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.379,
            -0.0,
            -0.0,
            0.301,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.262,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.836,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.346,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " persons",
            " at",
            " the",
            " individual",
            " level",
            ",",
            " according",
            " to",
            " group",
            " selection",
            " theory",
            ",",
            " the",
            " opposite",
            " may",
            " occur",
            " at",
            " the",
            " group",
            " level",
            " where",
            " groups",
            " consisting",
            " of",
            " the",
            " more",
            " altru",
            "istic",
            " persons",
            " may",
            " out",
            "comp",
            "ete",
            " groups",
            " consisting",
            " of",
            " the",
            " less",
            " altru",
            "istic",
            " persons",
            ".",
            " Such",
            " altru",
            "ism",
            " may",
            " only",
            " extend",
            " to",
            " ing",
            "roup",
            " members",
            " while",
            " directing",
            " prejudice",
            " and",
            " antagon",
            "ism",
            " against",
            " out",
            "group",
            " members",
            " ("
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.436,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.68,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 58,
          "is_repeated_datapoint": false,
          "tokens": [
            " with",
            " one",
            " another",
            " first",
            ".",
            " This",
            " may",
            " be",
            " due",
            " to",
            " better",
            " cooper",
            "at",
            "iveness",
            " assessments",
            " or",
            " promises",
            " exchange",
            ".",
            " They",
            " are",
            " more",
            " cooperative",
            " if",
            " they",
            " can",
            " gradually",
            " build",
            " trust",
            " instead",
            " of",
            " being",
            " asked",
            " to",
            " give",
            " extensive",
            " help",
            " immediately",
            ".",
            " Direct",
            " recipro",
            "city",
            " and",
            " cooperation",
            " in",
            " a",
            " group",
            " can",
            " be",
            " increased",
            " by",
            " changing",
            " the",
            " focus",
            " and",
            " incentives",
            " from",
            " intra",
            "-group",
            " competition",
            " to",
            " larger",
            "-scale"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.68,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " orders",
            " to",
            " form",
            " an",
            " elite",
            " group",
            " for",
            " reconnaissance",
            " and",
            " secret",
            " missions",
            ".",
            " Know",
            "l",
            "ton",
            "'s",
            " Rangers",
            ",",
            " which",
            " included",
            " Nathan",
            " Hale",
            ",",
            " became",
            " the",
            " Army",
            "'s",
            " first",
            " intelligence",
            " unit",
            ".",
            " When",
            " Washington",
            " was",
            " driven",
            " off",
            " Long",
            " Island",
            ",",
            " he",
            " soon",
            " realized",
            " that",
            " he",
            " would",
            " need",
            " more",
            " than",
            " military",
            " might",
            " and",
            " amateur",
            " spies",
            " to",
            " defeat",
            " the",
            " British",
            ".",
            " He",
            " was",
            " committed",
            " to",
            " professional"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.68,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " orders",
            " to",
            " form",
            " an",
            " elite",
            " group",
            " for",
            " reconnaissance",
            " and",
            " secret",
            " missions",
            ".",
            " Know",
            "l",
            "ton",
            "'s",
            " Rangers",
            ",",
            " which",
            " included",
            " Nathan",
            " Hale",
            ",",
            " became",
            " the",
            " Army",
            "'s",
            " first",
            " intelligence",
            " unit",
            ".",
            " When",
            " Washington",
            " was",
            " driven",
            " off",
            " Long",
            " Island",
            ",",
            " he",
            " soon",
            " realized",
            " that",
            " he",
            " would",
            " need",
            " more",
            " than",
            " military",
            " might",
            " and",
            " amateur",
            " spies",
            " to",
            " defeat",
            " the",
            " British",
            ".",
            " He",
            " was",
            " committed",
            " to",
            " professional"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.527,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 7,
          "is_repeated_datapoint": false,
          "tokens": [
            " group",
            " ",
            "11",
            " metals",
            " behave",
            " like",
            " main",
            "-group",
            " metals",
            " in",
            " their",
            " +",
            "1",
            " val",
            "ence",
            " states",
            ",",
            " and",
            " are",
            " hence",
            " somewhat",
            " related",
            " to",
            " the",
            " alk",
            "ali",
            " metals",
            ":",
            " this",
            " is",
            " one",
            " reason",
            " for",
            " their",
            " previously",
            " being",
            " labelled",
            " as",
            " \"",
            "group",
            " IB",
            "\",",
            " paralle",
            "ling",
            " the",
            " alk",
            "ali",
            " metals",
            "'",
            " \"",
            "group",
            " IA",
            "\".",
            " They",
            " are",
            " occasionally",
            " classified",
            " as",
            " post",
            "-transition",
            " metals",
            ".",
            " Their"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.676,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.527,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 7,
          "is_repeated_datapoint": false,
          "tokens": [
            " group",
            " ",
            "11",
            " metals",
            " behave",
            " like",
            " main",
            "-group",
            " metals",
            " in",
            " their",
            " +",
            "1",
            " val",
            "ence",
            " states",
            ",",
            " and",
            " are",
            " hence",
            " somewhat",
            " related",
            " to",
            " the",
            " alk",
            "ali",
            " metals",
            ":",
            " this",
            " is",
            " one",
            " reason",
            " for",
            " their",
            " previously",
            " being",
            " labelled",
            " as",
            " \"",
            "group",
            " IB",
            "\",",
            " paralle",
            "ling",
            " the",
            " alk",
            "ali",
            " metals",
            "'",
            " \"",
            "group",
            " IA",
            "\".",
            " They",
            " are",
            " occasionally",
            " classified",
            " as",
            " post",
            "-transition",
            " metals",
            ".",
            " Their"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.66,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.41,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " Chinese",
            " space",
            " program",
            ".",
            " The",
            " origin",
            " of",
            " the",
            " term",
            " is",
            " unclear",
            ";",
            " as",
            " early",
            " as",
            " May",
            " ",
            "199",
            "8",
            ",",
            " Ch",
            "iew",
            " Lee",
            " Y",
            "ih",
            " ()",
            " from",
            " Malaysia",
            ",",
            " used",
            " it",
            " in",
            " new",
            "sg",
            "roups",
            ".",
            "Par",
            "astr",
            "onaut",
            "For",
            " its",
            " ",
            "202",
            "2",
            " Astr",
            "onaut",
            " Group",
            ",",
            " the",
            " European",
            " Space",
            " Agency",
            " envisioned",
            " recruiting",
            " an",
            " astronaut",
            " with",
            " a",
            " physical",
            " disability",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " group",
            ".",
            " The",
            " two",
            " Om",
            "otic",
            " languages",
            " with",
            " the",
            " most",
            " speakers",
            " are",
            " Wol",
            "ait",
            "ta",
            " and",
            " G",
            "amo",
            "-G",
            "of",
            "a",
            "-D",
            "aw",
            "ro",
            ",",
            " with",
            " about",
            " ",
            "1",
            ".",
            "2",
            " million",
            " speakers",
            " each",
            ".",
            "A",
            " majority",
            " of",
            " specialists",
            " consider",
            " Om",
            "otic",
            " to",
            " constitute",
            " a",
            " sixth",
            " branch",
            " of",
            " Afro",
            "asi",
            "atic",
            ".",
            " Om",
            "otic",
            " was",
            " formerly",
            " considered",
            " part",
            " of",
            " the",
            " Cush",
            "itic",
            " branch"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.414,
            0.013,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.277,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 59,
          "is_repeated_datapoint": false,
          "tokens": [
            "5",
            "",
            "mg",
            "/mL",
            ",",
            " ",
            "10",
            "",
            "mg",
            "/mL",
            ",",
            " ",
            "20",
            "",
            "mg",
            "/mL",
            ")",
            " given",
            " to",
            " the",
            " same",
            " group",
            " of",
            " patients",
            ",",
            " then",
            " a",
            " linear",
            " trend",
            " estimation",
            " should",
            " be",
            " used",
            ".",
            " Typically",
            ",",
            " however",
            ",",
            " the",
            " one",
            "-way",
            " AN",
            "O",
            "VA",
            " is",
            " used",
            " to",
            " test",
            " for",
            " differences",
            " among",
            " at",
            " least",
            " three",
            " groups",
            ",",
            " since",
            " the",
            " two",
            "-group",
            " case",
            " can",
            " be"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " group",
            ")",
            " ca",
            "ud",
            "at",
            "ans",
            " are",
            " described",
            " via",
            " the",
            " name",
            " U",
            "rod",
            "ela",
            ".",
            " Gym",
            "n",
            "oph",
            "iona",
            " (",
            "ca",
            "ec",
            "ilians",
            " and",
            " relatives",
            "):",
            " Late",
            " Tri",
            "assic",
            " to",
            " present",
            "",
            "215",
            " current",
            " species",
            " in",
            " ",
            "10",
            " families",
            ".",
            " The",
            " name",
            " Ap",
            "oda",
            " is",
            " also",
            " sometimes",
            " used",
            " for",
            " ca",
            "ec",
            "ilians",
            ".",
            "Al",
            "lo",
            "ca",
            "ud",
            "ata",
            "",
            " (",
            "Al",
            "ban",
            "er"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.356,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " group",
            ",",
            " but",
            " had",
            " also",
            " included",
            " groups",
            " now",
            " located",
            " in",
            " L",
            "ilia",
            "les",
            ",",
            " Pand",
            "ana",
            "les",
            " and",
            " Z",
            "ing",
            "ib",
            "era",
            "les",
            ".",
            " Research",
            " in",
            " the",
            " ",
            "21",
            "st",
            " century",
            " has",
            " supported",
            " the",
            " mon",
            "ophy",
            "ly",
            " of",
            " As",
            "par",
            "ag",
            "ales",
            ",",
            " based",
            " on",
            " morphology",
            ",",
            " ",
            "18",
            "S",
            " r",
            "DNA",
            ",",
            " and",
            " other",
            " DNA",
            " sequences",
            ",",
            " although",
            " some",
            " phy",
            "logen",
            "etic"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " group",
            ".",
            " They",
            " reduce",
            " the",
            " surface",
            " tension",
            " of",
            " the",
            " em",
            "ulsion",
            " and",
            " thus",
            " prevent",
            " bit",
            "umen",
            " particles",
            " from",
            " f",
            "using",
            ".",
            " The",
            " em",
            "uls",
            "ifier",
            " charge",
            " defines",
            " the",
            " type",
            " of",
            " em",
            "ulsion",
            ":",
            " an",
            "ionic",
            " (",
            "neg",
            "atively",
            " charged",
            ")",
            " and",
            " c",
            "ation",
            "ic",
            " (",
            "posit",
            "ively",
            " charged",
            ").",
            " The",
            " concentration",
            " of",
            " an",
            " em",
            "uls",
            "ifier",
            " is",
            " a",
            " critical",
            " parameter",
            " affecting",
            " the",
            " size"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " group",
            ",",
            " the",
            " Gal",
            "at",
            "ians",
            ",",
            " who",
            " were",
            " the",
            " first",
            " to",
            " make",
            " Ankara",
            " one",
            " of",
            " their",
            " main",
            " tribal",
            " centers",
            ",",
            " the",
            " headquarters",
            " of",
            " the",
            " T",
            "ect",
            "os",
            "ages",
            " tribe",
            ".",
            " Other",
            " centers",
            " were",
            " P",
            "ess",
            "inus",
            ",",
            " today",
            "'s",
            " Ball",
            "",
            "his",
            "ar",
            ",",
            " for",
            " the",
            " Tro",
            "cm",
            "i",
            " tribe",
            ",",
            " and",
            " T",
            "av",
            "ium",
            ",",
            " to",
            " the",
            " east",
            " of",
            " Ankara",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.266
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " group",
            " (-",
            "NH",
            "2",
            ")",
            " gains",
            " a",
            " proton",
            " (-",
            "NH",
            ").",
            " The",
            " entire",
            " molecule",
            " has",
            " a",
            " net",
            " neutral",
            " charge",
            " and",
            " is",
            " a",
            " z",
            "witter",
            "ion",
            ",",
            " with",
            " the",
            " exception",
            " of",
            " amino",
            " acids",
            " with",
            " basic",
            " or",
            " acidic",
            " side",
            " chains",
            ".",
            " As",
            "part",
            "ic",
            " acid",
            ",",
            " for",
            " example",
            ",",
            " possesses",
            " one",
            " proton",
            "ated",
            " am",
            "ine",
            " and",
            " two",
            " de",
            "pro",
            "ton",
            "ated",
            " car",
            "box",
            "yl",
            " groups"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            0.025,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 32,
          "is_repeated_datapoint": false,
          "tokens": [
            " dark",
            " crust",
            ".",
            " Ph",
            "yt",
            "om",
            "elan",
            "in",
            " is",
            " found",
            " in",
            " most",
            " families",
            " of",
            " the",
            " As",
            "par",
            "ag",
            "ales",
            " (",
            "although",
            " not",
            " in",
            " Orch",
            "id",
            "aceae",
            ",",
            " thought",
            " to",
            " be",
            " the",
            " sister",
            "-group",
            " of",
            " the",
            " rest",
            " of",
            " the",
            " order",
            ").",
            "The",
            " leaves",
            " of",
            " almost",
            " all",
            " species",
            " form",
            " a",
            " tight",
            " ro",
            "set",
            "te",
            ",",
            " either",
            " at",
            " the",
            " base",
            " of",
            " the",
            " plant",
            " or",
            " at",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.621,
            0.008,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " group",
            ":",
            " while",
            " lithium",
            ",",
            " sodium",
            " and",
            " potassium",
            " merely",
            " burn",
            " in",
            " air",
            ",",
            " rub",
            "id",
            "ium",
            " and",
            " ca",
            "esium",
            " are",
            " py",
            "roph",
            "oric",
            " (",
            "sp",
            "ont",
            "aneously",
            " catch",
            " fire",
            " in",
            " air",
            ").",
            "The",
            " smaller",
            " alk",
            "ali",
            " metals",
            " tend",
            " to",
            " polar",
            "ise",
            " the",
            " larger",
            " an",
            "ions",
            " (",
            "the",
            " per",
            "oxide",
            " and",
            " super",
            "oxide",
            ")",
            " due",
            " to",
            " their",
            " small",
            " size",
            ".",
            " This",
            " attracts",
            " the",
            " electrons"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " group",
            ".",
            " The",
            " two",
            " Om",
            "otic",
            " languages",
            " with",
            " the",
            " most",
            " speakers",
            " are",
            " Wol",
            "ait",
            "ta",
            " and",
            " G",
            "amo",
            "-G",
            "of",
            "a",
            "-D",
            "aw",
            "ro",
            ",",
            " with",
            " about",
            " ",
            "1",
            ".",
            "2",
            " million",
            " speakers",
            " each",
            ".",
            "A",
            " majority",
            " of",
            " specialists",
            " consider",
            " Om",
            "otic",
            " to",
            " constitute",
            " a",
            " sixth",
            " branch",
            " of",
            " Afro",
            "asi",
            "atic",
            ".",
            " Om",
            "otic",
            " was",
            " formerly",
            " considered",
            " part",
            " of",
            " the",
            " Cush",
            "itic",
            " branch"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.621,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.356,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " group",
            ",",
            " but",
            " had",
            " also",
            " included",
            " groups",
            " now",
            " located",
            " in",
            " L",
            "ilia",
            "les",
            ",",
            " Pand",
            "ana",
            "les",
            " and",
            " Z",
            "ing",
            "ib",
            "era",
            "les",
            ".",
            " Research",
            " in",
            " the",
            " ",
            "21",
            "st",
            " century",
            " has",
            " supported",
            " the",
            " mon",
            "ophy",
            "ly",
            " of",
            " As",
            "par",
            "ag",
            "ales",
            ",",
            " based",
            " on",
            " morphology",
            ",",
            " ",
            "18",
            "S",
            " r",
            "DNA",
            ",",
            " and",
            " other",
            " DNA",
            " sequences",
            ",",
            " although",
            " some",
            " phy",
            "logen",
            "etic"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            0.025,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 32,
          "is_repeated_datapoint": false,
          "tokens": [
            " dark",
            " crust",
            ".",
            " Ph",
            "yt",
            "om",
            "elan",
            "in",
            " is",
            " found",
            " in",
            " most",
            " families",
            " of",
            " the",
            " As",
            "par",
            "ag",
            "ales",
            " (",
            "although",
            " not",
            " in",
            " Orch",
            "id",
            "aceae",
            ",",
            " thought",
            " to",
            " be",
            " the",
            " sister",
            "-group",
            " of",
            " the",
            " rest",
            " of",
            " the",
            " order",
            ").",
            "The",
            " leaves",
            " of",
            " almost",
            " all",
            " species",
            " form",
            " a",
            " tight",
            " ro",
            "set",
            "te",
            ",",
            " either",
            " at",
            " the",
            " base",
            " of",
            " the",
            " plant",
            " or",
            " at",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.414,
            0.013,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.277,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.621,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 59,
          "is_repeated_datapoint": false,
          "tokens": [
            "5",
            "",
            "mg",
            "/mL",
            ",",
            " ",
            "10",
            "",
            "mg",
            "/mL",
            ",",
            " ",
            "20",
            "",
            "mg",
            "/mL",
            ")",
            " given",
            " to",
            " the",
            " same",
            " group",
            " of",
            " patients",
            ",",
            " then",
            " a",
            " linear",
            " trend",
            " estimation",
            " should",
            " be",
            " used",
            ".",
            " Typically",
            ",",
            " however",
            ",",
            " the",
            " one",
            "-way",
            " AN",
            "O",
            "VA",
            " is",
            " used",
            " to",
            " test",
            " for",
            " differences",
            " among",
            " at",
            " least",
            " three",
            " groups",
            ",",
            " since",
            " the",
            " two",
            "-group",
            " case",
            " can",
            " be"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.459,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            "see",
            " also",
            " in",
            "-group",
            " favor",
            "it",
            "ism",
            ").",
            " Many",
            " other",
            " evolutionary",
            " scientists",
            " have",
            " criticized",
            " group",
            " selection",
            " theory",
            ".",
            "Such",
            " explanations",
            " do",
            " not",
            " imply",
            " that",
            " humans",
            " consciously",
            " calculate",
            " how",
            " to",
            " increase",
            " their",
            " inclusive",
            " fitness",
            " when",
            " doing",
            " altru",
            "istic",
            " acts",
            ".",
            " Instead",
            ",",
            " evolution",
            " has",
            " shaped",
            " psychological",
            " mechanisms",
            ",",
            " such",
            " as",
            " emotions",
            ",",
            " that",
            " promote",
            " certain",
            " altru",
            "istic",
            " behaviors",
            ".",
            "The",
            " benefits",
            " for",
            " the",
            " altru"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.441,
            -0.0,
            -0.0,
            0.299,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.418,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.398,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.422,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " iron",
            " tri",
            "ad",
            " and",
            " platinum",
            " group",
            " metals",
            "),",
            " and",
            " once",
            " under",
            " group",
            " IB",
            ".",
            " Group",
            " IB",
            " was",
            " nonetheless",
            " paren",
            "thes",
            "ised",
            " to",
            " note",
            " that",
            " it",
            " was",
            " tentative",
            ".",
            " Mend",
            "ele",
            "ev",
            "'s",
            " main",
            " criterion",
            " for",
            " group",
            " assignment",
            " was",
            " the",
            " maximum",
            " oxidation",
            " state",
            " of",
            " an",
            " element",
            ":",
            " on",
            " that",
            " basis",
            ",",
            " the",
            " group",
            " ",
            "11",
            " elements",
            " could",
            " not",
            " be",
            " classified",
            " in",
            " group",
            " IB"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.578,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.461,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 52,
          "is_repeated_datapoint": false,
          "tokens": [
            "ship",
            " terms",
            " in",
            " political",
            " speeches",
            " increased",
            " audience",
            " agreement",
            " with",
            " the",
            " speaker",
            " in",
            " one",
            " study",
            ".",
            " This",
            " effect",
            " was",
            " powerful",
            " for",
            " first",
            "born",
            "s",
            ",",
            " who",
            " are",
            " typically",
            " close",
            " to",
            " their",
            " families",
            ".",
            " V",
            "ested",
            " interests",
            ".",
            " People",
            " are",
            " likely",
            " to",
            " suffer",
            " if",
            " their",
            " friends",
            ",",
            " allies",
            " and",
            " those",
            " from",
            " similar",
            " social",
            " ing",
            "roups",
            " suffer",
            " or",
            " disappear",
            ".",
            " Helping",
            " such",
            " group",
            " members",
            " may",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.559,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "7",
            ",",
            " and",
            " International",
            " Organization",
            " for",
            " Standard",
            "ization",
            " TC",
            " ",
            "97",
            " SC",
            " ",
            "2",
            " voted",
            " during",
            " October",
            " to",
            " incorporate",
            " the",
            " change",
            " into",
            " its",
            " draft",
            " standard",
            ".",
            " The",
            " X",
            "3",
            ".",
            "2",
            ".",
            "4",
            " task",
            " group",
            " voted",
            " its",
            " approval",
            " for",
            " the",
            " change",
            " to",
            " ASCII",
            " at",
            " its",
            " May",
            " ",
            "196",
            "3",
            " meeting",
            ".",
            " Loc",
            "ating",
            " the",
            " lowercase",
            " letters",
            " in",
            " sticks",
            " ",
            "6",
            " and",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.547,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.352,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.438,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.406,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.393,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.42,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " a",
            " \"",
            "group",
            " VIII",
            "\"",
            " encompass",
            "ing",
            " today",
            "'s",
            " groups",
            " ",
            "8",
            " to",
            " ",
            "11",
            ".",
            " After",
            " the",
            " introduction",
            " of",
            " the",
            " ",
            "18",
            "-column",
            " table",
            ",",
            " the",
            " group",
            " IB",
            " elements",
            " were",
            " moved",
            " to",
            " their",
            " current",
            " position",
            " in",
            " the",
            " d",
            "-block",
            ",",
            " while",
            " alk",
            "ali",
            " metals",
            " were",
            " left",
            " in",
            " group",
            " IA",
            ".",
            " Later",
            " the",
            " group",
            "'s",
            " name",
            " was",
            " changed",
            " to",
            " group",
            " ",
            "1",
            " in"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.34,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.527
          ],
          "train_token_ind": 62,
          "is_repeated_datapoint": false,
          "tokens": [
            "ist",
            " may",
            " be",
            " increased",
            ",",
            " and",
            " the",
            " costs",
            " reduced",
            " by",
            " being",
            " more",
            " altru",
            "istic",
            " towards",
            " certain",
            " groups",
            ".",
            " Research",
            " has",
            " found",
            " that",
            " people",
            " are",
            " more",
            " altru",
            "istic",
            " to",
            " kin",
            " than",
            " to",
            " no",
            "-",
            "kin",
            ",",
            " to",
            " friends",
            " than",
            " strangers",
            ",",
            " to",
            " those",
            " attractive",
            " than",
            " to",
            " those",
            " un",
            "at",
            "tractive",
            ",",
            " to",
            " non",
            "-",
            "compet",
            "itors",
            " than",
            " competitors",
            ",",
            " and",
            " to",
            " members",
            " in",
            "-groups"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.492,
            0.027,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.443,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " placed",
            " within",
            " the",
            " aster",
            "id",
            " group",
            " of",
            " e",
            "udicots",
            " as",
            " circ",
            "ums",
            "cribed",
            " by",
            " the",
            " AP",
            "G",
            " III",
            " system",
            ".",
            " Within",
            " the",
            " aster",
            "ids",
            ",",
            " Ap",
            "iales",
            " belongs",
            " to",
            " an",
            " un",
            "rank",
            "ed",
            " group",
            " called",
            " the",
            " cam",
            "pan",
            "ul",
            "ids",
            ",",
            " and",
            " within",
            " the",
            " cam",
            "pan",
            "ul",
            "ids",
            ",",
            " it",
            " belongs",
            " to",
            " a",
            " cl",
            "ade",
            " known",
            " in",
            " phy",
            "logen",
            "etic",
            " n",
            "omencl",
            "ature"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.42,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.402,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.455,
            -0.0,
            -0.0,
            -0.0,
            0.424,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.41,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            " a",
            " car",
            "box",
            "yl",
            " group",
            " (",
            "thus",
            " they",
            " are",
            " car",
            "box",
            "y",
            "lic",
            " acids",
            "),",
            " an",
            " amino",
            " group",
            ",",
            " a",
            " hydrogen",
            " atom",
            " and",
            " a",
            " variable",
            " group",
            ".",
            " The",
            " variable",
            " group",
            ",",
            " also",
            " called",
            " the",
            " R",
            " group",
            " or",
            " side",
            " chain",
            ",",
            " determines",
            " the",
            " identity",
            " and",
            " many",
            " of",
            " the",
            " properties",
            " of",
            " a",
            " specific",
            " amino",
            " acid",
            ".",
            " In",
            " glyc",
            "ine",
            ",",
            " the",
            " simplest",
            " amino",
            " acid",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.291,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.322,
            -0.0,
            0.195,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.441,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " etc",
            ".).",
            " Since",
            " the",
            " distributions",
            " of",
            " dog",
            " weight",
            " within",
            " each",
            " of",
            " the",
            " groups",
            " (",
            "shown",
            " in",
            " blue",
            ")",
            " has",
            " a",
            " relatively",
            " large",
            " variance",
            ",",
            " and",
            " since",
            " the",
            " means",
            " are",
            " very",
            " similar",
            " across",
            " groups",
            ",",
            " grouping",
            " dogs",
            " by",
            " these",
            " characteristics",
            " does",
            " not",
            " produce",
            " an",
            " effective",
            " way",
            " to",
            " explain",
            " the",
            " variation",
            " in",
            " dog",
            " weights",
            ":",
            " knowing",
            " which",
            " group",
            " a",
            " dog",
            " is",
            " in",
            " doesn",
            "'t"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.418,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "198",
            "8",
            ".",
            " The",
            " trivial",
            " name",
            " \"",
            "alk",
            "ali",
            " metals",
            "\"",
            " comes",
            " from",
            " the",
            " fact",
            " that",
            " the",
            " hydro",
            "x",
            "ides",
            " of",
            " the",
            " group",
            " ",
            "1",
            " elements",
            " are",
            " all",
            " strong",
            " alk",
            "alis",
            " when",
            " dissolved",
            " in",
            " water",
            ".",
            "There",
            " were",
            " at",
            " least",
            " four",
            " erroneous",
            " and",
            " incomplete",
            " discoveries",
            " before",
            " Marg",
            "uer",
            "ite",
            " Pere",
            "y",
            " of",
            " the",
            " Cur",
            "ie",
            " Institute",
            " in",
            " Paris",
            ",",
            " France",
            " discovered",
            " franc"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.391,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.383,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 11,
          "is_repeated_datapoint": false,
          "tokens": [
            "par",
            "ag",
            "ales",
            ",",
            " generally",
            " to",
            " family",
            " level",
            ",",
            " but",
            " including",
            " groups",
            " which",
            " were",
            " recently",
            " and",
            " widely",
            " treated",
            " as",
            " families",
            " but",
            " which",
            " are",
            " now",
            " reduced",
            " to",
            " sub",
            "family",
            " rank",
            ",",
            " is",
            " shown",
            " below",
            ".",
            "The",
            " tree",
            " shown",
            " above",
            " can",
            " be",
            " divided",
            " into",
            " a",
            " basal",
            " paraph",
            "yle",
            "tic",
            " group",
            ",",
            " the",
            " '",
            "lower",
            " As",
            "par",
            "ag",
            "ales",
            " (",
            "as",
            "par",
            "ag",
            "oids",
            ")',",
            " from"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.391,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 58,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " and",
            " by",
            " using",
            " internal",
            " fertil",
            "isation",
            ".",
            " In",
            " sal",
            "am",
            "and",
            "rid",
            "s",
            ",",
            " the",
            " male",
            " deposits",
            " a",
            " bundle",
            " of",
            " sperm",
            ",",
            " the",
            " sper",
            "mat",
            "oph",
            "ore",
            ",",
            " and",
            " the",
            " female",
            " picks",
            " it",
            " up",
            " and",
            " inserts",
            " it",
            " into",
            " her",
            " clo",
            "aca",
            " where",
            " the",
            " sperm",
            " is",
            " stored",
            " until",
            " the",
            " eggs",
            " are",
            " laid",
            ".",
            " The",
            " largest",
            " family",
            " in",
            " this",
            " group",
            " is",
            " Ple",
            "th",
            "odont"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.367,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            "Israel",
            "]",
            " Miller",
            " didn",
            "'t",
            " mind",
            ".",
            " Miller",
            " loved",
            " them",
            ".\"",
            "In",
            " ",
            "195",
            "2",
            ",",
            " War",
            "hol",
            " had",
            " his",
            " first",
            " solo",
            " show",
            " at",
            " the",
            " Hugo",
            " Gallery",
            " in",
            " New",
            " York",
            ",",
            " and",
            " although",
            " that",
            " show",
            " was",
            " not",
            " well",
            " received",
            ",",
            " by",
            " ",
            "195",
            "6",
            ",",
            " he",
            " was",
            " included",
            " in",
            " his",
            " first",
            " group",
            " exhibition",
            " at",
            " the",
            " Museum",
            " of",
            " Modern",
            " Art",
            ",",
            " New",
            " York",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.326,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            " spirit",
            " alive",
            " was",
            " more",
            " important",
            ".",
            " Washington",
            " informed",
            " Henry",
            " Laure",
            "ns",
            ",",
            " then",
            " president",
            " of",
            " the",
            " Second",
            " Continental",
            " Congress",
            ",",
            " \"",
            "that",
            " the",
            " possession",
            " of",
            " our",
            " towns",
            ",",
            " while",
            " we",
            " have",
            " an",
            " army",
            " in",
            " the",
            " field",
            ",",
            " will",
            " avail",
            " them",
            " little",
            ".\"",
            "Although",
            " the",
            " Continental",
            " Congress",
            " was",
            " responsible",
            " for",
            " the",
            " war",
            " effort",
            " and",
            " provided",
            " supplies",
            " to",
            " the",
            " troops",
            ",",
            " Washington",
            " took",
            " it",
            " upon"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.196,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            " Europe",
            ",",
            " North",
            " America",
            ",",
            " South",
            " Korea",
            " and",
            " Japan",
            " have",
            " operations",
            " in",
            " Asia",
            "'s",
            " developing",
            " countries",
            " to",
            " take",
            " advantage",
            " of",
            " its",
            " abundant",
            " supply",
            " of",
            " cheap",
            " labour",
            " and",
            " relatively",
            " developed",
            " infrastructure",
            ".",
            "According",
            " to",
            " Cit",
            "igroup",
            " in",
            " ",
            "201",
            "1",
            ",",
            " ",
            "9",
            " of",
            " ",
            "11",
            " Global",
            " Growth",
            " Gener",
            "ators",
            " countries",
            " came",
            " from",
            " Asia",
            " driven",
            " by",
            " population",
            " and",
            " income",
            " growth",
            ".",
            " They",
            " are",
            " Bangladesh"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " coast",
            ".",
            " Fishing",
            " ",
            " Aber",
            "de",
            "ens",
            "hire",
            " is",
            " Scotland",
            "'s",
            " foremost",
            " fishing",
            " area",
            ".",
            " In",
            " ",
            "201",
            "0",
            ",",
            " catches",
            " landed",
            " at",
            " Aber",
            "de",
            "ens",
            "hire",
            "'s",
            " ports",
            " accounted",
            " for",
            " over",
            " half",
            " the",
            " total",
            " fish",
            " land",
            "ings",
            " in",
            " Scotland",
            " and",
            " almost",
            " ",
            "45",
            "%",
            " in",
            " the",
            " UK",
            ".",
            " Along",
            " with",
            " Aberdeen",
            " City",
            ",",
            " Peter",
            "head",
            " and",
            " Fraser",
            "burgh",
            " ports",
            " provide",
            " much"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " particular",
            " emphasis",
            " on",
            " its",
            " \"",
            "special",
            " relationship",
            "\"",
            " with",
            " Turkey",
            ".",
            "A",
            "zerbai",
            "jan",
            " has",
            " diplomatic",
            " relations",
            " with",
            " ",
            "158",
            " countries",
            " so",
            " far",
            " and",
            " holds",
            " membership",
            " in",
            " ",
            "38",
            " international",
            " organizations",
            ".",
            " It",
            " holds",
            " observer",
            " status",
            " in",
            " the",
            " Non",
            "-Al",
            "igned",
            " Movement",
            " and",
            " World",
            " Trade",
            " Organization",
            " and",
            " is",
            " a",
            " correspondent",
            " at",
            " the",
            " International",
            " Tele",
            "communication",
            " Union",
            ".",
            " ",
            "On",
            " ",
            "9",
            " May",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " spacecraft",
            ",",
            " separated",
            " from",
            " it",
            ".",
            " The",
            " crew",
            " then",
            " rotated",
            " the",
            " spacecraft",
            " to",
            " take",
            " photographs",
            " of",
            " the",
            " spent",
            " stage",
            " and",
            " then",
            " practiced",
            " flying",
            " in",
            " formation",
            " with",
            " it",
            ".",
            " As",
            " the",
            " crew",
            " rotated",
            " the",
            " spacecraft",
            ",",
            " they",
            " had",
            " their",
            " first",
            " views",
            " of",
            " the",
            " Earth",
            " as",
            " they",
            " moved",
            " away",
            " from",
            " it",
            "",
            "this",
            " marked",
            " the",
            " first",
            " time",
            " humans",
            " had",
            " viewed",
            " the",
            " whole",
            " Earth",
            " at",
            " once"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "ental",
            "ism",
            ")",
            " can",
            " be",
            " observed",
            " in",
            " the",
            " Tr",
            "act",
            "atus",
            " Log",
            "ico",
            "-",
            "Phil",
            "osoph",
            "icus",
            ".",
            " Later",
            " on",
            ",",
            " Witt",
            "gen",
            "stein",
            " rejected",
            " ep",
            "istem",
            "ological",
            " transcend",
            "ental",
            " ideal",
            "ism",
            " for",
            " Gott",
            "lob",
            " Fre",
            "ge",
            "'s",
            " conceptual",
            " realism",
            ".",
            " In",
            " later",
            " years",
            ",",
            " Witt",
            "gen",
            "stein",
            " became",
            " highly",
            " dismiss",
            "ive",
            " of",
            " Sch",
            "openh",
            "auer",
            ",",
            " describing",
            " him",
            " as",
            " an",
            " ultimately",
            " shallow"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " total",
            " of",
            " about",
            " ",
            "74",
            " (",
            "depending",
            " on",
            " what",
            " is",
            " considered",
            " a",
            " language",
            " and",
            " what",
            " is",
            " considered",
            " a",
            " dialect",
            ").",
            " These",
            " numbers",
            " do",
            " not",
            " include",
            " earlier",
            " states",
            " of",
            " languages",
            ",",
            " such",
            " as",
            " Middle",
            " Mong",
            "ol",
            ",",
            " Old",
            " Korean",
            ",",
            " or",
            " Old",
            " Japanese",
            ".",
            "U",
            "ral",
            "o",
            "-Al",
            "ta",
            "ic",
            " hypothesis",
            "In",
            " ",
            "184",
            "4",
            ",",
            " the",
            " Finnish",
            " phil",
            "ologist",
            " Matthias",
            " Ca",
            "str"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "rani",
    "etas",
    "arella",
    "714",
    "ienza"
  ],
  "bottom_logits": [
    " another",
    " forecast",
    "",
    " Brow",
    "iram"
  ],
  "act_min": -0.0,
  "act_max": 0.969
}

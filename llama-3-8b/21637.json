{
  "index": 21637,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.695,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 15,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            "16",
            " heavy",
            " appliances",
            " (",
            "fire",
            " tend",
            "ers",
            ",",
            " turn",
            "table",
            " l",
            "adders",
            ",",
            " and",
            " specialist",
            " four",
            "-wheel",
            " drive",
            " vehicles",
            "),",
            " four",
            " light",
            " support",
            " vehicles",
            " (",
            "cars",
            " and",
            " vans",
            ")",
            " and",
            " four",
            " amb",
            "ul",
            "ances",
            ".",
            "Histor",
            "ically",
            ",",
            " the",
            " families",
            " of",
            " the",
            " six",
            " ancient",
            " par",
            "ishes",
            " of",
            " And",
            "orra",
            " maintained",
            " local",
            " arrangements",
            " to",
            " assist",
            " each",
            " other",
            " in",
            " fighting",
            " fires",
            ".",
            " The",
            " first"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.68
          ],
          "train_token_ind": 51,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " website",
            " of",
            " the",
            " International",
            " Aluminium",
            " Institute",
            " E",
            "medicine",
            " â€“",
            " Aluminium",
            " ",
            " ",
            "Chem",
            "ical",
            " elements",
            "Post",
            "-transition",
            " metals",
            "Al",
            "uminium",
            "Elect",
            "rical",
            " conduct",
            "ors",
            "Py",
            "rote",
            "chn",
            "ic",
            " fuels",
            "Air",
            "ship",
            " technology",
            "Reduc",
            "ing",
            " agents",
            "E",
            "-number",
            " additives",
            "Native",
            " element",
            " minerals",
            "Chem",
            "ical",
            " elements",
            " with",
            " face",
            "-centered",
            " cubic",
            " structure",
            "<|begin_of_text|>",
            "Advanced"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.672,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " automobile",
            " makers",
            " to",
            " demonstrate",
            " their",
            " machines",
            ".",
            " By",
            " the",
            " ",
            "193",
            "0",
            "s",
            ",",
            " specialist",
            " racing",
            " cars",
            " had",
            " developed",
            ".",
            "There",
            " are",
            " now",
            " numerous",
            " different",
            " categories",
            ",",
            " each",
            " with",
            " different",
            " rules",
            " and",
            " regulations",
            ".",
            "History",
            "The",
            " first",
            " pre",
            "arr",
            "anged",
            " match",
            " race",
            " of",
            " two",
            " self",
            "-powered",
            " road",
            " vehicles",
            " over",
            " a",
            " prescribed",
            " route",
            " occurred",
            " at",
            " ",
            "4",
            ":",
            "30",
            " A",
            ".M",
            ".",
            " on"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.41,
            -0.0,
            -0.0,
            0.668,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 7,
          "is_repeated_datapoint": false,
          "tokens": [
            " multi",
            "-prof",
            "essional",
            " subject",
            " because",
            " it",
            " requires",
            " specialist",
            " understanding",
            " of",
            " the",
            " potential",
            " ethical",
            " issues",
            " in",
            " fields",
            " like",
            " medicine",
            ",",
            " business",
            " or",
            " information",
            " technology",
            ".",
            " Nowadays",
            ",",
            " ethical",
            " codes",
            " of",
            " conduct",
            " exist",
            " in",
            " almost",
            " every",
            " profession",
            ".",
            "An",
            " applied",
            " ethics",
            " approach",
            " to",
            " the",
            " examination",
            " of",
            " moral",
            " dile",
            "mmas",
            " can",
            " take",
            " many",
            " different",
            " forms",
            " but",
            " one",
            " of",
            " the",
            " most",
            " influential",
            " and",
            " most",
            " widely",
            " util",
            "ised"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.66,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " specialists",
            " as",
            " Pam",
            " Sh",
            "river",
            " and",
            " Peter",
            " Fleming",
            ".",
            "Personal",
            " life",
            " ",
            "K",
            "ourn",
            "ik",
            "ova",
            " was",
            " in",
            " a",
            " relationship",
            " with",
            " fellow",
            " Russian",
            ",",
            " Pavel",
            " B",
            "ure",
            ",",
            " an",
            " NHL",
            " ice",
            " hockey",
            " player",
            ".",
            " The",
            " two",
            " met",
            " in",
            " ",
            "199",
            "9",
            ",",
            " when",
            " K",
            "ourn",
            "ik",
            "ova",
            " was",
            " still",
            " linked",
            " to",
            " B",
            "ure",
            "'s",
            " former",
            " Russian",
            " teammate",
            " Sergei",
            " Fed",
            "or",
            "ov",
            ".",
            " B"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.656,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            "ersh",
            "win",
            " specialist",
            " Jack",
            " Gib",
            "bons",
            " made",
            " his",
            " own",
            " restoration",
            " of",
            " the",
            " original",
            " orchest",
            "ration",
            " of",
            " An",
            " American",
            " in",
            " Paris",
            ",",
            " working",
            " directly",
            " from",
            " G",
            "ersh",
            "win",
            "'s",
            " original",
            " manuscript",
            ",",
            " including",
            " the",
            " restoration",
            " of",
            " G",
            "ersh",
            "win",
            "'s",
            " sopr",
            "ano",
            " sax",
            "ophone",
            " parts",
            " removed",
            " in",
            " Campbell",
            "-W",
            "at",
            "son",
            "'s",
            " revision",
            ".",
            " Gib",
            "bons",
            "'",
            " restored",
            " orchest",
            "ration",
            " of",
            " An",
            " American",
            " in"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.644,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 48,
          "is_repeated_datapoint": false,
          "tokens": [
            " Unix",
            " conventions",
            ",",
            " the",
            " null",
            " character",
            " is",
            " used",
            " to",
            " terminate",
            " text",
            " strings",
            ";",
            " such",
            " null",
            "-",
            "terminated",
            " strings",
            " can",
            " be",
            " known",
            " in",
            " abbreviation",
            " as",
            " ASC",
            "IZ",
            " or",
            " ASC",
            "I",
            "IZ",
            ",",
            " where",
            " here",
            " Z",
            " stands",
            " for",
            " \"",
            "zero",
            "\".",
            "Control",
            " code",
            " chart",
            "Other",
            " representations",
            " might",
            " be",
            " used",
            " by",
            " specialist",
            " equipment",
            ",",
            " for",
            " example",
            " ISO",
            " ",
            "204",
            "7",
            " graphics",
            " or",
            " hexadecimal",
            " numbers",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.644,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            " Atlas",
            ",",
            " a",
            " computer",
            " used",
            " at",
            " the",
            " Lawrence",
            " Liver",
            "more",
            " National",
            " Laboratory",
            " in",
            " ",
            "200",
            "6",
            " Abb",
            "rev",
            "iated",
            " Test",
            " Language",
            " for",
            " All",
            " Systems",
            " (",
            "AT",
            "LAS",
            "),",
            " a",
            " computer",
            " language",
            " for",
            " equipment",
            " testing",
            " Advanced",
            " Technology",
            " Leisure",
            " Application",
            " Simulator",
            " (",
            "AT",
            "LAS",
            "),",
            " a",
            " hydraulic",
            " motion",
            " simulator",
            " used",
            " in",
            " theme",
            " parks",
            " ASP",
            ".NET",
            " AJAX",
            " (",
            "formerly",
            " \"",
            "Atlas",
            "\"),",
            " a"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.641,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.496,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " revive",
            " and",
            " recreate",
            " concepts",
            " of",
            " identity",
            " in",
            " connection",
            " to",
            " traditional",
            " ethnic",
            " origins",
            ".",
            "Advanced",
            " Chemistry",
            " helped",
            " to",
            " found",
            " the",
            " German",
            " chapter",
            " of",
            " the",
            " Z",
            "ulu",
            " nation",
            ".",
            "The",
            " rivalry",
            " between",
            " Advanced",
            " Chemistry",
            " and",
            " Die",
            " Fant",
            "ast",
            "ischen",
            " V",
            "ier",
            " has",
            " served",
            " to",
            " highlight",
            " a",
            " dich",
            "otomy",
            " in",
            " the",
            " routes",
            " that",
            " hip",
            " hop",
            " has",
            " taken",
            " in",
            " becoming",
            " a",
            " part",
            " of",
            " the",
            " German",
            " sounds"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.617,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 49,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " and",
            " Dorothy",
            " Met",
            "c",
            "alf",
            "-L",
            "inden",
            "burger",
            ".",
            "Bar",
            "bara",
            " Morgan",
            ",",
            " selected",
            " as",
            " back",
            "-up",
            " teacher",
            " to",
            " Christ",
            "a",
            " McA",
            "ul",
            "iffe",
            " in",
            " ",
            "198",
            "5",
            ",",
            " is",
            " considered",
            " to",
            " be",
            " the",
            " first",
            " Educ",
            "ator",
            " astronaut",
            " by",
            " the",
            " media",
            ",",
            " but",
            " she",
            " trained",
            " as",
            " a",
            " mission",
            " specialist",
            ".",
            "The",
            " Educ",
            "ator",
            " Astr",
            "onaut",
            " program",
            " is",
            " a",
            " successor",
            " to",
            " the",
            " Teacher"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            " rap",
            " in",
            " German",
            " (",
            "although",
            " their",
            " name",
            " is",
            " in",
            " English",
            ").",
            " Furthermore",
            ",",
            " their",
            " songs",
            " tackled",
            " controversial",
            " social",
            " and",
            " political",
            " issues",
            ",",
            " distinguishing",
            " them",
            " from",
            " early",
            " German",
            " hip",
            " hop",
            " group",
            " \"",
            "Die",
            " Fant",
            "ast",
            "ischen",
            " V",
            "ier",
            "\"",
            " (",
            "The",
            " Fantastic",
            " Four",
            "),",
            " ",
            " which",
            " had",
            " a",
            " more",
            " light",
            "-hearted",
            ",",
            " playful",
            ",",
            " party",
            " image",
            ".",
            "Career",
            "Advanced",
            " Chemistry",
            " frequently",
            " r",
            "apped"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.598,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "'s",
            " hope",
            " of",
            " actually",
            " being",
            " recognized",
            " as",
            " German",
            " citizens",
            " and",
            " not",
            " foreigners",
            ",",
            " despite",
            " their",
            " various",
            " other",
            " ethnic",
            " and",
            " cultural",
            " ties",
            ".",
            "In",
            "flu",
            "ences",
            "Advanced",
            " Chemistry",
            "'s",
            " work",
            " was",
            " rooted",
            " in",
            " German",
            " history",
            " and",
            " the",
            " country",
            "'s",
            " specific",
            " political",
            " realities",
            ".",
            " However",
            ",",
            " they",
            " also",
            " drew",
            " inspiration",
            " from",
            " African",
            "-American",
            " hip",
            "-hop",
            " acts",
            " like",
            " A",
            " Tribe",
            " Called",
            " Quest",
            " and",
            " Public",
            " Enemy"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 39,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " with",
            " around",
            " ",
            "240",
            " police",
            " officers",
            " supported",
            " by",
            " civilian",
            " assistants",
            ".",
            " The",
            " principal",
            " services",
            " supplied",
            " by",
            " the",
            " corps",
            " are",
            " uniform",
            "ed",
            " community",
            " policing",
            ",",
            " criminal",
            " detection",
            ",",
            " border",
            " control",
            ",",
            " and",
            " traffic",
            " policing",
            ".",
            " There",
            " are",
            " also",
            " small",
            " specialist",
            " units",
            " including",
            " police",
            " dogs",
            ",",
            " mountain",
            " rescue",
            ",",
            " and",
            " a",
            " bomb",
            " disposal",
            " team",
            ".",
            "G",
            "IPA",
            "The",
            " Gr",
            "up",
            " d",
            "'",
            "Int"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            " wants",
            " to",
            " buy",
            " sour",
            " milk",
            ".\"",
            "In",
            " May",
            " ",
            "201",
            "7",
            ",",
            " the",
            " company",
            " announced",
            " a",
            " $",
            "1",
            " billion",
            " funding",
            " project",
            " for",
            " \"",
            "advanced",
            " manufacturing",
            "\"",
            " in",
            " the",
            " United",
            " States",
            ",",
            " and",
            " subsequently",
            " invested",
            " $",
            "200",
            "Ã‚Å‚",
            "million",
            " in",
            " Cor",
            "ning",
            " Inc",
            ".,",
            " a",
            " manufacturer",
            " of",
            " tough",
            "ened",
            " Gor",
            "illa",
            " Glass",
            " technology",
            " used",
            " in",
            " its",
            " iPhone",
            " devices",
            ".",
            " The",
            " following",
            " December",
            ",",
            " Apple"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " Ple",
            "i",
            "ades",
            " Advanced",
            " Top",
            "ographic",
            " Laser",
            " Al",
            "tim",
            "eter",
            " System",
            " (",
            "AT",
            "LAS",
            "),",
            " a",
            " space",
            "-based",
            " lid",
            "ar",
            " instrument",
            " on",
            " IC",
            "ES",
            "at",
            "-",
            "2",
            " Aster",
            "oid",
            " Ter",
            "restrial",
            "-",
            "impact",
            " Last",
            " Alert",
            " System",
            " (",
            "AT",
            "LAS",
            ")",
            "Math",
            "ematics",
            " Atlas",
            " (",
            "top",
            "ology",
            "),",
            " a",
            " set",
            " of",
            " charts",
            " A",
            " set",
            " of",
            " charts",
            " which",
            " covers",
            " a"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 23,
          "is_repeated_datapoint": false,
          "tokens": [
            " wants",
            " to",
            " buy",
            " sour",
            " milk",
            ".\"",
            "In",
            " May",
            " ",
            "201",
            "7",
            ",",
            " the",
            " company",
            " announced",
            " a",
            " $",
            "1",
            " billion",
            " funding",
            " project",
            " for",
            " \"",
            "advanced",
            " manufacturing",
            "\"",
            " in",
            " the",
            " United",
            " States",
            ",",
            " and",
            " subsequently",
            " invested",
            " $",
            "200",
            "Ã‚Å‚",
            "million",
            " in",
            " Cor",
            "ning",
            " Inc",
            ".,",
            " a",
            " manufacturer",
            " of",
            " tough",
            "ened",
            " Gor",
            "illa",
            " Glass",
            " technology",
            " used",
            " in",
            " its",
            " iPhone",
            " devices",
            ".",
            " The",
            " following",
            " December",
            ",",
            " Apple"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.543,
            -0.0,
            -0.0,
            -0.0,
            0.586,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " Latin",
            " American",
            " trade",
            " union",
            " conf",
            "ederation",
            " Atlas",
            " languages",
            ",",
            " Ber",
            "ber",
            " languages",
            " spoken",
            " in",
            " the",
            " Atlas",
            " Mountains",
            " of",
            " Morocco",
            " AT",
            "LAS",
            " Network",
            ",",
            " a",
            " network",
            " of",
            " European",
            " special",
            " police",
            " units",
            " Atlas",
            " Uran",
            "ium",
            " Mill",
            " Atlas",
            " Corporation",
            ",",
            " a",
            " private",
            " military",
            " company",
            " by",
            " Call",
            " of",
            " Duty",
            ":",
            " Advanced",
            " Warfare",
            "See",
            " also",
            " Advanced",
            " Technology",
            " Large",
            "-A",
            "p",
            "erture",
            " Space"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.582,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " advanced",
            " primary",
            " and",
            " then",
            " secondary",
            " school",
            " education",
            ".",
            "In",
            " ",
            "189",
            "4",
            ",",
            " Herm",
            "ann",
            " and",
            " Jak",
            "ob",
            "'s",
            " company",
            " tender",
            "ed",
            " for",
            " a",
            " contract",
            " to",
            " install",
            " electric",
            " lighting",
            " in",
            " Munich",
            ",",
            " but",
            " without",
            " success",
            "â€”they",
            " lacked",
            " the",
            " capital",
            " that",
            " would",
            " have",
            " been",
            " required",
            " to",
            " update",
            " their",
            " technology",
            " from",
            " direct",
            " current",
            " to",
            " the",
            " more",
            " efficient",
            ",",
            " alternating",
            " current",
            " alternative",
            ".",
            " The",
            " failure",
            " of"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.574,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " Duty",
            ":",
            " Advanced",
            " Warfare",
            "Br",
            "ands",
            " and",
            " enterprises",
            " Atlas",
            " (",
            "ap",
            "pliance",
            " company",
            "),",
            " in",
            " Belarus",
            " Atlas",
            " (",
            "restaurant",
            "),",
            " a",
            " Mich",
            "elin",
            "-star",
            "red",
            " restaurant",
            " in",
            " Atlanta",
            " Atlas",
            " Consortium",
            ",",
            " a",
            " group",
            " of",
            " technology",
            " companies",
            " Atlas",
            " Cop",
            "co",
            ",",
            " a",
            " Swedish",
            " company",
            " founded",
            " in",
            " ",
            "187",
            "3",
            " Atlas",
            " Corporation",
            ",",
            " an",
            " investment",
            " company",
            " Atlas",
            " Ele"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.574,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " music",
            "ologists",
            " and",
            " other",
            " specialists",
            " engaged",
            " in",
            " the",
            " description",
            " and",
            " interpretation",
            " of",
            " cultural",
            " forms",
            ".",
            " Cognitive",
            " anthropology",
            " is",
            " concerned",
            " with",
            " what",
            " people",
            " from",
            " different",
            " groups",
            " know",
            " and",
            " how",
            " that",
            " implicit",
            " knowledge",
            " changes",
            " the",
            " way",
            " people",
            " perceive",
            " and",
            " relate",
            " to",
            " the",
            " world",
            " around",
            " them",
            ".",
            "Trans",
            "personal",
            " ",
            "Trans",
            "personal",
            " anthropology",
            " studies",
            " the",
            " relationship",
            " between",
            " altered",
            " states",
            " of",
            " consciousness",
            " and",
            " culture",
            ".",
            " As"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.574,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 13,
          "is_repeated_datapoint": false,
          "tokens": [
            " defiance",
            ".",
            " According",
            " to",
            " German",
            " hip",
            " hop",
            " enthusiast",
            " ",
            "9",
            "@",
            "home",
            ",",
            " Advanced",
            " Chemistry",
            " is",
            " part",
            " of",
            " a",
            " \"",
            "hip",
            "-hop",
            " movement",
            " [",
            "which",
            "]",
            " took",
            " a",
            " clear",
            " stance",
            " for",
            " the",
            " minorities",
            " and",
            " against",
            " the",
            " [",
            "m",
            "arg",
            "inal",
            "ization",
            "]",
            " of",
            " immigrants",
            " who",
            "...",
            "might",
            " be",
            " German",
            " on",
            " paper",
            ",",
            " but",
            " not",
            " in",
            " real",
            " life",
            ",\"",
            " which",
            " speaks",
            " to",
            " the",
            " group"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            0.574,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 2,
          "is_repeated_datapoint": false,
          "tokens": [
            " Duty",
            ":",
            " Advanced",
            " Warfare",
            "Br",
            "ands",
            " and",
            " enterprises",
            " Atlas",
            " (",
            "ap",
            "pliance",
            " company",
            "),",
            " in",
            " Belarus",
            " Atlas",
            " (",
            "restaurant",
            "),",
            " a",
            " Mich",
            "elin",
            "-star",
            "red",
            " restaurant",
            " in",
            " Atlanta",
            " Atlas",
            " Consortium",
            ",",
            " a",
            " group",
            " of",
            " technology",
            " companies",
            " Atlas",
            " Cop",
            "co",
            ",",
            " a",
            " Swedish",
            " company",
            " founded",
            " in",
            " ",
            "187",
            "3",
            " Atlas",
            " Corporation",
            ",",
            " an",
            " investment",
            " company",
            " Atlas",
            " Ele"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.57,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.52,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            "cape",
            ".",
            " ",
            " While",
            " Die",
            " Fant",
            "ast",
            "ischen",
            " V",
            "ier",
            " may",
            " be",
            " said",
            " to",
            " view",
            " hip",
            " hop",
            " primarily",
            " as",
            " an",
            " aesthetic",
            " art",
            " form",
            ",",
            " ",
            " Advanced",
            " Chemistry",
            " understand",
            " hip",
            " hop",
            " as",
            " being",
            " in",
            "extr",
            "ic",
            "ably",
            " linked",
            " to",
            " the",
            " social",
            " and",
            " political",
            " circumstances",
            " under",
            " which",
            " it",
            " is",
            " created",
            ".",
            " ",
            " For",
            " Advanced",
            " Chemistry",
            ",",
            " hip",
            " hop",
            " is",
            " a",
            " â€œ",
            "vehicle",
            " of",
            " general",
            " human"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.566,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 56,
          "is_repeated_datapoint": false,
          "tokens": [
            ".\"",
            " This",
            " insight",
            " is",
            " seen",
            " as",
            " significant",
            " by",
            " writers",
            " such",
            " as",
            " Betty",
            " To",
            "ole",
            " and",
            " Benjamin",
            " Wool",
            "ley",
            ",",
            " as",
            " well",
            " as",
            " the",
            " programmer",
            " John",
            " Graham",
            "-C",
            "um",
            "ming",
            ",",
            " whose",
            " project",
            " Plan",
            " ",
            "28",
            " has",
            " the",
            " aim",
            " of",
            " constructing",
            " the",
            " first",
            " complete",
            " Analy",
            "tical",
            " Engine",
            ".",
            "According",
            " to",
            " the",
            " historian",
            " of",
            " computing",
            " and",
            " B",
            "abbage",
            " specialist",
            " Dor",
            "on",
            " Sw",
            "ade",
            ":",
            "Ada"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.559,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " then",
            " as",
            " the",
            " Center",
            " for",
            " Advanced",
            " Film",
            " Studies",
            ".",
            " Also",
            " created",
            " in",
            " the",
            " early",
            " years",
            " were",
            " a",
            " rep",
            "ert",
            "ory",
            " film",
            " exhibition",
            " program",
            " at",
            " the",
            " Kennedy",
            " Center",
            " for",
            " the",
            " Performing",
            " Arts",
            " and",
            " the",
            " A",
            "FI",
            " Catalog",
            " of",
            " Feature",
            " Films",
            " â€”",
            " a",
            " scholarly",
            " source",
            " for",
            " American",
            " film",
            " history",
            ".",
            " The",
            " institute",
            " moved",
            " to",
            " its",
            " current",
            " eight",
            "-acre",
            " Hollywood",
            " campus",
            " in",
            " ",
            "198",
            "1",
            "."
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.555,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            " Chemistry",
            " is",
            " a",
            " German",
            " hip",
            " hop",
            " group",
            " from",
            " He",
            "idelberg",
            ",",
            " a",
            " scenic",
            " city",
            " in",
            " Bad",
            "en",
            "-W",
            "ÃƒÂ¼",
            "rt",
            "tem",
            "berg",
            ",",
            " South",
            " Germany",
            ".",
            " Advanced",
            " Chemistry",
            " was",
            " founded",
            " in",
            " ",
            "198",
            "7",
            " by",
            " Toni",
            " L",
            ",",
            " Lingu",
            "ist",
            ",",
            " Gee",
            "-One",
            ",",
            " DJ",
            " Mike",
            " MD",
            " (",
            "Mike",
            " Dip",
            "pon",
            ")",
            " and",
            " MC",
            " Torch",
            ".",
            " Each",
            " member",
            " of",
            " the",
            " group",
            " holds",
            " German"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.539,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.31,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.555,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            "igrant",
            " sentiment",
            " emerged",
            ",",
            " as",
            " well",
            " as",
            " attacks",
            " on",
            " the",
            " homes",
            " of",
            " refugees",
            " in",
            " the",
            " early",
            " ",
            "199",
            "0",
            "s",
            ".",
            " ",
            " Advanced",
            " Chemistry",
            " came",
            " to",
            " prominence",
            " in",
            " the",
            " wake",
            " of",
            " these",
            " actions",
            " because",
            " of",
            " their",
            " pro",
            "-mult",
            "icultural",
            " society",
            " stance",
            " in",
            " their",
            " music",
            ".",
            " ",
            " Advanced",
            " Chemistry",
            "'s",
            " attitudes",
            " rev",
            "olve",
            " around",
            " their",
            " attempts",
            " to",
            " create",
            " a",
            " distinct",
            " \"",
            "G",
            "erm",
            "anness"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.555,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " are",
            " confused",
            " by",
            " Advanced",
            " Chemistry",
            "'s",
            " elic",
            "itation",
            " of",
            " a",
            " German",
            " identity",
            " politics",
            " to",
            " which",
            " they",
            " technically",
            " do",
            " not",
            " belong",
            ".",
            " This",
            " cultural",
            " binary",
            " illustrates",
            " that",
            " rap",
            " has",
            " taken",
            " different",
            " routes",
            " in",
            " Germany",
            " and",
            " that",
            ",",
            " even",
            " among",
            " an",
            " already",
            " isolated",
            " immigrant",
            " population",
            ",",
            " there",
            " is",
            " still",
            " dis",
            "unity",
            " and",
            ",",
            " especially",
            ",",
            " disagreement",
            " on",
            " the",
            " relative",
            " importance",
            " of",
            " assim",
            "ilation",
            " versus",
            " cultural"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.555,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            " Chemistry",
            " is",
            " a",
            " German",
            " hip",
            " hop",
            " group",
            " from",
            " He",
            "idelberg",
            ",",
            " a",
            " scenic",
            " city",
            " in",
            " Bad",
            "en",
            "-W",
            "ÃƒÂ¼",
            "rt",
            "tem",
            "berg",
            ",",
            " South",
            " Germany",
            ".",
            " Advanced",
            " Chemistry",
            " was",
            " founded",
            " in",
            " ",
            "198",
            "7",
            " by",
            " Toni",
            " L",
            ",",
            " Lingu",
            "ist",
            ",",
            " Gee",
            "-One",
            ",",
            " DJ",
            " Mike",
            " MD",
            " (",
            "Mike",
            " Dip",
            "pon",
            ")",
            " and",
            " MC",
            " Torch",
            ".",
            " Each",
            " member",
            " of",
            " the",
            " group",
            " holds",
            " German"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.555,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            " are",
            " confused",
            " by",
            " Advanced",
            " Chemistry",
            "'s",
            " elic",
            "itation",
            " of",
            " a",
            " German",
            " identity",
            " politics",
            " to",
            " which",
            " they",
            " technically",
            " do",
            " not",
            " belong",
            ".",
            " This",
            " cultural",
            " binary",
            " illustrates",
            " that",
            " rap",
            " has",
            " taken",
            " different",
            " routes",
            " in",
            " Germany",
            " and",
            " that",
            ",",
            " even",
            " among",
            " an",
            " already",
            " isolated",
            " immigrant",
            " population",
            ",",
            " there",
            " is",
            " still",
            " dis",
            "unity",
            " and",
            ",",
            " especially",
            ",",
            " disagreement",
            " on",
            " the",
            " relative",
            " importance",
            " of",
            " assim",
            "ilation",
            " versus",
            " cultural"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.539,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.31,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.555,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 46,
          "is_repeated_datapoint": false,
          "tokens": [
            "igrant",
            " sentiment",
            " emerged",
            ",",
            " as",
            " well",
            " as",
            " attacks",
            " on",
            " the",
            " homes",
            " of",
            " refugees",
            " in",
            " the",
            " early",
            " ",
            "199",
            "0",
            "s",
            ".",
            " ",
            " Advanced",
            " Chemistry",
            " came",
            " to",
            " prominence",
            " in",
            " the",
            " wake",
            " of",
            " these",
            " actions",
            " because",
            " of",
            " their",
            " pro",
            "-mult",
            "icultural",
            " society",
            " stance",
            " in",
            " their",
            " music",
            ".",
            " ",
            " Advanced",
            " Chemistry",
            "'s",
            " attitudes",
            " rev",
            "olve",
            " around",
            " their",
            " attempts",
            " to",
            " create",
            " a",
            " distinct",
            " \"",
            "G",
            "erm",
            "anness"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.551,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            "In",
            " ",
            "196",
            "9",
            ",",
            " the",
            " institute",
            " established",
            " the",
            " A",
            "FI",
            " Conserv",
            "atory",
            " for",
            " Advanced",
            " Film",
            " Studies",
            " at",
            " Gre",
            "ystone",
            ",",
            " the",
            " D",
            "ohen",
            "y",
            " Mansion",
            " in",
            " Beverly",
            " Hills",
            ",",
            " California",
            ".",
            " The",
            " first",
            " class",
            " included",
            " filmmakers",
            " Ter",
            "rence",
            " Mal",
            "ick",
            ",",
            " Caleb",
            " Des",
            "ch",
            "anel",
            ",",
            " and",
            " Paul",
            " Sch",
            "r",
            "ader",
            ".",
            " That",
            " program",
            " grew",
            " into",
            " the",
            " A",
            "FI",
            " Conserv",
            "atory",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.551,
            -0.0,
            -0.0
          ],
          "train_token_ind": 60,
          "is_repeated_datapoint": false,
          "tokens": [
            "3",
            " -",
            " \"",
            "Wel",
            "cher",
            " Pf",
            "ad",
            " fÃƒÂ¼h",
            "rt",
            " zur",
            " Geschichte",
            "\"",
            " (",
            "12",
            "\"/",
            "M",
            "CD",
            ",",
            " M",
            "Z",
            "EE",
            ")",
            " ",
            "199",
            "4",
            " -",
            " \"",
            "Operation",
            " Ã‚Â§",
            " ",
            "3",
            "\"",
            " (",
            "12",
            "\"/",
            "M",
            "CD",
            ")",
            " ",
            "199",
            "4",
            " -",
            " \"",
            "Dir",
            " fe",
            "h",
            "lt",
            " der",
            " Funk",
            "!\"",
            " (",
            "12",
            "\"/",
            "M",
            "CD",
            ")",
            " ",
            "199",
            "5",
            " -",
            " Advanced",
            " Chemistry",
            " ("
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.484,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.547,
            -0.0
          ],
          "train_token_ind": 61,
          "is_repeated_datapoint": false,
          "tokens": [
            " to",
            " existing",
            " devices",
            " or",
            " the",
            " creation",
            " of",
            " new",
            " products",
            ".",
            "In",
            " the",
            " WI",
            "PO",
            " published",
            " ",
            "202",
            "1",
            " report",
            " on",
            " Technology",
            " Trends",
            ",",
            " assist",
            "ive",
            " products",
            " are",
            " grouped",
            " into",
            " either",
            " conventional",
            " or",
            " emerging",
            " technologies",
            ".",
            " Con",
            "ventional",
            " assisting",
            " technology",
            " tracks",
            " innovation",
            " within",
            " well",
            "-established",
            " assist",
            "ive",
            " products",
            ",",
            " whereas",
            " emerging",
            " assist",
            "ive",
            " technology",
            " refers",
            " to",
            " more",
            " advanced",
            " products",
            ".",
            " These",
            " identified",
            " advanced",
            " assist"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.547,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            "'s",
            " more",
            " exciting",
            " to",
            " experience",
            " my",
            " fellow",
            " Germans",
            " in",
            " new",
            " contexts",
            "...",
            "For",
            " me",
            ",",
            " it",
            "'s",
            " interesting",
            " to",
            " see",
            " what",
            " the",
            " kids",
            " try",
            " to",
            " do",
            " that",
            "'s",
            " different",
            " from",
            " what",
            " I",
            " know",
            ".\"",
            " ",
            " Advanced",
            " Chemistry",
            " were",
            " the",
            " first",
            " to",
            " use",
            " the",
            " term",
            " \"",
            "Af",
            "ro",
            "-G",
            "erman",
            "\"",
            " in",
            " a",
            " hip",
            " hop",
            " context",
            ".",
            " ",
            " This",
            " was",
            " part",
            " of",
            " the",
            " pro"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.459,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.535,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            "ive",
            " products",
            " are",
            " distinguished",
            " from",
            " the",
            " conventional",
            " ones",
            " by",
            " the",
            " use",
            " of",
            " one",
            " or",
            " more",
            " enabling",
            " technologies",
            " (",
            "for",
            " instance",
            ",",
            " artificial",
            " intelligence",
            ",",
            " Internet",
            " of",
            " Things",
            ",",
            " advanced",
            " sensors",
            ",",
            " new",
            " material",
            ",",
            " additive",
            " manufacturing",
            ",",
            " advanced",
            " robotics",
            ",",
            " augmented",
            " and",
            " virtual",
            " reality",
            ")",
            " or",
            " by",
            " the",
            " inclusion",
            " of",
            " implant",
            "able",
            " products",
            "/components",
            ".",
            " Such",
            " emerging",
            " assist",
            "ive",
            " products",
            " are",
            " either",
            " more"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 8,
          "is_repeated_datapoint": false,
          "tokens": [
            " took",
            " up",
            " a",
            " position",
            " at",
            " the",
            " Institute",
            " for",
            " Advanced",
            " Study",
            ",",
            " noted",
            " for",
            " having",
            " become",
            " a",
            " refuge",
            " for",
            " scientists",
            " fleeing",
            " Nazi",
            " Germany",
            ".",
            " At",
            " the",
            " time",
            ",",
            " most",
            " American",
            " universities",
            ",",
            " including",
            " Harvard",
            ",",
            " Princeton",
            " and",
            " Yale",
            ",",
            " had",
            " minimal",
            " or",
            " no",
            " Jewish",
            " faculty",
            " or",
            " students",
            ",",
            " as",
            " a",
            " result",
            " of",
            " their",
            " Jewish",
            " quotas",
            ",",
            " which",
            " lasted",
            " until",
            " the",
            " late",
            " ",
            "194",
            "0"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " master",
            "'s",
            " degree",
            " or",
            " a",
            " doctoral",
            " degree",
            ",",
            " is",
            " not",
            " required",
            ",",
            " but",
            " is",
            " strongly",
            " desired",
            ".",
            "Mission",
            " Specialist",
            " Educ",
            "ators",
            ",",
            " or",
            " \"",
            "Educ",
            "ator",
            " Astr",
            "onaut",
            "s",
            "\",",
            " were",
            " first",
            " selected",
            " in",
            " ",
            "200",
            "4",
            ",",
            " and",
            " as",
            " of",
            " ",
            "200",
            "7",
            ",",
            " there",
            " are",
            " three",
            " NASA",
            " Educ",
            "ator",
            " astronauts",
            ":",
            " Joseph",
            " M",
            ".",
            " Ac",
            "aba",
            ",",
            " Richard",
            " R",
            ".",
            " Arnold"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.492,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.482,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            " focuses",
            " on",
            " environment",
            ".",
            " In",
            " the",
            " conventional",
            " sector",
            ",",
            " mobility",
            " represent",
            " ",
            "54",
            "%",
            " of",
            " all",
            " patents",
            " fill",
            "ings",
            ",",
            " and",
            " is",
            " an",
            " indication",
            " of",
            " increased",
            " interest",
            " in",
            " advanced",
            " mobility",
            " assist",
            "ive",
            " product",
            " categories",
            ",",
            " such",
            " as",
            " advanced",
            " prost",
            "hetics",
            ",",
            " walking",
            " aids",
            ",",
            " wheel",
            "ch",
            "airs",
            ",",
            " and",
            " ex",
            "os",
            "keleton",
            "s",
            ".",
            "In",
            " the",
            " past",
            ",",
            " the",
            " top",
            " patent",
            " offices",
            " for"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.465,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " disabilities",
            " are",
            " participating",
            " in",
            " sports",
            ",",
            " leading",
            " to",
            " the",
            " development",
            " of",
            " new",
            " assist",
            "ive",
            " technology",
            ".",
            " Assist",
            "ive",
            " technology",
            " devices",
            " can",
            " be",
            " simple",
            ",",
            " or",
            " \"",
            "low",
            "-",
            "technology",
            "\",",
            " or",
            " they",
            " may",
            " use",
            " highly",
            " advanced",
            " technology",
            ".",
            " \"",
            "Low",
            "-tech",
            "\"",
            " devices",
            " can",
            " include",
            " vel",
            "cro",
            " gloves",
            " and",
            " adaptive",
            " bands",
            " and",
            " tubes",
            ".",
            " \"",
            "High",
            "-tech",
            "\"",
            " devices",
            " can",
            " include",
            " all",
            "-"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.41,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            " of",
            " the",
            " short",
            "-to",
            "-medium",
            "-l",
            "ifetime",
            " f",
            "ission",
            " products",
            " because",
            " it",
            " easily",
            " moves",
            " and",
            " spreads",
            " in",
            " nature",
            " due",
            " to",
            " the",
            " high",
            " water",
            " sol",
            "ub",
            "ility",
            " of",
            " its",
            " salts",
            ",",
            " and",
            " is",
            " taken",
            " up",
            " by",
            " the",
            " body",
            ",",
            " which",
            " mistakes",
            " it",
            " for",
            " its",
            " essential",
            " congen",
            "ers",
            " sodium",
            " and",
            " potassium",
            ".",
            "Period",
            "ic",
            " trends",
            " ",
            "The",
            " alk",
            "ali",
            " metals",
            " are",
            " more",
            " similar",
            " to",
            " each"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.003,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.369,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 32,
          "is_repeated_datapoint": false,
          "tokens": [
            "seconds",
            ".",
            " NGC",
            " ",
            "725",
            "2",
            " is",
            " a",
            " t",
            "angle",
            " of",
            " stars",
            " resulting",
            " from",
            " the",
            " collision",
            " of",
            " two",
            " large",
            " galaxies",
            " and",
            " is",
            " known",
            " as",
            " the",
            " At",
            "oms",
            "-for",
            "-P",
            "e",
            "ace",
            " galaxy",
            " because",
            " of",
            " its",
            " resemblance",
            " to",
            " a",
            " cartoon",
            " atom",
            ".",
            "Meteor",
            " showers",
            "There",
            " are",
            " three",
            " major",
            " meteor",
            " showers",
            " with",
            " radi",
            "ants",
            " in",
            " Aqu",
            "arius",
            ":",
            " the",
            " E",
            "ta",
            " Aqu",
            "ari",
            "ids"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.352,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 33,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            "Na",
            " (",
            "g",
            ")",
            " +",
            " K",
            "Cl",
            " (",
            "l",
            ")",
            " ",
            " Na",
            "Cl",
            " (",
            "l",
            ")",
            " +",
            " K",
            " (",
            "g",
            ")",
            "Although",
            " sodium",
            " is",
            " less",
            " reactive",
            " than",
            " potassium",
            ",",
            " this",
            " process",
            " works",
            " because",
            " at",
            " such",
            " high",
            " temperatures",
            " potassium",
            " is",
            " more",
            " volatile",
            " than",
            " sodium",
            " and",
            " can",
            " easily",
            " be",
            " distilled",
            " off",
            ",",
            " so",
            " that",
            " the",
            " equilibrium",
            " shifts",
            " towards",
            " the",
            " right",
            " to",
            " produce",
            " more",
            " potassium"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.336,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 16,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " leg",
            " pain",
            " and",
            " lack",
            " of",
            " match",
            " play",
            ".",
            " Ag",
            "assi",
            " withdrew",
            " from",
            " the",
            " Australian",
            " Open",
            " because",
            " of",
            " the",
            " ankle",
            " injury",
            ",",
            " and",
            " his",
            " back",
            " injury",
            " and",
            " other",
            " pains",
            " forced",
            " him",
            " to",
            " withdraw",
            " from",
            " several",
            " other",
            " events",
            ",",
            " eventually",
            " skipping",
            " the",
            " entire",
            " clay",
            "-court",
            " season",
            " including",
            " the",
            " French",
            " Open",
            ".",
            " This",
            " caused",
            " his",
            " ranking",
            " to",
            " drop",
            " out",
            " of",
            " the",
            " top",
            " ",
            "10",
            " for"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.31,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 11,
          "is_repeated_datapoint": false,
          "tokens": [
            "Liv",
            "est",
            "ock",
            " are",
            " one",
            " of",
            " the",
            " most",
            " significant",
            " contributors",
            " to",
            " today",
            "'s",
            " most",
            " serious",
            " environmental",
            " problems",
            "\".",
            " Liv",
            "est",
            "ock",
            " production",
            " occupies",
            " ",
            "70",
            "%",
            " of",
            " all",
            " land",
            " used",
            " for",
            " agriculture",
            ",",
            " or",
            " ",
            "30",
            "%",
            " of",
            " the",
            " land",
            " surface",
            " of",
            " the",
            " planet",
            ".",
            " It",
            " is",
            " one",
            " of",
            " the",
            " largest",
            " sources",
            " of",
            " greenhouse",
            " gases",
            ",",
            " responsible",
            " for",
            " ",
            "18",
            "%",
            " of",
            " the"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.268,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 21,
          "is_repeated_datapoint": false,
          "tokens": [
            " drawings",
            " is",
            " probably",
            " A",
            " Gold",
            " Book",
            ",",
            " compiled",
            " of",
            " sensitive",
            " drawings",
            " of",
            " young",
            " men",
            ".",
            " A",
            " Gold",
            " Book",
            " is",
            " so",
            " named",
            " because",
            " of",
            " the",
            " gold",
            " leaf",
            " that",
            " decor",
            "ates",
            " its",
            " pages",
            ".",
            " In",
            " April",
            " ",
            "201",
            "2",
            " a",
            " sketch",
            " of",
            " ",
            "193",
            "0",
            "s",
            " singer",
            " Rudy",
            " Val",
            "lee",
            " claimed",
            " to",
            " have",
            " been",
            " drawn",
            " by",
            " Andy",
            " War",
            "hol",
            " was",
            " found",
            " at",
            " a",
            " Las",
            " Vegas"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.245,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 43,
          "is_repeated_datapoint": false,
          "tokens": [
            " unreliable",
            ".",
            " ",
            " Thomson",
            " had",
            " encountered",
            " a",
            " similar",
            " problem",
            " in",
            " his",
            " work",
            " on",
            " cath",
            "ode",
            " rays",
            ",",
            " which",
            " he",
            " solved",
            " by",
            " creating",
            " a",
            " near",
            "-per",
            "fect",
            " vacuum",
            " in",
            " his",
            " instruments",
            ".",
            " R",
            "utherford",
            " did",
            " not",
            " think",
            " he",
            "'d",
            " run",
            " into",
            " this",
            " same",
            " problem",
            " because",
            " alpha",
            " particles",
            " are",
            " much",
            " heavier",
            " than",
            " electrons",
            ".",
            " According",
            " to",
            " Thomson",
            "'s",
            " model",
            " of",
            " the",
            " atom",
            ",",
            " the",
            " positive"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.23,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 44,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " following",
            " spring",
            ".",
            "P",
            "atri",
            "ot",
            " resurgence",
            "Two",
            " weeks",
            " after",
            " Congress",
            " withdrew",
            " to",
            " Baltimore",
            ",",
            " on",
            " the",
            " night",
            " of",
            " December",
            " ",
            "25",
            "â€“",
            "26",
            ",",
            " ",
            "177",
            "6",
            ",",
            " Washington",
            " crossed",
            " the",
            " Delaware",
            " River",
            ",",
            " leading",
            " a",
            " column",
            " of",
            " Continental",
            " Army",
            " troops",
            " from",
            " today",
            "'s",
            " Bucks",
            " County",
            ",",
            " Pennsylvania",
            ",",
            " located",
            " about",
            " ",
            "30",
            " miles",
            " up",
            "river",
            " from",
            " Philadelphia",
            ",",
            " to"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.226,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 59,
          "is_repeated_datapoint": false,
          "tokens": [
            " and",
            " his",
            " duties",
            " weigh",
            " heavily",
            " upon",
            " him",
            ".",
            " He",
            " never",
            " gets",
            " home",
            " until",
            " late",
            ",",
            " and",
            " he",
            " has",
            " to",
            " distance",
            " himself",
            " from",
            " the",
            " natural",
            " pity",
            " that",
            " he",
            " feels",
            " for",
            " the",
            " victims",
            ";",
            " otherwise",
            ",",
            " he",
            " would",
            " not",
            " be",
            " able",
            " to",
            " go",
            " on",
            ".",
            " It",
            " is",
            " especially",
            " hard",
            " for",
            " him",
            " when",
            " he",
            " visits",
            " a",
            " victim",
            " in",
            " the",
            " person",
            "'s",
            " home",
            " because",
            " he",
            " knows",
            " that"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.207,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.164,
            -0.0,
            -0.0
          ],
          "train_token_ind": 42,
          "is_repeated_datapoint": false,
          "tokens": [
            " divorced",
            " his",
            " wife",
            ",",
            " Ir",
            "ina",
            ",",
            " in",
            " June",
            " ",
            "197",
            "0",
            ".",
            " In",
            " the",
            " same",
            " year",
            ",",
            " he",
            " married",
            " Lar",
            "isa",
            " K",
            "iz",
            "il",
            "ova",
            " (",
            "n",
            "ÃƒÂ©e",
            " Eg",
            "ork",
            "ina",
            "),",
            " who",
            " had",
            " been",
            " a",
            " production",
            " assistant",
            " for",
            " the",
            " film",
            " Andre",
            "i",
            " Rub",
            "lev",
            " (",
            "they",
            " had",
            " been",
            " living",
            " together",
            " since",
            " ",
            "196",
            "5",
            ").",
            " Their",
            " son",
            ",",
            " Andre",
            "i",
            " And"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " it",
            " will",
            " cease",
            " to",
            " be",
            " divided",
            ".",
            " It",
            " will",
            " become",
            " all",
            " one",
            " thing",
            ",",
            " or",
            " all",
            " the",
            " other",
            ".\"",
            " The",
            " speech",
            " created",
            " a",
            " stark",
            " image",
            " of",
            " the",
            " danger",
            " of",
            " dis",
            "union",
            ".",
            " The",
            " stage",
            " was",
            " then",
            " set",
            " for",
            " the",
            " election",
            " of",
            " the",
            " Illinois",
            " legislature",
            " which",
            " would",
            ",",
            " in",
            " turn",
            ",",
            " select",
            " Lincoln",
            " or",
            " Douglas",
            ".",
            " When",
            " informed",
            " of",
            " Lincoln",
            "'s",
            " nomination",
            ",",
            " Douglas"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " if",
            " two",
            " pol",
            "ynomials",
            " p",
            "(x",
            "),",
            "q",
            "(x",
            ")",
            "Ã‚Å‚",
            "Ã¢Äª",
            "Äª",
            "Ã‚Å‚F",
            "[x",
            "]",
            " are",
            " relatively",
            " prime",
            " then",
            " they",
            " do",
            " not",
            " have",
            " a",
            " common",
            " root",
            ",",
            " for",
            " if",
            " a",
            "Ã‚Å‚",
            "Ã¢Äª",
            "Äª",
            "Ã‚Å‚F",
            " was",
            " a",
            " common",
            " root",
            ",",
            " then",
            "Ã‚Å‚p",
            "(x",
            ")",
            " and",
            " ",
            "Ã‚Å‚",
            "q",
            "(x",
            ")",
            " would",
            " both",
            " be",
            " multiples",
            " of",
            " x",
            "Ã‚Å‚",
            "Ã¢ÄªÄ´",
            "Ã‚Å‚",
            "a",
            " and",
            " therefore"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " Ankara",
            " Province",
            ",",
            " making",
            " it",
            " Turkey",
            "'s",
            " second",
            "-largest",
            " city",
            " after",
            " Istanbul",
            ",",
            " but",
            " first",
            " by",
            " the",
            " urban",
            " area",
            " (",
            "2",
            ",",
            "767",
            "Ã‚Å‚",
            "km",
            "2",
            ").",
            "S",
            "erving",
            " as",
            " the",
            " capital",
            " of",
            " the",
            " ancient",
            " Celtic",
            " state",
            " of",
            " Gal",
            "at",
            "ia",
            " (",
            "280",
            "â€“",
            "64",
            "Ã‚Å‚",
            "BC",
            "),",
            " and",
            " later",
            " of",
            " the",
            " Roman",
            " province",
            " with",
            " the",
            " same",
            " name",
            " (",
            "25",
            "Ã‚Å‚",
            "BC"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " ",
            " ()",
            " means",
            " \"",
            "stone",
            ",\"",
            " and",
            " some",
            " to",
            "pon",
            "yms",
            " may",
            " be",
            " derived",
            " from",
            " this",
            " word",
            ":",
            " ",
            " (",
            "P",
            "ella",
            ",",
            " the",
            " capital",
            " of",
            " ancient",
            " Macedonia",
            ")",
            " and",
            " ",
            " (",
            "P",
            "ell",
            "Ã„Äµ",
            "n",
            "Ã„Äµ",
            "/P",
            "ell",
            "ene",
            ").",
            "The",
            " H",
            "itt",
            "ite",
            " form",
            " Ap",
            "ali",
            "unas",
            " (",
            "d",
            ")",
            " is",
            " att",
            "ested",
            " in",
            " the",
            " Man",
            "apa",
            "-T",
            "ar",
            "h",
            "unta"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " altering",
            " cytok",
            "ine",
            " levels",
            " creates",
            " direct",
            " effects",
            " on",
            " areas",
            " of",
            " the",
            " brain",
            " such",
            " as",
            " the",
            " hypoth",
            "alam",
            "us",
            ",",
            " the",
            " area",
            " that",
            " triggers",
            " H",
            "PA",
            " axis",
            " activity",
            ".",
            " The",
            " H",
            "PA",
            " axis",
            " regulates",
            " production",
            " of",
            " cortisol",
            ",",
            " a",
            " hormone",
            " that",
            " takes",
            " part",
            " in",
            " the",
            " body",
            "'s",
            " stress",
            " response",
            ".",
            " When",
            " H",
            "PA",
            " activity",
            " spikes",
            ",",
            " cortisol",
            " levels",
            " increase",
            ",",
            " processing",
            " and",
            " reducing",
            " anxiety"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    "ÃªÂ²Â½ÃªÂ¸Â°",
    "rani",
    "Ã©Â»",
    "IRTH",
    "ooter"
  ],
  "bottom_logits": [
    "pth",
    " Mystic",
    " arm",
    "Forum",
    " trait"
  ],
  "act_min": -0.0,
  "act_max": 0.695
}
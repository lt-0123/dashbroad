{
  "index": 67194,
  "examples_quantiles": [
    {
      "quantile_name": "Top 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.785,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.018,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 17,
          "is_repeated_datapoint": false,
          "tokens": [
            " grow",
            " grain",
            ",",
            " potatoes",
            ",",
            " sugar",
            " be",
            "ets",
            ",",
            " cotton",
            " and",
            " tobacco",
            ".",
            " Liv",
            "est",
            "ock",
            ",",
            " dairy",
            " products",
            ",",
            " and",
            " wine",
            " and",
            " spirits",
            " are",
            " also",
            " important",
            " farm",
            " products",
            ".",
            " The",
            " Cas",
            "p",
            "ian",
            " fishing",
            " industry",
            " concentrates",
            " on",
            " the",
            " dwind",
            "ling",
            " stocks",
            " of",
            " st",
            "urgeon",
            " and",
            " bel",
            "uga",
            ".",
            " In",
            " ",
            "200",
            "2",
            " the",
            " Azerbai",
            "j",
            "ani",
            " merchant",
            " marine",
            " had",
            " ",
            "54",
            " ships"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.777,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            " or",
            " animal",
            " production",
            " systems",
            ".",
            " Transformation",
            " of",
            " primary",
            " products",
            " into",
            " end",
            "-con",
            "sumer",
            " products",
            " (",
            "e",
            ".g",
            ".,",
            " production",
            ",",
            " preservation",
            ",",
            " and",
            " packaging",
            " of",
            " dairy",
            " products",
            ")",
            " Prevention",
            " and",
            " correction",
            " of",
            " adverse",
            " environmental",
            " effects",
            " (",
            "e",
            ".g",
            ".,",
            " soil",
            " degradation",
            ",",
            " waste",
            " management",
            ",",
            " bi",
            "ore",
            "medi",
            "ation",
            ")",
            " The",
            "oretical",
            " production",
            " ecology",
            ",",
            " relating",
            " to",
            " crop",
            " production",
            " modeling",
            " Traditional",
            " agricultural"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.777,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 25,
          "is_repeated_datapoint": false,
          "tokens": [
            " or",
            " animal",
            " production",
            " systems",
            ".",
            " Transformation",
            " of",
            " primary",
            " products",
            " into",
            " end",
            "-con",
            "sumer",
            " products",
            " (",
            "e",
            ".g",
            ".,",
            " production",
            ",",
            " preservation",
            ",",
            " and",
            " packaging",
            " of",
            " dairy",
            " products",
            ")",
            " Prevention",
            " and",
            " correction",
            " of",
            " adverse",
            " environmental",
            " effects",
            " (",
            "e",
            ".g",
            ".,",
            " soil",
            " degradation",
            ",",
            " waste",
            " management",
            ",",
            " bi",
            "ore",
            "medi",
            "ation",
            ")",
            " The",
            "oretical",
            " production",
            " ecology",
            ",",
            " relating",
            " to",
            " crop",
            " production",
            " modeling",
            " Traditional",
            " agricultural"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.773,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 7,
          "is_repeated_datapoint": false,
          "tokens": [
            ",",
            " green",
            "houses",
            ",",
            " restaurants",
            ",",
            " a",
            " dairy",
            " farm",
            " and",
            " a",
            " brewery",
            ".",
            " It",
            " is",
            " a",
            " pleasant",
            " place",
            " to",
            " spend",
            " a",
            " day",
            " with",
            " family",
            ",",
            " be",
            " it",
            " for",
            " having",
            " pic",
            "n",
            "ics",
            ",",
            " hiking",
            ",",
            " biking",
            " or",
            " simply",
            " enjoying",
            " good",
            " food",
            " and",
            " nature",
            ".",
            " There",
            " is",
            " also",
            " an",
            " exact",
            " replica",
            " of",
            " the",
            " house",
            " where",
            " AtatÃ¼rk",
            " was",
            " born",
            " in",
            " ",
            "188",
            "1",
            ",",
            " in"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.766,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            "A",
            "gricult",
            "ure",
            " represents",
            " a",
            " very",
            " small",
            " fraction",
            " of",
            " the",
            " Al",
            "askan",
            " economy",
            ".",
            " Agricultural",
            " production",
            " is",
            " primarily",
            " for",
            " consumption",
            " within",
            " the",
            " state",
            " and",
            " includes",
            " nursery",
            " stock",
            ",",
            " dairy",
            " products",
            ",",
            " vegetables",
            ",",
            " and",
            " livestock",
            ".",
            " Manufacturing",
            " is",
            " limited",
            ",",
            " with",
            " most",
            " food",
            "st",
            "uffs",
            " and",
            " general",
            " goods",
            " imported",
            " from",
            " elsewhere",
            ".",
            "Employ",
            "ment",
            " is",
            " primarily",
            " in",
            " government",
            " and",
            " industries",
            " such",
            " as",
            " natural"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 1",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.766,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 45,
          "is_repeated_datapoint": false,
          "tokens": [
            "ots",
            ",",
            " pe",
            "aches",
            ",",
            " cher",
            "ries",
            ",",
            " fig",
            "s",
            ",",
            " sour",
            " cher",
            "ries",
            ",",
            " pl",
            "ums",
            ",",
            " and",
            " strawberries",
            "),",
            " vegetables",
            " (",
            "pot",
            "atoes",
            ",",
            " tomatoes",
            ",",
            " maize",
            ",",
            " onions",
            ",",
            " and",
            " wheat",
            "),",
            " sugar",
            " be",
            "ets",
            ",",
            " tobacco",
            ",",
            " meat",
            ",",
            " honey",
            ",",
            " dairy",
            " products",
            ",",
            " traditional",
            " medicine",
            " and",
            " aromatic",
            " plants",
            ".",
            " Further",
            ",",
            " the",
            " country",
            " is",
            " a",
            " worldwide",
            " significant",
            " producer"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.766,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 28,
          "is_repeated_datapoint": false,
          "tokens": [
            "A",
            "gricult",
            "ure",
            " represents",
            " a",
            " very",
            " small",
            " fraction",
            " of",
            " the",
            " Al",
            "askan",
            " economy",
            ".",
            " Agricultural",
            " production",
            " is",
            " primarily",
            " for",
            " consumption",
            " within",
            " the",
            " state",
            " and",
            " includes",
            " nursery",
            " stock",
            ",",
            " dairy",
            " products",
            ",",
            " vegetables",
            ",",
            " and",
            " livestock",
            ".",
            " Manufacturing",
            " is",
            " limited",
            ",",
            " with",
            " most",
            " food",
            "st",
            "uffs",
            " and",
            " general",
            " goods",
            " imported",
            " from",
            " elsewhere",
            ".",
            "Employ",
            "ment",
            " is",
            " primarily",
            " in",
            " government",
            " and",
            " industries",
            " such",
            " as",
            " natural"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.762,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            " Th",
            "ess",
            "alon",
            "iki",
            ",",
            " Greece",
            ".",
            " Visitors",
            " to",
            " the",
            " \"",
            "Ãĩ",
            "ift",
            "lik",
            "\"",
            " (",
            "farm",
            ")",
            " as",
            " it",
            " is",
            " affection",
            "ately",
            " called",
            " by",
            " An",
            "kar",
            "ans",
            ",",
            " can",
            " sample",
            " such",
            " famous",
            " products",
            " of",
            " the",
            " farm",
            " such",
            " as",
            " old",
            "-fashioned",
            " beer",
            " and",
            " ice",
            " cream",
            ",",
            " fresh",
            " dairy",
            " products",
            " and",
            " meat",
            " rolls",
            "/",
            "ke",
            "b",
            "abs",
            " made",
            " on",
            " charcoal",
            ",",
            " at",
            " a",
            " traditional"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.762,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            " Th",
            "ess",
            "alon",
            "iki",
            ",",
            " Greece",
            ".",
            " Visitors",
            " to",
            " the",
            " \"",
            "Ãĩ",
            "ift",
            "lik",
            "\"",
            " (",
            "farm",
            ")",
            " as",
            " it",
            " is",
            " affection",
            "ately",
            " called",
            " by",
            " An",
            "kar",
            "ans",
            ",",
            " can",
            " sample",
            " such",
            " famous",
            " products",
            " of",
            " the",
            " farm",
            " such",
            " as",
            " old",
            "-fashioned",
            " beer",
            " and",
            " ice",
            " cream",
            ",",
            " fresh",
            " dairy",
            " products",
            " and",
            " meat",
            " rolls",
            "/",
            "ke",
            "b",
            "abs",
            " made",
            " on",
            " charcoal",
            ",",
            " at",
            " a",
            " traditional"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.754,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 48,
          "is_repeated_datapoint": false,
          "tokens": [
            " The",
            " dance",
            " is",
            " considered",
            " part",
            " of",
            " Afghan",
            " identity",
            ".",
            "C",
            "uisine",
            " ",
            "Af",
            "ghan",
            " cuisine",
            " is",
            " largely",
            " based",
            " upon",
            " the",
            " nation",
            "'s",
            " chief",
            " crops",
            ",",
            " such",
            " as",
            " wheat",
            ",",
            " maize",
            ",",
            " barley",
            " and",
            " rice",
            ".",
            " Accom",
            "pany",
            "ing",
            " these",
            " staples",
            " are",
            " native",
            " fruits",
            " and",
            " vegetables",
            " as",
            " well",
            " as",
            " dairy",
            " products",
            " such",
            " as",
            " milk",
            ",",
            " yogurt",
            ",",
            " and",
            " whe",
            "y",
            ".",
            " Kab",
            "uli",
            " pal"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 2",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.75,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.055,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " alongside",
            " vegetables",
            " including",
            " peas",
            ",",
            " beans",
            ",",
            " and",
            " ol",
            "ives",
            ".",
            " Sheep",
            " and",
            " goats",
            " were",
            " kept",
            " mainly",
            " for",
            " dairy",
            " products",
            ".",
            "In",
            " the",
            " Americas",
            ",",
            " crops",
            " domestic",
            "ated",
            " in",
            " M",
            "eso",
            "amer",
            "ica",
            " (",
            "ap",
            "art",
            " from",
            " te",
            "os",
            "inte",
            ")",
            " include",
            " squash",
            ",",
            " beans",
            ",",
            " and",
            " c",
            "acao",
            ".",
            " Cocoa",
            " was",
            " domestic",
            "ated",
            " by",
            " the",
            " Mayo",
            " Ch",
            "inch",
            "ipe",
            " of",
            " the",
            " upper"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.75,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.055,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 18,
          "is_repeated_datapoint": false,
          "tokens": [
            " alongside",
            " vegetables",
            " including",
            " peas",
            ",",
            " beans",
            ",",
            " and",
            " ol",
            "ives",
            ".",
            " Sheep",
            " and",
            " goats",
            " were",
            " kept",
            " mainly",
            " for",
            " dairy",
            " products",
            ".",
            "In",
            " the",
            " Americas",
            ",",
            " crops",
            " domestic",
            "ated",
            " in",
            " M",
            "eso",
            "amer",
            "ica",
            " (",
            "ap",
            "art",
            " from",
            " te",
            "os",
            "inte",
            ")",
            " include",
            " squash",
            ",",
            " beans",
            ",",
            " and",
            " c",
            "acao",
            ".",
            " Cocoa",
            " was",
            " domestic",
            "ated",
            " by",
            " the",
            " Mayo",
            " Ch",
            "inch",
            "ipe",
            " of",
            " the",
            " upper"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.746,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            " companies",
            " mainly",
            " focused",
            " on",
            " research",
            " and",
            " development",
            ".",
            " There",
            " are",
            " multiple",
            " Big",
            " Tech",
            " companies",
            " with",
            " offices",
            " in",
            " the",
            " city",
            ",",
            " including",
            " Uber",
            " and",
            " Google",
            ".",
            "Several",
            " major",
            " companies",
            " are",
            " headquartered",
            " in",
            " A",
            "arhus",
            ",",
            " including",
            " four",
            " of",
            " the",
            " ten",
            " largest",
            " in",
            " the",
            " country",
            ".",
            " These",
            " include",
            " Ar",
            "la",
            " Foods",
            ",",
            " one",
            " of",
            " the",
            " largest",
            " dairy",
            " groups",
            " in",
            " Europe",
            ",",
            " S",
            "alling",
            " Group",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.746,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            " companies",
            " mainly",
            " focused",
            " on",
            " research",
            " and",
            " development",
            ".",
            " There",
            " are",
            " multiple",
            " Big",
            " Tech",
            " companies",
            " with",
            " offices",
            " in",
            " the",
            " city",
            ",",
            " including",
            " Uber",
            " and",
            " Google",
            ".",
            "Several",
            " major",
            " companies",
            " are",
            " headquartered",
            " in",
            " A",
            "arhus",
            ",",
            " including",
            " four",
            " of",
            " the",
            " ten",
            " largest",
            " in",
            " the",
            " country",
            ".",
            " These",
            " include",
            " Ar",
            "la",
            " Foods",
            ",",
            " one",
            " of",
            " the",
            " largest",
            " dairy",
            " groups",
            " in",
            " Europe",
            ",",
            " S",
            "alling",
            " Group",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.008,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.734,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            " arc",
            " between",
            " the",
            " pr",
            "air",
            "ies",
            " and",
            " the",
            " forests",
            ",",
            " from",
            " Calgary",
            ",",
            " north",
            " to",
            " Edmonton",
            ",",
            " and",
            " then",
            " east",
            " to",
            " Lloyd",
            "minster",
            ",",
            " contains",
            " the",
            " most",
            " fertile",
            " soil",
            " in",
            " the",
            " province",
            " and",
            " most",
            " of",
            " the",
            " population",
            ".",
            " Much",
            " of",
            " the",
            " unfore",
            "sted",
            " part",
            " of",
            " Alberta",
            " is",
            " given",
            " over",
            " either",
            " to",
            " grain",
            " or",
            " to",
            " dairy",
            " farming",
            ",",
            " with",
            " mixed",
            " farming",
            " more",
            " common",
            " in"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 3",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.59,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 57,
          "is_repeated_datapoint": false,
          "tokens": [
            " For",
            " the",
            " manufactured",
            " material",
            ",",
            " which",
            " is",
            " a",
            " refined",
            " residue",
            " from",
            " the",
            " dist",
            "illation",
            " process",
            " of",
            " selected",
            " crude",
            " oils",
            ",",
            " \"",
            "bit",
            "umen",
            "\"",
            " is",
            " the",
            " prevalent",
            " term",
            " in",
            " much",
            " of",
            " the",
            " world",
            ";",
            " however",
            ",",
            " in",
            " American",
            " English",
            ",",
            " \"",
            "as",
            "phalt",
            "\"",
            " is",
            " more",
            " commonly",
            " used",
            ".",
            " To",
            " help",
            " avoid",
            " confusion",
            ",",
            " the",
            " phrases",
            " \"",
            "liquid",
            " asphalt",
            "\",",
            " \"",
            "as",
            "phalt"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.438,
            -0.0,
            0.559,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 55,
          "is_repeated_datapoint": false,
          "tokens": [
            " A",
            " separation",
            " yield",
            " of",
            " ",
            "93",
            "%",
            " using",
            " nit",
            "ric",
            " acid",
            " has",
            " been",
            " reported",
            ",",
            " falling",
            " to",
            " ",
            "72",
            "%",
            " by",
            " the",
            " time",
            " purification",
            " procedures",
            " were",
            " completed",
            " (",
            "dist",
            "illation",
            " of",
            " nit",
            "ric",
            " acid",
            ",",
            " pur",
            "ging",
            " residual",
            " nitrogen",
            " ox",
            "ides",
            ",",
            " and",
            " red",
            "iss",
            "olving",
            " b",
            "ism",
            "uth",
            " nit",
            "rate",
            " to",
            " enable",
            " liquid",
            "–",
            "liquid",
            " extraction",
            ").",
            " Wet",
            " methods",
            " involve",
            " \"",
            "multiple"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.467,
            -0.0,
            0.555,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            " acid",
            " using",
            " an",
            " organic",
            " solvent",
            " such",
            " as",
            " dib",
            "ut",
            "yl",
            " ether",
            ",",
            " di",
            "is",
            "op",
            "rop",
            "yl",
            " ether",
            " (",
            "DI",
            "PE",
            "),",
            " or",
            " th",
            "io",
            "sem",
            "ic",
            "ar",
            "baz",
            "ide",
            ".",
            " Using",
            " liquid",
            "-",
            "liquid",
            " extraction",
            ",",
            " the",
            " a",
            "stat",
            "ine",
            " product",
            " can",
            " be",
            " repeatedly",
            " washed",
            " with",
            " an",
            " acid",
            ",",
            " such",
            " as",
            " H",
            "Cl",
            ",",
            " and",
            " extracted",
            " into",
            " the",
            " organic",
            " solvent",
            " layer",
            "."
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.004,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.531,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 29,
          "is_repeated_datapoint": false,
          "tokens": [
            " metals",
            " and",
            " their",
            " hy",
            "d",
            "rides",
            " react",
            " with",
            " acidic",
            " hydro",
            "car",
            "bons",
            ",",
            " for",
            " example",
            " cyc",
            "lop",
            "ent",
            "adi",
            "enes",
            " and",
            " terminal",
            " alk",
            "ynes",
            ",",
            " to",
            " give",
            " salts",
            ".",
            " Liquid",
            " ammonia",
            ",",
            " ether",
            ",",
            " or",
            " hydro",
            "carbon",
            " sol",
            "vents",
            " are",
            " used",
            ",",
            " the",
            " most",
            " common",
            " of",
            " which",
            " being",
            " tet",
            "ra",
            "hydro",
            "f",
            "uran",
            ".",
            " The",
            " most",
            " important",
            " of",
            " these",
            " compounds",
            " is",
            " sodium",
            " cyc"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " Dallas",
            ",",
            " Texas",
            ".",
            "Music",
            " ",
            "War",
            "hol",
            " strongly",
            " influenced",
            " the",
            " new",
            " wave",
            "/p",
            "unk",
            " rock",
            " band",
            " De",
            "vo",
            ",",
            " as",
            " well",
            " as",
            " David",
            " Bowie",
            ".",
            " Bowie",
            " recorded",
            " a",
            " song",
            " called",
            " \"",
            "Andy",
            " War",
            "hol",
            "\"",
            " for",
            " his",
            " ",
            "197",
            "1",
            " album",
            " H",
            "unky",
            " D",
            "ory",
            ".",
            " Lou",
            " Reed",
            " wrote",
            " the",
            " song",
            " \"",
            "Andy",
            "'s",
            " Chest",
            "\",",
            " about",
            " Valerie",
            " Sol",
            "anas",
            ","
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 4",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 37,
          "is_repeated_datapoint": false,
          "tokens": [
            "201",
            "1",
            ")",
            " suggest",
            " Sh",
            "om",
            "pen",
            " as",
            " an",
            " additional",
            " branch",
            ",",
            " and",
            " believe",
            " that",
            " a",
            " Viet",
            "o",
            "-K",
            "atu",
            "ic",
            " connection",
            " is",
            " worth",
            " investigating",
            ".",
            " In",
            " general",
            ",",
            " however",
            ",",
            " the",
            " family",
            " is",
            " thought",
            " to",
            " have",
            " diversified",
            " too",
            " quickly",
            " for",
            " a",
            " deeply",
            " nested",
            " structure",
            " to",
            " have",
            " developed",
            ",",
            " since",
            " Proto",
            "-A",
            "ust",
            "ro",
            "asi",
            "atic",
            " speakers",
            " are",
            " believed",
            " by",
            " Sid",
            "well",
            " to"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            " within",
            " Aust",
            "ro",
            "asi",
            "atic",
            " taking",
            " place",
            " during",
            " the",
            " Iron",
            " Age",
            ".",
            "Paul",
            " Sid",
            "well",
            " (",
            "201",
            "8",
            ")",
            " considers",
            " the",
            " Aust",
            "ro",
            "asi",
            "atic",
            " language",
            " family",
            " to",
            " have",
            " rapidly",
            " diversified",
            " around",
            " ",
            "4",
            ",",
            "000",
            " years",
            " B",
            ".P",
            ".",
            " during",
            " the",
            " arrival",
            " of",
            " rice",
            " agriculture",
            " in",
            " Ind",
            "och",
            "ina",
            ",",
            " but",
            " notes",
            " that",
            " the",
            " origin",
            " of",
            " Proto",
            "-A",
            "ust",
            "ro",
            "asi",
            "atic"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " Dallas",
            ",",
            " Texas",
            ",",
            " was",
            " renamed",
            " Cedar",
            " Crest",
            " Elementary",
            ".",
            " Johnston",
            " Middle",
            " School",
            " in",
            " Houston",
            ",",
            " Texas",
            ",",
            " was",
            " also",
            " renamed",
            " Meyer",
            "land",
            " Middle",
            " School",
            ".",
            " Three",
            " other",
            " elementary",
            " schools",
            " named",
            " for",
            " Confederate",
            " veterans",
            " were",
            " renamed",
            " simultaneously",
            ".",
            "See",
            " also",
            " Albert",
            " Sidney",
            " Johnston",
            " High",
            " School",
            ",",
            " a",
            " def",
            "unct",
            " public",
            " high",
            " school",
            " in",
            " Austin",
            ",",
            " Texas",
            " Statue",
            " of",
            " Albert",
            " Sidney"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " include",
            " Dallas",
            ",",
            " Low",
            "nd",
            "es",
            ",",
            " Mare",
            "ngo",
            " and",
            " Perry",
            ".\"",
            "In",
            " ",
            "197",
            "2",
            ",",
            " for",
            " the",
            " first",
            " time",
            " since",
            " ",
            "190",
            "1",
            ",",
            " the",
            " legislature",
            " completed",
            " the",
            " congressional",
            " red",
            "istrict",
            "ing",
            " based",
            " on",
            " the",
            " dec",
            "ennial",
            " census",
            ".",
            " This",
            " benefited",
            " the",
            " urban",
            " areas",
            " that",
            " had",
            " developed",
            ",",
            " as",
            " well",
            " as",
            " all",
            " in",
            " the",
            " population",
            " who",
            " had",
            " been",
            " under",
            "represented",
            " for"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 30,
          "is_repeated_datapoint": false,
          "tokens": [
            " within",
            " Aust",
            "ro",
            "asi",
            "atic",
            " taking",
            " place",
            " during",
            " the",
            " Iron",
            " Age",
            ".",
            "Paul",
            " Sid",
            "well",
            " (",
            "201",
            "8",
            ")",
            " considers",
            " the",
            " Aust",
            "ro",
            "asi",
            "atic",
            " language",
            " family",
            " to",
            " have",
            " rapidly",
            " diversified",
            " around",
            " ",
            "4",
            ",",
            "000",
            " years",
            " B",
            ".P",
            ".",
            " during",
            " the",
            " arrival",
            " of",
            " rice",
            " agriculture",
            " in",
            " Ind",
            "och",
            "ina",
            ",",
            " but",
            " notes",
            " that",
            " the",
            " origin",
            " of",
            " Proto",
            "-A",
            "ust",
            "ro",
            "asi",
            "atic"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 5",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            0.516,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 1,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " Dallas",
            ",",
            " Texas",
            ".",
            "Music",
            " ",
            "War",
            "hol",
            " strongly",
            " influenced",
            " the",
            " new",
            " wave",
            "/p",
            "unk",
            " rock",
            " band",
            " De",
            "vo",
            ",",
            " as",
            " well",
            " as",
            " David",
            " Bowie",
            ".",
            " Bowie",
            " recorded",
            " a",
            " song",
            " called",
            " \"",
            "Andy",
            " War",
            "hol",
            "\"",
            " for",
            " his",
            " ",
            "197",
            "1",
            " album",
            " H",
            "unky",
            " D",
            "ory",
            ".",
            " Lou",
            " Reed",
            " wrote",
            " the",
            " song",
            " \"",
            "Andy",
            "'s",
            " Chest",
            "\",",
            " about",
            " Valerie",
            " Sol",
            "anas",
            ","
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.512,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            " Hol",
            "ost",
            "ei",
            " and",
            " Tele",
            "ost",
            "ei",
            ".",
            " During",
            " the",
            " Mes",
            "ozo",
            "ic",
            " (",
            "Tri",
            "assic",
            ",",
            " Jurassic",
            ",",
            " C",
            "ret",
            "aceous",
            ")",
            " and",
            " C",
            "en",
            "ozo",
            "ic",
            " the",
            " tele",
            "ost",
            "s",
            " in",
            " particular",
            " diversified",
            " widely",
            ".",
            " As",
            " a",
            " result",
            ",",
            " ",
            "96",
            "%",
            " of",
            " living",
            " fish",
            " species",
            " are",
            " tele",
            "ost",
            "s",
            " (",
            "40",
            "%",
            " of",
            " all",
            " fish",
            " species",
            " belong",
            " to",
            " the",
            " tele"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.512,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 34,
          "is_repeated_datapoint": false,
          "tokens": [
            " Hol",
            "ost",
            "ei",
            " and",
            " Tele",
            "ost",
            "ei",
            ".",
            " During",
            " the",
            " Mes",
            "ozo",
            "ic",
            " (",
            "Tri",
            "assic",
            ",",
            " Jurassic",
            ",",
            " C",
            "ret",
            "aceous",
            ")",
            " and",
            " C",
            "en",
            "ozo",
            "ic",
            " the",
            " tele",
            "ost",
            "s",
            " in",
            " particular",
            " diversified",
            " widely",
            ".",
            " As",
            " a",
            " result",
            ",",
            " ",
            "96",
            "%",
            " of",
            " living",
            " fish",
            " species",
            " are",
            " tele",
            "ost",
            "s",
            " (",
            "40",
            "%",
            " of",
            " all",
            " fish",
            " species",
            " belong",
            " to",
            " the",
            " tele"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.044,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 15,
          "is_repeated_datapoint": false,
          "tokens": [
            "im",
            "bed",
            " fins",
            ",",
            " features",
            " that",
            " were",
            " helpful",
            " in",
            " adapting",
            " to",
            " dry",
            " land",
            ".",
            " They",
            " diversified",
            " and",
            " became",
            " ec",
            "ologically",
            " dominant",
            " during",
            " the",
            " Carbon",
            "ifer",
            "ous",
            " and",
            " Perm",
            "ian",
            " periods",
            ",",
            " but",
            " were",
            " later",
            " displaced",
            " in",
            " terrestrial",
            " environments",
            " by",
            " early",
            " rept",
            "iles",
            " and",
            " basal",
            " syn",
            "aps",
            "ids",
            " (",
            "m",
            "amm",
            "al",
            " predecessors",
            ").",
            " The",
            " origin",
            " of",
            " modern",
            " amphib",
            "ians",
            " belonging",
            " to",
            " L",
            "iss"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.508,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.036,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 3,
          "is_repeated_datapoint": false,
          "tokens": [
            "Scient",
            "ific",
            " research",
            "Liquid",
            " arg",
            "on",
            " is",
            " used",
            " as",
            " the",
            " target",
            " for",
            " neutr",
            "ino",
            " experiments",
            " and",
            " direct",
            " dark",
            " matter",
            " searches",
            ".",
            " The",
            " interaction",
            " between",
            " the",
            " hypothetical",
            " W",
            "IM",
            "Ps",
            " and",
            " an",
            " arg",
            "on",
            " nucleus",
            " produces",
            " sc",
            "int",
            "illation",
            " light",
            " that",
            " is",
            " detected",
            " by",
            " phot",
            "om",
            "ulti",
            "plier",
            " tubes",
            ".",
            " Two",
            "-phase",
            " detectors",
            " containing",
            " arg",
            "on",
            " gas",
            " are",
            " used",
            " to",
            " detect",
            " the",
            " ion"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.5,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 6,
          "is_repeated_datapoint": false,
          "tokens": [
            "0",
            "s",
            ",",
            " the",
            " music",
            " scene",
            " diversified",
            " into",
            " rock",
            " and",
            " other",
            " genres",
            " and",
            " in",
            " the",
            " ",
            "197",
            "0",
            "s",
            " and",
            " ",
            "198",
            "0",
            "s",
            ",",
            " A",
            "arhus",
            " became",
            " a",
            " centre",
            " for",
            " rock",
            " music",
            ",",
            " fostering",
            " iconic",
            " bands",
            " such",
            " as",
            " K",
            "lich",
            "Ã©",
            ",",
            " TV",
            "-",
            "2",
            " and",
            " Gn",
            "ags",
            " and",
            " artists",
            " such",
            " as",
            " Thomas",
            " Helm",
            "ig",
            " and",
            " Anne",
            " Lin",
            "net",
            ".",
            " Ac",
            "claimed"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.498,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.032,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " in",
            " the",
            " early",
            " ",
            "20",
            "th",
            " century",
            " to",
            " the",
            " point",
            " where",
            " many",
            " of",
            " the",
            " world",
            "'s",
            " higher",
            " educational",
            " institutions",
            " typically",
            " included",
            " anthropology",
            " departments",
            ",",
            " with",
            " many",
            " thousands",
            " having",
            " come",
            " into",
            " existence",
            ".",
            " Anthrop",
            "ology",
            " has",
            " diversified",
            " from",
            " a",
            " few",
            " major",
            " subdivisions",
            " to",
            " dozens",
            " more",
            ".",
            " Practical",
            " anthropology",
            ",",
            " the",
            " use",
            " of",
            " anthrop",
            "ological",
            " knowledge",
            " and",
            " technique",
            " to",
            " solve",
            " specific",
            " problems",
            ",",
            " has",
            " arrived"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.496,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 5,
          "is_repeated_datapoint": false,
          "tokens": [
            " moved",
            " to",
            " Cah",
            "aba",
            " in",
            " Dallas",
            " County",
            ".",
            "C",
            "ah",
            "aba",
            ",",
            " now",
            " a",
            " ghost",
            " town",
            ",",
            " was",
            " the",
            " first",
            " permanent",
            " state",
            " capital",
            " from",
            " ",
            "182",
            "0",
            " to",
            " ",
            "182",
            "5",
            ".",
            " The",
            " Alabama",
            " Fever",
            " land",
            " rush",
            " was",
            " underway",
            " when",
            " the",
            " state",
            " was",
            " admitted",
            " to",
            " the",
            " Union",
            ",",
            " with",
            " settlers",
            " and",
            " land",
            " spec",
            "ulators",
            " pouring",
            " into",
            " the",
            " state",
            " to",
            " take",
            " advantage",
            " of",
            " fertile"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.496,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 21,
          "is_repeated_datapoint": false,
          "tokens": [
            ")",
            " broadcast",
            " in",
            " both",
            " of",
            " Afghanistan",
            "'s",
            " official",
            " languages",
            " on",
            " radio",
            ".",
            " Press",
            " restrictions",
            " have",
            " been",
            " gradually",
            " relaxed",
            " and",
            " private",
            " media",
            " diversified",
            " since",
            " ",
            "200",
            "2",
            ",",
            " after",
            " more",
            " than",
            " two",
            " decades",
            " of",
            " tight",
            " controls",
            ".",
            "Af",
            "gh",
            "ans",
            " have",
            " long",
            " been",
            " accustomed",
            " to",
            " watching",
            " Indian",
            " Bollywood",
            " films",
            " and",
            " listening",
            " to",
            " its",
            " film",
            "i",
            " songs",
            ".",
            " It",
            " has",
            " been",
            " claimed",
            " that",
            " Afghanistan",
            " is"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.488,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " World",
            " Cup",
            " last",
            " July",
            " at",
            " BC",
            " Place",
            " in",
            " Vancouver",
            ",",
            " British",
            " Columbia",
            ",",
            " Canada",
            " before",
            " an",
            " undis",
            "puted",
            " AT",
            "&T",
            " Stadium",
            " audience",
            " of",
            " ",
            "101",
            ",",
            "763",
            " to",
            " open",
            " Wrestle",
            "Man",
            "ia",
            " ",
            "32",
            " in",
            " Dallas",
            ",",
            " Texas",
            ".",
            "In",
            " ",
            "201",
            "7",
            ",",
            " Jackie",
            " Evan",
            "cho",
            " released",
            " Together",
            " We",
            " Stand",
            ",",
            " a",
            " disc",
            " containing",
            " three",
            " patriotic",
            " songs",
            " including",
            " \"",
            "America",
            " the",
            " Beautiful"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 6",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.488,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " since",
            " the",
            " collapse",
            " of",
            " the",
            " communist",
            " regime",
            " in",
            " the",
            " country",
            ".",
            " It",
            " is",
            " very",
            " diversified",
            ",",
            " from",
            " electronics",
            ",",
            " manufacturing",
            ",",
            " textiles",
            ",",
            " to",
            " food",
            ",",
            " cement",
            ",",
            " mining",
            ",",
            " and",
            " energy",
            ".",
            " The",
            " Ant",
            "ea",
            " Cement",
            " plant",
            " in",
            " F",
            "ush",
            "Ã«",
            "-K",
            "ru",
            "j",
            "Ã«",
            " is",
            " considered",
            " one",
            " of",
            " the",
            " largest",
            " industrial",
            " green",
            "field",
            " investments",
            " in",
            " the",
            " country",
            ".",
            " Alban",
            "ian",
            " oil"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.488,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 35,
          "is_repeated_datapoint": false,
          "tokens": [
            " World",
            " Cup",
            " last",
            " July",
            " at",
            " BC",
            " Place",
            " in",
            " Vancouver",
            ",",
            " British",
            " Columbia",
            ",",
            " Canada",
            " before",
            " an",
            " undis",
            "puted",
            " AT",
            "&T",
            " Stadium",
            " audience",
            " of",
            " ",
            "101",
            ",",
            "763",
            " to",
            " open",
            " Wrestle",
            "Man",
            "ia",
            " ",
            "32",
            " in",
            " Dallas",
            ",",
            " Texas",
            ".",
            "In",
            " ",
            "201",
            "7",
            ",",
            " Jackie",
            " Evan",
            "cho",
            " released",
            " Together",
            " We",
            " Stand",
            ",",
            " a",
            " disc",
            " containing",
            " three",
            " patriotic",
            " songs",
            " including",
            " \"",
            "America",
            " the",
            " Beautiful"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.486,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 50,
          "is_repeated_datapoint": false,
          "tokens": [
            " with",
            " C",
            "AA",
            ".",
            "Equipment",
            " and",
            " endorsements",
            "Ag",
            "assi",
            " used",
            " Prince",
            " Graph",
            "ite",
            " r",
            "ackets",
            " early",
            " in",
            " his",
            " career",
            ".",
            " He",
            " signed",
            " a",
            " $",
            "7",
            "Âł",
            "million",
            " endorsement",
            " contract",
            " with",
            " Belgian",
            " tennis",
            " rac",
            "quet",
            " makers",
            " Don",
            "n",
            "ay",
            ".",
            " He",
            " later",
            " switched",
            " to",
            " Head",
            " Ti",
            " Radical",
            " racket",
            " and",
            " Head",
            "'s",
            " Liquid",
            "Metal",
            " Radical",
            " racket",
            ",",
            " having",
            " signed",
            " a",
            " multim",
            "illion",
            "-dollar",
            " endorsement"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.01,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.059,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.478,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 40,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            "0",
            " T",
            "DI",
            ",",
            " Audi",
            " A",
            "3",
            " Sport",
            "back",
            " ",
            "2",
            ".",
            "0",
            " T",
            "DI",
            " with",
            " S",
            " tr",
            "onic",
            " transmission",
            ")",
            " travelling",
            " across",
            " the",
            " American",
            " continent",
            " from",
            " New",
            " York",
            " to",
            " Los",
            " Angeles",
            ",",
            " passing",
            " major",
            " cities",
            " like",
            " Chicago",
            ",",
            " Dallas",
            " and",
            " Las",
            " Vegas",
            " during",
            " the",
            " ",
            "13",
            " daily",
            " stages",
            ",",
            " as",
            " well",
            " as",
            " natural",
            " wonders",
            " including",
            " the",
            " Rocky",
            " Mountains",
            ",",
            " Death",
            " Valley"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            0.473,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " Canadian",
            " painter",
            " and",
            " illustrator",
            " (",
            "d",
            ".",
            " ",
            "193",
            "0",
            ")",
            "185",
            "7",
            " –",
            " Arthur",
            " Wesley",
            " Dow",
            ",",
            " American",
            " painter",
            " and",
            " photographer",
            " (",
            "d",
            ".",
            " ",
            "192",
            "2",
            ")",
            "186",
            "0",
            " –",
            " Ren",
            "Ã©",
            " Lal",
            "ique",
            ",",
            " French",
            " sculpt",
            "or",
            " and",
            " jewellery",
            " designer",
            " (",
            "d",
            ".",
            " ",
            "194",
            "5",
            ")",
            "186",
            "1",
            " –",
            " Stan",
            "is",
            "las",
            " de",
            " Gu",
            "ait",
            "a",
            ",",
            " French",
            " poet"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 7",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.418,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.375,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 14,
          "is_repeated_datapoint": false,
          "tokens": [
            " South",
            " African",
            " football",
            "er",
            " ",
            " ",
            "198",
            "4",
            "  ",
            " –",
            " Diana",
            " Math",
            "eson",
            ",",
            " Canadian",
            " soccer",
            " player",
            "198",
            "5",
            " –",
            " Clarke",
            " Mac",
            "Arthur",
            ",",
            " Canadian",
            " ice",
            " hockey",
            " player",
            " ",
            " ",
            "198",
            "5",
            "  ",
            " –",
            " Frank",
            " O",
            "ng",
            "fi",
            "ang",
            ",",
            " Cam",
            "ero",
            "onian",
            " football",
            "er",
            " ",
            " ",
            "198",
            "5",
            "  ",
            " –",
            " Sin",
            "qua",
            " Walls",
            ",",
            " American",
            " basketball",
            " player",
            " and"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.412,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 10,
          "is_repeated_datapoint": false,
          "tokens": [
            " are",
            " dormant",
            " or",
            " other",
            " annual",
            "s",
            " are",
            " in",
            " seed",
            " form",
            " waiting",
            " for",
            " warmer",
            " weather",
            " to",
            " ger",
            "minate",
            ".",
            " Winter",
            " annual",
            "s",
            " die",
            " after",
            " flowering",
            " and",
            " setting",
            " seed",
            ".",
            " The",
            " seeds",
            " ger",
            "minate",
            " in",
            " the",
            " autumn",
            " or",
            " winter",
            " when",
            " the",
            " soil",
            " temperature",
            " is",
            " cool",
            ".",
            "Winter",
            " annual",
            "s",
            " typically",
            " grow",
            " low",
            " to",
            " the",
            " ground",
            ",",
            " where",
            " they",
            " are",
            " usually",
            " shelter",
            "ed",
            " from",
            " the",
            " col"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.394,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 26,
          "is_repeated_datapoint": false,
          "tokens": [
            " or",
            " '",
            "inactive",
            "',",
            " as",
            " a",
            " reference",
            " to",
            " the",
            " fact",
            " that",
            " the",
            " element",
            " undergo",
            "es",
            " almost",
            " no",
            " chemical",
            " reactions",
            ".",
            " The",
            " complete",
            " oct",
            "et",
            " (",
            "eight",
            " electrons",
            ")",
            " in",
            " the",
            " outer",
            " atomic",
            " shell",
            " makes",
            " arg",
            "on",
            " stable",
            " and",
            " resistant",
            " to",
            " bonding",
            " with",
            " other",
            " elements",
            ".",
            " Its",
            " triple",
            " point",
            " temperature",
            " of",
            " ",
            "83",
            ".",
            "805",
            "8",
            "ÂłK",
            " is",
            " a",
            " defining",
            " fixed",
            " point",
            " in",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.346,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 11,
          "is_repeated_datapoint": false,
          "tokens": [
            " Technology",
            " was",
            " held",
            " in",
            " Lu",
            "anda",
            " under",
            " the",
            " motto",
            " \"",
            "The",
            " challenges",
            " of",
            " telecommunications",
            " in",
            " the",
            " current",
            " context",
            " of",
            " Angola",
            "\",",
            " to",
            " promote",
            " debate",
            " on",
            " topical",
            " issues",
            " on",
            " telecommunications",
            " in",
            " Angola",
            " and",
            " worldwide",
            ".",
            " A",
            " study",
            " of",
            " this",
            " sector",
            ",",
            " presented",
            " at",
            " the",
            " forum",
            ",",
            " said",
            " Angola",
            " had",
            " the",
            " first",
            " telecommunications",
            " operator",
            " in",
            " Africa",
            " to",
            " test",
            " LTE",
            " –",
            " with",
            " speeds",
            " up",
            " to",
            " "
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.336,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 12,
          "is_repeated_datapoint": false,
          "tokens": [
            " all",
            " Blacks",
            " had",
            " lost",
            " the",
            " ability",
            " to",
            " vote",
            ".",
            " Despite",
            " numerous",
            " legal",
            " challenges",
            " which",
            " succeeded",
            " in",
            " overturn",
            "ing",
            " certain",
            " provisions",
            ",",
            " the",
            " state",
            " legislature",
            " would",
            " create",
            " new",
            " ones",
            " to",
            " maintain",
            " disen",
            "fr",
            "anch",
            "is",
            "ement",
            ".",
            " The",
            " exclusion",
            " of",
            " blacks",
            " from",
            " the",
            " political",
            " system",
            " persisted",
            " until",
            " after",
            " passage",
            " of",
            " federal",
            " civil",
            " rights",
            " legislation",
            " in",
            " ",
            "196",
            "5",
            " to",
            " enforce",
            " their",
            " constitutional",
            " rights",
            " as"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Subsample interval 8",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            0.025,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.03,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.009,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.309,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 47,
          "is_repeated_datapoint": false,
          "tokens": [
            " articles",
            " Outline",
            " of",
            " Alberta",
            " Royal",
            " e",
            "pon",
            "yms",
            " in",
            " Canada",
            "Notes",
            "References",
            "Further",
            " reading",
            "External",
            " links",
            " ",
            "  ",
            " Alberta",
            " Encyclopedia",
            " List",
            " of",
            " streets",
            " in",
            " Alberta",
            " with",
            " maps",
            " ",
            "190",
            "5",
            " establishments",
            " in",
            " Canada",
            "Pro",
            "vinces",
            " and",
            " territories",
            " of",
            " Canada",
            "States",
            " and",
            " territories",
            " established",
            " in",
            " ",
            "190",
            "5",
            "Canadian",
            " Pra",
            "ir",
            "ies",
            "<|begin_of_text|>"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.303,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.275,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 4,
          "is_repeated_datapoint": false,
          "tokens": [
            "eters",
            ";",
            " sym",
            "metrical",
            " scenes",
            " –",
            " passages",
            " featuring",
            " songs",
            " and",
            " decl",
            "aim",
            "ed",
            " verses",
            " in",
            " long",
            " lines",
            " of",
            " tet",
            "ram",
            "eters",
            ",",
            " arranged",
            " symmetric",
            "ally",
            " in",
            " two",
            " sections",
            " such",
            " that",
            " each",
            " half",
            " resembles",
            " the",
            " other",
            " in",
            " meter",
            " and",
            " line",
            " length",
            ";",
            " the",
            " agon",
            " and",
            " par",
            "ab",
            "asis",
            " can",
            " be",
            " considered",
            " specific",
            " instances",
            " of",
            " sym",
            "metrical",
            " scenes",
            ":",
            " par",
            "ab",
            "asis",
            " –",
            " verses",
            " through"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.285,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.26,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.275,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.262,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            " with",
            " nitrogen",
            "L",
            "ith",
            "ium",
            " is",
            " the",
            " only",
            " metal",
            " that",
            " combines",
            " directly",
            " with",
            " nitrogen",
            " at",
            " room",
            " temperature",
            ".",
            "3",
            "Li",
            " +",
            " ",
            "1",
            "/",
            "2",
            "N",
            "2",
            " âĨĴ",
            " Li",
            "3",
            "N",
            "Li",
            "3",
            "N",
            " can",
            " react",
            " with",
            " water",
            " to",
            " liber",
            "ate",
            " ammonia",
            ".",
            "Li",
            "3",
            "N",
            " +",
            " ",
            "3",
            "H",
            "2",
            "O",
            " âĨĴ",
            " ",
            "3",
            "Li",
            "OH",
            " +",
            " NH",
            "3"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.285,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.26,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.275,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.262,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 19,
          "is_repeated_datapoint": false,
          "tokens": [
            " with",
            " nitrogen",
            "L",
            "ith",
            "ium",
            " is",
            " the",
            " only",
            " metal",
            " that",
            " combines",
            " directly",
            " with",
            " nitrogen",
            " at",
            " room",
            " temperature",
            ".",
            "3",
            "Li",
            " +",
            " ",
            "1",
            "/",
            "2",
            "N",
            "2",
            " âĨĴ",
            " Li",
            "3",
            "N",
            "Li",
            "3",
            "N",
            " can",
            " react",
            " with",
            " water",
            " to",
            " liber",
            "ate",
            " ammonia",
            ".",
            "Li",
            "3",
            "N",
            " +",
            " ",
            "3",
            "H",
            "2",
            "O",
            " âĨĴ",
            " ",
            "3",
            "Li",
            "OH",
            " +",
            " NH",
            "3"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.158,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            0.188,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 54,
          "is_repeated_datapoint": false,
          "tokens": [
            " three",
            " years",
            " later",
            ",",
            " at",
            " the",
            " ",
            "193",
            "8",
            " ceremony",
            ".",
            " Nichols",
            " was",
            " nominated",
            " for",
            " three",
            " further",
            " Academy",
            " Awards",
            " during",
            " his",
            " career",
            ".",
            "George",
            " C",
            ".",
            " Scott",
            " became",
            " the",
            " second",
            " person",
            " to",
            " refuse",
            " his",
            " award",
            " (",
            "Best",
            " Actor",
            " in",
            " ",
            "197",
            "0",
            " for",
            " Patton",
            ")",
            " at",
            " the",
            " ",
            "43",
            "rd",
            " Academy",
            " Awards",
            " ceremony",
            ".",
            " Scott",
            " described",
            " it",
            " as",
            " a",
            " \"",
            "me",
            "at",
            " parade"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    },
    {
      "quantile_name": "Bottom 1%",
      "examples": [
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            "While",
            " still",
            " living",
            " in",
            " Winnipeg",
            ",",
            " in",
            " ",
            "193",
            "9",
            " van",
            " Vog",
            "t",
            " married",
            " Ed",
            "na",
            " May",
            "ne",
            " Hull",
            ",",
            " a",
            " fellow",
            " Manit",
            "ob",
            "an",
            ".",
            " ",
            " Hull",
            ",",
            " who",
            " had",
            " previously",
            " worked",
            " as",
            " a",
            " private",
            " secretary",
            ",",
            " went",
            " on",
            " to",
            " act",
            " as",
            " van",
            " Vog",
            "t",
            "'s",
            " typ",
            "ist",
            ",",
            " and",
            " was",
            " credited",
            " with",
            " writing",
            " several",
            " SF",
            " stories",
            " of",
            " her",
            " own",
            " throughout",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " successful",
            ".",
            " An",
            "arch",
            "ists",
            " also",
            " took",
            " part",
            " in",
            " revolutions",
            ".",
            " Many",
            " anarchists",
            ",",
            " especially",
            " the",
            " Gal",
            "lean",
            "ists",
            ",",
            " believed",
            " that",
            " these",
            " attempts",
            " would",
            " be",
            " the",
            " imp",
            "etus",
            " for",
            " a",
            " revolution",
            " against",
            " capitalism",
            " and",
            " the",
            " state",
            ".",
            " Many",
            " of",
            " these",
            " attacks",
            " were",
            " done",
            " by",
            " individual",
            " assail",
            "ants",
            " and",
            " the",
            " majority",
            " took",
            " place",
            " in",
            " the",
            " late",
            " ",
            "187",
            "0",
            "s",
            ",",
            " the",
            " early"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            ".",
            " This",
            " made",
            " the",
            " script",
            " easy",
            " to",
            " learn",
            ",",
            " and",
            " se",
            "af",
            "aring",
            " Ph",
            "oen",
            "ician",
            " merchants",
            " took",
            " the",
            " script",
            " throughout",
            " the",
            " then",
            "-known",
            " world",
            ".",
            "The",
            " Ph",
            "oen",
            "ician",
            " ab",
            "jad",
            " was",
            " a",
            " radical",
            " simpl",
            "ification",
            " of",
            " phon",
            "etic",
            " writing",
            ",",
            " since",
            " hier",
            "og",
            "lyph",
            "ics",
            " required",
            " the",
            " writer",
            " to",
            " pick",
            " a",
            " hier",
            "og",
            "lyph",
            " starting",
            " with",
            " the",
            " same",
            " sound",
            " that",
            " the"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " the",
            " in",
            "num",
            "erable",
            " centers",
            " of",
            " culture",
            "\";",
            " it",
            " is",
            " never",
            " original",
            ".",
            " With",
            " this",
            ",",
            " the",
            " perspective",
            " of",
            " the",
            " author",
            " is",
            " removed",
            " from",
            " the",
            " text",
            ",",
            " and",
            " the",
            " limits",
            " formerly",
            " imposed",
            " by",
            " the",
            " idea",
            " of",
            " one",
            " author",
            "ial",
            " voice",
            ",",
            " one",
            " ultimate",
            " and",
            " universal",
            " meaning",
            ",",
            " are",
            " destroyed",
            ".",
            " The",
            " explanation",
            " and",
            " meaning",
            " of",
            " a",
            " work",
            " does",
            " not",
            " have",
            " to",
            " be",
            " sought"
          ],
          "ha_haiku35_resampled": null
        },
        {
          "tokens_acts_list": [
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0,
            -0.0
          ],
          "train_token_ind": 0,
          "is_repeated_datapoint": false,
          "tokens": [
            " The",
            " country",
            " reached",
            " a",
            " major",
            " achievement",
            " in",
            " its",
            " foreign",
            " policy",
            " by",
            " securing",
            " membership",
            " in",
            " the",
            " North",
            " Atlantic",
            " Treaty",
            " Organization",
            " (",
            "N",
            "ATO",
            ")",
            " in",
            " ",
            "200",
            "9",
            ".",
            " Since",
            " obtaining",
            " candidate",
            " status",
            " in",
            " ",
            "201",
            "4",
            ",",
            " the",
            " country",
            " has",
            " also",
            " embarked",
            " on",
            " a",
            " comprehensive",
            " reform",
            " agenda",
            " to",
            " align",
            " itself",
            " with",
            " European",
            " Union",
            " (",
            "EU",
            ")",
            " accession",
            " standards",
            ",",
            " with",
            " the",
            " objective",
            " of"
          ],
          "ha_haiku35_resampled": null
        }
      ]
    }
  ],
  "top_logits": [
    ".gdx",
    "abaj",
    "ertest",
    "oshi",
    "Leod"
  ],
  "bottom_logits": [
    " Frag",
    " gere",
    " Emer",
    " generation",
    "times"
  ],
  "act_min": -0.0,
  "act_max": 0.785
}